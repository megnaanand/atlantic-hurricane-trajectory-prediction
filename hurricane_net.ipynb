{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYl6itUaG8M",
        "outputId": "9d4a4daf-a712-4db0-daef-d6bb49e3240d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZpPn-6aSjm",
        "outputId": "069cbc54-8c07-4d9f-c188-e2d78e6263c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wksjVxR-cZph",
        "outputId": "5351f9ef-d17a-4baa-8144-3697cf332659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  errors\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wU6pXh5ycf8N",
        "outputId": "159ad9ad-0e97-4787-c45d-34808b8a6428"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "elmYIsXechGh"
      },
      "outputs": [],
      "source": [
        "# Import various libraries throughout the software\n",
        "from pprint import pprint\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from geopy.distance import great_circle as vc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math as Math\n",
        "import datetime\n",
        "import dateutil\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IaLbuPxDdnVL"
      },
      "outputs": [],
      "source": [
        "# data cleaning/processing: (from hurricane-net, hammad)\n",
        "db = []\n",
        "with open('data/hurdat2-1851-2022-050423.txt') as raw: \n",
        "    for line in raw: \n",
        "        line = line.replace(' ', '').split(',')\n",
        "    \n",
        "        # Identify atlantic storm, first 2 letters should be AL\n",
        "        if (line[0][:2] == 'AL') :\n",
        "            storm_id = line[0]\n",
        "            storm_name = line[1]\n",
        "            storm_entries = line[2]\n",
        "\n",
        "            # Iterate and read through best track entries\n",
        "            for i in range(int(storm_entries)) :\n",
        "                entry = raw.readline().replace(' ', '').split(',')\n",
        "                # Filter -999 placeholder for missing central pressure\n",
        "                entry = [None if x == \"-999\" else x for x in entry]\n",
        "                # Construct date and time based on first two columns\n",
        "                timestamp = datetime.datetime(int(entry[0][:4]), int(entry[0][4:6]), int(entry[0][6:8]), int(entry[1][:2]), int(entry[1][3:]))\n",
        "                # Add entry into our current database\n",
        "                db.append([storm_id, storm_name, timestamp] + entry[2:-1])\n",
        "        else :\n",
        "            print(\"Error, unidentified storm \".join(str(line[0])))\n",
        "\n",
        "# Return DataFrame\n",
        "dataset = pd.DataFrame(db, columns = ['storm_id', 'storm_name', 'entry_time', 'entry_id', 'entry_status', 'lat', 'long','max_wind', 'min_pressure', '34kt_ne', '34kt_se', '34kt_sw', '34kt_nw', '50kt_ne', '50kt_se', '50kt_sw', '50kt_nw', '64kt_ne', '64kt_se', '64kt_sw', '64kt_nw'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YVqCzNzDmg0R"
      },
      "outputs": [],
      "source": [
        "models = dict()\n",
        "class model :\n",
        "  '''\n",
        "  PURPOSE: To create a class for each model included in the forecast error database\n",
        "  METHOD: Provide an API\n",
        "  OUTOUT: A class with a DataFrame and associated operations\n",
        "  '''\n",
        "  name = None\n",
        "  # Dictionary key: STMID\n",
        "  storm = dict()\n",
        "  def __init__(self, model_name) :\n",
        "    self.name = model_name\n",
        "    return\n",
        "\n",
        "with open('errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt') as raw :\n",
        "    lines = raw.readlines()\n",
        "    \n",
        "    # Get model names and declare model objects\n",
        "    line = lines[1].split()\n",
        "    model_names = line[2:]\n",
        "    for model_name in model_names :\n",
        "        models[model_name] = model(model_name)\n",
        "    \n",
        "    # Data starts at line 9 \n",
        "    for line in lines[9:] :\n",
        "        line = line.split()\n",
        "        # Identify atlantic storm date, storm id, associated sample sizes, latitude and longitude, and windspeed\n",
        "        timestamp = datetime.datetime.strptime(line[0], \"%d-%m-%Y/%H:%M:%S\")\n",
        "        storm_id = line[1]\n",
        "        sample_sizes = {\"F012\": float(line[2]), \"F024\": float(line[3]),\"F036\": float(line[4]), \"F048\": float(line[5]), \"F072\": float(line[6]), \"F096\": float(line[7]), \"F120\": float(line[8]), \"F144\": float(line[9]), \"F168\": float(line[10])} \n",
        "        latitude = float(line[11])\n",
        "        longitude = float(line[12])\n",
        "        wind_speed = float(line[13])\n",
        "    \n",
        "                \n",
        "        # Iterate through model forecast track and intensity errors \n",
        "        for i in range(len(model_names)) :\n",
        "            intensity_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[14 + (20 * i) : 24 + (20 * i)]])))\n",
        "            track_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[24 + (20 * i) : 34 + (20 * i)]])))\n",
        "        \n",
        "        # Add forecast to model and storm, initialize if storm id does not exist\n",
        "        if storm_id not in models[model_names[i]].storm.keys() :\n",
        "            models[model_names[i]].storm[storm_id] = dict()\n",
        "\n",
        "        models[model_names[i]].storm[storm_id].update({\n",
        "            timestamp : {\n",
        "            \"sample_sizes\" : sample_sizes,\n",
        "            \"lat\" : latitude,\n",
        "            \"long\" : longitude,\n",
        "            \"wind_speed\" : wind_speed,\n",
        "            \"intensity_forecast\" : intensity_forecast,\n",
        "            \"track_forecast\" : track_forecast,\n",
        "            }\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4AXCzkl7Sw",
        "outputId": "3c9cc4de-e841-40c7-aee5-9e997e6f3d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 30, 6, 0): 0.0,\n",
            "                                      datetime.datetime(2005, 8, 30, 18, 0): 20.9,\n",
            "                                      datetime.datetime(2005, 8, 31, 18, 0): 93.6,\n",
            "                                      datetime.datetime(2005, 9, 1, 18, 0): 170.2,\n",
            "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'lat': 0.0,\n",
            "        'long': 26.3,\n",
            "        'sample_sizes': {       'F012': 0.33,\n",
            "                                'F024': 0.33,\n",
            "                                'F036': 0.33,\n",
            "                                'F048': 0.0,\n",
            "                                'F072': 0.0,\n",
            "                                'F096': 0.0,\n",
            "                                'F120': 0.0,\n",
            "                                'F144': 0.0,\n",
            "                                'F168': 0.0},\n",
            "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 18, 0): 0.0,\n",
            "                                  datetime.datetime(2005, 8, 31, 18, 0): 28.0,\n",
            "                                  datetime.datetime(2005, 9, 1, 18, 0): 32.0,\n",
            "                                  datetime.datetime(2005, 9, 2, 18, 0): 17.0,\n",
            "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'wind_speed': 88.6}\n"
          ]
        }
      ],
      "source": [
        "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
        "pprint(models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "6jC4jkJSG7-C",
        "outputId": "f9a526ce-9e01-4c43-96d6-4bccad6191f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
              "44681  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
              "44682  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
              "44683  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
              "44684  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
              "44685  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
              "\n",
              "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
              "44681  75.1W       30         1008       0  ...       0       0       0   \n",
              "44682  75.7W       30         1007       0  ...       0       0       0   \n",
              "44683  76.2W       30         1007       0  ...       0       0       0   \n",
              "44684  76.5W       35         1006      60  ...       0       0       0   \n",
              "44685  76.9W       40         1003      60  ...       0       0       0   \n",
              "\n",
              "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
              "44681       0       0       0       0       0       0       0  \n",
              "44682       0       0       0       0       0       0       0  \n",
              "44683       0       0       0       0       0       0       0  \n",
              "44684       0       0       0       0       0       0       0  \n",
              "44685       0       0       0       0       0       0       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60d0bb79-486b-4433-9acf-017c7e3e5bd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_id</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>34kt_ne</th>\n",
              "      <th>...</th>\n",
              "      <th>34kt_sw</th>\n",
              "      <th>34kt_nw</th>\n",
              "      <th>50kt_ne</th>\n",
              "      <th>50kt_se</th>\n",
              "      <th>50kt_sw</th>\n",
              "      <th>50kt_nw</th>\n",
              "      <th>64kt_ne</th>\n",
              "      <th>64kt_se</th>\n",
              "      <th>64kt_sw</th>\n",
              "      <th>64kt_nw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44681</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-23 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.1N</td>\n",
              "      <td>75.1W</td>\n",
              "      <td>30</td>\n",
              "      <td>1008</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44682</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.4N</td>\n",
              "      <td>75.7W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44683</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.8N</td>\n",
              "      <td>76.2W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44684</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>24.5N</td>\n",
              "      <td>76.5W</td>\n",
              "      <td>35</td>\n",
              "      <td>1006</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44685</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>25.4N</td>\n",
              "      <td>76.9W</td>\n",
              "      <td>40</td>\n",
              "      <td>1003</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60d0bb79-486b-4433-9acf-017c7e3e5bd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60d0bb79-486b-4433-9acf-017c7e3e5bd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60d0bb79-486b-4433-9acf-017c7e3e5bd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
        "dataset.query('storm_id == \"AL122005\"').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1USsREqJHDnG"
      },
      "source": [
        "# Transform Data\n",
        "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a storm_id dictionary to store storm names matched with ID's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Db-7PBHHBR",
        "outputId": "2920b660-fff8-4f1b-ba9d-ed0b9076b2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming HURDAT2 into objects . . .\n",
            "Transforming 53976/53976 entries from HURDAT2\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Create hurricane class\n",
        "class hurricane(object) : \n",
        "    def __init__(self, name, id) :\n",
        "        # Set instance variables\n",
        "        self.name = name\n",
        "        self.id = id\n",
        "        self.entries = dict()\n",
        "        self.models = dict()\n",
        "        \n",
        "        return\n",
        "    # Add hurricane track entry based on standard HURDAT2 format\n",
        "    def add_entry(self, array) :\n",
        "        entry = {\n",
        "            array[0] : { # dateteime of entry\n",
        "                'entry_time' : array[0], \n",
        "                'entry_id' : array[1],\n",
        "                'entry_status' : array[2],\n",
        "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
        "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
        "                'max_wind' : float(array[5]),\n",
        "                'min_pressure' : 980 if array[6] is None else float(array[6]), # Early records are -999 or None\n",
        "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
        "                'distance': 0,\n",
        "                'direction': 0\n",
        "            }\n",
        "        }\n",
        "        self.entries.update(entry)\n",
        "        \n",
        "        return\n",
        "    # Add hurricane model errors\n",
        "    def add_model(self, name, model) :\n",
        "        self.models[name] = model\n",
        "        \n",
        "        return\n",
        "\n",
        "\n",
        "    def update_dist_direc(self):\n",
        "      t = pd.DataFrame(self.entries.values())\n",
        "      dst = 0\n",
        "      prev = (0,0)\n",
        "      \n",
        "      # For all latitude and longitude points of hurricane, calculate the angle of travel and distance\n",
        "      for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "          \n",
        "          if prev == (0,0):\n",
        "              prev = p\n",
        "              continue \n",
        "          # Stores the distance into the DataFrame\n",
        "          list(self.entries.values())[index]['distance'] = vc(prev,p).miles\n",
        "          \n",
        "          dLon = p[1] - prev[1];  \n",
        "          temp = float(p[0]) # p[0] is a str?\n",
        "          y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "          \n",
        "          x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "          brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "          if (brng < 0):\n",
        "              brng+= 360;\n",
        "          \n",
        "          # Stores the angle of travel into the DataFrame\n",
        "          list(self.entries.values())[index]['direction'] = brng\n",
        "          # if self.id == 'AL122005' and index==2:\n",
        "          if self.id == 'AL081994' and index==2:\n",
        "            print(f'p[1]:{p[1]}')\n",
        "            print(f'prev[1]:{prev[1]}')\n",
        "            print(f'dLon:{dLon}')\n",
        "            print(f'temp:{temp}')\n",
        "            print(f'y_x:{y_x}')\n",
        "            print(f'x_x:{x_x}')\n",
        "            print(f'brng:{brng}')\n",
        "          dst += vc(prev,p).miles\n",
        "          prev = p\n",
        "\n",
        "# Storm ID Key for matching between datasets\n",
        "storm_ids = dict()\n",
        "# Parse in hurricanes\n",
        "hurricanes = dict()\n",
        "\n",
        "print(\"Transforming HURDAT2 into objects . . .\")\n",
        "for index, entry in dataset.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset)), end = \"\\r\")\n",
        "    # New hurricane\n",
        "    if entry['storm_id'] not in hurricanes :\n",
        "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxGx5Rg-uN_"
      },
      "source": [
        "# Load Data\n",
        "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPbnSHF8-s9O",
        "outputId": "d3824867-ae44-44b3-e1e9-a4a2a6ac1286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n"
          ]
        }
      ],
      "source": [
        "# Get all available model errors\n",
        "# Load model errors into hurricanes\n",
        "for id in storm_ids :\n",
        "    for model in models :\n",
        "        # Skip if this hurricane does not have the model\n",
        "        if id not in models[model].storm :\n",
        "            continue\n",
        "        hurricanes[id].add_model(model, models[model].storm[id])\n",
        "    hurricanes[id].update_dist_direc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LZL5n_PJCTh1",
        "outputId": "4048330e-908e-4c64-9303-e7a912e378ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction  \n",
              "0    0.000000  \n",
              "1  306.719439  \n",
              "2  259.483425  \n",
              "3  214.647871  \n",
              "4  205.375417  \n",
              "5  220.828574  \n",
              "6  226.705956  \n",
              "7  284.940686  \n",
              "8  332.536353  \n",
              "9  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d6849c0-a022-414d-a237-5a00d36be10a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d6849c0-a022-414d-a237-5a00d36be10a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d6849c0-a022-414d-a237-5a00d36be10a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d6849c0-a022-414d-a237-5a00d36be10a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#will test distance and direction of the bulk update vs individual update\n",
        "t=pd.DataFrame(hurricanes['AL081994'].entries.values())\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z3EhCEBPDa_j"
      },
      "outputs": [],
      "source": [
        "t['dist']=0\n",
        "t['direc']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPUaZqElDiHF",
        "outputId": "f556fa51-56d2-4f46-fcfc-fd7c9341387c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:0,prev:(16.0, 84.5)\n",
            "1 306.71943856277255\n",
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n",
            "2 259.4834249123352\n",
            "3 214.6478709156233\n",
            "4 205.37541693715318\n",
            "5 220.82857383503298\n",
            "6 226.7059563604921\n",
            "7 284.9406861076747\n",
            "8 332.53635339353264\n",
            "9 342.17177270335054\n"
          ]
        }
      ],
      "source": [
        "#testing for one hurricane\n",
        "prev=(0,0)\n",
        "for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "  if prev == (0,0):\n",
        "    prev = p\n",
        "    print(f'index:{index},prev:{prev}')\n",
        "    continue \n",
        "  # Stores the distance into the DataFrame\n",
        "  t.at[index,'dist'] = vc(prev,p).miles\n",
        "\n",
        "  dLon = p[1] - prev[1];  \n",
        "  temp = float(p[0]) # p[0] is a str?\n",
        "  y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "\n",
        "  x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "  brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "  if (brng < 0):\n",
        "    brng+= 360;\n",
        "  t.at[index,'direc'] = brng\n",
        "  if index==2:\n",
        "    print(f'p[1]:{p[1]}')\n",
        "    print(f'prev[1]:{prev[1]}')\n",
        "    print(f'dLon:{dLon}')\n",
        "    print(f'temp:{temp}')\n",
        "    print(f'y_x:{y_x}')\n",
        "    print(f'x_x:{x_x}')\n",
        "    print(f'brng:{brng}')\n",
        "  print(index,t.at[index,'direc'])\n",
        "  prev = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "A-6f67phDjvJ",
        "outputId": "57a2c34f-faf3-4693-dc9a-02bbed99fd0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction       dist       direc  \n",
              "0    0.000000   0.000000    0.000000  \n",
              "1  306.719439  44.891903  306.719439  \n",
              "2  259.483425  54.796781  259.483425  \n",
              "3  214.647871  53.433344  214.647871  \n",
              "4  205.375417  59.976134  205.375417  \n",
              "5  220.828574  53.406014  220.828574  \n",
              "6  226.705956  19.864134  226.705956  \n",
              "7  284.940686  13.242757  284.940686  \n",
              "8  332.536353  21.036343  332.536353  \n",
              "9  342.171773  19.874439  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e48c06c-3e43-4db3-9bf8-f8bf84ec6450\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "      <th>dist</th>\n",
              "      <th>direc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e48c06c-3e43-4db3-9bf8-f8bf84ec6450')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e48c06c-3e43-4db3-9bf8-f8bf84ec6450 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e48c06c-3e43-4db3-9bf8-f8bf84ec6450');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t #to check that distance calculation and direction calculation from bulk vs individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwdLRdvVDrxM",
        "outputId": "9410e27a-2c91-4267-ced2-37a0c7236802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['OFCL', 'BCD5'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "models.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt3z6MwrD23n"
      },
      "source": [
        "# Feature Engineering & Data Augmentation\n",
        "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
        "\n",
        "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
        "1. Date Information\n",
        "2. Zonal Speed Of The Storm (U) (kt)\n",
        "3. Meridional Speed Of The Storm (V) (kt)\n",
        "4. 12-h Change In Intensity (DVMX) (kt)\n",
        "\n",
        "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE9LxW_OD7q8",
        "outputId": "6f480515-0240-4e0b-cdf3-a66f5e4df1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineered 1944/1952 hurricanes for 5 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Scaling Data . . . (1 timestep for unqiue data)\n",
            "Feature engineered 1952/1952 hurricanes for 1 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Done scaling.\n"
          ]
        }
      ],
      "source": [
        "def feature_extraction(timestep, previous) :\n",
        "    '''\n",
        "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
        "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
        "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
        "            previous - previous timestep dictionary of features in the hurricane object format\n",
        "    OUTPUT: Dictionary of features\n",
        "    \n",
        "    timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'entry-time' : datetime\n",
        "    }\n",
        "    '''\n",
        "    features = {\n",
        "        'lat' : timestep['lat'],\n",
        "        'long' : timestep['long'],\n",
        "        'max_wind' : timestep['max_wind'],\n",
        "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'min_pressure' : timestep['min_pressure'], \n",
        "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'year' : timestep['entry_time'].year,\n",
        "        'month' : timestep['entry_time'].month,\n",
        "        'day' : timestep['entry_time'].day,\n",
        "        'hour' : timestep['entry_time'].hour,\n",
        "        'delta_pressure': (timestep['min_pressure'] - previous['min_pressure']) /\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'distance': timestep['distance'],\n",
        "        'direction': timestep['direction']\n",
        "    }\n",
        "    return features\n",
        "    \n",
        "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
        "    '''\n",
        "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
        "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
        "    INPUT:  storm - hurricane object\n",
        "            timesteps - (default = 1) number of timesteps to calculate\n",
        "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
        "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
        "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
        "    '''\n",
        "    x = []\n",
        "    # Create testing data structure with a dictionary\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    y = dict([(time,[]) for time in times])\n",
        "    \n",
        "    # Sort by entry time\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
        "    \n",
        "    for index in range(len(entries)) :\n",
        "        if index < timesteps : # Flag for insufficient initial time steps\n",
        "            continue\n",
        "\n",
        "        # If we're not including None values, check to see if there will be any\n",
        "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
        "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
        "            \n",
        "        # Calculate time steps and their features for independent values\n",
        "        sample = []\n",
        "        for step in range(timesteps) :\n",
        "            # Training sample\n",
        "            timestep = entries[index - step]\n",
        "            previous = entries[index - step - 1]\n",
        "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
        "        x.append(sample) # Add our constructed sample\n",
        "        \n",
        "        # Calculate time steps and their features for dependent values\n",
        "        for future in times :\n",
        "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
        "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
        "            \n",
        "            if timestep and previous: \n",
        "                y[future].append(feature_extraction(timestep, previous))\n",
        "            else :\n",
        "                y[future].append(None)\n",
        "    \n",
        "    # Return output, if there is no output, return None.\n",
        "    if len(x) == 0 :\n",
        "        return None\n",
        "    else:\n",
        "        return {'x': x, 'y': y}\n",
        "def shape(hurricanes, timesteps, remove_missing = True) :\n",
        "    '''\n",
        "    PURPOSE: Shape our data for input into machine learning models\n",
        "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            timesteps - number of timesteps for the shape\n",
        "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
        "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
        "    '''\n",
        "    x = []\n",
        "    y = []\n",
        "    lag = 24 # lag time in hours\n",
        "    precision = np.float64 # defines the precision of our data type\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    count = 0\n",
        "    for hurricane in hurricanes.values() :\n",
        "        count += 1\n",
        "        result = storm_x_y(hurricane, timesteps, lag)\n",
        "        if result is None :\n",
        "            continue\n",
        "        # Extract only the values from the strom features using our specified precision\n",
        "        hurricane_x = np.array(\n",
        "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
        "            dtype = precision)\n",
        "        hurricane_y = np.array(\n",
        "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
        "            dtype = precision)\n",
        "        # Disregard if algorithm requires no missing values\n",
        "        if remove_missing :\n",
        "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
        "                continue\n",
        "        # Add to our results\n",
        "        x.extend(hurricane_x)\n",
        "        y.extend(hurricane_y)\n",
        "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
        "    print(\"\\nDone feature engineering hurricanes.\")\n",
        "    \n",
        "    return {'x': np.array(x), 'y': np.array(y)}\n",
        "def scaler(processed_data, hurricanes) :\n",
        "    '''\n",
        "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
        "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
        "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
        "            2) RobustScaler object fit with appropriate data\n",
        "    '''\n",
        "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
        "    # Create our scaler\n",
        "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
        "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
        "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(x)\n",
        "    \n",
        "    # Scale our data\n",
        "    for index in range(len(processed_data['x'])) :\n",
        "        # Scale our x\n",
        "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
        "        # Scale our y\n",
        "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
        "    print(\"Done scaling.\")\n",
        "    return processed_data, scaler\n",
        "# Finalize and scale procesed data into a dictionary\n",
        "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
        "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NapGhxs0vKF4"
      },
      "source": [
        "# Model Architecture\n",
        "Following feature engineering, we are now ready to input our data into a machine learning algorithm. The scope of this project will attempt a deep learning approach to forecasting Atlantic tropical cyclones. We will experiment with nunermous different architectures but we will focus around a Recurrent Neural Network utilizing LSTM cells.\n",
        "\n",
        "Notes:\n",
        "\n",
        "1.   We will use 500 epochs for wind intensity because the validation loss is not decreasing\n",
        "2.   We will use 1,000 epochs for latitute and longitude"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda, Attention, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.context_vector = self.add_weight(shape=(self.hidden_size,),\n",
        "                                              initializer='random_normal',\n",
        "                                              trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hidden_states, _ = inputs\n",
        "\n",
        "        context_vector = tf.expand_dims(self.context_vector, axis=0)\n",
        "        context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[0], axis=0)\n",
        "\n",
        "        attention_weights = tf.einsum('ijk,ik->ij', hidden_states, context_vector)\n",
        "        attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "\n",
        "        weighted_sum = tf.einsum('ij,ijk->ik', attention_weights, hidden_states)\n",
        "\n",
        "        return weighted_sum\n",
        "\n"
      ],
      "metadata": {
        "id": "1_LGW5zSQpeV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wd7P0bXwvg97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "9eac83a8-f9a8-47e5-885f-dc9879bae6b7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0396cf5ee434>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Create our cross-validation data structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Define the features to train for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'processed_data' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def attention_layer(inputs):\n",
        "    hidden_states, context_vector = inputs\n",
        "    \n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    \n",
        "    # Reshape context vector to perform element-wise multiplication\n",
        "    context_vector = Dense(hidden_size)(context_vector)\n",
        "    context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[1], axis=1)\n",
        "    \n",
        "    # Attention mechanism\n",
        "    attention_weights = tf.keras.layers.Attention()([hidden_states, context_vector])\n",
        "    attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "    \n",
        "    # Weighted sum of hidden states\n",
        "    weighted_sum = tf.reduce_sum(attention_weights * hidden_states, axis=1)\n",
        "    \n",
        "    return weighted_sum\n",
        "\n",
        "def build_model(input_shape, hidden_units, output_dim, dropout_rate=0.05, recurrent_dropout_rate=0.05):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    lstm_output = LSTM(hidden_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)(inputs)\n",
        "    attention_output = AttentionLayer(hidden_units)([lstm_output, lstm_output])\n",
        "    output = Dense(output_dim)(attention_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "def train_model(X_train, X_test, y_train, y_test, output_dim, n_epochs):\n",
        "    input_shape = X_train.shape[1:]\n",
        "    hidden_units = 256\n",
        "\n",
        "    model = build_model(input_shape, hidden_units, output_dim)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Early stopping\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        history = model.fit(X_train, y_train, epochs=1, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
        "        print(\"Loss:\", history.history['loss'][0])\n",
        "        print(\"Validation Loss:\", history.history['val_loss'][0])\n",
        "        print()\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Create our cross-validation data structure\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_data['x'], processed_data['y'], test_size=0.2)\n",
        "\n",
        "# Define the features to train for\n",
        "features = [2, 0, 1, 12, 13]  # Specify the indices of the features to train for\n",
        "\n",
        "# Train multiple models\n",
        "models = []\n",
        "histories = []\n",
        "n_epochs = 500\n",
        "\n",
        "for feature_idx in features:\n",
        "    y_train_feature = np.array([[[features[feature_idx]] for features in y] for y in y_train], dtype=np.float64)\n",
        "    y_test_feature = np.array([[[features[feature_idx]] for features in y] for y in y_test], dtype=np.float64)\n",
        "    \n",
        "    model, history = train_model(X_train, X_test, y_train_feature, y_test_feature, output_dim=1, n_epochs=n_epochs)\n",
        "    \n",
        "    models.append(model)\n",
        "    histories.append(history)\n",
        "\n",
        "# Access the history of each model\n",
        "for i, history in enumerate(histories):\n",
        "    print(f\"History for Model {i+1}\")\n",
        "    print(\"Loss:\", history.history['loss'])\n",
        "    print(\"Validation Loss:\", history.history['val_loss'])\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}