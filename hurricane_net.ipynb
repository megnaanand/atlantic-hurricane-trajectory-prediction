{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FoYl6itUaG8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a619fe39-7d7a-447e-f8f3-67920b3cf043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IKZpPn-6aSjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a9ed1f-be98-4bbf-c9f8-1f4109156884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wksjVxR-cZph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb8d285-9c53-4659-bc1a-157a1bce19dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  errors\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wU6pXh5ycf8N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89c2d616-b2e1-4563-bffe-71991e50b326"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "elmYIsXechGh"
      },
      "outputs": [],
      "source": [
        "# Import various libraries throughout the software\n",
        "from pprint import pprint\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from geopy.distance import great_circle as vc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math as Math\n",
        "import datetime\n",
        "import dateutil\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IaLbuPxDdnVL"
      },
      "outputs": [],
      "source": [
        "# data cleaning/processing: (from hurricane-net, hammad)\n",
        "db = []\n",
        "with open('data/hurdat2-1851-2022-050423.txt') as raw: \n",
        "    for line in raw: \n",
        "        line = line.replace(' ', '').split(',')\n",
        "    \n",
        "        # Identify atlantic storm, first 2 letters should be AL\n",
        "        if (line[0][:2] == 'AL') :\n",
        "            storm_id = line[0]\n",
        "            storm_name = line[1]\n",
        "            storm_entries = line[2]\n",
        "\n",
        "            # Iterate and read through best track entries\n",
        "            for i in range(int(storm_entries)) :\n",
        "                entry = raw.readline().replace(' ', '').split(',')\n",
        "                # Filter -999 placeholder for missing central pressure\n",
        "                entry = [None if x == \"-999\" else x for x in entry]\n",
        "                # Construct date and time based on first two columns\n",
        "                timestamp = datetime.datetime(int(entry[0][:4]), int(entry[0][4:6]), int(entry[0][6:8]), int(entry[1][:2]), int(entry[1][3:]))\n",
        "                # Add entry into our current database\n",
        "                db.append([storm_id, storm_name, timestamp] + entry[2:-1])\n",
        "        else :\n",
        "            print(\"Error, unidentified storm \".join(str(line[0])))\n",
        "\n",
        "# Return DataFrame\n",
        "dataset = pd.DataFrame(db, columns = ['storm_id', 'storm_name', 'entry_time', 'entry_id', 'entry_status', 'lat', 'long','max_wind', 'min_pressure', '34kt_ne', '34kt_se', '34kt_sw', '34kt_nw', '50kt_ne', '50kt_se', '50kt_sw', '50kt_nw', '64kt_ne', '64kt_se', '64kt_sw', '64kt_nw'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YVqCzNzDmg0R"
      },
      "outputs": [],
      "source": [
        "models = dict()\n",
        "class model :\n",
        "  '''\n",
        "  PURPOSE: To create a class for each model included in the forecast error database\n",
        "  METHOD: Provide an API\n",
        "  OUTOUT: A class with a DataFrame and associated operations\n",
        "  '''\n",
        "  name = None\n",
        "  # Dictionary key: STMID\n",
        "  storm = dict()\n",
        "  def __init__(self, model_name) :\n",
        "    self.name = model_name\n",
        "    return\n",
        "\n",
        "with open('errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt') as raw :\n",
        "    lines = raw.readlines()\n",
        "    \n",
        "    # Get model names and declare model objects\n",
        "    line = lines[1].split()\n",
        "    model_names = line[2:]\n",
        "    for model_name in model_names :\n",
        "        models[model_name] = model(model_name)\n",
        "    \n",
        "    # Data starts at line 9 \n",
        "    for line in lines[9:] :\n",
        "        line = line.split()\n",
        "        # Identify atlantic storm date, storm id, associated sample sizes, latitude and longitude, and windspeed\n",
        "        timestamp = datetime.datetime.strptime(line[0], \"%d-%m-%Y/%H:%M:%S\")\n",
        "        storm_id = line[1]\n",
        "        sample_sizes = {\"F012\": float(line[2]), \"F024\": float(line[3]),\"F036\": float(line[4]), \"F048\": float(line[5]), \"F072\": float(line[6]), \"F096\": float(line[7]), \"F120\": float(line[8]), \"F144\": float(line[9]), \"F168\": float(line[10])} \n",
        "        latitude = float(line[11])\n",
        "        longitude = float(line[12])\n",
        "        wind_speed = float(line[13])\n",
        "    \n",
        "                \n",
        "        # Iterate through model forecast track and intensity errors \n",
        "        for i in range(len(model_names)) :\n",
        "            intensity_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[14 + (20 * i) : 24 + (20 * i)]])))\n",
        "            track_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[24 + (20 * i) : 34 + (20 * i)]])))\n",
        "        \n",
        "        # Add forecast to model and storm, initialize if storm id does not exist\n",
        "        if storm_id not in models[model_names[i]].storm.keys() :\n",
        "            models[model_names[i]].storm[storm_id] = dict()\n",
        "\n",
        "        models[model_names[i]].storm[storm_id].update({\n",
        "            timestamp : {\n",
        "            \"sample_sizes\" : sample_sizes,\n",
        "            \"lat\" : latitude,\n",
        "            \"long\" : longitude,\n",
        "            \"wind_speed\" : wind_speed,\n",
        "            \"intensity_forecast\" : intensity_forecast,\n",
        "            \"track_forecast\" : track_forecast,\n",
        "            }\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hG4AXCzkl7Sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a26698-d45a-4110-d577-cbebac26f067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 30, 6, 0): 0.0,\n",
            "                                      datetime.datetime(2005, 8, 30, 18, 0): 20.9,\n",
            "                                      datetime.datetime(2005, 8, 31, 18, 0): 93.6,\n",
            "                                      datetime.datetime(2005, 9, 1, 18, 0): 170.2,\n",
            "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'lat': 0.0,\n",
            "        'long': 26.3,\n",
            "        'sample_sizes': {       'F012': 0.33,\n",
            "                                'F024': 0.33,\n",
            "                                'F036': 0.33,\n",
            "                                'F048': 0.0,\n",
            "                                'F072': 0.0,\n",
            "                                'F096': 0.0,\n",
            "                                'F120': 0.0,\n",
            "                                'F144': 0.0,\n",
            "                                'F168': 0.0},\n",
            "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 18, 0): 0.0,\n",
            "                                  datetime.datetime(2005, 8, 31, 18, 0): 28.0,\n",
            "                                  datetime.datetime(2005, 9, 1, 18, 0): 32.0,\n",
            "                                  datetime.datetime(2005, 9, 2, 18, 0): 17.0,\n",
            "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'wind_speed': 88.6}\n"
          ]
        }
      ],
      "source": [
        "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
        "pprint(models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6jC4jkJSG7-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d8fa08f6-949b-4e0b-9ab7-6985c77414c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
              "44681  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
              "44682  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
              "44683  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
              "44684  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
              "44685  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
              "\n",
              "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
              "44681  75.1W       30         1008       0  ...       0       0       0   \n",
              "44682  75.7W       30         1007       0  ...       0       0       0   \n",
              "44683  76.2W       30         1007       0  ...       0       0       0   \n",
              "44684  76.5W       35         1006      60  ...       0       0       0   \n",
              "44685  76.9W       40         1003      60  ...       0       0       0   \n",
              "\n",
              "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
              "44681       0       0       0       0       0       0       0  \n",
              "44682       0       0       0       0       0       0       0  \n",
              "44683       0       0       0       0       0       0       0  \n",
              "44684       0       0       0       0       0       0       0  \n",
              "44685       0       0       0       0       0       0       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_id</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>34kt_ne</th>\n",
              "      <th>...</th>\n",
              "      <th>34kt_sw</th>\n",
              "      <th>34kt_nw</th>\n",
              "      <th>50kt_ne</th>\n",
              "      <th>50kt_se</th>\n",
              "      <th>50kt_sw</th>\n",
              "      <th>50kt_nw</th>\n",
              "      <th>64kt_ne</th>\n",
              "      <th>64kt_se</th>\n",
              "      <th>64kt_sw</th>\n",
              "      <th>64kt_nw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44681</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-23 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.1N</td>\n",
              "      <td>75.1W</td>\n",
              "      <td>30</td>\n",
              "      <td>1008</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44682</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.4N</td>\n",
              "      <td>75.7W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44683</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.8N</td>\n",
              "      <td>76.2W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44684</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>24.5N</td>\n",
              "      <td>76.5W</td>\n",
              "      <td>35</td>\n",
              "      <td>1006</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44685</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>25.4N</td>\n",
              "      <td>76.9W</td>\n",
              "      <td>40</td>\n",
              "      <td>1003</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
        "dataset.query('storm_id == \"AL122005\"').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1USsREqJHDnG"
      },
      "source": [
        "# Transform Data\n",
        "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a storm_id dictionary to store storm names matched with ID's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o_Db-7PBHHBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd866b54-4b2e-4237-d2dd-bbba48efba4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming HURDAT2 into objects . . .\n",
            "Transforming 53976/53976 entries from HURDAT2\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Create hurricane class\n",
        "class hurricane(object) : \n",
        "    def __init__(self, name, id) :\n",
        "        # Set instance variables\n",
        "        self.name = name\n",
        "        self.id = id\n",
        "        self.entries = dict()\n",
        "        self.models = dict()\n",
        "        \n",
        "        return\n",
        "    # Add hurricane track entry based on standard HURDAT2 format\n",
        "    def add_entry(self, array) :\n",
        "        entry = {\n",
        "            array[0] : { # dateteime of entry\n",
        "                'entry_time' : array[0], \n",
        "                'entry_id' : array[1],\n",
        "                'entry_status' : array[2],\n",
        "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
        "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
        "                'max_wind' : float(array[5]),\n",
        "                'min_pressure' : 980 if array[6] is None else float(array[6]), # Early records are -999 or None\n",
        "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
        "                'distance': 0,\n",
        "                'direction': 0\n",
        "            }\n",
        "        }\n",
        "        self.entries.update(entry)\n",
        "        \n",
        "        return\n",
        "    # Add hurricane model errors\n",
        "    def add_model(self, name, model) :\n",
        "        self.models[name] = model\n",
        "        \n",
        "        return\n",
        "\n",
        "\n",
        "    def update_dist_direc(self):\n",
        "      t = pd.DataFrame(self.entries.values())\n",
        "      dst = 0\n",
        "      prev = (0,0)\n",
        "      \n",
        "      # For all latitude and longitude points of hurricane, calculate the angle of travel and distance\n",
        "      for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "          \n",
        "          if prev == (0,0):\n",
        "              prev = p\n",
        "              continue \n",
        "          # Stores the distance into the DataFrame\n",
        "          list(self.entries.values())[index]['distance'] = vc(prev,p).miles\n",
        "          \n",
        "          dLon = p[1] - prev[1];  \n",
        "          temp = float(p[0]) # p[0] is a str?\n",
        "          y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "          \n",
        "          x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "          brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "          if (brng < 0):\n",
        "              brng+= 360;\n",
        "          \n",
        "          # Stores the angle of travel into the DataFrame\n",
        "          list(self.entries.values())[index]['direction'] = brng\n",
        "          # if self.id == 'AL122005' and index==2:\n",
        "          if self.id == 'AL081994' and index==2:\n",
        "            print(f'p[1]:{p[1]}')\n",
        "            print(f'prev[1]:{prev[1]}')\n",
        "            print(f'dLon:{dLon}')\n",
        "            print(f'temp:{temp}')\n",
        "            print(f'y_x:{y_x}')\n",
        "            print(f'x_x:{x_x}')\n",
        "            print(f'brng:{brng}')\n",
        "          dst += vc(prev,p).miles\n",
        "          prev = p\n",
        "\n",
        "# Storm ID Key for matching between datasets\n",
        "storm_ids = dict()\n",
        "# Parse in hurricanes\n",
        "hurricanes = dict()\n",
        "\n",
        "print(\"Transforming HURDAT2 into objects . . .\")\n",
        "for index, entry in dataset.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset)), end = \"\\r\")\n",
        "    # New hurricane\n",
        "    if entry['storm_id'] not in hurricanes :\n",
        "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxGx5Rg-uN_"
      },
      "source": [
        "# Load Data\n",
        "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lPbnSHF8-s9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23c6148-8307-4991-b403-bcc7042fe2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n"
          ]
        }
      ],
      "source": [
        "# Get all available model errors\n",
        "# Load model errors into hurricanes\n",
        "for id in storm_ids :\n",
        "    for model in models :\n",
        "        # Skip if this hurricane does not have the model\n",
        "        if id not in models[model].storm :\n",
        "            continue\n",
        "        hurricanes[id].add_model(model, models[model].storm[id])\n",
        "    hurricanes[id].update_dist_direc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LZL5n_PJCTh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "3a55b651-816d-489f-caf5-5c99cfe14d7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction  \n",
              "0    0.000000  \n",
              "1  306.719439  \n",
              "2  259.483425  \n",
              "3  214.647871  \n",
              "4  205.375417  \n",
              "5  220.828574  \n",
              "6  226.705956  \n",
              "7  284.940686  \n",
              "8  332.536353  \n",
              "9  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdab8448-71f3-4f8c-a851-d1f4fc875833\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdab8448-71f3-4f8c-a851-d1f4fc875833')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdab8448-71f3-4f8c-a851-d1f4fc875833 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdab8448-71f3-4f8c-a851-d1f4fc875833');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#will test distance and direction of the bulk update vs individual update\n",
        "t=pd.DataFrame(hurricanes['AL081994'].entries.values())\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z3EhCEBPDa_j"
      },
      "outputs": [],
      "source": [
        "t['dist']=0\n",
        "t['direc']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uPUaZqElDiHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0c6a07-38b4-411b-f129-c7c7852bc484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:0,prev:(16.0, 84.5)\n",
            "1 306.71943856277255\n",
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n",
            "2 259.4834249123352\n",
            "3 214.6478709156233\n",
            "4 205.37541693715318\n",
            "5 220.82857383503298\n",
            "6 226.7059563604921\n",
            "7 284.9406861076747\n",
            "8 332.53635339353264\n",
            "9 342.17177270335054\n"
          ]
        }
      ],
      "source": [
        "#testing for one hurricane\n",
        "prev=(0,0)\n",
        "for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "  if prev == (0,0):\n",
        "    prev = p\n",
        "    print(f'index:{index},prev:{prev}')\n",
        "    continue \n",
        "  # Stores the distance into the DataFrame\n",
        "  t.at[index,'dist'] = vc(prev,p).miles\n",
        "\n",
        "  dLon = p[1] - prev[1];  \n",
        "  temp = float(p[0]) # p[0] is a str?\n",
        "  y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "\n",
        "  x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "  brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "  if (brng < 0):\n",
        "    brng+= 360;\n",
        "  t.at[index,'direc'] = brng\n",
        "  if index==2:\n",
        "    print(f'p[1]:{p[1]}')\n",
        "    print(f'prev[1]:{prev[1]}')\n",
        "    print(f'dLon:{dLon}')\n",
        "    print(f'temp:{temp}')\n",
        "    print(f'y_x:{y_x}')\n",
        "    print(f'x_x:{x_x}')\n",
        "    print(f'brng:{brng}')\n",
        "  print(index,t.at[index,'direc'])\n",
        "  prev = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A-6f67phDjvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64290a44-b16e-46c7-c03f-2f462a6ef827"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction       dist       direc  \n",
              "0    0.000000   0.000000    0.000000  \n",
              "1  306.719439  44.891903  306.719439  \n",
              "2  259.483425  54.796781  259.483425  \n",
              "3  214.647871  53.433344  214.647871  \n",
              "4  205.375417  59.976134  205.375417  \n",
              "5  220.828574  53.406014  220.828574  \n",
              "6  226.705956  19.864134  226.705956  \n",
              "7  284.940686  13.242757  284.940686  \n",
              "8  332.536353  21.036343  332.536353  \n",
              "9  342.171773  19.874439  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "      <th>dist</th>\n",
              "      <th>direc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t #to check that distance calculation and direction calculation from bulk vs individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PwdLRdvVDrxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b0decf-e9f8-46bd-99d0-2563d291d5c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['OFCL', 'BCD5'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "models.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt3z6MwrD23n"
      },
      "source": [
        "# Feature Engineering & Data Augmentation\n",
        "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
        "\n",
        "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
        "1. Date Information\n",
        "2. Zonal Speed Of The Storm (U) (kt)\n",
        "3. Meridional Speed Of The Storm (V) (kt)\n",
        "4. 12-h Change In Intensity (DVMX) (kt)\n",
        "\n",
        "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LE9LxW_OD7q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5e60a4-d6cd-460a-b49a-22ea65655d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineered 1944/1952 hurricanes for 5 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Scaling Data . . . (1 timestep for unqiue data)\n",
            "Feature engineered 1952/1952 hurricanes for 1 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Done scaling.\n"
          ]
        }
      ],
      "source": [
        "def feature_extraction(timestep, previous) :\n",
        "    '''\n",
        "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
        "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
        "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
        "            previous - previous timestep dictionary of features in the hurricane object format\n",
        "    OUTPUT: Dictionary of features\n",
        "    \n",
        "    timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'entry-time' : datetime\n",
        "    }\n",
        "    '''\n",
        "    features = {\n",
        "        'lat' : timestep['lat'],\n",
        "        'long' : timestep['long'],\n",
        "        'max_wind' : timestep['max_wind'],\n",
        "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'min_pressure' : timestep['min_pressure'], \n",
        "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'year' : timestep['entry_time'].year,\n",
        "        'month' : timestep['entry_time'].month,\n",
        "        'day' : timestep['entry_time'].day,\n",
        "        'hour' : timestep['entry_time'].hour,\n",
        "        'delta_pressure': (timestep['min_pressure'] - previous['min_pressure']) /\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'distance': timestep['distance'],\n",
        "        'direction': timestep['direction']\n",
        "    }\n",
        "    return features\n",
        "    \n",
        "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
        "    '''\n",
        "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
        "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
        "    INPUT:  storm - hurricane object\n",
        "            timesteps - (default = 1) number of timesteps to calculate\n",
        "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
        "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
        "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
        "    '''\n",
        "    x = []\n",
        "    # Create testing data structure with a dictionary\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    y = dict([(time,[]) for time in times])\n",
        "    \n",
        "    # Sort by entry time\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
        "    \n",
        "    for index in range(len(entries)) :\n",
        "        if index < timesteps : # Flag for insufficient initial time steps\n",
        "            continue\n",
        "\n",
        "        # If we're not including None values, check to see if there will be any\n",
        "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
        "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
        "            \n",
        "        # Calculate time steps and their features for independent values\n",
        "        sample = []\n",
        "        for step in range(timesteps) :\n",
        "            # Training sample\n",
        "            timestep = entries[index - step]\n",
        "            previous = entries[index - step - 1]\n",
        "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
        "        x.append(sample) # Add our constructed sample\n",
        "        \n",
        "        # Calculate time steps and their features for dependent values\n",
        "        for future in times :\n",
        "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
        "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
        "            \n",
        "            if timestep and previous: \n",
        "                y[future].append(feature_extraction(timestep, previous))\n",
        "            else :\n",
        "                y[future].append(None)\n",
        "    \n",
        "    # Return output, if there is no output, return None.\n",
        "    if len(x) == 0 :\n",
        "        return None\n",
        "    else:\n",
        "        return {'x': x, 'y': y}\n",
        "def shape(hurricanes, timesteps, remove_missing = True) :\n",
        "    '''\n",
        "    PURPOSE: Shape our data for input into machine learning models\n",
        "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            timesteps - number of timesteps for the shape\n",
        "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
        "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
        "    '''\n",
        "    x = []\n",
        "    y = []\n",
        "    lag = 24 # lag time in hours\n",
        "    precision = np.float64 # defines the precision of our data type\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    count = 0\n",
        "    for hurricane in hurricanes.values() :\n",
        "        count += 1\n",
        "        result = storm_x_y(hurricane, timesteps, lag)\n",
        "        if result is None :\n",
        "            continue\n",
        "        # Extract only the values from the strom features using our specified precision\n",
        "        hurricane_x = np.array(\n",
        "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
        "            dtype = precision)\n",
        "        hurricane_y = np.array(\n",
        "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
        "            dtype = precision)\n",
        "        # Disregard if algorithm requires no missing values\n",
        "        if remove_missing :\n",
        "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
        "                continue\n",
        "        # Add to our results\n",
        "        x.extend(hurricane_x)\n",
        "        y.extend(hurricane_y)\n",
        "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
        "    print(\"\\nDone feature engineering hurricanes.\")\n",
        "    \n",
        "    return {'x': np.array(x), 'y': np.array(y)}\n",
        "def scaler(processed_data, hurricanes) :\n",
        "    '''\n",
        "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
        "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
        "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
        "            2) RobustScaler object fit with appropriate data\n",
        "    '''\n",
        "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
        "    # Create our scaler\n",
        "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
        "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
        "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(x)\n",
        "    \n",
        "    # Scale our data\n",
        "    for index in range(len(processed_data['x'])) :\n",
        "        # Scale our x\n",
        "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
        "        # Scale our y\n",
        "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
        "    print(\"Done scaling.\")\n",
        "    return processed_data, scaler\n",
        "# Finalize and scale procesed data into a dictionary\n",
        "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
        "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NapGhxs0vKF4"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda, Attention, Layer, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.context_vector = self.add_weight(shape=(self.hidden_size,),\n",
        "                                              initializer='random_normal',\n",
        "                                              trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hidden_states, _ = inputs\n",
        "\n",
        "        context_vector = tf.expand_dims(self.context_vector, axis=0)\n",
        "        context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[0], axis=0)\n",
        "\n",
        "        attention_weights = tf.einsum('ijk,ik->ij', hidden_states, context_vector)\n",
        "        attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "\n",
        "        weighted_sum = tf.einsum('ij,ijk->ik', attention_weights, hidden_states)\n",
        "\n",
        "        return weighted_sum"
      ],
      "metadata": {
        "id": "1_LGW5zSQpeV"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Wd7P0bXwvg97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0e1a2f-0a7f-4ae1-e39a-24b5e47a0312"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_18 (LSTM)                 (None, 5, 128)       73216       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " attention_layer_21 (AttentionL  (None, 128)         128         ['lstm_18[0][0]',                \n",
            " ayer)                                                            'lstm_18[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 128)       0           ['attention_layer_21[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDistri  (None, 1, 1)        129         ['reshape_4[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.4366 - val_loss: 0.3164\n",
            "Loss: 0.43659764528274536\n",
            "Validation Loss: 0.31638509035110474\n",
            "\n",
            "Epoch 2/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.3333 - val_loss: 0.3072\n",
            "Loss: 0.3333064019680023\n",
            "Validation Loss: 0.30719253420829773\n",
            "\n",
            "Epoch 3/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.3180 - val_loss: 0.2996\n",
            "Loss: 0.3179780840873718\n",
            "Validation Loss: 0.29955488443374634\n",
            "\n",
            "Epoch 4/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.3131 - val_loss: 0.2961\n",
            "Loss: 0.3131020963191986\n",
            "Validation Loss: 0.2961391806602478\n",
            "\n",
            "Epoch 5/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.3098 - val_loss: 0.2925\n",
            "Loss: 0.3098403215408325\n",
            "Validation Loss: 0.29245173931121826\n",
            "\n",
            "Epoch 6/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.3052 - val_loss: 0.2901\n",
            "Loss: 0.30517736077308655\n",
            "Validation Loss: 0.29005345702171326\n",
            "\n",
            "Epoch 7/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.3000 - val_loss: 0.2869\n",
            "Loss: 0.2999842166900635\n",
            "Validation Loss: 0.2869071066379547\n",
            "\n",
            "Epoch 8/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2983 - val_loss: 0.2854\n",
            "Loss: 0.2982657849788666\n",
            "Validation Loss: 0.28539901971817017\n",
            "\n",
            "Epoch 9/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2975 - val_loss: 0.2837\n",
            "Loss: 0.2975063621997833\n",
            "Validation Loss: 0.2836698293685913\n",
            "\n",
            "Epoch 10/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2935 - val_loss: 0.2821\n",
            "Loss: 0.293536514043808\n",
            "Validation Loss: 0.2820701599121094\n",
            "\n",
            "Epoch 11/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2937 - val_loss: 0.2841\n",
            "Loss: 0.29367440938949585\n",
            "Validation Loss: 0.28409257531166077\n",
            "\n",
            "Epoch 12/750\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2919 - val_loss: 0.2813\n",
            "Loss: 0.29185983538627625\n",
            "Validation Loss: 0.28126347064971924\n",
            "\n",
            "Epoch 13/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2890 - val_loss: 0.2791\n",
            "Loss: 0.2889667749404907\n",
            "Validation Loss: 0.2790662348270416\n",
            "\n",
            "Epoch 14/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2859 - val_loss: 0.2784\n",
            "Loss: 0.2859257757663727\n",
            "Validation Loss: 0.27838000655174255\n",
            "\n",
            "Epoch 15/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2871 - val_loss: 0.2766\n",
            "Loss: 0.2870987355709076\n",
            "Validation Loss: 0.27657654881477356\n",
            "\n",
            "Epoch 16/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2855 - val_loss: 0.2766\n",
            "Loss: 0.28546562790870667\n",
            "Validation Loss: 0.27664241194725037\n",
            "\n",
            "Epoch 17/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2826 - val_loss: 0.2754\n",
            "Loss: 0.2825608253479004\n",
            "Validation Loss: 0.27544575929641724\n",
            "\n",
            "Epoch 18/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2827 - val_loss: 0.2746\n",
            "Loss: 0.2827320694923401\n",
            "Validation Loss: 0.2745985984802246\n",
            "\n",
            "Epoch 19/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2817 - val_loss: 0.2746\n",
            "Loss: 0.28165027499198914\n",
            "Validation Loss: 0.2745981514453888\n",
            "\n",
            "Epoch 20/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2819 - val_loss: 0.2714\n",
            "Loss: 0.28190547227859497\n",
            "Validation Loss: 0.2713826596736908\n",
            "\n",
            "Epoch 21/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2782 - val_loss: 0.2705\n",
            "Loss: 0.27816689014434814\n",
            "Validation Loss: 0.270452082157135\n",
            "\n",
            "Epoch 22/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2772 - val_loss: 0.2713\n",
            "Loss: 0.2772296071052551\n",
            "Validation Loss: 0.27130722999572754\n",
            "\n",
            "Epoch 23/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2756 - val_loss: 0.2696\n",
            "Loss: 0.2756475508213043\n",
            "Validation Loss: 0.269596666097641\n",
            "\n",
            "Epoch 24/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2740 - val_loss: 0.2675\n",
            "Loss: 0.27400121092796326\n",
            "Validation Loss: 0.26754921674728394\n",
            "\n",
            "Epoch 25/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2752 - val_loss: 0.2676\n",
            "Loss: 0.27521100640296936\n",
            "Validation Loss: 0.2676165997982025\n",
            "\n",
            "Epoch 26/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2760 - val_loss: 0.2721\n",
            "Loss: 0.2759614586830139\n",
            "Validation Loss: 0.2721039950847626\n",
            "\n",
            "Epoch 27/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2731 - val_loss: 0.2674\n",
            "Loss: 0.2730567753314972\n",
            "Validation Loss: 0.2673753499984741\n",
            "\n",
            "Epoch 28/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2705 - val_loss: 0.2665\n",
            "Loss: 0.2704894244670868\n",
            "Validation Loss: 0.266507625579834\n",
            "\n",
            "Epoch 29/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2710 - val_loss: 0.2651\n",
            "Loss: 0.2709781527519226\n",
            "Validation Loss: 0.26514551043510437\n",
            "\n",
            "Epoch 30/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2725 - val_loss: 0.2637\n",
            "Loss: 0.2725224196910858\n",
            "Validation Loss: 0.26373523473739624\n",
            "\n",
            "Epoch 31/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2718 - val_loss: 0.2676\n",
            "Loss: 0.27183055877685547\n",
            "Validation Loss: 0.2676178514957428\n",
            "\n",
            "Epoch 32/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2683 - val_loss: 0.2637\n",
            "Loss: 0.26830846071243286\n",
            "Validation Loss: 0.26371800899505615\n",
            "\n",
            "Epoch 33/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2697 - val_loss: 0.2620\n",
            "Loss: 0.26966843008995056\n",
            "Validation Loss: 0.2619852125644684\n",
            "\n",
            "Epoch 34/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2647 - val_loss: 0.2607\n",
            "Loss: 0.26470106840133667\n",
            "Validation Loss: 0.2606912851333618\n",
            "\n",
            "Epoch 35/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2673 - val_loss: 0.2601\n",
            "Loss: 0.26732519268989563\n",
            "Validation Loss: 0.26005223393440247\n",
            "\n",
            "Epoch 36/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2661 - val_loss: 0.2623\n",
            "Loss: 0.26608794927597046\n",
            "Validation Loss: 0.262314110994339\n",
            "\n",
            "Epoch 37/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2652 - val_loss: 0.2619\n",
            "Loss: 0.26520973443984985\n",
            "Validation Loss: 0.26190370321273804\n",
            "\n",
            "Epoch 38/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2663 - val_loss: 0.2625\n",
            "Loss: 0.26625004410743713\n",
            "Validation Loss: 0.2625366747379303\n",
            "\n",
            "Epoch 39/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2648 - val_loss: 0.2594\n",
            "Loss: 0.26477691531181335\n",
            "Validation Loss: 0.2594459652900696\n",
            "\n",
            "Epoch 40/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2652 - val_loss: 0.2632\n",
            "Loss: 0.26524674892425537\n",
            "Validation Loss: 0.26320308446884155\n",
            "\n",
            "Epoch 41/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2622 - val_loss: 0.2578\n",
            "Loss: 0.26222100853919983\n",
            "Validation Loss: 0.25775426626205444\n",
            "\n",
            "Epoch 42/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2617 - val_loss: 0.2574\n",
            "Loss: 0.26170724630355835\n",
            "Validation Loss: 0.25743454694747925\n",
            "\n",
            "Epoch 43/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2611 - val_loss: 0.2594\n",
            "Loss: 0.26114028692245483\n",
            "Validation Loss: 0.25944381952285767\n",
            "\n",
            "Epoch 44/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2621 - val_loss: 0.2558\n",
            "Loss: 0.2620888352394104\n",
            "Validation Loss: 0.25578367710113525\n",
            "\n",
            "Epoch 45/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2605 - val_loss: 0.2567\n",
            "Loss: 0.26048997044563293\n",
            "Validation Loss: 0.25666502118110657\n",
            "\n",
            "Epoch 46/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2592 - val_loss: 0.2580\n",
            "Loss: 0.25921282172203064\n",
            "Validation Loss: 0.25801944732666016\n",
            "\n",
            "Epoch 47/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2584 - val_loss: 0.2552\n",
            "Loss: 0.2584451138973236\n",
            "Validation Loss: 0.25519582629203796\n",
            "\n",
            "Epoch 48/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2579 - val_loss: 0.2540\n",
            "Loss: 0.2578945755958557\n",
            "Validation Loss: 0.254018634557724\n",
            "\n",
            "Epoch 49/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2565 - val_loss: 0.2516\n",
            "Loss: 0.2565056383609772\n",
            "Validation Loss: 0.2515600621700287\n",
            "\n",
            "Epoch 50/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2554 - val_loss: 0.2544\n",
            "Loss: 0.25537002086639404\n",
            "Validation Loss: 0.2543913722038269\n",
            "\n",
            "Epoch 51/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2554 - val_loss: 0.2543\n",
            "Loss: 0.25542929768562317\n",
            "Validation Loss: 0.2542995810508728\n",
            "\n",
            "Epoch 52/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2550 - val_loss: 0.2543\n",
            "Loss: 0.25501778721809387\n",
            "Validation Loss: 0.25432446599006653\n",
            "\n",
            "Epoch 53/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2541 - val_loss: 0.2522\n",
            "Loss: 0.2540723979473114\n",
            "Validation Loss: 0.25220561027526855\n",
            "\n",
            "Epoch 54/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2524 - val_loss: 0.2530\n",
            "Loss: 0.25237271189689636\n",
            "Validation Loss: 0.25301593542099\n",
            "\n",
            "Epoch 55/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2537 - val_loss: 0.2516\n",
            "Loss: 0.2536630630493164\n",
            "Validation Loss: 0.2515619397163391\n",
            "\n",
            "Epoch 56/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2514 - val_loss: 0.2520\n",
            "Loss: 0.25137460231781006\n",
            "Validation Loss: 0.25198355317115784\n",
            "\n",
            "Epoch 57/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2514 - val_loss: 0.2496\n",
            "Loss: 0.25141987204551697\n",
            "Validation Loss: 0.2496437281370163\n",
            "\n",
            "Epoch 58/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2505 - val_loss: 0.2493\n",
            "Loss: 0.25052785873413086\n",
            "Validation Loss: 0.24930302798748016\n",
            "\n",
            "Epoch 59/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2498 - val_loss: 0.2469\n",
            "Loss: 0.24979986250400543\n",
            "Validation Loss: 0.2469422072172165\n",
            "\n",
            "Epoch 60/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2503 - val_loss: 0.2482\n",
            "Loss: 0.25027748942375183\n",
            "Validation Loss: 0.2482466697692871\n",
            "\n",
            "Epoch 61/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2487 - val_loss: 0.2484\n",
            "Loss: 0.24868734180927277\n",
            "Validation Loss: 0.2484091967344284\n",
            "\n",
            "Epoch 62/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2488 - val_loss: 0.2496\n",
            "Loss: 0.24878886342048645\n",
            "Validation Loss: 0.24958404898643494\n",
            "\n",
            "Epoch 63/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2453 - val_loss: 0.2489\n",
            "Loss: 0.24527481198310852\n",
            "Validation Loss: 0.24886444211006165\n",
            "\n",
            "Epoch 64/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2441 - val_loss: 0.2450\n",
            "Loss: 0.24405401945114136\n",
            "Validation Loss: 0.24498820304870605\n",
            "\n",
            "Epoch 65/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2445 - val_loss: 0.2481\n",
            "Loss: 0.2444535344839096\n",
            "Validation Loss: 0.248139426112175\n",
            "\n",
            "Epoch 66/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2455 - val_loss: 0.2456\n",
            "Loss: 0.24547013640403748\n",
            "Validation Loss: 0.24558331072330475\n",
            "\n",
            "Epoch 67/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2445 - val_loss: 0.2471\n",
            "Loss: 0.24447296559810638\n",
            "Validation Loss: 0.2470555156469345\n",
            "\n",
            "Epoch 68/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2437 - val_loss: 0.2435\n",
            "Loss: 0.24372054636478424\n",
            "Validation Loss: 0.243473619222641\n",
            "\n",
            "Epoch 69/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2442 - val_loss: 0.2430\n",
            "Loss: 0.24417026340961456\n",
            "Validation Loss: 0.24298638105392456\n",
            "\n",
            "Epoch 70/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2436 - val_loss: 0.2432\n",
            "Loss: 0.2436327487230301\n",
            "Validation Loss: 0.24323005974292755\n",
            "\n",
            "Epoch 71/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2424 - val_loss: 0.2466\n",
            "Loss: 0.242435023188591\n",
            "Validation Loss: 0.24664564430713654\n",
            "\n",
            "Epoch 72/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2414 - val_loss: 0.2431\n",
            "Loss: 0.24142226576805115\n",
            "Validation Loss: 0.24308077991008759\n",
            "\n",
            "Epoch 73/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2415 - val_loss: 0.2429\n",
            "Loss: 0.24146436154842377\n",
            "Validation Loss: 0.24294136464595795\n",
            "\n",
            "Epoch 74/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2405 - val_loss: 0.2414\n",
            "Loss: 0.24048002064228058\n",
            "Validation Loss: 0.24139787256717682\n",
            "\n",
            "Epoch 75/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2400 - val_loss: 0.2383\n",
            "Loss: 0.2399643063545227\n",
            "Validation Loss: 0.23831814527511597\n",
            "\n",
            "Epoch 76/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2389 - val_loss: 0.2409\n",
            "Loss: 0.23894934356212616\n",
            "Validation Loss: 0.2409428507089615\n",
            "\n",
            "Epoch 77/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2388 - val_loss: 0.2390\n",
            "Loss: 0.23881947994232178\n",
            "Validation Loss: 0.23897404968738556\n",
            "\n",
            "Epoch 78/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2368 - val_loss: 0.2399\n",
            "Loss: 0.23675477504730225\n",
            "Validation Loss: 0.23986555635929108\n",
            "\n",
            "Epoch 79/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2380 - val_loss: 0.2373\n",
            "Loss: 0.23801307380199432\n",
            "Validation Loss: 0.23730894923210144\n",
            "\n",
            "Epoch 80/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2357 - val_loss: 0.2403\n",
            "Loss: 0.2357032150030136\n",
            "Validation Loss: 0.24030661582946777\n",
            "\n",
            "Epoch 81/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2366 - val_loss: 0.2451\n",
            "Loss: 0.23657159507274628\n",
            "Validation Loss: 0.24513131380081177\n",
            "\n",
            "Epoch 82/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2382 - val_loss: 0.2417\n",
            "Loss: 0.23817597329616547\n",
            "Validation Loss: 0.2417295128107071\n",
            "\n",
            "Epoch 83/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2371 - val_loss: 0.2411\n",
            "Loss: 0.23708786070346832\n",
            "Validation Loss: 0.24110276997089386\n",
            "\n",
            "Epoch 84/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2364 - val_loss: 0.2362\n",
            "Loss: 0.23637408018112183\n",
            "Validation Loss: 0.236180379986763\n",
            "\n",
            "Epoch 85/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2329 - val_loss: 0.2367\n",
            "Loss: 0.23290640115737915\n",
            "Validation Loss: 0.23669251799583435\n",
            "\n",
            "Epoch 86/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2340 - val_loss: 0.2328\n",
            "Loss: 0.23398950695991516\n",
            "Validation Loss: 0.2327895164489746\n",
            "\n",
            "Epoch 87/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2334 - val_loss: 0.2339\n",
            "Loss: 0.2334311455488205\n",
            "Validation Loss: 0.23387998342514038\n",
            "\n",
            "Epoch 88/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2332 - val_loss: 0.2345\n",
            "Loss: 0.23323887586593628\n",
            "Validation Loss: 0.2345050722360611\n",
            "\n",
            "Epoch 89/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2314 - val_loss: 0.2335\n",
            "Loss: 0.2314406782388687\n",
            "Validation Loss: 0.23353838920593262\n",
            "\n",
            "Epoch 90/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2316 - val_loss: 0.2356\n",
            "Loss: 0.23164308071136475\n",
            "Validation Loss: 0.23563122749328613\n",
            "\n",
            "Epoch 91/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2320 - val_loss: 0.2323\n",
            "Loss: 0.232046440243721\n",
            "Validation Loss: 0.2323342114686966\n",
            "\n",
            "Epoch 92/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2290 - val_loss: 0.2330\n",
            "Loss: 0.2290019541978836\n",
            "Validation Loss: 0.23296312987804413\n",
            "\n",
            "Epoch 93/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2312 - val_loss: 0.2362\n",
            "Loss: 0.2312338799238205\n",
            "Validation Loss: 0.2362302839756012\n",
            "\n",
            "Epoch 94/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2309 - val_loss: 0.2303\n",
            "Loss: 0.23094792664051056\n",
            "Validation Loss: 0.2303253412246704\n",
            "\n",
            "Epoch 95/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2318 - val_loss: 0.2278\n",
            "Loss: 0.23175525665283203\n",
            "Validation Loss: 0.22780726850032806\n",
            "\n",
            "Epoch 96/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2299 - val_loss: 0.2318\n",
            "Loss: 0.22993405163288116\n",
            "Validation Loss: 0.23183508217334747\n",
            "\n",
            "Epoch 97/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2298 - val_loss: 0.2314\n",
            "Loss: 0.2298378050327301\n",
            "Validation Loss: 0.23144055902957916\n",
            "\n",
            "Epoch 98/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2284 - val_loss: 0.2286\n",
            "Loss: 0.22841933369636536\n",
            "Validation Loss: 0.22858649492263794\n",
            "\n",
            "Epoch 99/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2285 - val_loss: 0.2290\n",
            "Loss: 0.22848203778266907\n",
            "Validation Loss: 0.2290462702512741\n",
            "\n",
            "Epoch 100/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2267 - val_loss: 0.2329\n",
            "Loss: 0.22674155235290527\n",
            "Validation Loss: 0.23291748762130737\n",
            "\n",
            "Epoch 101/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2280 - val_loss: 0.2287\n",
            "Loss: 0.2280215322971344\n",
            "Validation Loss: 0.22871530055999756\n",
            "\n",
            "Epoch 102/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2278 - val_loss: 0.2265\n",
            "Loss: 0.22778885066509247\n",
            "Validation Loss: 0.2264719158411026\n",
            "\n",
            "Epoch 103/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2257 - val_loss: 0.2324\n",
            "Loss: 0.22566165030002594\n",
            "Validation Loss: 0.23243384063243866\n",
            "\n",
            "Epoch 104/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2268 - val_loss: 0.2280\n",
            "Loss: 0.22681911289691925\n",
            "Validation Loss: 0.22802448272705078\n",
            "\n",
            "Epoch 105/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2261 - val_loss: 0.2278\n",
            "Loss: 0.22605165839195251\n",
            "Validation Loss: 0.22779996693134308\n",
            "\n",
            "Epoch 106/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2269 - val_loss: 0.2288\n",
            "Loss: 0.22692298889160156\n",
            "Validation Loss: 0.22881798446178436\n",
            "\n",
            "Epoch 107/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2254 - val_loss: 0.2319\n",
            "Loss: 0.22536009550094604\n",
            "Validation Loss: 0.23186446726322174\n",
            "\n",
            "Epoch 108/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2267 - val_loss: 0.2248\n",
            "Loss: 0.22668543457984924\n",
            "Validation Loss: 0.22476525604724884\n",
            "\n",
            "Epoch 109/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2225 - val_loss: 0.2211\n",
            "Loss: 0.2225273698568344\n",
            "Validation Loss: 0.22112464904785156\n",
            "\n",
            "Epoch 110/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2241 - val_loss: 0.2234\n",
            "Loss: 0.22408638894557953\n",
            "Validation Loss: 0.22341173887252808\n",
            "\n",
            "Epoch 111/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2249 - val_loss: 0.2246\n",
            "Loss: 0.22492270171642303\n",
            "Validation Loss: 0.22462353110313416\n",
            "\n",
            "Epoch 112/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2217 - val_loss: 0.2249\n",
            "Loss: 0.22167307138442993\n",
            "Validation Loss: 0.22487932443618774\n",
            "\n",
            "Epoch 113/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2220 - val_loss: 0.2243\n",
            "Loss: 0.22196897864341736\n",
            "Validation Loss: 0.2243337780237198\n",
            "\n",
            "Epoch 114/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2220 - val_loss: 0.2233\n",
            "Loss: 0.22198370099067688\n",
            "Validation Loss: 0.2232970893383026\n",
            "\n",
            "Epoch 115/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2208 - val_loss: 0.2240\n",
            "Loss: 0.2207747846841812\n",
            "Validation Loss: 0.22403506934642792\n",
            "\n",
            "Epoch 116/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2220 - val_loss: 0.2204\n",
            "Loss: 0.2220005989074707\n",
            "Validation Loss: 0.22043795883655548\n",
            "\n",
            "Epoch 117/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2209 - val_loss: 0.2203\n",
            "Loss: 0.2209484875202179\n",
            "Validation Loss: 0.22031842172145844\n",
            "\n",
            "Epoch 118/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2205 - val_loss: 0.2258\n",
            "Loss: 0.22053588926792145\n",
            "Validation Loss: 0.22576728463172913\n",
            "\n",
            "Epoch 119/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2198 - val_loss: 0.2232\n",
            "Loss: 0.21983377635478973\n",
            "Validation Loss: 0.22319862246513367\n",
            "\n",
            "Epoch 120/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2201 - val_loss: 0.2197\n",
            "Loss: 0.22007238864898682\n",
            "Validation Loss: 0.21965186297893524\n",
            "\n",
            "Epoch 121/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2204 - val_loss: 0.2207\n",
            "Loss: 0.22044923901557922\n",
            "Validation Loss: 0.22065655887126923\n",
            "\n",
            "Epoch 122/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2198 - val_loss: 0.2181\n",
            "Loss: 0.21982082724571228\n",
            "Validation Loss: 0.21813084185123444\n",
            "\n",
            "Epoch 123/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2188 - val_loss: 0.2193\n",
            "Loss: 0.21879860758781433\n",
            "Validation Loss: 0.21928216516971588\n",
            "\n",
            "Epoch 124/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2192 - val_loss: 0.2191\n",
            "Loss: 0.21918250620365143\n",
            "Validation Loss: 0.219065323472023\n",
            "\n",
            "Epoch 125/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2182 - val_loss: 0.2180\n",
            "Loss: 0.21820510923862457\n",
            "Validation Loss: 0.21799206733703613\n",
            "\n",
            "Epoch 126/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2179 - val_loss: 0.2190\n",
            "Loss: 0.21790626645088196\n",
            "Validation Loss: 0.21895915269851685\n",
            "\n",
            "Epoch 127/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2174 - val_loss: 0.2217\n",
            "Loss: 0.2174113243818283\n",
            "Validation Loss: 0.22166278958320618\n",
            "\n",
            "Epoch 128/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2180 - val_loss: 0.2218\n",
            "Loss: 0.21798653900623322\n",
            "Validation Loss: 0.22176676988601685\n",
            "\n",
            "Epoch 129/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2174 - val_loss: 0.2210\n",
            "Loss: 0.2173917442560196\n",
            "Validation Loss: 0.22099687159061432\n",
            "\n",
            "Epoch 130/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2170 - val_loss: 0.2182\n",
            "Loss: 0.21702010929584503\n",
            "Validation Loss: 0.21820227801799774\n",
            "\n",
            "Epoch 131/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2173 - val_loss: 0.2148\n",
            "Loss: 0.21733419597148895\n",
            "Validation Loss: 0.2148188352584839\n",
            "\n",
            "Epoch 132/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2173 - val_loss: 0.2152\n",
            "Loss: 0.21730256080627441\n",
            "Validation Loss: 0.21519553661346436\n",
            "\n",
            "Epoch 133/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2152 - val_loss: 0.2196\n",
            "Loss: 0.2152494490146637\n",
            "Validation Loss: 0.2195923626422882\n",
            "\n",
            "Epoch 134/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2168 - val_loss: 0.2142\n",
            "Loss: 0.21682946383953094\n",
            "Validation Loss: 0.21420839428901672\n",
            "\n",
            "Epoch 135/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2142 - val_loss: 0.2148\n",
            "Loss: 0.21417154371738434\n",
            "Validation Loss: 0.21481728553771973\n",
            "\n",
            "Epoch 136/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2160 - val_loss: 0.2159\n",
            "Loss: 0.21596895158290863\n",
            "Validation Loss: 0.21593475341796875\n",
            "\n",
            "Epoch 137/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2143 - val_loss: 0.2159\n",
            "Loss: 0.2142898291349411\n",
            "Validation Loss: 0.2158876210451126\n",
            "\n",
            "Epoch 138/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2137 - val_loss: 0.2161\n",
            "Loss: 0.2137327939271927\n",
            "Validation Loss: 0.21609540283679962\n",
            "\n",
            "Epoch 139/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2121 - val_loss: 0.2181\n",
            "Loss: 0.21209615468978882\n",
            "Validation Loss: 0.21806474030017853\n",
            "\n",
            "Epoch 140/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2134 - val_loss: 0.2161\n",
            "Loss: 0.21343053877353668\n",
            "Validation Loss: 0.21606168150901794\n",
            "\n",
            "Epoch 141/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2119 - val_loss: 0.2118\n",
            "Loss: 0.21187375485897064\n",
            "Validation Loss: 0.21184080839157104\n",
            "\n",
            "Epoch 142/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2119 - val_loss: 0.2146\n",
            "Loss: 0.21189476549625397\n",
            "Validation Loss: 0.21459124982357025\n",
            "\n",
            "Epoch 143/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2135 - val_loss: 0.2116\n",
            "Loss: 0.21345295011997223\n",
            "Validation Loss: 0.2116435468196869\n",
            "\n",
            "Epoch 144/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2122 - val_loss: 0.2108\n",
            "Loss: 0.2121705859899521\n",
            "Validation Loss: 0.2107776552438736\n",
            "\n",
            "Epoch 145/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2138 - val_loss: 0.2166\n",
            "Loss: 0.21379226446151733\n",
            "Validation Loss: 0.2166346311569214\n",
            "\n",
            "Epoch 146/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2127 - val_loss: 0.2152\n",
            "Loss: 0.21266672015190125\n",
            "Validation Loss: 0.21515555679798126\n",
            "\n",
            "Epoch 147/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2129 - val_loss: 0.2123\n",
            "Loss: 0.21294564008712769\n",
            "Validation Loss: 0.21225498616695404\n",
            "\n",
            "Epoch 148/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2104 - val_loss: 0.2139\n",
            "Loss: 0.21038217842578888\n",
            "Validation Loss: 0.21387359499931335\n",
            "\n",
            "Epoch 149/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2113 - val_loss: 0.2144\n",
            "Loss: 0.21129833161830902\n",
            "Validation Loss: 0.21438930928707123\n",
            "\n",
            "Epoch 150/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2108 - val_loss: 0.2111\n",
            "Loss: 0.21077051758766174\n",
            "Validation Loss: 0.21111640334129333\n",
            "\n",
            "Epoch 151/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2106 - val_loss: 0.2099\n",
            "Loss: 0.21057678759098053\n",
            "Validation Loss: 0.20988960564136505\n",
            "\n",
            "Epoch 152/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2120 - val_loss: 0.2129\n",
            "Loss: 0.2119678109884262\n",
            "Validation Loss: 0.21285000443458557\n",
            "\n",
            "Epoch 153/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2095 - val_loss: 0.2120\n",
            "Loss: 0.20952296257019043\n",
            "Validation Loss: 0.2120181769132614\n",
            "\n",
            "Epoch 154/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2093 - val_loss: 0.2094\n",
            "Loss: 0.2093416303396225\n",
            "Validation Loss: 0.20936556160449982\n",
            "\n",
            "Epoch 155/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2096 - val_loss: 0.2111\n",
            "Loss: 0.20962375402450562\n",
            "Validation Loss: 0.21108920872211456\n",
            "\n",
            "Epoch 156/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2092 - val_loss: 0.2088\n",
            "Loss: 0.20917068421840668\n",
            "Validation Loss: 0.20875973999500275\n",
            "\n",
            "Epoch 157/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2084 - val_loss: 0.2086\n",
            "Loss: 0.20843829214572906\n",
            "Validation Loss: 0.2086174488067627\n",
            "\n",
            "Epoch 158/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2076 - val_loss: 0.2118\n",
            "Loss: 0.20762649178504944\n",
            "Validation Loss: 0.2117590308189392\n",
            "\n",
            "Epoch 159/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2099 - val_loss: 0.2104\n",
            "Loss: 0.20987173914909363\n",
            "Validation Loss: 0.21039935946464539\n",
            "\n",
            "Epoch 160/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2102 - val_loss: 0.2103\n",
            "Loss: 0.21024109423160553\n",
            "Validation Loss: 0.21025113761425018\n",
            "\n",
            "Epoch 161/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2094 - val_loss: 0.2112\n",
            "Loss: 0.20936022698879242\n",
            "Validation Loss: 0.2111557573080063\n",
            "\n",
            "Epoch 162/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2096 - val_loss: 0.2098\n",
            "Loss: 0.20962712168693542\n",
            "Validation Loss: 0.20975971221923828\n",
            "\n",
            "Epoch 163/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2085 - val_loss: 0.2138\n",
            "Loss: 0.20854857563972473\n",
            "Validation Loss: 0.2138156294822693\n",
            "\n",
            "Epoch 164/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2080 - val_loss: 0.2083\n",
            "Loss: 0.20802965760231018\n",
            "Validation Loss: 0.2083076387643814\n",
            "\n",
            "Epoch 165/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.2072 - val_loss: 0.2079\n",
            "Loss: 0.20719142258167267\n",
            "Validation Loss: 0.20790459215641022\n",
            "\n",
            "Epoch 166/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2059 - val_loss: 0.2076\n",
            "Loss: 0.20587357878684998\n",
            "Validation Loss: 0.20761947333812714\n",
            "\n",
            "Epoch 167/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2076 - val_loss: 0.2070\n",
            "Loss: 0.2075989544391632\n",
            "Validation Loss: 0.20698627829551697\n",
            "\n",
            "Epoch 168/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2079 - val_loss: 0.2067\n",
            "Loss: 0.20786257088184357\n",
            "Validation Loss: 0.2067110240459442\n",
            "\n",
            "Epoch 169/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2063 - val_loss: 0.2108\n",
            "Loss: 0.20625564455986023\n",
            "Validation Loss: 0.21077680587768555\n",
            "\n",
            "Epoch 170/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2062 - val_loss: 0.2104\n",
            "Loss: 0.20622849464416504\n",
            "Validation Loss: 0.2104206085205078\n",
            "\n",
            "Epoch 171/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2050 - val_loss: 0.2114\n",
            "Loss: 0.20495089888572693\n",
            "Validation Loss: 0.21142743527889252\n",
            "\n",
            "Epoch 172/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2052 - val_loss: 0.2093\n",
            "Loss: 0.20515325665473938\n",
            "Validation Loss: 0.2092810720205307\n",
            "\n",
            "Epoch 173/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2068 - val_loss: 0.2066\n",
            "Loss: 0.20677202939987183\n",
            "Validation Loss: 0.20663389563560486\n",
            "\n",
            "Epoch 174/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2053 - val_loss: 0.2032\n",
            "Loss: 0.20525363087654114\n",
            "Validation Loss: 0.2032345086336136\n",
            "\n",
            "Epoch 175/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2066 - val_loss: 0.2058\n",
            "Loss: 0.20659108459949493\n",
            "Validation Loss: 0.20580992102622986\n",
            "\n",
            "Epoch 176/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2050 - val_loss: 0.2062\n",
            "Loss: 0.20504581928253174\n",
            "Validation Loss: 0.20615357160568237\n",
            "\n",
            "Epoch 177/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2031 - val_loss: 0.2108\n",
            "Loss: 0.20311175286769867\n",
            "Validation Loss: 0.210750013589859\n",
            "\n",
            "Epoch 178/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2058 - val_loss: 0.2045\n",
            "Loss: 0.20578372478485107\n",
            "Validation Loss: 0.20447050034999847\n",
            "\n",
            "Epoch 179/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2029 - val_loss: 0.2042\n",
            "Loss: 0.20288002490997314\n",
            "Validation Loss: 0.20417127013206482\n",
            "\n",
            "Epoch 180/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2053 - val_loss: 0.2047\n",
            "Loss: 0.20526176691055298\n",
            "Validation Loss: 0.2046724259853363\n",
            "\n",
            "Epoch 181/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2037 - val_loss: 0.2072\n",
            "Loss: 0.2037372589111328\n",
            "Validation Loss: 0.20715652406215668\n",
            "\n",
            "Epoch 182/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2041 - val_loss: 0.2051\n",
            "Loss: 0.20406731963157654\n",
            "Validation Loss: 0.2050924152135849\n",
            "\n",
            "Epoch 183/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2027 - val_loss: 0.2042\n",
            "Loss: 0.2027071714401245\n",
            "Validation Loss: 0.20419631898403168\n",
            "\n",
            "Epoch 184/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2044 - val_loss: 0.2051\n",
            "Loss: 0.2044428288936615\n",
            "Validation Loss: 0.20506463944911957\n",
            "\n",
            "Epoch 185/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2034 - val_loss: 0.2020\n",
            "Loss: 0.20344899594783783\n",
            "Validation Loss: 0.20195412635803223\n",
            "\n",
            "Epoch 186/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2039 - val_loss: 0.2063\n",
            "Loss: 0.20387320220470428\n",
            "Validation Loss: 0.206338569521904\n",
            "\n",
            "Epoch 187/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2025 - val_loss: 0.2050\n",
            "Loss: 0.202487513422966\n",
            "Validation Loss: 0.20504797995090485\n",
            "\n",
            "Epoch 188/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2029 - val_loss: 0.2054\n",
            "Loss: 0.202862948179245\n",
            "Validation Loss: 0.20541490614414215\n",
            "\n",
            "Epoch 189/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2028 - val_loss: 0.2034\n",
            "Loss: 0.20280514657497406\n",
            "Validation Loss: 0.20342807471752167\n",
            "\n",
            "Epoch 190/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2032 - val_loss: 0.2048\n",
            "Loss: 0.20316821336746216\n",
            "Validation Loss: 0.20481669902801514\n",
            "\n",
            "Epoch 191/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2019 - val_loss: 0.2034\n",
            "Loss: 0.20193828642368317\n",
            "Validation Loss: 0.2033844292163849\n",
            "\n",
            "Epoch 192/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2029 - val_loss: 0.2053\n",
            "Loss: 0.20294177532196045\n",
            "Validation Loss: 0.20526014268398285\n",
            "\n",
            "Epoch 193/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2041 - val_loss: 0.2009\n",
            "Loss: 0.2041291743516922\n",
            "Validation Loss: 0.2008545994758606\n",
            "\n",
            "Epoch 194/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2029 - val_loss: 0.2030\n",
            "Loss: 0.20288026332855225\n",
            "Validation Loss: 0.20303206145763397\n",
            "\n",
            "Epoch 195/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2008 - val_loss: 0.2017\n",
            "Loss: 0.20080970227718353\n",
            "Validation Loss: 0.2016938030719757\n",
            "\n",
            "Epoch 196/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2013 - val_loss: 0.2043\n",
            "Loss: 0.20126517117023468\n",
            "Validation Loss: 0.20426207780838013\n",
            "\n",
            "Epoch 197/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2027 - val_loss: 0.2043\n",
            "Loss: 0.20270375907421112\n",
            "Validation Loss: 0.20431096851825714\n",
            "\n",
            "Epoch 198/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2017 - val_loss: 0.2018\n",
            "Loss: 0.20172420144081116\n",
            "Validation Loss: 0.20177455246448517\n",
            "\n",
            "Epoch 199/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2030 - val_loss: 0.2021\n",
            "Loss: 0.20295007526874542\n",
            "Validation Loss: 0.20209860801696777\n",
            "\n",
            "Epoch 200/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2010 - val_loss: 0.2033\n",
            "Loss: 0.20099063217639923\n",
            "Validation Loss: 0.20329339802265167\n",
            "\n",
            "Epoch 201/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2002 - val_loss: 0.2018\n",
            "Loss: 0.2002371847629547\n",
            "Validation Loss: 0.20178240537643433\n",
            "\n",
            "Epoch 202/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2000 - val_loss: 0.2004\n",
            "Loss: 0.2000267654657364\n",
            "Validation Loss: 0.20044106245040894\n",
            "\n",
            "Epoch 203/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2013 - val_loss: 0.2021\n",
            "Loss: 0.20126019418239594\n",
            "Validation Loss: 0.2020983099937439\n",
            "\n",
            "Epoch 204/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2003 - val_loss: 0.2011\n",
            "Loss: 0.20031724870204926\n",
            "Validation Loss: 0.20108959078788757\n",
            "\n",
            "Epoch 205/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1994 - val_loss: 0.1996\n",
            "Loss: 0.19941633939743042\n",
            "Validation Loss: 0.199567049741745\n",
            "\n",
            "Epoch 206/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1996 - val_loss: 0.1988\n",
            "Loss: 0.19961045682430267\n",
            "Validation Loss: 0.19881321489810944\n",
            "\n",
            "Epoch 207/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1999 - val_loss: 0.1983\n",
            "Loss: 0.19994501769542694\n",
            "Validation Loss: 0.19833816587924957\n",
            "\n",
            "Epoch 208/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1984 - val_loss: 0.2012\n",
            "Loss: 0.19837847352027893\n",
            "Validation Loss: 0.20116175711154938\n",
            "\n",
            "Epoch 209/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1997 - val_loss: 0.2001\n",
            "Loss: 0.19966872036457062\n",
            "Validation Loss: 0.20014944672584534\n",
            "\n",
            "Epoch 210/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1997 - val_loss: 0.1986\n",
            "Loss: 0.19974738359451294\n",
            "Validation Loss: 0.19860005378723145\n",
            "\n",
            "Epoch 211/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1989 - val_loss: 0.1989\n",
            "Loss: 0.19891424477100372\n",
            "Validation Loss: 0.1989084631204605\n",
            "\n",
            "Epoch 212/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1998 - val_loss: 0.2013\n",
            "Loss: 0.19977767765522003\n",
            "Validation Loss: 0.2012745440006256\n",
            "\n",
            "Epoch 213/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1996 - val_loss: 0.1985\n",
            "Loss: 0.19957350194454193\n",
            "Validation Loss: 0.19847801327705383\n",
            "\n",
            "Epoch 214/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1995 - val_loss: 0.1978\n",
            "Loss: 0.19947406649589539\n",
            "Validation Loss: 0.19782505929470062\n",
            "\n",
            "Epoch 215/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1979 - val_loss: 0.1989\n",
            "Loss: 0.1979496031999588\n",
            "Validation Loss: 0.1988639235496521\n",
            "\n",
            "Epoch 216/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1973 - val_loss: 0.2007\n",
            "Loss: 0.19725532829761505\n",
            "Validation Loss: 0.20070523023605347\n",
            "\n",
            "Epoch 217/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1974 - val_loss: 0.2012\n",
            "Loss: 0.1973702609539032\n",
            "Validation Loss: 0.20120781660079956\n",
            "\n",
            "Epoch 218/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1972 - val_loss: 0.1973\n",
            "Loss: 0.19722004234790802\n",
            "Validation Loss: 0.19728362560272217\n",
            "\n",
            "Epoch 219/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1976 - val_loss: 0.1963\n",
            "Loss: 0.19757111370563507\n",
            "Validation Loss: 0.19633892178535461\n",
            "\n",
            "Epoch 220/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1984 - val_loss: 0.2000\n",
            "Loss: 0.19842477142810822\n",
            "Validation Loss: 0.19996966421604156\n",
            "\n",
            "Epoch 221/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1967 - val_loss: 0.1991\n",
            "Loss: 0.1967373639345169\n",
            "Validation Loss: 0.19912976026535034\n",
            "\n",
            "Epoch 222/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1980 - val_loss: 0.1976\n",
            "Loss: 0.19795073568820953\n",
            "Validation Loss: 0.19761589169502258\n",
            "\n",
            "Epoch 223/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1988 - val_loss: 0.1972\n",
            "Loss: 0.19879354536533356\n",
            "Validation Loss: 0.19717755913734436\n",
            "\n",
            "Epoch 224/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1976 - val_loss: 0.1953\n",
            "Loss: 0.19764205813407898\n",
            "Validation Loss: 0.19533953070640564\n",
            "\n",
            "Epoch 225/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1961 - val_loss: 0.1958\n",
            "Loss: 0.1961185336112976\n",
            "Validation Loss: 0.19581995904445648\n",
            "\n",
            "Epoch 226/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1953 - val_loss: 0.2006\n",
            "Loss: 0.19530120491981506\n",
            "Validation Loss: 0.20062968134880066\n",
            "\n",
            "Epoch 227/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1967 - val_loss: 0.1978\n",
            "Loss: 0.19667084515094757\n",
            "Validation Loss: 0.19784845411777496\n",
            "\n",
            "Epoch 228/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1972 - val_loss: 0.1941\n",
            "Loss: 0.19722633063793182\n",
            "Validation Loss: 0.19414246082305908\n",
            "\n",
            "Epoch 229/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1960 - val_loss: 0.1951\n",
            "Loss: 0.19601427018642426\n",
            "Validation Loss: 0.1951199471950531\n",
            "\n",
            "Epoch 230/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1967 - val_loss: 0.1983\n",
            "Loss: 0.19666410982608795\n",
            "Validation Loss: 0.198298841714859\n",
            "\n",
            "Epoch 231/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1965 - val_loss: 0.1951\n",
            "Loss: 0.19649796187877655\n",
            "Validation Loss: 0.19510123133659363\n",
            "\n",
            "Epoch 232/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1978 - val_loss: 0.1954\n",
            "Loss: 0.19779632985591888\n",
            "Validation Loss: 0.1953911930322647\n",
            "\n",
            "Epoch 233/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1956 - val_loss: 0.1946\n",
            "Loss: 0.19557064771652222\n",
            "Validation Loss: 0.19457897543907166\n",
            "\n",
            "Epoch 234/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1949 - val_loss: 0.1949\n",
            "Loss: 0.19493527710437775\n",
            "Validation Loss: 0.19487732648849487\n",
            "\n",
            "Epoch 235/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1966 - val_loss: 0.1976\n",
            "Loss: 0.19661135971546173\n",
            "Validation Loss: 0.19761547446250916\n",
            "\n",
            "Epoch 236/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1968 - val_loss: 0.1965\n",
            "Loss: 0.19682881236076355\n",
            "Validation Loss: 0.1965145319700241\n",
            "\n",
            "Epoch 237/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1953 - val_loss: 0.1965\n",
            "Loss: 0.19529736042022705\n",
            "Validation Loss: 0.19649817049503326\n",
            "\n",
            "Epoch 238/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1943 - val_loss: 0.1974\n",
            "Loss: 0.19428083300590515\n",
            "Validation Loss: 0.1973831057548523\n",
            "\n",
            "Epoch 239/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1940 - val_loss: 0.1953\n",
            "Loss: 0.1940205991268158\n",
            "Validation Loss: 0.1953219771385193\n",
            "\n",
            "Epoch 240/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1942 - val_loss: 0.1926\n",
            "Loss: 0.19424450397491455\n",
            "Validation Loss: 0.19262447953224182\n",
            "\n",
            "Epoch 241/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1959 - val_loss: 0.1967\n",
            "Loss: 0.19588631391525269\n",
            "Validation Loss: 0.19669929146766663\n",
            "\n",
            "Epoch 242/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1953 - val_loss: 0.1946\n",
            "Loss: 0.19528070092201233\n",
            "Validation Loss: 0.19459353387355804\n",
            "\n",
            "Epoch 243/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1964 - val_loss: 0.1955\n",
            "Loss: 0.19638244807720184\n",
            "Validation Loss: 0.19554276764392853\n",
            "\n",
            "Epoch 244/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1941 - val_loss: 0.1946\n",
            "Loss: 0.19412805140018463\n",
            "Validation Loss: 0.1946401447057724\n",
            "\n",
            "Epoch 245/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1949 - val_loss: 0.1955\n",
            "Loss: 0.19488190114498138\n",
            "Validation Loss: 0.19551672041416168\n",
            "\n",
            "Epoch 246/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1948 - val_loss: 0.1964\n",
            "Loss: 0.1948261559009552\n",
            "Validation Loss: 0.19636844098567963\n",
            "\n",
            "Epoch 247/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1947 - val_loss: 0.1955\n",
            "Loss: 0.19465596973896027\n",
            "Validation Loss: 0.19550997018814087\n",
            "\n",
            "Epoch 248/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1933 - val_loss: 0.1961\n",
            "Loss: 0.19333581626415253\n",
            "Validation Loss: 0.19608959555625916\n",
            "\n",
            "Epoch 249/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1941 - val_loss: 0.1984\n",
            "Loss: 0.19405333697795868\n",
            "Validation Loss: 0.19836413860321045\n",
            "\n",
            "Epoch 250/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1964 - val_loss: 0.1952\n",
            "Loss: 0.196353942155838\n",
            "Validation Loss: 0.19516362249851227\n",
            "\n",
            "Epoch 251/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1942 - val_loss: 0.1927\n",
            "Loss: 0.19415238499641418\n",
            "Validation Loss: 0.19267582893371582\n",
            "\n",
            "Epoch 252/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1941 - val_loss: 0.1914\n",
            "Loss: 0.19413620233535767\n",
            "Validation Loss: 0.191446915268898\n",
            "\n",
            "Epoch 253/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1932 - val_loss: 0.1934\n",
            "Loss: 0.19322332739830017\n",
            "Validation Loss: 0.19341439008712769\n",
            "\n",
            "Epoch 254/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1931 - val_loss: 0.1923\n",
            "Loss: 0.19312690198421478\n",
            "Validation Loss: 0.19229337573051453\n",
            "\n",
            "Epoch 255/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1923 - val_loss: 0.1908\n",
            "Loss: 0.19233658909797668\n",
            "Validation Loss: 0.19082435965538025\n",
            "\n",
            "Epoch 256/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1932 - val_loss: 0.1925\n",
            "Loss: 0.19318264722824097\n",
            "Validation Loss: 0.19246889650821686\n",
            "\n",
            "Epoch 257/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1943 - val_loss: 0.1953\n",
            "Loss: 0.19430288672447205\n",
            "Validation Loss: 0.19525791704654694\n",
            "\n",
            "Epoch 258/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1932 - val_loss: 0.1930\n",
            "Loss: 0.19315679371356964\n",
            "Validation Loss: 0.1930367797613144\n",
            "\n",
            "Epoch 259/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1906 - val_loss: 0.1948\n",
            "Loss: 0.1905629187822342\n",
            "Validation Loss: 0.19483497738838196\n",
            "\n",
            "Epoch 260/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1930 - val_loss: 0.1944\n",
            "Loss: 0.19302770495414734\n",
            "Validation Loss: 0.19436350464820862\n",
            "\n",
            "Epoch 261/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1928 - val_loss: 0.1924\n",
            "Loss: 0.19282007217407227\n",
            "Validation Loss: 0.19239644706249237\n",
            "\n",
            "Epoch 262/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1919 - val_loss: 0.1925\n",
            "Loss: 0.1918802708387375\n",
            "Validation Loss: 0.19245034456253052\n",
            "\n",
            "Epoch 263/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1920 - val_loss: 0.1941\n",
            "Loss: 0.1920161247253418\n",
            "Validation Loss: 0.1941199004650116\n",
            "\n",
            "Epoch 264/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1913 - val_loss: 0.1944\n",
            "Loss: 0.19127778708934784\n",
            "Validation Loss: 0.19442299008369446\n",
            "\n",
            "Epoch 265/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1928 - val_loss: 0.1922\n",
            "Loss: 0.19279637932777405\n",
            "Validation Loss: 0.1921892911195755\n",
            "\n",
            "Epoch 266/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1907 - val_loss: 0.1906\n",
            "Loss: 0.1906513273715973\n",
            "Validation Loss: 0.19058918952941895\n",
            "\n",
            "Epoch 267/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1909 - val_loss: 0.1916\n",
            "Loss: 0.19088347256183624\n",
            "Validation Loss: 0.19159014523029327\n",
            "\n",
            "Epoch 268/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1926 - val_loss: 0.1930\n",
            "Loss: 0.1925678700208664\n",
            "Validation Loss: 0.19298014044761658\n",
            "\n",
            "Epoch 269/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1915 - val_loss: 0.1921\n",
            "Loss: 0.1915336400270462\n",
            "Validation Loss: 0.19209729135036469\n",
            "\n",
            "Epoch 270/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1920 - val_loss: 0.1943\n",
            "Loss: 0.19199182093143463\n",
            "Validation Loss: 0.19430381059646606\n",
            "\n",
            "Epoch 271/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1908 - val_loss: 0.1927\n",
            "Loss: 0.1908116340637207\n",
            "Validation Loss: 0.19265899062156677\n",
            "\n",
            "Epoch 272/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1909 - val_loss: 0.1920\n",
            "Loss: 0.19092942774295807\n",
            "Validation Loss: 0.1919575184583664\n",
            "\n",
            "Epoch 273/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1936 - val_loss: 0.1919\n",
            "Loss: 0.19364237785339355\n",
            "Validation Loss: 0.19190829992294312\n",
            "\n",
            "Epoch 274/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1909 - val_loss: 0.1909\n",
            "Loss: 0.19090284407138824\n",
            "Validation Loss: 0.19092601537704468\n",
            "\n",
            "Epoch 275/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1896 - val_loss: 0.1902\n",
            "Loss: 0.18956562876701355\n",
            "Validation Loss: 0.19022859632968903\n",
            "\n",
            "Epoch 276/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1919 - val_loss: 0.1901\n",
            "Loss: 0.19190947711467743\n",
            "Validation Loss: 0.19006696343421936\n",
            "\n",
            "Epoch 277/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1896 - val_loss: 0.1901\n",
            "Loss: 0.1895866096019745\n",
            "Validation Loss: 0.19014689326286316\n",
            "\n",
            "Epoch 278/750\n",
            "21/21 [==============================] - 4s 177ms/step - loss: 0.1901 - val_loss: 0.1915\n",
            "Loss: 0.190069317817688\n",
            "Validation Loss: 0.19152326881885529\n",
            "\n",
            "Epoch 279/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1909 - val_loss: 0.1926\n",
            "Loss: 0.19088876247406006\n",
            "Validation Loss: 0.19257713854312897\n",
            "\n",
            "Epoch 280/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1904 - val_loss: 0.1905\n",
            "Loss: 0.1904316395521164\n",
            "Validation Loss: 0.19050627946853638\n",
            "\n",
            "Epoch 281/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1886 - val_loss: 0.1906\n",
            "Loss: 0.18861123919487\n",
            "Validation Loss: 0.1905701458454132\n",
            "\n",
            "Epoch 282/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1900 - val_loss: 0.1937\n",
            "Loss: 0.189999520778656\n",
            "Validation Loss: 0.19371449947357178\n",
            "\n",
            "Epoch 283/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1891 - val_loss: 0.1899\n",
            "Loss: 0.18907223641872406\n",
            "Validation Loss: 0.1898956298828125\n",
            "\n",
            "Epoch 284/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1894 - val_loss: 0.1895\n",
            "Loss: 0.18942968547344208\n",
            "Validation Loss: 0.18947339057922363\n",
            "\n",
            "Epoch 285/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1886 - val_loss: 0.1916\n",
            "Loss: 0.18859657645225525\n",
            "Validation Loss: 0.1915651261806488\n",
            "\n",
            "Epoch 286/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1910 - val_loss: 0.1912\n",
            "Loss: 0.19097353518009186\n",
            "Validation Loss: 0.19119377434253693\n",
            "\n",
            "Epoch 287/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1886 - val_loss: 0.1897\n",
            "Loss: 0.1885838657617569\n",
            "Validation Loss: 0.18970100581645966\n",
            "\n",
            "Epoch 288/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1895 - val_loss: 0.1870\n",
            "Loss: 0.1894976943731308\n",
            "Validation Loss: 0.18702563643455505\n",
            "\n",
            "Epoch 289/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1892 - val_loss: 0.1898\n",
            "Loss: 0.18920502066612244\n",
            "Validation Loss: 0.18980379402637482\n",
            "\n",
            "Epoch 290/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1893 - val_loss: 0.1897\n",
            "Loss: 0.189259335398674\n",
            "Validation Loss: 0.18972770869731903\n",
            "\n",
            "Epoch 291/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1893 - val_loss: 0.1889\n",
            "Loss: 0.18931938707828522\n",
            "Validation Loss: 0.18885642290115356\n",
            "\n",
            "Epoch 292/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1876 - val_loss: 0.1893\n",
            "Loss: 0.187606543302536\n",
            "Validation Loss: 0.18928763270378113\n",
            "\n",
            "Epoch 293/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1896 - val_loss: 0.1908\n",
            "Loss: 0.1895897537469864\n",
            "Validation Loss: 0.19080042839050293\n",
            "\n",
            "Epoch 294/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1888 - val_loss: 0.1890\n",
            "Loss: 0.1887749880552292\n",
            "Validation Loss: 0.18896545469760895\n",
            "\n",
            "Epoch 295/750\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1871 - val_loss: 0.1885\n",
            "Loss: 0.18706034123897552\n",
            "Validation Loss: 0.18854749202728271\n",
            "\n",
            "Epoch 296/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1889 - val_loss: 0.1904\n",
            "Loss: 0.18891721963882446\n",
            "Validation Loss: 0.19044260680675507\n",
            "\n",
            "Epoch 297/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1897 - val_loss: 0.1895\n",
            "Loss: 0.18965353071689606\n",
            "Validation Loss: 0.189453125\n",
            "\n",
            "Epoch 298/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1900 - val_loss: 0.1913\n",
            "Loss: 0.1900196224451065\n",
            "Validation Loss: 0.19126106798648834\n",
            "\n",
            "Epoch 299/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1885 - val_loss: 0.1894\n",
            "Loss: 0.1884814202785492\n",
            "Validation Loss: 0.18943026661872864\n",
            "\n",
            "Epoch 300/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1888 - val_loss: 0.1894\n",
            "Loss: 0.18881534039974213\n",
            "Validation Loss: 0.18936876952648163\n",
            "\n",
            "Epoch 301/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1875 - val_loss: 0.1889\n",
            "Loss: 0.18745164573192596\n",
            "Validation Loss: 0.18891654908657074\n",
            "\n",
            "Epoch 302/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1887 - val_loss: 0.1920\n",
            "Loss: 0.18867278099060059\n",
            "Validation Loss: 0.19196593761444092\n",
            "\n",
            "Epoch 303/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1880 - val_loss: 0.1896\n",
            "Loss: 0.18796421587467194\n",
            "Validation Loss: 0.18961405754089355\n",
            "\n",
            "Epoch 304/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1891 - val_loss: 0.1895\n",
            "Loss: 0.18913348019123077\n",
            "Validation Loss: 0.18953284621238708\n",
            "\n",
            "Epoch 305/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1884 - val_loss: 0.1886\n",
            "Loss: 0.188384011387825\n",
            "Validation Loss: 0.18860942125320435\n",
            "\n",
            "Epoch 306/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1882 - val_loss: 0.1872\n",
            "Loss: 0.1881943643093109\n",
            "Validation Loss: 0.18719784915447235\n",
            "\n",
            "Epoch 307/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1882 - val_loss: 0.1888\n",
            "Loss: 0.18817850947380066\n",
            "Validation Loss: 0.188780277967453\n",
            "\n",
            "Epoch 308/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Loss: 0.18842187523841858\n",
            "Validation Loss: 0.1876671314239502\n",
            "\n",
            "Epoch 309/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1884 - val_loss: 0.1881\n",
            "Loss: 0.18842528760433197\n",
            "Validation Loss: 0.18808259069919586\n",
            "\n",
            "Epoch 310/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1878 - val_loss: 0.1865\n",
            "Loss: 0.18784670531749725\n",
            "Validation Loss: 0.1865498274564743\n",
            "\n",
            "Epoch 311/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1884 - val_loss: 0.1900\n",
            "Loss: 0.18841443955898285\n",
            "Validation Loss: 0.19003282487392426\n",
            "\n",
            "Epoch 312/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1901 - val_loss: 0.1867\n",
            "Loss: 0.19005076587200165\n",
            "Validation Loss: 0.18671643733978271\n",
            "\n",
            "Epoch 313/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1864 - val_loss: 0.1858\n",
            "Loss: 0.18638335168361664\n",
            "Validation Loss: 0.18579912185668945\n",
            "\n",
            "Epoch 314/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1869 - val_loss: 0.1850\n",
            "Loss: 0.18694739043712616\n",
            "Validation Loss: 0.18497763574123383\n",
            "\n",
            "Epoch 315/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1876 - val_loss: 0.1860\n",
            "Loss: 0.18764089047908783\n",
            "Validation Loss: 0.1860189586877823\n",
            "\n",
            "Epoch 316/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1885 - val_loss: 0.1851\n",
            "Loss: 0.18847933411598206\n",
            "Validation Loss: 0.18506662547588348\n",
            "\n",
            "Epoch 317/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1869 - val_loss: 0.1871\n",
            "Loss: 0.18691320717334747\n",
            "Validation Loss: 0.18705593049526215\n",
            "\n",
            "Epoch 318/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1873 - val_loss: 0.1887\n",
            "Loss: 0.18732696771621704\n",
            "Validation Loss: 0.1886623650789261\n",
            "\n",
            "Epoch 319/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1873 - val_loss: 0.1888\n",
            "Loss: 0.18733900785446167\n",
            "Validation Loss: 0.18884973227977753\n",
            "\n",
            "Epoch 320/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1863 - val_loss: 0.1892\n",
            "Loss: 0.1862650066614151\n",
            "Validation Loss: 0.1891607642173767\n",
            "\n",
            "Epoch 321/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1859 - val_loss: 0.1891\n",
            "Loss: 0.18587318062782288\n",
            "Validation Loss: 0.189096599817276\n",
            "\n",
            "Epoch 322/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1866 - val_loss: 0.1885\n",
            "Loss: 0.18658410012722015\n",
            "Validation Loss: 0.18848875164985657\n",
            "\n",
            "Epoch 323/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1856 - val_loss: 0.1849\n",
            "Loss: 0.1855912059545517\n",
            "Validation Loss: 0.18489611148834229\n",
            "\n",
            "Epoch 324/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1864 - val_loss: 0.1853\n",
            "Loss: 0.18637576699256897\n",
            "Validation Loss: 0.18527239561080933\n",
            "\n",
            "Epoch 325/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1867 - val_loss: 0.1864\n",
            "Loss: 0.1867404729127884\n",
            "Validation Loss: 0.1864047348499298\n",
            "\n",
            "Epoch 326/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1872 - val_loss: 0.1853\n",
            "Loss: 0.18719147145748138\n",
            "Validation Loss: 0.18533754348754883\n",
            "\n",
            "Epoch 327/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1866 - val_loss: 0.1871\n",
            "Loss: 0.18658776581287384\n",
            "Validation Loss: 0.1871473491191864\n",
            "\n",
            "Epoch 328/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1856 - val_loss: 0.1883\n",
            "Loss: 0.18557561933994293\n",
            "Validation Loss: 0.18825042247772217\n",
            "\n",
            "Epoch 329/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1866 - val_loss: 0.1875\n",
            "Loss: 0.18663939833641052\n",
            "Validation Loss: 0.18751409649848938\n",
            "\n",
            "Epoch 330/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1859 - val_loss: 0.1865\n",
            "Loss: 0.18592847883701324\n",
            "Validation Loss: 0.1865490823984146\n",
            "\n",
            "Epoch 331/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1845 - val_loss: 0.1863\n",
            "Loss: 0.18454599380493164\n",
            "Validation Loss: 0.1862984299659729\n",
            "\n",
            "Epoch 332/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1856 - val_loss: 0.1866\n",
            "Loss: 0.18563465774059296\n",
            "Validation Loss: 0.18663272261619568\n",
            "\n",
            "Epoch 333/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1863 - val_loss: 0.1846\n",
            "Loss: 0.18627601861953735\n",
            "Validation Loss: 0.18456225097179413\n",
            "\n",
            "Epoch 334/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1853 - val_loss: 0.1843\n",
            "Loss: 0.18528908491134644\n",
            "Validation Loss: 0.18426121771335602\n",
            "\n",
            "Epoch 335/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1855 - val_loss: 0.1849\n",
            "Loss: 0.1854860782623291\n",
            "Validation Loss: 0.18491066992282867\n",
            "\n",
            "Epoch 336/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1854 - val_loss: 0.1870\n",
            "Loss: 0.1853507161140442\n",
            "Validation Loss: 0.18703003227710724\n",
            "\n",
            "Epoch 337/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1857 - val_loss: 0.1851\n",
            "Loss: 0.18568308651447296\n",
            "Validation Loss: 0.18509061634540558\n",
            "\n",
            "Epoch 338/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1851 - val_loss: 0.1848\n",
            "Loss: 0.18514999747276306\n",
            "Validation Loss: 0.1847885698080063\n",
            "\n",
            "Epoch 339/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1866 - val_loss: 0.1850\n",
            "Loss: 0.18660439550876617\n",
            "Validation Loss: 0.18497183918952942\n",
            "\n",
            "Epoch 340/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1846 - val_loss: 0.1844\n",
            "Loss: 0.1846465766429901\n",
            "Validation Loss: 0.18437913060188293\n",
            "\n",
            "Epoch 341/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1840 - val_loss: 0.1835\n",
            "Loss: 0.18402093648910522\n",
            "Validation Loss: 0.18352416157722473\n",
            "\n",
            "Epoch 342/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1840 - val_loss: 0.1857\n",
            "Loss: 0.1840450018644333\n",
            "Validation Loss: 0.1857374757528305\n",
            "\n",
            "Epoch 343/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1852 - val_loss: 0.1856\n",
            "Loss: 0.18524564802646637\n",
            "Validation Loss: 0.18561221659183502\n",
            "\n",
            "Epoch 344/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1847 - val_loss: 0.1836\n",
            "Loss: 0.18470674753189087\n",
            "Validation Loss: 0.18355289101600647\n",
            "\n",
            "Epoch 345/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1845 - val_loss: 0.1832\n",
            "Loss: 0.18448317050933838\n",
            "Validation Loss: 0.18317081034183502\n",
            "\n",
            "Epoch 346/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1853 - val_loss: 0.1825\n",
            "Loss: 0.1852933019399643\n",
            "Validation Loss: 0.18246442079544067\n",
            "\n",
            "Epoch 347/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1834 - val_loss: 0.1852\n",
            "Loss: 0.18340133130550385\n",
            "Validation Loss: 0.1851731687784195\n",
            "\n",
            "Epoch 348/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1845 - val_loss: 0.1822\n",
            "Loss: 0.18447495996952057\n",
            "Validation Loss: 0.1821955293416977\n",
            "\n",
            "Epoch 349/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1847 - val_loss: 0.1835\n",
            "Loss: 0.18467532098293304\n",
            "Validation Loss: 0.1834806203842163\n",
            "\n",
            "Epoch 350/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1843 - val_loss: 0.1847\n",
            "Loss: 0.18425890803337097\n",
            "Validation Loss: 0.18465296924114227\n",
            "\n",
            "Epoch 351/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1850 - val_loss: 0.1851\n",
            "Loss: 0.1850431114435196\n",
            "Validation Loss: 0.18510718643665314\n",
            "\n",
            "Epoch 352/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1849 - val_loss: 0.1844\n",
            "Loss: 0.18493060767650604\n",
            "Validation Loss: 0.1843545287847519\n",
            "\n",
            "Epoch 353/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1835 - val_loss: 0.1836\n",
            "Loss: 0.1834530085325241\n",
            "Validation Loss: 0.18361952900886536\n",
            "\n",
            "Epoch 354/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1847 - val_loss: 0.1845\n",
            "Loss: 0.18473970890045166\n",
            "Validation Loss: 0.18453213572502136\n",
            "\n",
            "Epoch 355/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1831 - val_loss: 0.1838\n",
            "Loss: 0.1830798238515854\n",
            "Validation Loss: 0.18377815186977386\n",
            "\n",
            "Epoch 356/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1834 - val_loss: 0.1858\n",
            "Loss: 0.18337690830230713\n",
            "Validation Loss: 0.18577134609222412\n",
            "\n",
            "Epoch 357/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1832 - val_loss: 0.1845\n",
            "Loss: 0.18323813378810883\n",
            "Validation Loss: 0.1845361292362213\n",
            "\n",
            "Epoch 358/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1839 - val_loss: 0.1846\n",
            "Loss: 0.18388797342777252\n",
            "Validation Loss: 0.18463391065597534\n",
            "\n",
            "Epoch 359/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1852 - val_loss: 0.1844\n",
            "Loss: 0.18524277210235596\n",
            "Validation Loss: 0.18439491093158722\n",
            "\n",
            "Epoch 360/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1845 - val_loss: 0.1839\n",
            "Loss: 0.18449175357818604\n",
            "Validation Loss: 0.1839160919189453\n",
            "\n",
            "Epoch 361/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1821 - val_loss: 0.1849\n",
            "Loss: 0.1820799559354782\n",
            "Validation Loss: 0.1849215179681778\n",
            "\n",
            "Epoch 362/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1836 - val_loss: 0.1842\n",
            "Loss: 0.18364185094833374\n",
            "Validation Loss: 0.1841776818037033\n",
            "\n",
            "Epoch 363/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1843 - val_loss: 0.1820\n",
            "Loss: 0.1842527836561203\n",
            "Validation Loss: 0.18203486502170563\n",
            "\n",
            "Epoch 364/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1852 - val_loss: 0.1841\n",
            "Loss: 0.1851738542318344\n",
            "Validation Loss: 0.18407215178012848\n",
            "\n",
            "Epoch 365/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1835 - val_loss: 0.1851\n",
            "Loss: 0.1834501028060913\n",
            "Validation Loss: 0.18510335683822632\n",
            "\n",
            "Epoch 366/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1835 - val_loss: 0.1836\n",
            "Loss: 0.1834748536348343\n",
            "Validation Loss: 0.18362967669963837\n",
            "\n",
            "Epoch 367/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1833 - val_loss: 0.1832\n",
            "Loss: 0.18334437906742096\n",
            "Validation Loss: 0.18315163254737854\n",
            "\n",
            "Epoch 368/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1819 - val_loss: 0.1854\n",
            "Loss: 0.18194431066513062\n",
            "Validation Loss: 0.18541674315929413\n",
            "\n",
            "Epoch 369/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1819 - val_loss: 0.1843\n",
            "Loss: 0.18187934160232544\n",
            "Validation Loss: 0.18425948917865753\n",
            "\n",
            "Epoch 370/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1829 - val_loss: 0.1866\n",
            "Loss: 0.18290969729423523\n",
            "Validation Loss: 0.1865672767162323\n",
            "\n",
            "Epoch 371/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1833 - val_loss: 0.1846\n",
            "Loss: 0.18327046930789948\n",
            "Validation Loss: 0.1845908910036087\n",
            "\n",
            "Epoch 372/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1826 - val_loss: 0.1827\n",
            "Loss: 0.1825823038816452\n",
            "Validation Loss: 0.182717964053154\n",
            "\n",
            "Epoch 373/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1835 - val_loss: 0.1826\n",
            "Loss: 0.18348370492458344\n",
            "Validation Loss: 0.18256524205207825\n",
            "\n",
            "Epoch 374/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1836 - val_loss: 0.1842\n",
            "Loss: 0.183643639087677\n",
            "Validation Loss: 0.18417814373970032\n",
            "\n",
            "Epoch 375/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1829 - val_loss: 0.1827\n",
            "Loss: 0.18292579054832458\n",
            "Validation Loss: 0.18271873891353607\n",
            "\n",
            "Epoch 376/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1822 - val_loss: 0.1830\n",
            "Loss: 0.18217577040195465\n",
            "Validation Loss: 0.1829637885093689\n",
            "\n",
            "Epoch 377/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1813 - val_loss: 0.1853\n",
            "Loss: 0.1813267022371292\n",
            "Validation Loss: 0.18533821403980255\n",
            "\n",
            "Epoch 378/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1828 - val_loss: 0.1817\n",
            "Loss: 0.18279193341732025\n",
            "Validation Loss: 0.1816599816083908\n",
            "\n",
            "Epoch 379/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1814 - val_loss: 0.1828\n",
            "Loss: 0.1814136505126953\n",
            "Validation Loss: 0.1828349530696869\n",
            "\n",
            "Epoch 380/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1831 - val_loss: 0.1815\n",
            "Loss: 0.18312720954418182\n",
            "Validation Loss: 0.18149372935295105\n",
            "\n",
            "Epoch 381/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1831 - val_loss: 0.1838\n",
            "Loss: 0.18310682475566864\n",
            "Validation Loss: 0.18375806510448456\n",
            "\n",
            "Epoch 382/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1822 - val_loss: 0.1821\n",
            "Loss: 0.18220816552639008\n",
            "Validation Loss: 0.18212884664535522\n",
            "\n",
            "Epoch 383/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1824 - val_loss: 0.1830\n",
            "Loss: 0.18237020075321198\n",
            "Validation Loss: 0.1829816699028015\n",
            "\n",
            "Epoch 384/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1817 - val_loss: 0.1828\n",
            "Loss: 0.1817348450422287\n",
            "Validation Loss: 0.18284110724925995\n",
            "\n",
            "Epoch 385/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1824 - val_loss: 0.1805\n",
            "Loss: 0.1824323832988739\n",
            "Validation Loss: 0.18050828576087952\n",
            "\n",
            "Epoch 386/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1825 - val_loss: 0.1845\n",
            "Loss: 0.18252532184123993\n",
            "Validation Loss: 0.1844850480556488\n",
            "\n",
            "Epoch 387/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1812 - val_loss: 0.1841\n",
            "Loss: 0.18122218549251556\n",
            "Validation Loss: 0.1840551495552063\n",
            "\n",
            "Epoch 388/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1821 - val_loss: 0.1825\n",
            "Loss: 0.18211860954761505\n",
            "Validation Loss: 0.18254488706588745\n",
            "\n",
            "Epoch 389/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1821 - val_loss: 0.1826\n",
            "Loss: 0.18211084604263306\n",
            "Validation Loss: 0.18257226049900055\n",
            "\n",
            "Epoch 390/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1818 - val_loss: 0.1853\n",
            "Loss: 0.18182405829429626\n",
            "Validation Loss: 0.1853024959564209\n",
            "\n",
            "Epoch 391/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1816 - val_loss: 0.1821\n",
            "Loss: 0.18157760798931122\n",
            "Validation Loss: 0.18214470148086548\n",
            "\n",
            "Epoch 392/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1823 - val_loss: 0.1822\n",
            "Loss: 0.1823243647813797\n",
            "Validation Loss: 0.18219593167304993\n",
            "\n",
            "Epoch 393/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1818 - val_loss: 0.1826\n",
            "Loss: 0.1818217635154724\n",
            "Validation Loss: 0.18257954716682434\n",
            "\n",
            "Epoch 394/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1826 - val_loss: 0.1845\n",
            "Loss: 0.18258392810821533\n",
            "Validation Loss: 0.18451175093650818\n",
            "\n",
            "Epoch 395/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1815 - val_loss: 0.1851\n",
            "Loss: 0.1814892739057541\n",
            "Validation Loss: 0.185093954205513\n",
            "\n",
            "Epoch 396/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1820 - val_loss: 0.1848\n",
            "Loss: 0.1820068061351776\n",
            "Validation Loss: 0.1848420947790146\n",
            "\n",
            "Epoch 397/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1797 - val_loss: 0.1843\n",
            "Loss: 0.1797335147857666\n",
            "Validation Loss: 0.1843467652797699\n",
            "\n",
            "Epoch 398/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1816 - val_loss: 0.1833\n",
            "Loss: 0.18160806596279144\n",
            "Validation Loss: 0.18334731459617615\n",
            "\n",
            "Epoch 399/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1825 - val_loss: 0.1823\n",
            "Loss: 0.18254466354846954\n",
            "Validation Loss: 0.18231803178787231\n",
            "\n",
            "Epoch 400/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1819 - val_loss: 0.1816\n",
            "Loss: 0.181862935423851\n",
            "Validation Loss: 0.18159592151641846\n",
            "\n",
            "Epoch 401/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1817 - val_loss: 0.1838\n",
            "Loss: 0.1816999763250351\n",
            "Validation Loss: 0.18378253281116486\n",
            "\n",
            "Epoch 402/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1812 - val_loss: 0.1822\n",
            "Loss: 0.1812056452035904\n",
            "Validation Loss: 0.1821541041135788\n",
            "\n",
            "Epoch 403/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1805 - val_loss: 0.1832\n",
            "Loss: 0.1805400401353836\n",
            "Validation Loss: 0.1831660121679306\n",
            "\n",
            "Epoch 404/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1818 - val_loss: 0.1823\n",
            "Loss: 0.18183985352516174\n",
            "Validation Loss: 0.18230557441711426\n",
            "\n",
            "Epoch 405/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1812 - val_loss: 0.1808\n",
            "Loss: 0.1812475472688675\n",
            "Validation Loss: 0.1808028370141983\n",
            "\n",
            "Epoch 406/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1815 - val_loss: 0.1814\n",
            "Loss: 0.181483656167984\n",
            "Validation Loss: 0.18138247728347778\n",
            "\n",
            "Epoch 407/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1821 - val_loss: 0.1809\n",
            "Loss: 0.18211932480335236\n",
            "Validation Loss: 0.1809350550174713\n",
            "\n",
            "Epoch 408/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1809 - val_loss: 0.1811\n",
            "Loss: 0.18091654777526855\n",
            "Validation Loss: 0.1810881346464157\n",
            "\n",
            "Epoch 409/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1796 - val_loss: 0.1835\n",
            "Loss: 0.1796296238899231\n",
            "Validation Loss: 0.18348468840122223\n",
            "\n",
            "Epoch 410/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1802 - val_loss: 0.1845\n",
            "Loss: 0.18015623092651367\n",
            "Validation Loss: 0.18452037870883942\n",
            "\n",
            "Epoch 411/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1804 - val_loss: 0.1846\n",
            "Loss: 0.18038183450698853\n",
            "Validation Loss: 0.18460193276405334\n",
            "\n",
            "Epoch 412/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1802 - val_loss: 0.1805\n",
            "Loss: 0.18020758032798767\n",
            "Validation Loss: 0.1805064082145691\n",
            "\n",
            "Epoch 413/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1802 - val_loss: 0.1794\n",
            "Loss: 0.18016664683818817\n",
            "Validation Loss: 0.17938435077667236\n",
            "\n",
            "Epoch 414/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1816 - val_loss: 0.1806\n",
            "Loss: 0.18155552446842194\n",
            "Validation Loss: 0.18060117959976196\n",
            "\n",
            "Epoch 415/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1814 - val_loss: 0.1829\n",
            "Loss: 0.181360125541687\n",
            "Validation Loss: 0.18289019167423248\n",
            "\n",
            "Epoch 416/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1800 - val_loss: 0.1809\n",
            "Loss: 0.1800355464220047\n",
            "Validation Loss: 0.18092429637908936\n",
            "\n",
            "Epoch 417/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1798 - val_loss: 0.1801\n",
            "Loss: 0.17975924909114838\n",
            "Validation Loss: 0.18007530272006989\n",
            "\n",
            "Epoch 418/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1796 - val_loss: 0.1813\n",
            "Loss: 0.17956921458244324\n",
            "Validation Loss: 0.18129335343837738\n",
            "\n",
            "Epoch 419/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1798 - val_loss: 0.1824\n",
            "Loss: 0.17977245151996613\n",
            "Validation Loss: 0.18242698907852173\n",
            "\n",
            "Epoch 420/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1804 - val_loss: 0.1803\n",
            "Loss: 0.18037837743759155\n",
            "Validation Loss: 0.1803334355354309\n",
            "\n",
            "Epoch 421/750\n",
            "21/21 [==============================] - 4s 171ms/step - loss: 0.1803 - val_loss: 0.1800\n",
            "Loss: 0.18027284741401672\n",
            "Validation Loss: 0.17999394237995148\n",
            "\n",
            "Epoch 422/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1801 - val_loss: 0.1798\n",
            "Loss: 0.18009738624095917\n",
            "Validation Loss: 0.1797696053981781\n",
            "\n",
            "Epoch 423/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1808 - val_loss: 0.1784\n",
            "Loss: 0.18081507086753845\n",
            "Validation Loss: 0.1784384846687317\n",
            "\n",
            "Epoch 424/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1803 - val_loss: 0.1809\n",
            "Loss: 0.18030360341072083\n",
            "Validation Loss: 0.18089796602725983\n",
            "\n",
            "Epoch 425/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1802 - val_loss: 0.1801\n",
            "Loss: 0.18016405403614044\n",
            "Validation Loss: 0.18005795776844025\n",
            "\n",
            "Epoch 426/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1794 - val_loss: 0.1798\n",
            "Loss: 0.17940445244312286\n",
            "Validation Loss: 0.17975568771362305\n",
            "\n",
            "Epoch 427/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1801 - val_loss: 0.1795\n",
            "Loss: 0.18012483417987823\n",
            "Validation Loss: 0.179486945271492\n",
            "\n",
            "Epoch 428/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1795 - val_loss: 0.1845\n",
            "Loss: 0.1795322597026825\n",
            "Validation Loss: 0.18453086912631989\n",
            "\n",
            "Epoch 429/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1806 - val_loss: 0.1795\n",
            "Loss: 0.18055102229118347\n",
            "Validation Loss: 0.17945215106010437\n",
            "\n",
            "Epoch 430/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1805 - val_loss: 0.1807\n",
            "Loss: 0.18046291172504425\n",
            "Validation Loss: 0.18074482679367065\n",
            "\n",
            "Epoch 431/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Loss: 0.18007785081863403\n",
            "Validation Loss: 0.17935936152935028\n",
            "\n",
            "Epoch 432/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1800 - val_loss: 0.1794\n",
            "Loss: 0.18001797795295715\n",
            "Validation Loss: 0.17942717671394348\n",
            "\n",
            "Epoch 433/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1794 - val_loss: 0.1802\n",
            "Loss: 0.17938543856143951\n",
            "Validation Loss: 0.1802038699388504\n",
            "\n",
            "Epoch 434/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1800 - val_loss: 0.1796\n",
            "Loss: 0.17999367415905\n",
            "Validation Loss: 0.17956353724002838\n",
            "\n",
            "Epoch 435/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1795 - val_loss: 0.1788\n",
            "Loss: 0.17953449487686157\n",
            "Validation Loss: 0.1787649244070053\n",
            "\n",
            "Epoch 436/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1800 - val_loss: 0.1815\n",
            "Loss: 0.1799870878458023\n",
            "Validation Loss: 0.18153780698776245\n",
            "\n",
            "Epoch 437/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1804 - val_loss: 0.1805\n",
            "Loss: 0.18041841685771942\n",
            "Validation Loss: 0.18051248788833618\n",
            "\n",
            "Epoch 438/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1794 - val_loss: 0.1792\n",
            "Loss: 0.1793949007987976\n",
            "Validation Loss: 0.1791965812444687\n",
            "\n",
            "Epoch 439/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1800 - val_loss: 0.1782\n",
            "Loss: 0.1800227165222168\n",
            "Validation Loss: 0.17819322645664215\n",
            "\n",
            "Epoch 440/750\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1791 - val_loss: 0.1788\n",
            "Loss: 0.17910705506801605\n",
            "Validation Loss: 0.17883001267910004\n",
            "\n",
            "Epoch 441/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1802 - val_loss: 0.1818\n",
            "Loss: 0.18022093176841736\n",
            "Validation Loss: 0.18179923295974731\n",
            "\n",
            "Epoch 442/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1785 - val_loss: 0.1805\n",
            "Loss: 0.17850053310394287\n",
            "Validation Loss: 0.180498868227005\n",
            "\n",
            "Epoch 443/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1781 - val_loss: 0.1810\n",
            "Loss: 0.17809903621673584\n",
            "Validation Loss: 0.1810164600610733\n",
            "\n",
            "Epoch 444/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1780 - val_loss: 0.1810\n",
            "Loss: 0.17798522114753723\n",
            "Validation Loss: 0.18096350133419037\n",
            "\n",
            "Epoch 445/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1794 - val_loss: 0.1777\n",
            "Loss: 0.17938335239887238\n",
            "Validation Loss: 0.17767107486724854\n",
            "\n",
            "Epoch 446/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1785 - val_loss: 0.1792\n",
            "Loss: 0.17854629456996918\n",
            "Validation Loss: 0.17921465635299683\n",
            "\n",
            "Epoch 447/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1782 - val_loss: 0.1785\n",
            "Loss: 0.17818386852741241\n",
            "Validation Loss: 0.17850807309150696\n",
            "\n",
            "Epoch 448/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1787 - val_loss: 0.1839\n",
            "Loss: 0.17868557572364807\n",
            "Validation Loss: 0.18394741415977478\n",
            "\n",
            "Epoch 449/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1795 - val_loss: 0.1806\n",
            "Loss: 0.17954900860786438\n",
            "Validation Loss: 0.18059998750686646\n",
            "\n",
            "Epoch 450/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1791 - val_loss: 0.1795\n",
            "Loss: 0.17907209694385529\n",
            "Validation Loss: 0.1795133501291275\n",
            "\n",
            "Epoch 451/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1770 - val_loss: 0.1788\n",
            "Loss: 0.17703725397586823\n",
            "Validation Loss: 0.17877225577831268\n",
            "\n",
            "Epoch 452/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1786 - val_loss: 0.1779\n",
            "Loss: 0.17858535051345825\n",
            "Validation Loss: 0.1779160499572754\n",
            "\n",
            "Epoch 453/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1777 - val_loss: 0.1789\n",
            "Loss: 0.17774534225463867\n",
            "Validation Loss: 0.17886577546596527\n",
            "\n",
            "Epoch 454/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1768 - val_loss: 0.1792\n",
            "Loss: 0.1767638921737671\n",
            "Validation Loss: 0.179196298122406\n",
            "\n",
            "Epoch 455/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1782 - val_loss: 0.1789\n",
            "Loss: 0.17823514342308044\n",
            "Validation Loss: 0.1788935512304306\n",
            "\n",
            "Epoch 456/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1795 - val_loss: 0.1769\n",
            "Loss: 0.1795089840888977\n",
            "Validation Loss: 0.17686352133750916\n",
            "\n",
            "Epoch 457/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1775 - val_loss: 0.1797\n",
            "Loss: 0.1775369942188263\n",
            "Validation Loss: 0.1797499805688858\n",
            "\n",
            "Epoch 458/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1793 - val_loss: 0.1767\n",
            "Loss: 0.17933404445648193\n",
            "Validation Loss: 0.17665790021419525\n",
            "\n",
            "Epoch 459/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1790 - val_loss: 0.1785\n",
            "Loss: 0.178953617811203\n",
            "Validation Loss: 0.1784566342830658\n",
            "\n",
            "Epoch 460/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1787 - val_loss: 0.1791\n",
            "Loss: 0.17867444455623627\n",
            "Validation Loss: 0.1790805160999298\n",
            "\n",
            "Epoch 461/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1769 - val_loss: 0.1768\n",
            "Loss: 0.17685158550739288\n",
            "Validation Loss: 0.17681090533733368\n",
            "\n",
            "Epoch 462/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1792 - val_loss: 0.1777\n",
            "Loss: 0.17923645675182343\n",
            "Validation Loss: 0.1776837408542633\n",
            "\n",
            "Epoch 463/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1785 - val_loss: 0.1805\n",
            "Loss: 0.17848093807697296\n",
            "Validation Loss: 0.1805000603199005\n",
            "\n",
            "Epoch 464/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1770 - val_loss: 0.1773\n",
            "Loss: 0.17703399062156677\n",
            "Validation Loss: 0.1772719919681549\n",
            "\n",
            "Epoch 465/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1790 - val_loss: 0.1795\n",
            "Loss: 0.17901453375816345\n",
            "Validation Loss: 0.17945070564746857\n",
            "\n",
            "Epoch 466/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1775 - val_loss: 0.1789\n",
            "Loss: 0.17752191424369812\n",
            "Validation Loss: 0.17892427742481232\n",
            "\n",
            "Epoch 467/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1795 - val_loss: 0.1778\n",
            "Loss: 0.17948848009109497\n",
            "Validation Loss: 0.17784066498279572\n",
            "\n",
            "Epoch 468/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1777 - val_loss: 0.1767\n",
            "Loss: 0.17774009704589844\n",
            "Validation Loss: 0.176691934466362\n",
            "\n",
            "Epoch 469/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1781 - val_loss: 0.1762\n",
            "Loss: 0.1780751347541809\n",
            "Validation Loss: 0.17623862624168396\n",
            "\n",
            "Epoch 470/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1780 - val_loss: 0.1779\n",
            "Loss: 0.17802715301513672\n",
            "Validation Loss: 0.17792446911334991\n",
            "\n",
            "Epoch 471/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1786 - val_loss: 0.1766\n",
            "Loss: 0.17859841883182526\n",
            "Validation Loss: 0.17662304639816284\n",
            "\n",
            "Epoch 472/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1783 - val_loss: 0.1799\n",
            "Loss: 0.17827853560447693\n",
            "Validation Loss: 0.17987363040447235\n",
            "\n",
            "Epoch 473/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1774 - val_loss: 0.1788\n",
            "Loss: 0.1773977279663086\n",
            "Validation Loss: 0.17882290482521057\n",
            "\n",
            "Epoch 474/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1768 - val_loss: 0.1775\n",
            "Loss: 0.17683406174182892\n",
            "Validation Loss: 0.17753151059150696\n",
            "\n",
            "Epoch 475/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1762 - val_loss: 0.1786\n",
            "Loss: 0.17620229721069336\n",
            "Validation Loss: 0.17861302196979523\n",
            "\n",
            "Epoch 476/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1761 - val_loss: 0.1783\n",
            "Loss: 0.17613868415355682\n",
            "Validation Loss: 0.17834579944610596\n",
            "\n",
            "Epoch 477/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1773 - val_loss: 0.1775\n",
            "Loss: 0.17731522023677826\n",
            "Validation Loss: 0.1775258183479309\n",
            "\n",
            "Epoch 478/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1771 - val_loss: 0.1791\n",
            "Loss: 0.17711858451366425\n",
            "Validation Loss: 0.17914877831935883\n",
            "\n",
            "Epoch 479/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1786 - val_loss: 0.1792\n",
            "Loss: 0.17857463657855988\n",
            "Validation Loss: 0.1791970431804657\n",
            "\n",
            "Epoch 480/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1791 - val_loss: 0.1781\n",
            "Loss: 0.17911355197429657\n",
            "Validation Loss: 0.1781029999256134\n",
            "\n",
            "Epoch 481/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1762 - val_loss: 0.1789\n",
            "Loss: 0.1762119084596634\n",
            "Validation Loss: 0.17886628210544586\n",
            "\n",
            "Epoch 482/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1771 - val_loss: 0.1771\n",
            "Loss: 0.17705616354942322\n",
            "Validation Loss: 0.17713764309883118\n",
            "\n",
            "Epoch 483/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1773 - val_loss: 0.1801\n",
            "Loss: 0.1772804856300354\n",
            "Validation Loss: 0.1800892949104309\n",
            "\n",
            "Epoch 484/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1781 - val_loss: 0.1793\n",
            "Loss: 0.17809590697288513\n",
            "Validation Loss: 0.1792869120836258\n",
            "\n",
            "Epoch 485/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1771 - val_loss: 0.1805\n",
            "Loss: 0.17705127596855164\n",
            "Validation Loss: 0.1804763525724411\n",
            "\n",
            "Epoch 486/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1771 - val_loss: 0.1786\n",
            "Loss: 0.1771019697189331\n",
            "Validation Loss: 0.17863543331623077\n",
            "\n",
            "Epoch 487/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1792 - val_loss: 0.1759\n",
            "Loss: 0.17923396825790405\n",
            "Validation Loss: 0.17585918307304382\n",
            "\n",
            "Epoch 488/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1779 - val_loss: 0.1769\n",
            "Loss: 0.17786049842834473\n",
            "Validation Loss: 0.17693296074867249\n",
            "\n",
            "Epoch 489/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1776 - val_loss: 0.1753\n",
            "Loss: 0.1776447743177414\n",
            "Validation Loss: 0.1753029227256775\n",
            "\n",
            "Epoch 490/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1754 - val_loss: 0.1751\n",
            "Loss: 0.17539219558238983\n",
            "Validation Loss: 0.17514735460281372\n",
            "\n",
            "Epoch 491/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1760 - val_loss: 0.1772\n",
            "Loss: 0.17597854137420654\n",
            "Validation Loss: 0.17720474302768707\n",
            "\n",
            "Epoch 492/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1761 - val_loss: 0.1774\n",
            "Loss: 0.1761418879032135\n",
            "Validation Loss: 0.1774033010005951\n",
            "\n",
            "Epoch 493/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1763 - val_loss: 0.1761\n",
            "Loss: 0.1762533187866211\n",
            "Validation Loss: 0.17613445222377777\n",
            "\n",
            "Epoch 494/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1770 - val_loss: 0.1766\n",
            "Loss: 0.1769787073135376\n",
            "Validation Loss: 0.17659315466880798\n",
            "\n",
            "Epoch 495/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1761 - val_loss: 0.1767\n",
            "Loss: 0.17610220611095428\n",
            "Validation Loss: 0.17669712007045746\n",
            "\n",
            "Epoch 496/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1770 - val_loss: 0.1758\n",
            "Loss: 0.17701274156570435\n",
            "Validation Loss: 0.17580915987491608\n",
            "\n",
            "Epoch 497/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1769 - val_loss: 0.1777\n",
            "Loss: 0.17690162360668182\n",
            "Validation Loss: 0.17770734429359436\n",
            "\n",
            "Epoch 498/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1764 - val_loss: 0.1760\n",
            "Loss: 0.1763657182455063\n",
            "Validation Loss: 0.1759970337152481\n",
            "\n",
            "Epoch 499/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1769 - val_loss: 0.1802\n",
            "Loss: 0.17689409852027893\n",
            "Validation Loss: 0.18023531138896942\n",
            "\n",
            "Epoch 500/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1767 - val_loss: 0.1788\n",
            "Loss: 0.17673653364181519\n",
            "Validation Loss: 0.17881247401237488\n",
            "\n",
            "Epoch 501/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1771 - val_loss: 0.1770\n",
            "Loss: 0.17706020176410675\n",
            "Validation Loss: 0.17699754238128662\n",
            "\n",
            "Epoch 502/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1772 - val_loss: 0.1785\n",
            "Loss: 0.17718841135501862\n",
            "Validation Loss: 0.1785118132829666\n",
            "\n",
            "Epoch 503/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1761 - val_loss: 0.1763\n",
            "Loss: 0.17605756223201752\n",
            "Validation Loss: 0.17627787590026855\n",
            "\n",
            "Epoch 504/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1753 - val_loss: 0.1769\n",
            "Loss: 0.17528299987316132\n",
            "Validation Loss: 0.17689839005470276\n",
            "\n",
            "Epoch 505/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1772 - val_loss: 0.1771\n",
            "Loss: 0.17724134027957916\n",
            "Validation Loss: 0.17712731659412384\n",
            "\n",
            "Epoch 506/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1758 - val_loss: 0.1754\n",
            "Loss: 0.17580832540988922\n",
            "Validation Loss: 0.1754128485918045\n",
            "\n",
            "Epoch 507/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1755 - val_loss: 0.1768\n",
            "Loss: 0.17549432814121246\n",
            "Validation Loss: 0.17683714628219604\n",
            "\n",
            "Epoch 508/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1769 - val_loss: 0.1776\n",
            "Loss: 0.17689499258995056\n",
            "Validation Loss: 0.17764945328235626\n",
            "\n",
            "Epoch 509/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1775 - val_loss: 0.1764\n",
            "Loss: 0.17747172713279724\n",
            "Validation Loss: 0.17636685073375702\n",
            "\n",
            "Epoch 510/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1756 - val_loss: 0.1746\n",
            "Loss: 0.17563290894031525\n",
            "Validation Loss: 0.17455153167247772\n",
            "\n",
            "Epoch 511/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1770 - val_loss: 0.1773\n",
            "Loss: 0.17695841193199158\n",
            "Validation Loss: 0.17734868824481964\n",
            "\n",
            "Epoch 512/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1753 - val_loss: 0.1778\n",
            "Loss: 0.1753336638212204\n",
            "Validation Loss: 0.17777173221111298\n",
            "\n",
            "Epoch 513/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1754 - val_loss: 0.1782\n",
            "Loss: 0.17535972595214844\n",
            "Validation Loss: 0.1781938374042511\n",
            "\n",
            "Epoch 514/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1764 - val_loss: 0.1782\n",
            "Loss: 0.17635828256607056\n",
            "Validation Loss: 0.17816656827926636\n",
            "\n",
            "Epoch 515/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1759 - val_loss: 0.1773\n",
            "Loss: 0.17586347460746765\n",
            "Validation Loss: 0.1772644817829132\n",
            "\n",
            "Epoch 516/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1758 - val_loss: 0.1765\n",
            "Loss: 0.1757831573486328\n",
            "Validation Loss: 0.17651231586933136\n",
            "\n",
            "Epoch 517/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1760 - val_loss: 0.1764\n",
            "Loss: 0.176040917634964\n",
            "Validation Loss: 0.17636193335056305\n",
            "\n",
            "Epoch 518/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1766 - val_loss: 0.1759\n",
            "Loss: 0.1766366958618164\n",
            "Validation Loss: 0.1758546382188797\n",
            "\n",
            "Epoch 519/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1763 - val_loss: 0.1765\n",
            "Loss: 0.1763373762369156\n",
            "Validation Loss: 0.17649848759174347\n",
            "\n",
            "Epoch 520/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1764 - val_loss: 0.1766\n",
            "Loss: 0.17640340328216553\n",
            "Validation Loss: 0.1766366958618164\n",
            "\n",
            "Epoch 521/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1758 - val_loss: 0.1746\n",
            "Loss: 0.17576375603675842\n",
            "Validation Loss: 0.17460449039936066\n",
            "\n",
            "Epoch 522/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1751 - val_loss: 0.1755\n",
            "Loss: 0.17510312795639038\n",
            "Validation Loss: 0.17546170949935913\n",
            "\n",
            "Epoch 523/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1745 - val_loss: 0.1783\n",
            "Loss: 0.17453692853450775\n",
            "Validation Loss: 0.1783120036125183\n",
            "\n",
            "Epoch 524/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1769 - val_loss: 0.1763\n",
            "Loss: 0.17691412568092346\n",
            "Validation Loss: 0.17632073163986206\n",
            "\n",
            "Epoch 525/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1760 - val_loss: 0.1747\n",
            "Loss: 0.1760273426771164\n",
            "Validation Loss: 0.17465803027153015\n",
            "\n",
            "Epoch 526/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1766 - val_loss: 0.1766\n",
            "Loss: 0.17659880220890045\n",
            "Validation Loss: 0.17664599418640137\n",
            "\n",
            "Epoch 527/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1759 - val_loss: 0.1771\n",
            "Loss: 0.1759093552827835\n",
            "Validation Loss: 0.17706198990345\n",
            "\n",
            "Epoch 528/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1765 - val_loss: 0.1799\n",
            "Loss: 0.17654003202915192\n",
            "Validation Loss: 0.1799149364233017\n",
            "\n",
            "Epoch 529/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1764 - val_loss: 0.1776\n",
            "Loss: 0.1763545125722885\n",
            "Validation Loss: 0.17757068574428558\n",
            "\n",
            "Epoch 530/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1751 - val_loss: 0.1781\n",
            "Loss: 0.17510810494422913\n",
            "Validation Loss: 0.1781260073184967\n",
            "\n",
            "Epoch 531/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1755 - val_loss: 0.1773\n",
            "Loss: 0.17548049986362457\n",
            "Validation Loss: 0.1773141622543335\n",
            "\n",
            "Epoch 532/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1753 - val_loss: 0.1750\n",
            "Loss: 0.17525175213813782\n",
            "Validation Loss: 0.17498764395713806\n",
            "\n",
            "Epoch 533/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1772 - val_loss: 0.1759\n",
            "Loss: 0.17723149061203003\n",
            "Validation Loss: 0.17593128979206085\n",
            "\n",
            "Epoch 534/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1755 - val_loss: 0.1778\n",
            "Loss: 0.17552395164966583\n",
            "Validation Loss: 0.1778138130903244\n",
            "\n",
            "Epoch 535/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1754 - val_loss: 0.1781\n",
            "Loss: 0.17540214955806732\n",
            "Validation Loss: 0.17805854976177216\n",
            "\n",
            "Epoch 536/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1755 - val_loss: 0.1751\n",
            "Loss: 0.17554867267608643\n",
            "Validation Loss: 0.1751072108745575\n",
            "\n",
            "Epoch 537/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1749 - val_loss: 0.1751\n",
            "Loss: 0.174886554479599\n",
            "Validation Loss: 0.17507368326187134\n",
            "\n",
            "Epoch 538/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1748 - val_loss: 0.1756\n",
            "Loss: 0.1748444139957428\n",
            "Validation Loss: 0.17560343444347382\n",
            "\n",
            "Epoch 539/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1750 - val_loss: 0.1752\n",
            "Loss: 0.1749650090932846\n",
            "Validation Loss: 0.17521940171718597\n",
            "\n",
            "Epoch 540/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1748 - val_loss: 0.1752\n",
            "Loss: 0.17477130889892578\n",
            "Validation Loss: 0.17517094314098358\n",
            "\n",
            "Epoch 541/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1761 - val_loss: 0.1769\n",
            "Loss: 0.1760728806257248\n",
            "Validation Loss: 0.1768866777420044\n",
            "\n",
            "Epoch 542/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1756 - val_loss: 0.1764\n",
            "Loss: 0.175599604845047\n",
            "Validation Loss: 0.1764010637998581\n",
            "\n",
            "Epoch 543/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1762 - val_loss: 0.1768\n",
            "Loss: 0.17617692053318024\n",
            "Validation Loss: 0.17679257690906525\n",
            "\n",
            "Epoch 544/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1760 - val_loss: 0.1749\n",
            "Loss: 0.17603561282157898\n",
            "Validation Loss: 0.1748596876859665\n",
            "\n",
            "Epoch 545/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1768 - val_loss: 0.1749\n",
            "Loss: 0.17683814465999603\n",
            "Validation Loss: 0.1748700737953186\n",
            "\n",
            "Epoch 546/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1757 - val_loss: 0.1765\n",
            "Loss: 0.17566007375717163\n",
            "Validation Loss: 0.1764885038137436\n",
            "\n",
            "Epoch 547/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1743 - val_loss: 0.1764\n",
            "Loss: 0.17425473034381866\n",
            "Validation Loss: 0.17642734944820404\n",
            "\n",
            "Epoch 548/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1754 - val_loss: 0.1769\n",
            "Loss: 0.1753806322813034\n",
            "Validation Loss: 0.17688488960266113\n",
            "\n",
            "Epoch 549/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1750 - val_loss: 0.1751\n",
            "Loss: 0.17495545744895935\n",
            "Validation Loss: 0.17505984008312225\n",
            "\n",
            "Epoch 550/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1752 - val_loss: 0.1793\n",
            "Loss: 0.175245001912117\n",
            "Validation Loss: 0.17931000888347626\n",
            "\n",
            "Epoch 551/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1759 - val_loss: 0.1776\n",
            "Loss: 0.1758904755115509\n",
            "Validation Loss: 0.1776372194290161\n",
            "\n",
            "Epoch 552/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1742 - val_loss: 0.1746\n",
            "Loss: 0.17421339452266693\n",
            "Validation Loss: 0.17464278638362885\n",
            "\n",
            "Epoch 553/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1745 - val_loss: 0.1757\n",
            "Loss: 0.17447823286056519\n",
            "Validation Loss: 0.17573577165603638\n",
            "\n",
            "Epoch 554/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1741 - val_loss: 0.1763\n",
            "Loss: 0.1740603893995285\n",
            "Validation Loss: 0.17625169456005096\n",
            "\n",
            "Epoch 555/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1748 - val_loss: 0.1761\n",
            "Loss: 0.17477133870124817\n",
            "Validation Loss: 0.1761447936296463\n",
            "\n",
            "Epoch 556/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1746 - val_loss: 0.1783\n",
            "Loss: 0.17457012832164764\n",
            "Validation Loss: 0.1782846301794052\n",
            "\n",
            "Epoch 557/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1749 - val_loss: 0.1751\n",
            "Loss: 0.17490015923976898\n",
            "Validation Loss: 0.17511051893234253\n",
            "\n",
            "Epoch 558/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1753 - val_loss: 0.1748\n",
            "Loss: 0.1752796769142151\n",
            "Validation Loss: 0.1747630089521408\n",
            "\n",
            "Epoch 559/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1758 - val_loss: 0.1766\n",
            "Loss: 0.1757703274488449\n",
            "Validation Loss: 0.17658260464668274\n",
            "\n",
            "Epoch 560/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1727 - val_loss: 0.1744\n",
            "Loss: 0.17272326350212097\n",
            "Validation Loss: 0.174409881234169\n",
            "\n",
            "Epoch 561/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1738 - val_loss: 0.1751\n",
            "Loss: 0.17383143305778503\n",
            "Validation Loss: 0.17505872249603271\n",
            "\n",
            "Epoch 562/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1742 - val_loss: 0.1740\n",
            "Loss: 0.17423631250858307\n",
            "Validation Loss: 0.17400053143501282\n",
            "\n",
            "Epoch 563/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1732 - val_loss: 0.1764\n",
            "Loss: 0.1731700599193573\n",
            "Validation Loss: 0.17641282081604004\n",
            "\n",
            "Epoch 564/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1731 - val_loss: 0.1764\n",
            "Loss: 0.17311610281467438\n",
            "Validation Loss: 0.1763717532157898\n",
            "\n",
            "Epoch 565/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1739 - val_loss: 0.1783\n",
            "Loss: 0.1738627851009369\n",
            "Validation Loss: 0.17834384739398956\n",
            "\n",
            "Epoch 566/750\n",
            "21/21 [==============================] - 4s 178ms/step - loss: 0.1747 - val_loss: 0.1766\n",
            "Loss: 0.1746707558631897\n",
            "Validation Loss: 0.17656128108501434\n",
            "\n",
            "Epoch 567/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1751 - val_loss: 0.1750\n",
            "Loss: 0.17510108649730682\n",
            "Validation Loss: 0.175001323223114\n",
            "\n",
            "Epoch 568/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1741 - val_loss: 0.1757\n",
            "Loss: 0.1740940362215042\n",
            "Validation Loss: 0.17573297023773193\n",
            "\n",
            "Epoch 569/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1755 - val_loss: 0.1752\n",
            "Loss: 0.17549090087413788\n",
            "Validation Loss: 0.1752454936504364\n",
            "\n",
            "Epoch 570/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1735 - val_loss: 0.1756\n",
            "Loss: 0.17352299392223358\n",
            "Validation Loss: 0.17559616267681122\n",
            "\n",
            "Epoch 571/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1733 - val_loss: 0.1740\n",
            "Loss: 0.17325611412525177\n",
            "Validation Loss: 0.17403638362884521\n",
            "\n",
            "Epoch 572/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1750 - val_loss: 0.1772\n",
            "Loss: 0.1750102937221527\n",
            "Validation Loss: 0.17721396684646606\n",
            "\n",
            "Epoch 573/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1750 - val_loss: 0.1752\n",
            "Loss: 0.17497995495796204\n",
            "Validation Loss: 0.1751750111579895\n",
            "\n",
            "Epoch 574/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1732 - val_loss: 0.1754\n",
            "Loss: 0.17321619391441345\n",
            "Validation Loss: 0.1753806471824646\n",
            "\n",
            "Epoch 575/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1738 - val_loss: 0.1769\n",
            "Loss: 0.17384900152683258\n",
            "Validation Loss: 0.17688703536987305\n",
            "\n",
            "Epoch 576/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1748 - val_loss: 0.1744\n",
            "Loss: 0.1748117357492447\n",
            "Validation Loss: 0.1743764579296112\n",
            "\n",
            "Epoch 577/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1739 - val_loss: 0.1762\n",
            "Loss: 0.17388275265693665\n",
            "Validation Loss: 0.17616456747055054\n",
            "\n",
            "Epoch 578/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1733 - val_loss: 0.1762\n",
            "Loss: 0.1732979714870453\n",
            "Validation Loss: 0.1762038916349411\n",
            "\n",
            "Epoch 579/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1732 - val_loss: 0.1753\n",
            "Loss: 0.17324836552143097\n",
            "Validation Loss: 0.17532691359519958\n",
            "\n",
            "Epoch 580/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1736 - val_loss: 0.1764\n",
            "Loss: 0.17355328798294067\n",
            "Validation Loss: 0.17642150819301605\n",
            "\n",
            "Epoch 581/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1750 - val_loss: 0.1755\n",
            "Loss: 0.1749713271856308\n",
            "Validation Loss: 0.17554348707199097\n",
            "\n",
            "Epoch 582/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1732 - val_loss: 0.1771\n",
            "Loss: 0.17324696481227875\n",
            "Validation Loss: 0.1771317720413208\n",
            "\n",
            "Epoch 583/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1737 - val_loss: 0.1739\n",
            "Loss: 0.17370282113552094\n",
            "Validation Loss: 0.17393389344215393\n",
            "\n",
            "Epoch 584/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1738 - val_loss: 0.1738\n",
            "Loss: 0.17381078004837036\n",
            "Validation Loss: 0.17381292581558228\n",
            "\n",
            "Epoch 585/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1737 - val_loss: 0.1758\n",
            "Loss: 0.17369584739208221\n",
            "Validation Loss: 0.17581820487976074\n",
            "\n",
            "Epoch 586/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1749 - val_loss: 0.1751\n",
            "Loss: 0.17493665218353271\n",
            "Validation Loss: 0.17507268488407135\n",
            "\n",
            "Epoch 587/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1744 - val_loss: 0.1743\n",
            "Loss: 0.1744387298822403\n",
            "Validation Loss: 0.1743423044681549\n",
            "\n",
            "Epoch 588/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1725 - val_loss: 0.1761\n",
            "Loss: 0.17252495884895325\n",
            "Validation Loss: 0.17608238756656647\n",
            "\n",
            "Epoch 589/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1729 - val_loss: 0.1762\n",
            "Loss: 0.17289972305297852\n",
            "Validation Loss: 0.17623037099838257\n",
            "\n",
            "Epoch 590/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1741 - val_loss: 0.1750\n",
            "Loss: 0.17406022548675537\n",
            "Validation Loss: 0.17498818039894104\n",
            "\n",
            "Epoch 591/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1742 - val_loss: 0.1748\n",
            "Loss: 0.17417234182357788\n",
            "Validation Loss: 0.17483434081077576\n",
            "\n",
            "Epoch 592/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1720 - val_loss: 0.1737\n",
            "Loss: 0.17197349667549133\n",
            "Validation Loss: 0.17370319366455078\n",
            "\n",
            "Epoch 593/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1735 - val_loss: 0.1748\n",
            "Loss: 0.1735377460718155\n",
            "Validation Loss: 0.17480631172657013\n",
            "\n",
            "Epoch 594/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1758 - val_loss: 0.1732\n",
            "Loss: 0.17579784989356995\n",
            "Validation Loss: 0.17320458590984344\n",
            "\n",
            "Epoch 595/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1735 - val_loss: 0.1753\n",
            "Loss: 0.17347389459609985\n",
            "Validation Loss: 0.17533689737319946\n",
            "\n",
            "Epoch 596/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1733 - val_loss: 0.1737\n",
            "Loss: 0.17329372465610504\n",
            "Validation Loss: 0.17370250821113586\n",
            "\n",
            "Epoch 597/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1735 - val_loss: 0.1745\n",
            "Loss: 0.17347346246242523\n",
            "Validation Loss: 0.17454349994659424\n",
            "\n",
            "Epoch 598/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1737 - val_loss: 0.1747\n",
            "Loss: 0.1737004965543747\n",
            "Validation Loss: 0.17469193041324615\n",
            "\n",
            "Epoch 599/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1717 - val_loss: 0.1733\n",
            "Loss: 0.1717439591884613\n",
            "Validation Loss: 0.17325559258460999\n",
            "\n",
            "Epoch 600/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1734 - val_loss: 0.1755\n",
            "Loss: 0.17338679730892181\n",
            "Validation Loss: 0.17548991739749908\n",
            "\n",
            "Epoch 601/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1740 - val_loss: 0.1730\n",
            "Loss: 0.17395184934139252\n",
            "Validation Loss: 0.1730399876832962\n",
            "\n",
            "Epoch 602/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1735 - val_loss: 0.1743\n",
            "Loss: 0.17350783944129944\n",
            "Validation Loss: 0.1743120551109314\n",
            "\n",
            "Epoch 603/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1729 - val_loss: 0.1757\n",
            "Loss: 0.17286962270736694\n",
            "Validation Loss: 0.17573456466197968\n",
            "\n",
            "Epoch 604/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1728 - val_loss: 0.1739\n",
            "Loss: 0.1728215366601944\n",
            "Validation Loss: 0.17385178804397583\n",
            "\n",
            "Epoch 605/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1746 - val_loss: 0.1749\n",
            "Loss: 0.17455187439918518\n",
            "Validation Loss: 0.17491567134857178\n",
            "\n",
            "Epoch 606/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1729 - val_loss: 0.1743\n",
            "Loss: 0.172866553068161\n",
            "Validation Loss: 0.17428217828273773\n",
            "\n",
            "Epoch 607/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1731 - val_loss: 0.1739\n",
            "Loss: 0.17309115827083588\n",
            "Validation Loss: 0.1739172637462616\n",
            "\n",
            "Epoch 608/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1736 - val_loss: 0.1783\n",
            "Loss: 0.1735982596874237\n",
            "Validation Loss: 0.17830032110214233\n",
            "\n",
            "Epoch 609/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1734 - val_loss: 0.1742\n",
            "Loss: 0.1733817160129547\n",
            "Validation Loss: 0.1741945594549179\n",
            "\n",
            "Epoch 610/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1737 - val_loss: 0.1761\n",
            "Loss: 0.1737229824066162\n",
            "Validation Loss: 0.17608825862407684\n",
            "\n",
            "Epoch 611/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1735 - val_loss: 0.1732\n",
            "Loss: 0.17345240712165833\n",
            "Validation Loss: 0.1732037365436554\n",
            "\n",
            "Epoch 612/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1727 - val_loss: 0.1726\n",
            "Loss: 0.17269261181354523\n",
            "Validation Loss: 0.17259171605110168\n",
            "\n",
            "Epoch 613/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1736 - val_loss: 0.1767\n",
            "Loss: 0.17359225451946259\n",
            "Validation Loss: 0.17669710516929626\n",
            "\n",
            "Epoch 614/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1724 - val_loss: 0.1740\n",
            "Loss: 0.1723654866218567\n",
            "Validation Loss: 0.1739695817232132\n",
            "\n",
            "Epoch 615/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1734 - val_loss: 0.1734\n",
            "Loss: 0.17342278361320496\n",
            "Validation Loss: 0.1733570098876953\n",
            "\n",
            "Epoch 616/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1730 - val_loss: 0.1755\n",
            "Loss: 0.17303165793418884\n",
            "Validation Loss: 0.1755068302154541\n",
            "\n",
            "Epoch 617/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1728 - val_loss: 0.1755\n",
            "Loss: 0.1727740615606308\n",
            "Validation Loss: 0.17547528445720673\n",
            "\n",
            "Epoch 618/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1723 - val_loss: 0.1752\n",
            "Loss: 0.17230713367462158\n",
            "Validation Loss: 0.17515552043914795\n",
            "\n",
            "Epoch 619/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1722 - val_loss: 0.1739\n",
            "Loss: 0.17217816412448883\n",
            "Validation Loss: 0.17389623820781708\n",
            "\n",
            "Epoch 620/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1729 - val_loss: 0.1726\n",
            "Loss: 0.17293745279312134\n",
            "Validation Loss: 0.1726333200931549\n",
            "\n",
            "Epoch 621/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1723 - val_loss: 0.1760\n",
            "Loss: 0.17230117321014404\n",
            "Validation Loss: 0.1759806126356125\n",
            "\n",
            "Epoch 622/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1733 - val_loss: 0.1750\n",
            "Loss: 0.17334413528442383\n",
            "Validation Loss: 0.17500729858875275\n",
            "\n",
            "Epoch 623/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1731 - val_loss: 0.1770\n",
            "Loss: 0.17311152815818787\n",
            "Validation Loss: 0.177005797624588\n",
            "\n",
            "Epoch 624/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1730 - val_loss: 0.1742\n",
            "Loss: 0.17295771837234497\n",
            "Validation Loss: 0.1742314249277115\n",
            "\n",
            "Epoch 625/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1734 - val_loss: 0.1734\n",
            "Loss: 0.17337337136268616\n",
            "Validation Loss: 0.17342399060726166\n",
            "\n",
            "Epoch 626/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1725 - val_loss: 0.1756\n",
            "Loss: 0.1724984347820282\n",
            "Validation Loss: 0.17564727365970612\n",
            "\n",
            "Epoch 627/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1736 - val_loss: 0.1738\n",
            "Loss: 0.17359057068824768\n",
            "Validation Loss: 0.17383672297000885\n",
            "\n",
            "Epoch 628/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1728 - val_loss: 0.1763\n",
            "Loss: 0.17282773554325104\n",
            "Validation Loss: 0.17625366151332855\n",
            "\n",
            "Epoch 629/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1733 - val_loss: 0.1743\n",
            "Loss: 0.1733253300189972\n",
            "Validation Loss: 0.17431999742984772\n",
            "\n",
            "Epoch 630/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1728 - val_loss: 0.1730\n",
            "Loss: 0.17276448011398315\n",
            "Validation Loss: 0.17298392951488495\n",
            "\n",
            "Epoch 631/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1712 - val_loss: 0.1733\n",
            "Loss: 0.17123493552207947\n",
            "Validation Loss: 0.1733475923538208\n",
            "\n",
            "Epoch 632/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1731 - val_loss: 0.1744\n",
            "Loss: 0.17307569086551666\n",
            "Validation Loss: 0.17435094714164734\n",
            "\n",
            "Epoch 633/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1721 - val_loss: 0.1756\n",
            "Loss: 0.17206087708473206\n",
            "Validation Loss: 0.1756480634212494\n",
            "\n",
            "Epoch 634/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1719 - val_loss: 0.1723\n",
            "Loss: 0.17192886769771576\n",
            "Validation Loss: 0.17233362793922424\n",
            "\n",
            "Epoch 635/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1734 - val_loss: 0.1731\n",
            "Loss: 0.17338630557060242\n",
            "Validation Loss: 0.17313769459724426\n",
            "\n",
            "Epoch 636/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1737 - val_loss: 0.1748\n",
            "Loss: 0.17372730374336243\n",
            "Validation Loss: 0.1747981607913971\n",
            "\n",
            "Epoch 637/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1736 - val_loss: 0.1752\n",
            "Loss: 0.17364025115966797\n",
            "Validation Loss: 0.1751771867275238\n",
            "\n",
            "Epoch 638/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1723 - val_loss: 0.1739\n",
            "Loss: 0.1722988337278366\n",
            "Validation Loss: 0.17389747500419617\n",
            "\n",
            "Epoch 639/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1727 - val_loss: 0.1726\n",
            "Loss: 0.17274780571460724\n",
            "Validation Loss: 0.17258475720882416\n",
            "\n",
            "Epoch 640/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1722 - val_loss: 0.1724\n",
            "Loss: 0.17221005260944366\n",
            "Validation Loss: 0.17235521972179413\n",
            "\n",
            "Epoch 641/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1726 - val_loss: 0.1722\n",
            "Loss: 0.1726396679878235\n",
            "Validation Loss: 0.17220300436019897\n",
            "\n",
            "Epoch 642/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1715 - val_loss: 0.1750\n",
            "Loss: 0.17151060700416565\n",
            "Validation Loss: 0.17504961788654327\n",
            "\n",
            "Epoch 643/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1732 - val_loss: 0.1764\n",
            "Loss: 0.17321708798408508\n",
            "Validation Loss: 0.17643676698207855\n",
            "\n",
            "Epoch 644/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1722 - val_loss: 0.1719\n",
            "Loss: 0.1721731722354889\n",
            "Validation Loss: 0.1719350963830948\n",
            "\n",
            "Epoch 645/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1726 - val_loss: 0.1731\n",
            "Loss: 0.17260921001434326\n",
            "Validation Loss: 0.17308183014392853\n",
            "\n",
            "Epoch 646/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1730 - val_loss: 0.1716\n",
            "Loss: 0.17301416397094727\n",
            "Validation Loss: 0.1715659350156784\n",
            "\n",
            "Epoch 647/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1721 - val_loss: 0.1733\n",
            "Loss: 0.1721440553665161\n",
            "Validation Loss: 0.17334488034248352\n",
            "\n",
            "Epoch 648/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1721 - val_loss: 0.1735\n",
            "Loss: 0.17214451730251312\n",
            "Validation Loss: 0.17353223264217377\n",
            "\n",
            "Epoch 649/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1723 - val_loss: 0.1731\n",
            "Loss: 0.17228397727012634\n",
            "Validation Loss: 0.1730828583240509\n",
            "\n",
            "Epoch 650/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1708 - val_loss: 0.1751\n",
            "Loss: 0.17083202302455902\n",
            "Validation Loss: 0.17507386207580566\n",
            "\n",
            "Epoch 651/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1723 - val_loss: 0.1745\n",
            "Loss: 0.17228442430496216\n",
            "Validation Loss: 0.1745442897081375\n",
            "\n",
            "Epoch 652/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1727 - val_loss: 0.1722\n",
            "Loss: 0.17268946766853333\n",
            "Validation Loss: 0.1721859723329544\n",
            "\n",
            "Epoch 653/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1730 - val_loss: 0.1729\n",
            "Loss: 0.1730010062456131\n",
            "Validation Loss: 0.172851100564003\n",
            "\n",
            "Epoch 654/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1721 - val_loss: 0.1740\n",
            "Loss: 0.17207419872283936\n",
            "Validation Loss: 0.17402279376983643\n",
            "\n",
            "Epoch 655/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1720 - val_loss: 0.1727\n",
            "Loss: 0.17202752828598022\n",
            "Validation Loss: 0.17271199822425842\n",
            "\n",
            "Epoch 656/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1732 - val_loss: 0.1739\n",
            "Loss: 0.1731555461883545\n",
            "Validation Loss: 0.17391395568847656\n",
            "\n",
            "Epoch 657/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1713 - val_loss: 0.1721\n",
            "Loss: 0.17129294574260712\n",
            "Validation Loss: 0.17207351326942444\n",
            "\n",
            "Epoch 658/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1721 - val_loss: 0.1725\n",
            "Loss: 0.17211443185806274\n",
            "Validation Loss: 0.1724582016468048\n",
            "\n",
            "Epoch 659/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1722 - val_loss: 0.1734\n",
            "Loss: 0.1721833348274231\n",
            "Validation Loss: 0.1733589470386505\n",
            "\n",
            "Epoch 660/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1712 - val_loss: 0.1722\n",
            "Loss: 0.1711563616991043\n",
            "Validation Loss: 0.17218109965324402\n",
            "\n",
            "Epoch 661/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1721 - val_loss: 0.1728\n",
            "Loss: 0.17208492755889893\n",
            "Validation Loss: 0.17283855378627777\n",
            "\n",
            "Epoch 662/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1726 - val_loss: 0.1730\n",
            "Loss: 0.17257897555828094\n",
            "Validation Loss: 0.17299120128154755\n",
            "\n",
            "Epoch 663/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1728 - val_loss: 0.1725\n",
            "Loss: 0.17283034324645996\n",
            "Validation Loss: 0.17253707349300385\n",
            "\n",
            "Epoch 664/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1713 - val_loss: 0.1762\n",
            "Loss: 0.17134328186511993\n",
            "Validation Loss: 0.1762380450963974\n",
            "\n",
            "Epoch 665/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1710 - val_loss: 0.1710\n",
            "Loss: 0.17103731632232666\n",
            "Validation Loss: 0.1709951013326645\n",
            "\n",
            "Epoch 666/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1700 - val_loss: 0.1718\n",
            "Loss: 0.1700373888015747\n",
            "Validation Loss: 0.17181460559368134\n",
            "\n",
            "Epoch 667/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1720 - val_loss: 0.1701\n",
            "Loss: 0.1719609498977661\n",
            "Validation Loss: 0.17005577683448792\n",
            "\n",
            "Epoch 668/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1723 - val_loss: 0.1720\n",
            "Loss: 0.17229510843753815\n",
            "Validation Loss: 0.17201204597949982\n",
            "\n",
            "Epoch 669/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1715 - val_loss: 0.1733\n",
            "Loss: 0.17152546346187592\n",
            "Validation Loss: 0.17327706515789032\n",
            "\n",
            "Epoch 670/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1709 - val_loss: 0.1718\n",
            "Loss: 0.17089122533798218\n",
            "Validation Loss: 0.17176784574985504\n",
            "\n",
            "Epoch 671/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1712 - val_loss: 0.1718\n",
            "Loss: 0.1711953729391098\n",
            "Validation Loss: 0.17180763185024261\n",
            "\n",
            "Epoch 672/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1721 - val_loss: 0.1724\n",
            "Loss: 0.17212699353694916\n",
            "Validation Loss: 0.1724356710910797\n",
            "\n",
            "Epoch 673/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1711 - val_loss: 0.1719\n",
            "Loss: 0.17110614478588104\n",
            "Validation Loss: 0.17192214727401733\n",
            "\n",
            "Epoch 674/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1711 - val_loss: 0.1742\n",
            "Loss: 0.17111660540103912\n",
            "Validation Loss: 0.17422938346862793\n",
            "\n",
            "Epoch 675/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1724 - val_loss: 0.1737\n",
            "Loss: 0.17235079407691956\n",
            "Validation Loss: 0.17372308671474457\n",
            "\n",
            "Epoch 676/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1715 - val_loss: 0.1736\n",
            "Loss: 0.17148730158805847\n",
            "Validation Loss: 0.17359763383865356\n",
            "\n",
            "Epoch 677/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1712 - val_loss: 0.1737\n",
            "Loss: 0.17123442888259888\n",
            "Validation Loss: 0.17374932765960693\n",
            "\n",
            "Epoch 678/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1712 - val_loss: 0.1719\n",
            "Loss: 0.17123939096927643\n",
            "Validation Loss: 0.17194002866744995\n",
            "\n",
            "Epoch 679/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1721 - val_loss: 0.1730\n",
            "Loss: 0.17207728326320648\n",
            "Validation Loss: 0.17303088307380676\n",
            "\n",
            "Epoch 680/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1716 - val_loss: 0.1710\n",
            "Loss: 0.17155440151691437\n",
            "Validation Loss: 0.17096489667892456\n",
            "\n",
            "Epoch 681/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1718 - val_loss: 0.1719\n",
            "Loss: 0.17179477214813232\n",
            "Validation Loss: 0.1719323694705963\n",
            "\n",
            "Epoch 682/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1736 - val_loss: 0.1720\n",
            "Loss: 0.17362864315509796\n",
            "Validation Loss: 0.17197385430335999\n",
            "\n",
            "Epoch 683/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1707 - val_loss: 0.1710\n",
            "Loss: 0.1707182228565216\n",
            "Validation Loss: 0.1710321307182312\n",
            "\n",
            "Epoch 684/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1718 - val_loss: 0.1718\n",
            "Loss: 0.17178967595100403\n",
            "Validation Loss: 0.17177920043468475\n",
            "\n",
            "Epoch 685/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1716 - val_loss: 0.1719\n",
            "Loss: 0.17159482836723328\n",
            "Validation Loss: 0.17190752923488617\n",
            "\n",
            "Epoch 686/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1709 - val_loss: 0.1718\n",
            "Loss: 0.17093351483345032\n",
            "Validation Loss: 0.17177405953407288\n",
            "\n",
            "Epoch 687/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1711 - val_loss: 0.1731\n",
            "Loss: 0.1710895448923111\n",
            "Validation Loss: 0.1730792224407196\n",
            "\n",
            "Epoch 688/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1711 - val_loss: 0.1744\n",
            "Loss: 0.17105220258235931\n",
            "Validation Loss: 0.17440256476402283\n",
            "\n",
            "Epoch 689/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1706 - val_loss: 0.1749\n",
            "Loss: 0.17055904865264893\n",
            "Validation Loss: 0.1748863011598587\n",
            "\n",
            "Epoch 690/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1714 - val_loss: 0.1710\n",
            "Loss: 0.17140346765518188\n",
            "Validation Loss: 0.17103147506713867\n",
            "\n",
            "Epoch 691/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1699 - val_loss: 0.1714\n",
            "Loss: 0.16991543769836426\n",
            "Validation Loss: 0.17141802608966827\n",
            "\n",
            "Epoch 692/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1709 - val_loss: 0.1726\n",
            "Loss: 0.17086170613765717\n",
            "Validation Loss: 0.17264322936534882\n",
            "\n",
            "Epoch 693/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1714 - val_loss: 0.1761\n",
            "Loss: 0.17137663066387177\n",
            "Validation Loss: 0.1760629266500473\n",
            "\n",
            "Epoch 694/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1719 - val_loss: 0.1731\n",
            "Loss: 0.17189708352088928\n",
            "Validation Loss: 0.17306886613368988\n",
            "\n",
            "Epoch 695/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1716 - val_loss: 0.1708\n",
            "Loss: 0.17162087559700012\n",
            "Validation Loss: 0.17082050442695618\n",
            "\n",
            "Epoch 696/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1704 - val_loss: 0.1747\n",
            "Loss: 0.17035871744155884\n",
            "Validation Loss: 0.17470566928386688\n",
            "\n",
            "Epoch 697/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1711 - val_loss: 0.1733\n",
            "Loss: 0.1710510551929474\n",
            "Validation Loss: 0.17327597737312317\n",
            "\n",
            "Epoch 698/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1695 - val_loss: 0.1718\n",
            "Loss: 0.16951115429401398\n",
            "Validation Loss: 0.1717531532049179\n",
            "\n",
            "Epoch 699/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1709 - val_loss: 0.1737\n",
            "Loss: 0.17090705037117004\n",
            "Validation Loss: 0.17371539771556854\n",
            "\n",
            "Epoch 700/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1709 - val_loss: 0.1738\n",
            "Loss: 0.17090068757534027\n",
            "Validation Loss: 0.17376351356506348\n",
            "\n",
            "Epoch 701/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1712 - val_loss: 0.1714\n",
            "Loss: 0.17116683721542358\n",
            "Validation Loss: 0.17144684493541718\n",
            "\n",
            "Epoch 702/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1702 - val_loss: 0.1730\n",
            "Loss: 0.17016060650348663\n",
            "Validation Loss: 0.17302405834197998\n",
            "\n",
            "Epoch 703/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1712 - val_loss: 0.1714\n",
            "Loss: 0.17121559381484985\n",
            "Validation Loss: 0.17136281728744507\n",
            "\n",
            "Epoch 704/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1702 - val_loss: 0.1713\n",
            "Loss: 0.17023442685604095\n",
            "Validation Loss: 0.1712971180677414\n",
            "\n",
            "Epoch 705/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1696 - val_loss: 0.1735\n",
            "Loss: 0.16964848339557648\n",
            "Validation Loss: 0.1734504997730255\n",
            "\n",
            "Epoch 706/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1714 - val_loss: 0.1734\n",
            "Loss: 0.17143990099430084\n",
            "Validation Loss: 0.1733793318271637\n",
            "\n",
            "Epoch 707/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1709 - val_loss: 0.1733\n",
            "Loss: 0.17088566720485687\n",
            "Validation Loss: 0.17333997786045074\n",
            "\n",
            "Epoch 708/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1702 - val_loss: 0.1727\n",
            "Loss: 0.17019544541835785\n",
            "Validation Loss: 0.17273561656475067\n",
            "\n",
            "Epoch 709/750\n",
            "21/21 [==============================] - 4s 172ms/step - loss: 0.1702 - val_loss: 0.1718\n",
            "Loss: 0.17020563781261444\n",
            "Validation Loss: 0.17175360023975372\n",
            "\n",
            "Epoch 710/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1717 - val_loss: 0.1742\n",
            "Loss: 0.17167827486991882\n",
            "Validation Loss: 0.17423133552074432\n",
            "\n",
            "Epoch 711/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1715 - val_loss: 0.1719\n",
            "Loss: 0.1715477555990219\n",
            "Validation Loss: 0.17190971970558167\n",
            "\n",
            "Epoch 712/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1709 - val_loss: 0.1732\n",
            "Loss: 0.1708899289369583\n",
            "Validation Loss: 0.17316503822803497\n",
            "\n",
            "Epoch 713/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1709 - val_loss: 0.1745\n",
            "Loss: 0.17090852558612823\n",
            "Validation Loss: 0.17445993423461914\n",
            "\n",
            "Epoch 714/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1704 - val_loss: 0.1727\n",
            "Loss: 0.17044547200202942\n",
            "Validation Loss: 0.1726990044116974\n",
            "\n",
            "Epoch 715/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1705 - val_loss: 0.1714\n",
            "Loss: 0.17051950097084045\n",
            "Validation Loss: 0.17139092087745667\n",
            "\n",
            "Epoch 716/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1717 - val_loss: 0.1717\n",
            "Loss: 0.1716521829366684\n",
            "Validation Loss: 0.17167364060878754\n",
            "\n",
            "Epoch 717/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1696 - val_loss: 0.1716\n",
            "Loss: 0.1696353256702423\n",
            "Validation Loss: 0.17159004509449005\n",
            "\n",
            "Epoch 718/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1704 - val_loss: 0.1724\n",
            "Loss: 0.17043305933475494\n",
            "Validation Loss: 0.17237703502178192\n",
            "\n",
            "Epoch 719/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1698 - val_loss: 0.1727\n",
            "Loss: 0.1698419153690338\n",
            "Validation Loss: 0.17265616357326508\n",
            "\n",
            "Epoch 720/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1703 - val_loss: 0.1715\n",
            "Loss: 0.17034436762332916\n",
            "Validation Loss: 0.17153671383857727\n",
            "\n",
            "Epoch 721/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1706 - val_loss: 0.1727\n",
            "Loss: 0.17058809101581573\n",
            "Validation Loss: 0.17273131012916565\n",
            "\n",
            "Epoch 722/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1715 - val_loss: 0.1724\n",
            "Loss: 0.1715492457151413\n",
            "Validation Loss: 0.17235291004180908\n",
            "\n",
            "Epoch 723/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1710 - val_loss: 0.1748\n",
            "Loss: 0.17102760076522827\n",
            "Validation Loss: 0.17479293048381805\n",
            "\n",
            "Epoch 724/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1706 - val_loss: 0.1756\n",
            "Loss: 0.17063480615615845\n",
            "Validation Loss: 0.17558076977729797\n",
            "\n",
            "Epoch 725/750\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1712 - val_loss: 0.1731\n",
            "Loss: 0.17123129963874817\n",
            "Validation Loss: 0.17307671904563904\n",
            "\n",
            "Epoch 726/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1703 - val_loss: 0.1748\n",
            "Loss: 0.1703355461359024\n",
            "Validation Loss: 0.17482945322990417\n",
            "\n",
            "Epoch 727/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1691 - val_loss: 0.1713\n",
            "Loss: 0.16908679902553558\n",
            "Validation Loss: 0.17129509150981903\n",
            "\n",
            "Epoch 728/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1700 - val_loss: 0.1722\n",
            "Loss: 0.16997991502285004\n",
            "Validation Loss: 0.17223981022834778\n",
            "\n",
            "Epoch 729/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1711 - val_loss: 0.1730\n",
            "Loss: 0.17113065719604492\n",
            "Validation Loss: 0.17302542924880981\n",
            "\n",
            "Epoch 730/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1707 - val_loss: 0.1738\n",
            "Loss: 0.17068567872047424\n",
            "Validation Loss: 0.17375804483890533\n",
            "\n",
            "Epoch 731/750\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1701 - val_loss: 0.1701\n",
            "Loss: 0.17012262344360352\n",
            "Validation Loss: 0.17009590566158295\n",
            "\n",
            "Epoch 732/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1709 - val_loss: 0.1717\n",
            "Loss: 0.17092368006706238\n",
            "Validation Loss: 0.17170938849449158\n",
            "\n",
            "Epoch 733/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1706 - val_loss: 0.1717\n",
            "Loss: 0.17059418559074402\n",
            "Validation Loss: 0.17170129716396332\n",
            "\n",
            "Epoch 734/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1701 - val_loss: 0.1727\n",
            "Loss: 0.17005014419555664\n",
            "Validation Loss: 0.17274071276187897\n",
            "\n",
            "Epoch 735/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1691 - val_loss: 0.1726\n",
            "Loss: 0.16912099719047546\n",
            "Validation Loss: 0.1726270169019699\n",
            "\n",
            "Epoch 736/750\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1709 - val_loss: 0.1710\n",
            "Loss: 0.17089150846004486\n",
            "Validation Loss: 0.1709967851638794\n",
            "\n",
            "Epoch 737/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1698 - val_loss: 0.1721\n",
            "Loss: 0.16981326043605804\n",
            "Validation Loss: 0.17211459577083588\n",
            "\n",
            "Epoch 738/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1711 - val_loss: 0.1717\n",
            "Loss: 0.1711050122976303\n",
            "Validation Loss: 0.17168062925338745\n",
            "\n",
            "Epoch 739/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1707 - val_loss: 0.1734\n",
            "Loss: 0.17066259682178497\n",
            "Validation Loss: 0.17338885366916656\n",
            "\n",
            "Epoch 740/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1706 - val_loss: 0.1710\n",
            "Loss: 0.17060579359531403\n",
            "Validation Loss: 0.17098945379257202\n",
            "\n",
            "Epoch 741/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1700 - val_loss: 0.1730\n",
            "Loss: 0.17002378404140472\n",
            "Validation Loss: 0.17296570539474487\n",
            "\n",
            "Epoch 742/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1702 - val_loss: 0.1707\n",
            "Loss: 0.17015087604522705\n",
            "Validation Loss: 0.17074111104011536\n",
            "\n",
            "Epoch 743/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1707 - val_loss: 0.1704\n",
            "Loss: 0.1706642210483551\n",
            "Validation Loss: 0.17038866877555847\n",
            "\n",
            "Epoch 744/750\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1707 - val_loss: 0.1707\n",
            "Loss: 0.1707020252943039\n",
            "Validation Loss: 0.170679971575737\n",
            "\n",
            "Epoch 745/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1699 - val_loss: 0.1726\n",
            "Loss: 0.16986556351184845\n",
            "Validation Loss: 0.17260108888149261\n",
            "\n",
            "Epoch 746/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.1705 - val_loss: 0.1702\n",
            "Loss: 0.1704813688993454\n",
            "Validation Loss: 0.17016154527664185\n",
            "\n",
            "Epoch 747/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1693 - val_loss: 0.1704\n",
            "Loss: 0.16929008066654205\n",
            "Validation Loss: 0.17042133212089539\n",
            "\n",
            "Epoch 748/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.1682 - val_loss: 0.1702\n",
            "Loss: 0.16822408139705658\n",
            "Validation Loss: 0.1701730191707611\n",
            "\n",
            "Epoch 749/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1702 - val_loss: 0.1737\n",
            "Loss: 0.17015378177165985\n",
            "Validation Loss: 0.17374283075332642\n",
            "\n",
            "Epoch 750/750\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.1700 - val_loss: 0.1705\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1700247973203659\n",
            "Validation Loss: 0.17052045464515686\n",
            "\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_20 (InputLayer)          [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_19 (LSTM)                 (None, 5, 128)       73216       ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " attention_layer_22 (AttentionL  (None, 128)         128         ['lstm_19[0][0]',                \n",
            " ayer)                                                            'lstm_19[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1, 128)       0           ['attention_layer_22[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_6 (TimeDistri  (None, 1, 1)        129         ['reshape_5[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.8074 - val_loss: 0.4341\n",
            "Loss: 0.8073787093162537\n",
            "Validation Loss: 0.43409475684165955\n",
            "\n",
            "Epoch 2/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.4412 - val_loss: 0.3225\n",
            "Loss: 0.4412391185760498\n",
            "Validation Loss: 0.32253286242485046\n",
            "\n",
            "Epoch 3/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3819 - val_loss: 0.3003\n",
            "Loss: 0.38185063004493713\n",
            "Validation Loss: 0.30032527446746826\n",
            "\n",
            "Epoch 4/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3641 - val_loss: 0.2872\n",
            "Loss: 0.3640674948692322\n",
            "Validation Loss: 0.2871975004673004\n",
            "\n",
            "Epoch 5/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3526 - val_loss: 0.2799\n",
            "Loss: 0.3526195287704468\n",
            "Validation Loss: 0.27988529205322266\n",
            "\n",
            "Epoch 6/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3449 - val_loss: 0.2764\n",
            "Loss: 0.3448505401611328\n",
            "Validation Loss: 0.27639415860176086\n",
            "\n",
            "Epoch 7/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3370 - val_loss: 0.2718\n",
            "Loss: 0.3369709253311157\n",
            "Validation Loss: 0.27180612087249756\n",
            "\n",
            "Epoch 8/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.3309 - val_loss: 0.2717\n",
            "Loss: 0.33085402846336365\n",
            "Validation Loss: 0.2717450261116028\n",
            "\n",
            "Epoch 9/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3259 - val_loss: 0.2682\n",
            "Loss: 0.3259262144565582\n",
            "Validation Loss: 0.26824209094047546\n",
            "\n",
            "Epoch 10/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3224 - val_loss: 0.2698\n",
            "Loss: 0.32242462038993835\n",
            "Validation Loss: 0.2698412239551544\n",
            "\n",
            "Epoch 11/750\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.3228 - val_loss: 0.2681\n",
            "Loss: 0.3227508068084717\n",
            "Validation Loss: 0.26805180311203003\n",
            "\n",
            "Epoch 12/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3209 - val_loss: 0.2710\n",
            "Loss: 0.3209024965763092\n",
            "Validation Loss: 0.2710133492946625\n",
            "\n",
            "Epoch 13/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3159 - val_loss: 0.2664\n",
            "Loss: 0.31585410237312317\n",
            "Validation Loss: 0.26639223098754883\n",
            "\n",
            "Epoch 14/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.3124 - val_loss: 0.2649\n",
            "Loss: 0.3123948574066162\n",
            "Validation Loss: 0.26492592692375183\n",
            "\n",
            "Epoch 15/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.3111 - val_loss: 0.2657\n",
            "Loss: 0.31113773584365845\n",
            "Validation Loss: 0.2657341957092285\n",
            "\n",
            "Epoch 16/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3088 - val_loss: 0.2635\n",
            "Loss: 0.3087843656539917\n",
            "Validation Loss: 0.2634601294994354\n",
            "\n",
            "Epoch 17/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3072 - val_loss: 0.2634\n",
            "Loss: 0.30721601843833923\n",
            "Validation Loss: 0.2634180188179016\n",
            "\n",
            "Epoch 18/750\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.3056 - val_loss: 0.2619\n",
            "Loss: 0.3055860698223114\n",
            "Validation Loss: 0.2619381546974182\n",
            "\n",
            "Epoch 19/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.3041 - val_loss: 0.2606\n",
            "Loss: 0.30410051345825195\n",
            "Validation Loss: 0.2605857253074646\n",
            "\n",
            "Epoch 20/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2998 - val_loss: 0.2608\n",
            "Loss: 0.29978418350219727\n",
            "Validation Loss: 0.2608211934566498\n",
            "\n",
            "Epoch 21/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.3014 - val_loss: 0.2627\n",
            "Loss: 0.3013976514339447\n",
            "Validation Loss: 0.2627091109752655\n",
            "\n",
            "Epoch 22/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2996 - val_loss: 0.2608\n",
            "Loss: 0.29961490631103516\n",
            "Validation Loss: 0.26083099842071533\n",
            "\n",
            "Epoch 23/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2980 - val_loss: 0.2595\n",
            "Loss: 0.29795828461647034\n",
            "Validation Loss: 0.2594967782497406\n",
            "\n",
            "Epoch 24/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2922 - val_loss: 0.2565\n",
            "Loss: 0.292190283536911\n",
            "Validation Loss: 0.2564544677734375\n",
            "\n",
            "Epoch 25/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2940 - val_loss: 0.2559\n",
            "Loss: 0.29398927092552185\n",
            "Validation Loss: 0.2559047043323517\n",
            "\n",
            "Epoch 26/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2920 - val_loss: 0.2567\n",
            "Loss: 0.2920156419277191\n",
            "Validation Loss: 0.2566574215888977\n",
            "\n",
            "Epoch 27/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2906 - val_loss: 0.2568\n",
            "Loss: 0.2906085252761841\n",
            "Validation Loss: 0.2568228542804718\n",
            "\n",
            "Epoch 28/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2876 - val_loss: 0.2553\n",
            "Loss: 0.287555992603302\n",
            "Validation Loss: 0.25526875257492065\n",
            "\n",
            "Epoch 29/750\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2887 - val_loss: 0.2537\n",
            "Loss: 0.2887094020843506\n",
            "Validation Loss: 0.2536773085594177\n",
            "\n",
            "Epoch 30/750\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2845 - val_loss: 0.2541\n",
            "Loss: 0.2845172882080078\n",
            "Validation Loss: 0.2540544271469116\n",
            "\n",
            "Epoch 31/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2857 - val_loss: 0.2547\n",
            "Loss: 0.28566494584083557\n",
            "Validation Loss: 0.2546975016593933\n",
            "\n",
            "Epoch 32/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2851 - val_loss: 0.2563\n",
            "Loss: 0.2850600481033325\n",
            "Validation Loss: 0.2563319504261017\n",
            "\n",
            "Epoch 33/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2851 - val_loss: 0.2564\n",
            "Loss: 0.2851446270942688\n",
            "Validation Loss: 0.2564091086387634\n",
            "\n",
            "Epoch 34/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2844 - val_loss: 0.2550\n",
            "Loss: 0.2844253182411194\n",
            "Validation Loss: 0.2549614906311035\n",
            "\n",
            "Epoch 35/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2848 - val_loss: 0.2523\n",
            "Loss: 0.2847915291786194\n",
            "Validation Loss: 0.25228846073150635\n",
            "\n",
            "Epoch 36/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2824 - val_loss: 0.2524\n",
            "Loss: 0.2823527455329895\n",
            "Validation Loss: 0.25235846638679504\n",
            "\n",
            "Epoch 37/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2818 - val_loss: 0.2519\n",
            "Loss: 0.2817704677581787\n",
            "Validation Loss: 0.25191524624824524\n",
            "\n",
            "Epoch 38/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2774 - val_loss: 0.2519\n",
            "Loss: 0.27743932604789734\n",
            "Validation Loss: 0.2519369125366211\n",
            "\n",
            "Epoch 39/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2774 - val_loss: 0.2496\n",
            "Loss: 0.2774350643157959\n",
            "Validation Loss: 0.24955669045448303\n",
            "\n",
            "Epoch 40/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2783 - val_loss: 0.2517\n",
            "Loss: 0.278310090303421\n",
            "Validation Loss: 0.2517217993736267\n",
            "\n",
            "Epoch 41/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2773 - val_loss: 0.2494\n",
            "Loss: 0.2773369252681732\n",
            "Validation Loss: 0.24935081601142883\n",
            "\n",
            "Epoch 42/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2764 - val_loss: 0.2493\n",
            "Loss: 0.2764355540275574\n",
            "Validation Loss: 0.2493310123682022\n",
            "\n",
            "Epoch 43/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2755 - val_loss: 0.2494\n",
            "Loss: 0.2755231559276581\n",
            "Validation Loss: 0.2493652105331421\n",
            "\n",
            "Epoch 44/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2749 - val_loss: 0.2494\n",
            "Loss: 0.27487093210220337\n",
            "Validation Loss: 0.2493748515844345\n",
            "\n",
            "Epoch 45/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2739 - val_loss: 0.2477\n",
            "Loss: 0.27388402819633484\n",
            "Validation Loss: 0.2477090209722519\n",
            "\n",
            "Epoch 46/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2716 - val_loss: 0.2478\n",
            "Loss: 0.27162623405456543\n",
            "Validation Loss: 0.24784685671329498\n",
            "\n",
            "Epoch 47/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2708 - val_loss: 0.2479\n",
            "Loss: 0.2708284258842468\n",
            "Validation Loss: 0.247868150472641\n",
            "\n",
            "Epoch 48/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2698 - val_loss: 0.2467\n",
            "Loss: 0.26982638239860535\n",
            "Validation Loss: 0.24674005806446075\n",
            "\n",
            "Epoch 49/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2721 - val_loss: 0.2471\n",
            "Loss: 0.27211254835128784\n",
            "Validation Loss: 0.24707162380218506\n",
            "\n",
            "Epoch 50/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2701 - val_loss: 0.2453\n",
            "Loss: 0.2701385021209717\n",
            "Validation Loss: 0.24530580639839172\n",
            "\n",
            "Epoch 51/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2689 - val_loss: 0.2474\n",
            "Loss: 0.2688770592212677\n",
            "Validation Loss: 0.24735192954540253\n",
            "\n",
            "Epoch 52/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2697 - val_loss: 0.2454\n",
            "Loss: 0.26971518993377686\n",
            "Validation Loss: 0.245352104306221\n",
            "\n",
            "Epoch 53/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2674 - val_loss: 0.2470\n",
            "Loss: 0.26744672656059265\n",
            "Validation Loss: 0.24701108038425446\n",
            "\n",
            "Epoch 54/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2687 - val_loss: 0.2422\n",
            "Loss: 0.2687104344367981\n",
            "Validation Loss: 0.24217021465301514\n",
            "\n",
            "Epoch 55/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2683 - val_loss: 0.2437\n",
            "Loss: 0.2682599425315857\n",
            "Validation Loss: 0.24369819462299347\n",
            "\n",
            "Epoch 56/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2656 - val_loss: 0.2429\n",
            "Loss: 0.2656432092189789\n",
            "Validation Loss: 0.24289344251155853\n",
            "\n",
            "Epoch 57/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2664 - val_loss: 0.2437\n",
            "Loss: 0.26635077595710754\n",
            "Validation Loss: 0.2437351644039154\n",
            "\n",
            "Epoch 58/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2657 - val_loss: 0.2435\n",
            "Loss: 0.2657182216644287\n",
            "Validation Loss: 0.2434971034526825\n",
            "\n",
            "Epoch 59/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2629 - val_loss: 0.2408\n",
            "Loss: 0.2629116475582123\n",
            "Validation Loss: 0.2407888025045395\n",
            "\n",
            "Epoch 60/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2652 - val_loss: 0.2424\n",
            "Loss: 0.2652319073677063\n",
            "Validation Loss: 0.2423684448003769\n",
            "\n",
            "Epoch 61/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2644 - val_loss: 0.2418\n",
            "Loss: 0.26439228653907776\n",
            "Validation Loss: 0.24175216257572174\n",
            "\n",
            "Epoch 62/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2621 - val_loss: 0.2384\n",
            "Loss: 0.2620856761932373\n",
            "Validation Loss: 0.23838335275650024\n",
            "\n",
            "Epoch 63/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2622 - val_loss: 0.2390\n",
            "Loss: 0.2622312009334564\n",
            "Validation Loss: 0.2390008568763733\n",
            "\n",
            "Epoch 64/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2613 - val_loss: 0.2400\n",
            "Loss: 0.2613165080547333\n",
            "Validation Loss: 0.24000316858291626\n",
            "\n",
            "Epoch 65/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2617 - val_loss: 0.2389\n",
            "Loss: 0.26165682077407837\n",
            "Validation Loss: 0.23894327878952026\n",
            "\n",
            "Epoch 66/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2608 - val_loss: 0.2359\n",
            "Loss: 0.2608241140842438\n",
            "Validation Loss: 0.23587174713611603\n",
            "\n",
            "Epoch 67/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2610 - val_loss: 0.2408\n",
            "Loss: 0.2610027492046356\n",
            "Validation Loss: 0.24075280129909515\n",
            "\n",
            "Epoch 68/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2600 - val_loss: 0.2379\n",
            "Loss: 0.2599533498287201\n",
            "Validation Loss: 0.2378574162721634\n",
            "\n",
            "Epoch 69/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2590 - val_loss: 0.2392\n",
            "Loss: 0.2589767277240753\n",
            "Validation Loss: 0.23916180431842804\n",
            "\n",
            "Epoch 70/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2579 - val_loss: 0.2350\n",
            "Loss: 0.2579299807548523\n",
            "Validation Loss: 0.2349889874458313\n",
            "\n",
            "Epoch 71/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2590 - val_loss: 0.2365\n",
            "Loss: 0.2590017318725586\n",
            "Validation Loss: 0.23648513853549957\n",
            "\n",
            "Epoch 72/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2560 - val_loss: 0.2350\n",
            "Loss: 0.2559586465358734\n",
            "Validation Loss: 0.23502585291862488\n",
            "\n",
            "Epoch 73/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2563 - val_loss: 0.2360\n",
            "Loss: 0.25628697872161865\n",
            "Validation Loss: 0.2359745055437088\n",
            "\n",
            "Epoch 74/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2570 - val_loss: 0.2375\n",
            "Loss: 0.2570265531539917\n",
            "Validation Loss: 0.23752468824386597\n",
            "\n",
            "Epoch 75/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2549 - val_loss: 0.2367\n",
            "Loss: 0.2548782229423523\n",
            "Validation Loss: 0.23667801916599274\n",
            "\n",
            "Epoch 76/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2557 - val_loss: 0.2378\n",
            "Loss: 0.25569573044776917\n",
            "Validation Loss: 0.23775586485862732\n",
            "\n",
            "Epoch 77/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2542 - val_loss: 0.2366\n",
            "Loss: 0.2541833519935608\n",
            "Validation Loss: 0.23656779527664185\n",
            "\n",
            "Epoch 78/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2549 - val_loss: 0.2367\n",
            "Loss: 0.2548966109752655\n",
            "Validation Loss: 0.23674015700817108\n",
            "\n",
            "Epoch 79/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2527 - val_loss: 0.2328\n",
            "Loss: 0.2526545822620392\n",
            "Validation Loss: 0.23283256590366364\n",
            "\n",
            "Epoch 80/750\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2534 - val_loss: 0.2321\n",
            "Loss: 0.2533605694770813\n",
            "Validation Loss: 0.2320997416973114\n",
            "\n",
            "Epoch 81/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2534 - val_loss: 0.2318\n",
            "Loss: 0.2533811032772064\n",
            "Validation Loss: 0.23179176449775696\n",
            "\n",
            "Epoch 82/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2524 - val_loss: 0.2331\n",
            "Loss: 0.2524035573005676\n",
            "Validation Loss: 0.23310096561908722\n",
            "\n",
            "Epoch 83/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2528 - val_loss: 0.2328\n",
            "Loss: 0.25276806950569153\n",
            "Validation Loss: 0.232778400182724\n",
            "\n",
            "Epoch 84/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2528 - val_loss: 0.2281\n",
            "Loss: 0.252787709236145\n",
            "Validation Loss: 0.22805453836917877\n",
            "\n",
            "Epoch 85/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2519 - val_loss: 0.2318\n",
            "Loss: 0.2518610656261444\n",
            "Validation Loss: 0.2318413257598877\n",
            "\n",
            "Epoch 86/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2509 - val_loss: 0.2321\n",
            "Loss: 0.25086045265197754\n",
            "Validation Loss: 0.2321065366268158\n",
            "\n",
            "Epoch 87/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2516 - val_loss: 0.2330\n",
            "Loss: 0.2515834867954254\n",
            "Validation Loss: 0.23304681479930878\n",
            "\n",
            "Epoch 88/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2529 - val_loss: 0.2311\n",
            "Loss: 0.2528785765171051\n",
            "Validation Loss: 0.23107749223709106\n",
            "\n",
            "Epoch 89/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2492 - val_loss: 0.2333\n",
            "Loss: 0.24915605783462524\n",
            "Validation Loss: 0.23329415917396545\n",
            "\n",
            "Epoch 90/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2489 - val_loss: 0.2281\n",
            "Loss: 0.24888849258422852\n",
            "Validation Loss: 0.2281368225812912\n",
            "\n",
            "Epoch 91/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2477 - val_loss: 0.2310\n",
            "Loss: 0.24767498672008514\n",
            "Validation Loss: 0.23102018237113953\n",
            "\n",
            "Epoch 92/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2486 - val_loss: 0.2298\n",
            "Loss: 0.24858464300632477\n",
            "Validation Loss: 0.22976785898208618\n",
            "\n",
            "Epoch 93/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2471 - val_loss: 0.2298\n",
            "Loss: 0.24709320068359375\n",
            "Validation Loss: 0.22982093691825867\n",
            "\n",
            "Epoch 94/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2476 - val_loss: 0.2312\n",
            "Loss: 0.24760636687278748\n",
            "Validation Loss: 0.23119601607322693\n",
            "\n",
            "Epoch 95/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2484 - val_loss: 0.2293\n",
            "Loss: 0.2483886480331421\n",
            "Validation Loss: 0.22932936251163483\n",
            "\n",
            "Epoch 96/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2487 - val_loss: 0.2273\n",
            "Loss: 0.24868042767047882\n",
            "Validation Loss: 0.2272903174161911\n",
            "\n",
            "Epoch 97/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2466 - val_loss: 0.2286\n",
            "Loss: 0.2466028481721878\n",
            "Validation Loss: 0.22864064574241638\n",
            "\n",
            "Epoch 98/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2466 - val_loss: 0.2275\n",
            "Loss: 0.24664637446403503\n",
            "Validation Loss: 0.22747673094272614\n",
            "\n",
            "Epoch 99/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2453 - val_loss: 0.2266\n",
            "Loss: 0.24528123438358307\n",
            "Validation Loss: 0.22664996981620789\n",
            "\n",
            "Epoch 100/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2467 - val_loss: 0.2303\n",
            "Loss: 0.24665822088718414\n",
            "Validation Loss: 0.23033484816551208\n",
            "\n",
            "Epoch 101/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2469 - val_loss: 0.2279\n",
            "Loss: 0.24688591063022614\n",
            "Validation Loss: 0.22790931165218353\n",
            "\n",
            "Epoch 102/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2438 - val_loss: 0.2303\n",
            "Loss: 0.24380585551261902\n",
            "Validation Loss: 0.23032252490520477\n",
            "\n",
            "Epoch 103/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2452 - val_loss: 0.2298\n",
            "Loss: 0.24515357613563538\n",
            "Validation Loss: 0.22984659671783447\n",
            "\n",
            "Epoch 104/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2461 - val_loss: 0.2257\n",
            "Loss: 0.246101975440979\n",
            "Validation Loss: 0.22569599747657776\n",
            "\n",
            "Epoch 105/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2450 - val_loss: 0.2244\n",
            "Loss: 0.244993656873703\n",
            "Validation Loss: 0.22435832023620605\n",
            "\n",
            "Epoch 106/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2421 - val_loss: 0.2256\n",
            "Loss: 0.242123082280159\n",
            "Validation Loss: 0.22564812004566193\n",
            "\n",
            "Epoch 107/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2436 - val_loss: 0.2260\n",
            "Loss: 0.24364925920963287\n",
            "Validation Loss: 0.2259577214717865\n",
            "\n",
            "Epoch 108/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2414 - val_loss: 0.2246\n",
            "Loss: 0.24141548573970795\n",
            "Validation Loss: 0.2245868295431137\n",
            "\n",
            "Epoch 109/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2435 - val_loss: 0.2290\n",
            "Loss: 0.24346710741519928\n",
            "Validation Loss: 0.2289787381887436\n",
            "\n",
            "Epoch 110/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2437 - val_loss: 0.2231\n",
            "Loss: 0.2437496930360794\n",
            "Validation Loss: 0.2231481969356537\n",
            "\n",
            "Epoch 111/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2432 - val_loss: 0.2274\n",
            "Loss: 0.24319130182266235\n",
            "Validation Loss: 0.2273501753807068\n",
            "\n",
            "Epoch 112/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2417 - val_loss: 0.2252\n",
            "Loss: 0.24170592427253723\n",
            "Validation Loss: 0.22518351674079895\n",
            "\n",
            "Epoch 113/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2432 - val_loss: 0.2262\n",
            "Loss: 0.24320781230926514\n",
            "Validation Loss: 0.22622166574001312\n",
            "\n",
            "Epoch 114/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2399 - val_loss: 0.2237\n",
            "Loss: 0.23989930748939514\n",
            "Validation Loss: 0.2236577570438385\n",
            "\n",
            "Epoch 115/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2422 - val_loss: 0.2223\n",
            "Loss: 0.24215899407863617\n",
            "Validation Loss: 0.22226972877979279\n",
            "\n",
            "Epoch 116/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2407 - val_loss: 0.2235\n",
            "Loss: 0.2406878024339676\n",
            "Validation Loss: 0.22354687750339508\n",
            "\n",
            "Epoch 117/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2403 - val_loss: 0.2250\n",
            "Loss: 0.24033257365226746\n",
            "Validation Loss: 0.2249949872493744\n",
            "\n",
            "Epoch 118/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2405 - val_loss: 0.2212\n",
            "Loss: 0.2405393123626709\n",
            "Validation Loss: 0.22123898565769196\n",
            "\n",
            "Epoch 119/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2387 - val_loss: 0.2245\n",
            "Loss: 0.238744854927063\n",
            "Validation Loss: 0.22452031075954437\n",
            "\n",
            "Epoch 120/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2388 - val_loss: 0.2234\n",
            "Loss: 0.23882223665714264\n",
            "Validation Loss: 0.2233671396970749\n",
            "\n",
            "Epoch 121/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2394 - val_loss: 0.2241\n",
            "Loss: 0.23938293755054474\n",
            "Validation Loss: 0.22406303882598877\n",
            "\n",
            "Epoch 122/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2395 - val_loss: 0.2223\n",
            "Loss: 0.23954124748706818\n",
            "Validation Loss: 0.2222832888364792\n",
            "\n",
            "Epoch 123/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2385 - val_loss: 0.2195\n",
            "Loss: 0.23846100270748138\n",
            "Validation Loss: 0.21953372657299042\n",
            "\n",
            "Epoch 124/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2373 - val_loss: 0.2210\n",
            "Loss: 0.23732520639896393\n",
            "Validation Loss: 0.22098630666732788\n",
            "\n",
            "Epoch 125/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2394 - val_loss: 0.2200\n",
            "Loss: 0.23943231999874115\n",
            "Validation Loss: 0.22003819048404694\n",
            "\n",
            "Epoch 126/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2365 - val_loss: 0.2204\n",
            "Loss: 0.2365136593580246\n",
            "Validation Loss: 0.2204456776380539\n",
            "\n",
            "Epoch 127/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2392 - val_loss: 0.2190\n",
            "Loss: 0.23922382295131683\n",
            "Validation Loss: 0.21897462010383606\n",
            "\n",
            "Epoch 128/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2374 - val_loss: 0.2209\n",
            "Loss: 0.23743262887001038\n",
            "Validation Loss: 0.22094184160232544\n",
            "\n",
            "Epoch 129/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2374 - val_loss: 0.2229\n",
            "Loss: 0.2373759001493454\n",
            "Validation Loss: 0.2228555828332901\n",
            "\n",
            "Epoch 130/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2370 - val_loss: 0.2218\n",
            "Loss: 0.23695489764213562\n",
            "Validation Loss: 0.2217687964439392\n",
            "\n",
            "Epoch 131/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2365 - val_loss: 0.2190\n",
            "Loss: 0.23647908866405487\n",
            "Validation Loss: 0.21902769804000854\n",
            "\n",
            "Epoch 132/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2375 - val_loss: 0.2228\n",
            "Loss: 0.23751813173294067\n",
            "Validation Loss: 0.22283165156841278\n",
            "\n",
            "Epoch 133/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2360 - val_loss: 0.2208\n",
            "Loss: 0.2359970211982727\n",
            "Validation Loss: 0.22080394625663757\n",
            "\n",
            "Epoch 134/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2347 - val_loss: 0.2169\n",
            "Loss: 0.23468291759490967\n",
            "Validation Loss: 0.21687349677085876\n",
            "\n",
            "Epoch 135/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2360 - val_loss: 0.2199\n",
            "Loss: 0.23604999482631683\n",
            "Validation Loss: 0.21991834044456482\n",
            "\n",
            "Epoch 136/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2369 - val_loss: 0.2207\n",
            "Loss: 0.2368752658367157\n",
            "Validation Loss: 0.2207319587469101\n",
            "\n",
            "Epoch 137/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2348 - val_loss: 0.2214\n",
            "Loss: 0.23481984436511993\n",
            "Validation Loss: 0.22143273055553436\n",
            "\n",
            "Epoch 138/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2335 - val_loss: 0.2216\n",
            "Loss: 0.23352444171905518\n",
            "Validation Loss: 0.22156772017478943\n",
            "\n",
            "Epoch 139/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2352 - val_loss: 0.2198\n",
            "Loss: 0.23517507314682007\n",
            "Validation Loss: 0.21977536380290985\n",
            "\n",
            "Epoch 140/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2336 - val_loss: 0.2170\n",
            "Loss: 0.23358581960201263\n",
            "Validation Loss: 0.2169705033302307\n",
            "\n",
            "Epoch 141/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2350 - val_loss: 0.2184\n",
            "Loss: 0.23502182960510254\n",
            "Validation Loss: 0.21836067736148834\n",
            "\n",
            "Epoch 142/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2347 - val_loss: 0.2159\n",
            "Loss: 0.2346963733434677\n",
            "Validation Loss: 0.21586166322231293\n",
            "\n",
            "Epoch 143/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2327 - val_loss: 0.2177\n",
            "Loss: 0.2327379286289215\n",
            "Validation Loss: 0.2177000641822815\n",
            "\n",
            "Epoch 144/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2329 - val_loss: 0.2197\n",
            "Loss: 0.23290148377418518\n",
            "Validation Loss: 0.21970421075820923\n",
            "\n",
            "Epoch 145/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2337 - val_loss: 0.2212\n",
            "Loss: 0.2336881011724472\n",
            "Validation Loss: 0.22116194665431976\n",
            "\n",
            "Epoch 146/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2311 - val_loss: 0.2190\n",
            "Loss: 0.23106718063354492\n",
            "Validation Loss: 0.21895647048950195\n",
            "\n",
            "Epoch 147/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2345 - val_loss: 0.2167\n",
            "Loss: 0.2345472276210785\n",
            "Validation Loss: 0.2167440503835678\n",
            "\n",
            "Epoch 148/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2341 - val_loss: 0.2185\n",
            "Loss: 0.23407655954360962\n",
            "Validation Loss: 0.21849368512630463\n",
            "\n",
            "Epoch 149/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2326 - val_loss: 0.2166\n",
            "Loss: 0.23256491124629974\n",
            "Validation Loss: 0.21662640571594238\n",
            "\n",
            "Epoch 150/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2322 - val_loss: 0.2155\n",
            "Loss: 0.2321629673242569\n",
            "Validation Loss: 0.21552151441574097\n",
            "\n",
            "Epoch 151/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2316 - val_loss: 0.2177\n",
            "Loss: 0.23162685334682465\n",
            "Validation Loss: 0.21768289804458618\n",
            "\n",
            "Epoch 152/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2316 - val_loss: 0.2145\n",
            "Loss: 0.23162582516670227\n",
            "Validation Loss: 0.21453659236431122\n",
            "\n",
            "Epoch 153/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2310 - val_loss: 0.2165\n",
            "Loss: 0.23104287683963776\n",
            "Validation Loss: 0.21650788187980652\n",
            "\n",
            "Epoch 154/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2300 - val_loss: 0.2189\n",
            "Loss: 0.229950949549675\n",
            "Validation Loss: 0.2189372032880783\n",
            "\n",
            "Epoch 155/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2302 - val_loss: 0.2148\n",
            "Loss: 0.23018376529216766\n",
            "Validation Loss: 0.2148008793592453\n",
            "\n",
            "Epoch 156/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2292 - val_loss: 0.2140\n",
            "Loss: 0.2292347550392151\n",
            "Validation Loss: 0.2140347808599472\n",
            "\n",
            "Epoch 157/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2303 - val_loss: 0.2170\n",
            "Loss: 0.23030929267406464\n",
            "Validation Loss: 0.21699649095535278\n",
            "\n",
            "Epoch 158/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2289 - val_loss: 0.2126\n",
            "Loss: 0.2288672775030136\n",
            "Validation Loss: 0.21258440613746643\n",
            "\n",
            "Epoch 159/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2291 - val_loss: 0.2143\n",
            "Loss: 0.2290891855955124\n",
            "Validation Loss: 0.21427027881145477\n",
            "\n",
            "Epoch 160/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2291 - val_loss: 0.2166\n",
            "Loss: 0.22909560799598694\n",
            "Validation Loss: 0.21656647324562073\n",
            "\n",
            "Epoch 161/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2266 - val_loss: 0.2146\n",
            "Loss: 0.22662316262722015\n",
            "Validation Loss: 0.2146211415529251\n",
            "\n",
            "Epoch 162/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2303 - val_loss: 0.2152\n",
            "Loss: 0.23030202090740204\n",
            "Validation Loss: 0.21522341668605804\n",
            "\n",
            "Epoch 163/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2303 - val_loss: 0.2145\n",
            "Loss: 0.23028653860092163\n",
            "Validation Loss: 0.21448394656181335\n",
            "\n",
            "Epoch 164/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2285 - val_loss: 0.2138\n",
            "Loss: 0.22847995162010193\n",
            "Validation Loss: 0.21378633379936218\n",
            "\n",
            "Epoch 165/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2287 - val_loss: 0.2114\n",
            "Loss: 0.22872279584407806\n",
            "Validation Loss: 0.21144306659698486\n",
            "\n",
            "Epoch 166/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2260 - val_loss: 0.2140\n",
            "Loss: 0.22600220143795013\n",
            "Validation Loss: 0.2140452265739441\n",
            "\n",
            "Epoch 167/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2273 - val_loss: 0.2131\n",
            "Loss: 0.22725357115268707\n",
            "Validation Loss: 0.213082954287529\n",
            "\n",
            "Epoch 168/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2262 - val_loss: 0.2149\n",
            "Loss: 0.22624795138835907\n",
            "Validation Loss: 0.21490629017353058\n",
            "\n",
            "Epoch 169/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2284 - val_loss: 0.2161\n",
            "Loss: 0.2283795326948166\n",
            "Validation Loss: 0.21610677242279053\n",
            "\n",
            "Epoch 170/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2266 - val_loss: 0.2124\n",
            "Loss: 0.22659149765968323\n",
            "Validation Loss: 0.21236483752727509\n",
            "\n",
            "Epoch 171/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2282 - val_loss: 0.2104\n",
            "Loss: 0.22816523909568787\n",
            "Validation Loss: 0.2103845626115799\n",
            "\n",
            "Epoch 172/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2255 - val_loss: 0.2132\n",
            "Loss: 0.2254999279975891\n",
            "Validation Loss: 0.2131817638874054\n",
            "\n",
            "Epoch 173/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2264 - val_loss: 0.2094\n",
            "Loss: 0.2264155000448227\n",
            "Validation Loss: 0.20935332775115967\n",
            "\n",
            "Epoch 174/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2251 - val_loss: 0.2125\n",
            "Loss: 0.22511990368366241\n",
            "Validation Loss: 0.21249528229236603\n",
            "\n",
            "Epoch 175/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2255 - val_loss: 0.2114\n",
            "Loss: 0.22550196945667267\n",
            "Validation Loss: 0.211420476436615\n",
            "\n",
            "Epoch 176/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2261 - val_loss: 0.2155\n",
            "Loss: 0.22605031728744507\n",
            "Validation Loss: 0.21547597646713257\n",
            "\n",
            "Epoch 177/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2263 - val_loss: 0.2095\n",
            "Loss: 0.22632050514221191\n",
            "Validation Loss: 0.20947173237800598\n",
            "\n",
            "Epoch 178/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2266 - val_loss: 0.2134\n",
            "Loss: 0.22656014561653137\n",
            "Validation Loss: 0.21337823569774628\n",
            "\n",
            "Epoch 179/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2259 - val_loss: 0.2122\n",
            "Loss: 0.22591012716293335\n",
            "Validation Loss: 0.21218381822109222\n",
            "\n",
            "Epoch 180/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2260 - val_loss: 0.2083\n",
            "Loss: 0.22601717710494995\n",
            "Validation Loss: 0.2083471715450287\n",
            "\n",
            "Epoch 181/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2247 - val_loss: 0.2116\n",
            "Loss: 0.2246633917093277\n",
            "Validation Loss: 0.2115844488143921\n",
            "\n",
            "Epoch 182/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2257 - val_loss: 0.2118\n",
            "Loss: 0.2257414311170578\n",
            "Validation Loss: 0.21181520819664001\n",
            "\n",
            "Epoch 183/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2244 - val_loss: 0.2094\n",
            "Loss: 0.2243897169828415\n",
            "Validation Loss: 0.2093784511089325\n",
            "\n",
            "Epoch 184/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2259 - val_loss: 0.2116\n",
            "Loss: 0.22591666877269745\n",
            "Validation Loss: 0.21163350343704224\n",
            "\n",
            "Epoch 185/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2235 - val_loss: 0.2123\n",
            "Loss: 0.22352235019207\n",
            "Validation Loss: 0.21230924129486084\n",
            "\n",
            "Epoch 186/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2229 - val_loss: 0.2117\n",
            "Loss: 0.2229396402835846\n",
            "Validation Loss: 0.21165774762630463\n",
            "\n",
            "Epoch 187/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2250 - val_loss: 0.2099\n",
            "Loss: 0.2249891459941864\n",
            "Validation Loss: 0.2098543792963028\n",
            "\n",
            "Epoch 188/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2217 - val_loss: 0.2125\n",
            "Loss: 0.22168773412704468\n",
            "Validation Loss: 0.21250872313976288\n",
            "\n",
            "Epoch 189/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2241 - val_loss: 0.2071\n",
            "Loss: 0.22410136461257935\n",
            "Validation Loss: 0.20707105100154877\n",
            "\n",
            "Epoch 190/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2236 - val_loss: 0.2101\n",
            "Loss: 0.22364136576652527\n",
            "Validation Loss: 0.2100914865732193\n",
            "\n",
            "Epoch 191/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2237 - val_loss: 0.2081\n",
            "Loss: 0.2236700803041458\n",
            "Validation Loss: 0.20805463194847107\n",
            "\n",
            "Epoch 192/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2243 - val_loss: 0.2095\n",
            "Loss: 0.22434766590595245\n",
            "Validation Loss: 0.20953769981861115\n",
            "\n",
            "Epoch 193/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2261 - val_loss: 0.2083\n",
            "Loss: 0.22611317038536072\n",
            "Validation Loss: 0.20833584666252136\n",
            "\n",
            "Epoch 194/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2242 - val_loss: 0.2097\n",
            "Loss: 0.22419659793376923\n",
            "Validation Loss: 0.20970787107944489\n",
            "\n",
            "Epoch 195/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2222 - val_loss: 0.2082\n",
            "Loss: 0.22217415273189545\n",
            "Validation Loss: 0.20820406079292297\n",
            "\n",
            "Epoch 196/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2218 - val_loss: 0.2065\n",
            "Loss: 0.22179849445819855\n",
            "Validation Loss: 0.20650382339954376\n",
            "\n",
            "Epoch 197/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2216 - val_loss: 0.2094\n",
            "Loss: 0.2216062843799591\n",
            "Validation Loss: 0.20941504836082458\n",
            "\n",
            "Epoch 198/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2232 - val_loss: 0.2092\n",
            "Loss: 0.2232317477464676\n",
            "Validation Loss: 0.20919108390808105\n",
            "\n",
            "Epoch 199/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2233 - val_loss: 0.2109\n",
            "Loss: 0.22330309450626373\n",
            "Validation Loss: 0.21088309586048126\n",
            "\n",
            "Epoch 200/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2237 - val_loss: 0.2112\n",
            "Loss: 0.22373197972774506\n",
            "Validation Loss: 0.21124188601970673\n",
            "\n",
            "Epoch 201/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2225 - val_loss: 0.2101\n",
            "Loss: 0.22245889902114868\n",
            "Validation Loss: 0.21011213958263397\n",
            "\n",
            "Epoch 202/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2209 - val_loss: 0.2081\n",
            "Loss: 0.22090235352516174\n",
            "Validation Loss: 0.20807290077209473\n",
            "\n",
            "Epoch 203/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2229 - val_loss: 0.2077\n",
            "Loss: 0.2228594869375229\n",
            "Validation Loss: 0.20765778422355652\n",
            "\n",
            "Epoch 204/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2225 - val_loss: 0.2081\n",
            "Loss: 0.2225472629070282\n",
            "Validation Loss: 0.2080998718738556\n",
            "\n",
            "Epoch 205/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2211 - val_loss: 0.2094\n",
            "Loss: 0.2210879623889923\n",
            "Validation Loss: 0.20941562950611115\n",
            "\n",
            "Epoch 206/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2216 - val_loss: 0.2085\n",
            "Loss: 0.2215597927570343\n",
            "Validation Loss: 0.2084936499595642\n",
            "\n",
            "Epoch 207/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2214 - val_loss: 0.2124\n",
            "Loss: 0.2213813215494156\n",
            "Validation Loss: 0.21240116655826569\n",
            "\n",
            "Epoch 208/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2185 - val_loss: 0.2075\n",
            "Loss: 0.2185424566268921\n",
            "Validation Loss: 0.20747943222522736\n",
            "\n",
            "Epoch 209/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2193 - val_loss: 0.2068\n",
            "Loss: 0.21930168569087982\n",
            "Validation Loss: 0.20681290328502655\n",
            "\n",
            "Epoch 210/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2189 - val_loss: 0.2092\n",
            "Loss: 0.21890400350093842\n",
            "Validation Loss: 0.2092202603816986\n",
            "\n",
            "Epoch 211/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2189 - val_loss: 0.2083\n",
            "Loss: 0.21888215839862823\n",
            "Validation Loss: 0.20828336477279663\n",
            "\n",
            "Epoch 212/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2189 - val_loss: 0.2063\n",
            "Loss: 0.2189258337020874\n",
            "Validation Loss: 0.20630604028701782\n",
            "\n",
            "Epoch 213/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2187 - val_loss: 0.2064\n",
            "Loss: 0.21874982118606567\n",
            "Validation Loss: 0.20643775165081024\n",
            "\n",
            "Epoch 214/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2206 - val_loss: 0.2047\n",
            "Loss: 0.22058318555355072\n",
            "Validation Loss: 0.20472337305545807\n",
            "\n",
            "Epoch 215/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2185 - val_loss: 0.2090\n",
            "Loss: 0.21851862967014313\n",
            "Validation Loss: 0.20897158980369568\n",
            "\n",
            "Epoch 216/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2206 - val_loss: 0.2072\n",
            "Loss: 0.22060999274253845\n",
            "Validation Loss: 0.20717628300189972\n",
            "\n",
            "Epoch 217/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2194 - val_loss: 0.2082\n",
            "Loss: 0.21936585009098053\n",
            "Validation Loss: 0.208152174949646\n",
            "\n",
            "Epoch 218/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2204 - val_loss: 0.2090\n",
            "Loss: 0.22041939198970795\n",
            "Validation Loss: 0.20903781056404114\n",
            "\n",
            "Epoch 219/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2184 - val_loss: 0.2067\n",
            "Loss: 0.21843409538269043\n",
            "Validation Loss: 0.20667017996311188\n",
            "\n",
            "Epoch 220/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2186 - val_loss: 0.2058\n",
            "Loss: 0.2186233550310135\n",
            "Validation Loss: 0.20575861632823944\n",
            "\n",
            "Epoch 221/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2179 - val_loss: 0.2054\n",
            "Loss: 0.2178822010755539\n",
            "Validation Loss: 0.20541107654571533\n",
            "\n",
            "Epoch 222/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2182 - val_loss: 0.2068\n",
            "Loss: 0.21819013357162476\n",
            "Validation Loss: 0.20675022900104523\n",
            "\n",
            "Epoch 223/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2173 - val_loss: 0.2064\n",
            "Loss: 0.21725362539291382\n",
            "Validation Loss: 0.20636016130447388\n",
            "\n",
            "Epoch 224/750\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.2190 - val_loss: 0.2067\n",
            "Loss: 0.21902403235435486\n",
            "Validation Loss: 0.20666424930095673\n",
            "\n",
            "Epoch 225/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2187 - val_loss: 0.2093\n",
            "Loss: 0.21867910027503967\n",
            "Validation Loss: 0.20930585265159607\n",
            "\n",
            "Epoch 226/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2185 - val_loss: 0.2063\n",
            "Loss: 0.2184816151857376\n",
            "Validation Loss: 0.20629768073558807\n",
            "\n",
            "Epoch 227/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2179 - val_loss: 0.2109\n",
            "Loss: 0.21792112290859222\n",
            "Validation Loss: 0.21090193092823029\n",
            "\n",
            "Epoch 228/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2175 - val_loss: 0.2050\n",
            "Loss: 0.2175149917602539\n",
            "Validation Loss: 0.20499150454998016\n",
            "\n",
            "Epoch 229/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2162 - val_loss: 0.2073\n",
            "Loss: 0.21621669828891754\n",
            "Validation Loss: 0.20730189979076385\n",
            "\n",
            "Epoch 230/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2199 - val_loss: 0.2069\n",
            "Loss: 0.21994845569133759\n",
            "Validation Loss: 0.2069038599729538\n",
            "\n",
            "Epoch 231/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2165 - val_loss: 0.2036\n",
            "Loss: 0.21646416187286377\n",
            "Validation Loss: 0.20355439186096191\n",
            "\n",
            "Epoch 232/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2172 - val_loss: 0.2048\n",
            "Loss: 0.21723654866218567\n",
            "Validation Loss: 0.20476603507995605\n",
            "\n",
            "Epoch 233/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2163 - val_loss: 0.2032\n",
            "Loss: 0.2162555456161499\n",
            "Validation Loss: 0.2032390534877777\n",
            "\n",
            "Epoch 234/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2167 - val_loss: 0.2042\n",
            "Loss: 0.21665027737617493\n",
            "Validation Loss: 0.2042263299226761\n",
            "\n",
            "Epoch 235/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2173 - val_loss: 0.2053\n",
            "Loss: 0.21730071306228638\n",
            "Validation Loss: 0.2052508145570755\n",
            "\n",
            "Epoch 236/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2161 - val_loss: 0.2049\n",
            "Loss: 0.21605926752090454\n",
            "Validation Loss: 0.2048739790916443\n",
            "\n",
            "Epoch 237/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2169 - val_loss: 0.2040\n",
            "Loss: 0.21689806878566742\n",
            "Validation Loss: 0.2039564698934555\n",
            "\n",
            "Epoch 238/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2173 - val_loss: 0.2030\n",
            "Loss: 0.21731242537498474\n",
            "Validation Loss: 0.20295096933841705\n",
            "\n",
            "Epoch 239/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2162 - val_loss: 0.2090\n",
            "Loss: 0.21618039906024933\n",
            "Validation Loss: 0.20899589359760284\n",
            "\n",
            "Epoch 240/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2169 - val_loss: 0.2007\n",
            "Loss: 0.21693941950798035\n",
            "Validation Loss: 0.20071899890899658\n",
            "\n",
            "Epoch 241/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2153 - val_loss: 0.2042\n",
            "Loss: 0.21527110040187836\n",
            "Validation Loss: 0.2042093127965927\n",
            "\n",
            "Epoch 242/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2149 - val_loss: 0.2079\n",
            "Loss: 0.21494349837303162\n",
            "Validation Loss: 0.20790842175483704\n",
            "\n",
            "Epoch 243/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2139 - val_loss: 0.2029\n",
            "Loss: 0.21391065418720245\n",
            "Validation Loss: 0.20287145674228668\n",
            "\n",
            "Epoch 244/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2138 - val_loss: 0.2036\n",
            "Loss: 0.21380242705345154\n",
            "Validation Loss: 0.20359478890895844\n",
            "\n",
            "Epoch 245/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2137 - val_loss: 0.2014\n",
            "Loss: 0.21367308497428894\n",
            "Validation Loss: 0.20142662525177002\n",
            "\n",
            "Epoch 246/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2150 - val_loss: 0.2045\n",
            "Loss: 0.2150263488292694\n",
            "Validation Loss: 0.20451658964157104\n",
            "\n",
            "Epoch 247/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2154 - val_loss: 0.2013\n",
            "Loss: 0.21537242829799652\n",
            "Validation Loss: 0.20127755403518677\n",
            "\n",
            "Epoch 248/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2137 - val_loss: 0.2031\n",
            "Loss: 0.21367359161376953\n",
            "Validation Loss: 0.20314745604991913\n",
            "\n",
            "Epoch 249/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2148 - val_loss: 0.2030\n",
            "Loss: 0.21477767825126648\n",
            "Validation Loss: 0.20296542346477509\n",
            "\n",
            "Epoch 250/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2144 - val_loss: 0.2028\n",
            "Loss: 0.21436621248722076\n",
            "Validation Loss: 0.2027762085199356\n",
            "\n",
            "Epoch 251/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2135 - val_loss: 0.2003\n",
            "Loss: 0.21346259117126465\n",
            "Validation Loss: 0.2002774178981781\n",
            "\n",
            "Epoch 252/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2145 - val_loss: 0.2022\n",
            "Loss: 0.21447911858558655\n",
            "Validation Loss: 0.20218013226985931\n",
            "\n",
            "Epoch 253/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2139 - val_loss: 0.2065\n",
            "Loss: 0.21388138830661774\n",
            "Validation Loss: 0.20654645562171936\n",
            "\n",
            "Epoch 254/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2132 - val_loss: 0.2034\n",
            "Loss: 0.21317358314990997\n",
            "Validation Loss: 0.20335422456264496\n",
            "\n",
            "Epoch 255/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2149 - val_loss: 0.2006\n",
            "Loss: 0.21486368775367737\n",
            "Validation Loss: 0.20057998597621918\n",
            "\n",
            "Epoch 256/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2134 - val_loss: 0.2019\n",
            "Loss: 0.2134111076593399\n",
            "Validation Loss: 0.2018798589706421\n",
            "\n",
            "Epoch 257/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2142 - val_loss: 0.2033\n",
            "Loss: 0.21422472596168518\n",
            "Validation Loss: 0.20331020653247833\n",
            "\n",
            "Epoch 258/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2139 - val_loss: 0.2043\n",
            "Loss: 0.213902547955513\n",
            "Validation Loss: 0.204270139336586\n",
            "\n",
            "Epoch 259/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2145 - val_loss: 0.2018\n",
            "Loss: 0.21447288990020752\n",
            "Validation Loss: 0.20182985067367554\n",
            "\n",
            "Epoch 260/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2125 - val_loss: 0.2036\n",
            "Loss: 0.21246574819087982\n",
            "Validation Loss: 0.20356407761573792\n",
            "\n",
            "Epoch 261/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2137 - val_loss: 0.2034\n",
            "Loss: 0.2137068212032318\n",
            "Validation Loss: 0.2033533751964569\n",
            "\n",
            "Epoch 262/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2122 - val_loss: 0.2026\n",
            "Loss: 0.21223147213459015\n",
            "Validation Loss: 0.20263731479644775\n",
            "\n",
            "Epoch 263/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2145 - val_loss: 0.2020\n",
            "Loss: 0.21451596915721893\n",
            "Validation Loss: 0.20202244818210602\n",
            "\n",
            "Epoch 264/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2140 - val_loss: 0.2017\n",
            "Loss: 0.2139742225408554\n",
            "Validation Loss: 0.20170097053050995\n",
            "\n",
            "Epoch 265/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2133 - val_loss: 0.1995\n",
            "Loss: 0.2133391946554184\n",
            "Validation Loss: 0.19949114322662354\n",
            "\n",
            "Epoch 266/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2138 - val_loss: 0.2062\n",
            "Loss: 0.21379990875720978\n",
            "Validation Loss: 0.20618940889835358\n",
            "\n",
            "Epoch 267/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2130 - val_loss: 0.2015\n",
            "Loss: 0.2129632979631424\n",
            "Validation Loss: 0.20146921277046204\n",
            "\n",
            "Epoch 268/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2136 - val_loss: 0.2019\n",
            "Loss: 0.21363544464111328\n",
            "Validation Loss: 0.20192158222198486\n",
            "\n",
            "Epoch 269/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2125 - val_loss: 0.1985\n",
            "Loss: 0.21250440180301666\n",
            "Validation Loss: 0.19848966598510742\n",
            "\n",
            "Epoch 270/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2109 - val_loss: 0.2033\n",
            "Loss: 0.2108970731496811\n",
            "Validation Loss: 0.20329967141151428\n",
            "\n",
            "Epoch 271/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2117 - val_loss: 0.1997\n",
            "Loss: 0.21170558035373688\n",
            "Validation Loss: 0.19971832633018494\n",
            "\n",
            "Epoch 272/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2124 - val_loss: 0.2035\n",
            "Loss: 0.21242442727088928\n",
            "Validation Loss: 0.20345386862754822\n",
            "\n",
            "Epoch 273/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2115 - val_loss: 0.2012\n",
            "Loss: 0.21150605380535126\n",
            "Validation Loss: 0.2011648416519165\n",
            "\n",
            "Epoch 274/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2114 - val_loss: 0.2037\n",
            "Loss: 0.2113850861787796\n",
            "Validation Loss: 0.2037198692560196\n",
            "\n",
            "Epoch 275/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2113 - val_loss: 0.2027\n",
            "Loss: 0.21127451956272125\n",
            "Validation Loss: 0.20272214710712433\n",
            "\n",
            "Epoch 276/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2107 - val_loss: 0.2008\n",
            "Loss: 0.21066878736019135\n",
            "Validation Loss: 0.20083491504192352\n",
            "\n",
            "Epoch 277/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2103 - val_loss: 0.1997\n",
            "Loss: 0.21032147109508514\n",
            "Validation Loss: 0.19972026348114014\n",
            "\n",
            "Epoch 278/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2117 - val_loss: 0.1977\n",
            "Loss: 0.21167071163654327\n",
            "Validation Loss: 0.19774554669857025\n",
            "\n",
            "Epoch 279/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2113 - val_loss: 0.2009\n",
            "Loss: 0.21128340065479279\n",
            "Validation Loss: 0.20090045034885406\n",
            "\n",
            "Epoch 280/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2119 - val_loss: 0.2000\n",
            "Loss: 0.21191802620887756\n",
            "Validation Loss: 0.20004011690616608\n",
            "\n",
            "Epoch 281/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2106 - val_loss: 0.2024\n",
            "Loss: 0.21061743795871735\n",
            "Validation Loss: 0.2023863047361374\n",
            "\n",
            "Epoch 282/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2098 - val_loss: 0.1991\n",
            "Loss: 0.20983636379241943\n",
            "Validation Loss: 0.19906048476696014\n",
            "\n",
            "Epoch 283/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2113 - val_loss: 0.1996\n",
            "Loss: 0.21132127940654755\n",
            "Validation Loss: 0.19959460198879242\n",
            "\n",
            "Epoch 284/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2090 - val_loss: 0.1999\n",
            "Loss: 0.20901897549629211\n",
            "Validation Loss: 0.19990196824073792\n",
            "\n",
            "Epoch 285/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2099 - val_loss: 0.1995\n",
            "Loss: 0.20991691946983337\n",
            "Validation Loss: 0.19953392446041107\n",
            "\n",
            "Epoch 286/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2093 - val_loss: 0.2025\n",
            "Loss: 0.209284707903862\n",
            "Validation Loss: 0.20245449244976044\n",
            "\n",
            "Epoch 287/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2094 - val_loss: 0.2031\n",
            "Loss: 0.20939235389232635\n",
            "Validation Loss: 0.2031138837337494\n",
            "\n",
            "Epoch 288/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2104 - val_loss: 0.1982\n",
            "Loss: 0.2104073017835617\n",
            "Validation Loss: 0.19822436571121216\n",
            "\n",
            "Epoch 289/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2102 - val_loss: 0.1978\n",
            "Loss: 0.21020857989788055\n",
            "Validation Loss: 0.19780579209327698\n",
            "\n",
            "Epoch 290/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2097 - val_loss: 0.1989\n",
            "Loss: 0.209696426987648\n",
            "Validation Loss: 0.1989143341779709\n",
            "\n",
            "Epoch 291/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2102 - val_loss: 0.1995\n",
            "Loss: 0.21023160219192505\n",
            "Validation Loss: 0.199459046125412\n",
            "\n",
            "Epoch 292/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2088 - val_loss: 0.2001\n",
            "Loss: 0.20875445008277893\n",
            "Validation Loss: 0.20006544888019562\n",
            "\n",
            "Epoch 293/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2073 - val_loss: 0.2004\n",
            "Loss: 0.20725439488887787\n",
            "Validation Loss: 0.20038862526416779\n",
            "\n",
            "Epoch 294/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2095 - val_loss: 0.1997\n",
            "Loss: 0.20945027470588684\n",
            "Validation Loss: 0.19966402649879456\n",
            "\n",
            "Epoch 295/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2095 - val_loss: 0.1988\n",
            "Loss: 0.20946212112903595\n",
            "Validation Loss: 0.1987660527229309\n",
            "\n",
            "Epoch 296/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2103 - val_loss: 0.2003\n",
            "Loss: 0.21028336882591248\n",
            "Validation Loss: 0.200289785861969\n",
            "\n",
            "Epoch 297/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2096 - val_loss: 0.1997\n",
            "Loss: 0.20955093204975128\n",
            "Validation Loss: 0.19966290891170502\n",
            "\n",
            "Epoch 298/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2082 - val_loss: 0.1997\n",
            "Loss: 0.2081722766160965\n",
            "Validation Loss: 0.19972267746925354\n",
            "\n",
            "Epoch 299/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2084 - val_loss: 0.1995\n",
            "Loss: 0.208352193236351\n",
            "Validation Loss: 0.19953662157058716\n",
            "\n",
            "Epoch 300/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2099 - val_loss: 0.1991\n",
            "Loss: 0.20990829169750214\n",
            "Validation Loss: 0.19908365607261658\n",
            "\n",
            "Epoch 301/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2093 - val_loss: 0.2006\n",
            "Loss: 0.20929597318172455\n",
            "Validation Loss: 0.2006324678659439\n",
            "\n",
            "Epoch 302/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2087 - val_loss: 0.2000\n",
            "Loss: 0.2087266594171524\n",
            "Validation Loss: 0.19998443126678467\n",
            "\n",
            "Epoch 303/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2088 - val_loss: 0.2011\n",
            "Loss: 0.2087782919406891\n",
            "Validation Loss: 0.2011270672082901\n",
            "\n",
            "Epoch 304/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2099 - val_loss: 0.1995\n",
            "Loss: 0.20985963940620422\n",
            "Validation Loss: 0.19946596026420593\n",
            "\n",
            "Epoch 305/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2076 - val_loss: 0.2012\n",
            "Loss: 0.20756033062934875\n",
            "Validation Loss: 0.20119281113147736\n",
            "\n",
            "Epoch 306/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2066 - val_loss: 0.1973\n",
            "Loss: 0.20664390921592712\n",
            "Validation Loss: 0.1973334103822708\n",
            "\n",
            "Epoch 307/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2079 - val_loss: 0.1989\n",
            "Loss: 0.20794571936130524\n",
            "Validation Loss: 0.19885969161987305\n",
            "\n",
            "Epoch 308/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2079 - val_loss: 0.1989\n",
            "Loss: 0.20793402194976807\n",
            "Validation Loss: 0.1988903135061264\n",
            "\n",
            "Epoch 309/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2077 - val_loss: 0.1996\n",
            "Loss: 0.2077186107635498\n",
            "Validation Loss: 0.1995994597673416\n",
            "\n",
            "Epoch 310/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2089 - val_loss: 0.1991\n",
            "Loss: 0.20887704193592072\n",
            "Validation Loss: 0.1991443634033203\n",
            "\n",
            "Epoch 311/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2091 - val_loss: 0.1973\n",
            "Loss: 0.20912708342075348\n",
            "Validation Loss: 0.1973285675048828\n",
            "\n",
            "Epoch 312/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2079 - val_loss: 0.1972\n",
            "Loss: 0.207856222987175\n",
            "Validation Loss: 0.19722042977809906\n",
            "\n",
            "Epoch 313/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2093 - val_loss: 0.1991\n",
            "Loss: 0.20929133892059326\n",
            "Validation Loss: 0.19911623001098633\n",
            "\n",
            "Epoch 314/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2079 - val_loss: 0.1983\n",
            "Loss: 0.20788870751857758\n",
            "Validation Loss: 0.1982950121164322\n",
            "\n",
            "Epoch 315/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2064 - val_loss: 0.1977\n",
            "Loss: 0.20640894770622253\n",
            "Validation Loss: 0.19771218299865723\n",
            "\n",
            "Epoch 316/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2079 - val_loss: 0.1957\n",
            "Loss: 0.20785044133663177\n",
            "Validation Loss: 0.19573940336704254\n",
            "\n",
            "Epoch 317/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2078 - val_loss: 0.1989\n",
            "Loss: 0.20776472985744476\n",
            "Validation Loss: 0.1988527625799179\n",
            "\n",
            "Epoch 318/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2069 - val_loss: 0.1980\n",
            "Loss: 0.20692004263401031\n",
            "Validation Loss: 0.1979629397392273\n",
            "\n",
            "Epoch 319/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2069 - val_loss: 0.1981\n",
            "Loss: 0.20694895088672638\n",
            "Validation Loss: 0.1980656087398529\n",
            "\n",
            "Epoch 320/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2071 - val_loss: 0.1975\n",
            "Loss: 0.20712782442569733\n",
            "Validation Loss: 0.1975426822900772\n",
            "\n",
            "Epoch 321/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2054 - val_loss: 0.1985\n",
            "Loss: 0.20541533827781677\n",
            "Validation Loss: 0.1984880566596985\n",
            "\n",
            "Epoch 322/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2065 - val_loss: 0.1961\n",
            "Loss: 0.20645840466022491\n",
            "Validation Loss: 0.19605512917041779\n",
            "\n",
            "Epoch 323/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2063 - val_loss: 0.1980\n",
            "Loss: 0.2063484489917755\n",
            "Validation Loss: 0.19796903431415558\n",
            "\n",
            "Epoch 324/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2071 - val_loss: 0.1967\n",
            "Loss: 0.2071204036474228\n",
            "Validation Loss: 0.196676567196846\n",
            "\n",
            "Epoch 325/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2081 - val_loss: 0.1972\n",
            "Loss: 0.20809908211231232\n",
            "Validation Loss: 0.19717533886432648\n",
            "\n",
            "Epoch 326/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2082 - val_loss: 0.2011\n",
            "Loss: 0.20816688239574432\n",
            "Validation Loss: 0.2011496126651764\n",
            "\n",
            "Epoch 327/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2073 - val_loss: 0.1966\n",
            "Loss: 0.20726941525936127\n",
            "Validation Loss: 0.19664333760738373\n",
            "\n",
            "Epoch 328/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2062 - val_loss: 0.1971\n",
            "Loss: 0.20616646111011505\n",
            "Validation Loss: 0.19707104563713074\n",
            "\n",
            "Epoch 329/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2070 - val_loss: 0.1973\n",
            "Loss: 0.2069740891456604\n",
            "Validation Loss: 0.1972881704568863\n",
            "\n",
            "Epoch 330/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2065 - val_loss: 0.1981\n",
            "Loss: 0.20651918649673462\n",
            "Validation Loss: 0.1981273740530014\n",
            "\n",
            "Epoch 331/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2059 - val_loss: 0.1957\n",
            "Loss: 0.20589785277843475\n",
            "Validation Loss: 0.19572527706623077\n",
            "\n",
            "Epoch 332/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2060 - val_loss: 0.1964\n",
            "Loss: 0.20597489178180695\n",
            "Validation Loss: 0.19639769196510315\n",
            "\n",
            "Epoch 333/750\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2051 - val_loss: 0.1988\n",
            "Loss: 0.20509116351604462\n",
            "Validation Loss: 0.1988198608160019\n",
            "\n",
            "Epoch 334/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2061 - val_loss: 0.1974\n",
            "Loss: 0.20606207847595215\n",
            "Validation Loss: 0.19740985333919525\n",
            "\n",
            "Epoch 335/750\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2066 - val_loss: 0.1954\n",
            "Loss: 0.2066168189048767\n",
            "Validation Loss: 0.1954222321510315\n",
            "\n",
            "Epoch 336/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2060 - val_loss: 0.1961\n",
            "Loss: 0.20604129135608673\n",
            "Validation Loss: 0.1960536539554596\n",
            "\n",
            "Epoch 337/750\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2052 - val_loss: 0.1986\n",
            "Loss: 0.2051820009946823\n",
            "Validation Loss: 0.19861210882663727\n",
            "\n",
            "Epoch 338/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2069 - val_loss: 0.1932\n",
            "Loss: 0.20688024163246155\n",
            "Validation Loss: 0.19317415356636047\n",
            "\n",
            "Epoch 339/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2058 - val_loss: 0.1956\n",
            "Loss: 0.2057817429304123\n",
            "Validation Loss: 0.19563201069831848\n",
            "\n",
            "Epoch 340/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2057 - val_loss: 0.1984\n",
            "Loss: 0.20568281412124634\n",
            "Validation Loss: 0.19842098653316498\n",
            "\n",
            "Epoch 341/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2052 - val_loss: 0.1950\n",
            "Loss: 0.20515747368335724\n",
            "Validation Loss: 0.19497478008270264\n",
            "\n",
            "Epoch 342/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2049 - val_loss: 0.1958\n",
            "Loss: 0.20488141477108002\n",
            "Validation Loss: 0.19584794342517853\n",
            "\n",
            "Epoch 343/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2044 - val_loss: 0.1969\n",
            "Loss: 0.2044258862733841\n",
            "Validation Loss: 0.19690553843975067\n",
            "\n",
            "Epoch 344/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2047 - val_loss: 0.1957\n",
            "Loss: 0.20469725131988525\n",
            "Validation Loss: 0.19570142030715942\n",
            "\n",
            "Epoch 345/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2055 - val_loss: 0.1959\n",
            "Loss: 0.20551228523254395\n",
            "Validation Loss: 0.19586995244026184\n",
            "\n",
            "Epoch 346/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2061 - val_loss: 0.1963\n",
            "Loss: 0.20610016584396362\n",
            "Validation Loss: 0.1963038146495819\n",
            "\n",
            "Epoch 347/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2043 - val_loss: 0.1973\n",
            "Loss: 0.2042892575263977\n",
            "Validation Loss: 0.19734036922454834\n",
            "\n",
            "Epoch 348/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2042 - val_loss: 0.1934\n",
            "Loss: 0.20420455932617188\n",
            "Validation Loss: 0.1934475153684616\n",
            "\n",
            "Epoch 349/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2055 - val_loss: 0.1976\n",
            "Loss: 0.20550212264060974\n",
            "Validation Loss: 0.19763310253620148\n",
            "\n",
            "Epoch 350/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2050 - val_loss: 0.2008\n",
            "Loss: 0.20497295260429382\n",
            "Validation Loss: 0.2007601112127304\n",
            "\n",
            "Epoch 351/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2070 - val_loss: 0.1949\n",
            "Loss: 0.2070178985595703\n",
            "Validation Loss: 0.1949000358581543\n",
            "\n",
            "Epoch 352/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2053 - val_loss: 0.1964\n",
            "Loss: 0.20530574023723602\n",
            "Validation Loss: 0.1964145451784134\n",
            "\n",
            "Epoch 353/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2045 - val_loss: 0.1977\n",
            "Loss: 0.20447705686092377\n",
            "Validation Loss: 0.19768890738487244\n",
            "\n",
            "Epoch 354/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2049 - val_loss: 0.1949\n",
            "Loss: 0.20489756762981415\n",
            "Validation Loss: 0.19489051401615143\n",
            "\n",
            "Epoch 355/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2047 - val_loss: 0.1952\n",
            "Loss: 0.2046872228384018\n",
            "Validation Loss: 0.19522406160831451\n",
            "\n",
            "Epoch 356/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2036 - val_loss: 0.1970\n",
            "Loss: 0.20360392332077026\n",
            "Validation Loss: 0.19698554277420044\n",
            "\n",
            "Epoch 357/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2054 - val_loss: 0.1971\n",
            "Loss: 0.20543713867664337\n",
            "Validation Loss: 0.19711944460868835\n",
            "\n",
            "Epoch 358/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2045 - val_loss: 0.1979\n",
            "Loss: 0.2045365571975708\n",
            "Validation Loss: 0.1978999525308609\n",
            "\n",
            "Epoch 359/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2040 - val_loss: 0.1946\n",
            "Loss: 0.20399339497089386\n",
            "Validation Loss: 0.19462202489376068\n",
            "\n",
            "Epoch 360/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2046 - val_loss: 0.1979\n",
            "Loss: 0.20463460683822632\n",
            "Validation Loss: 0.19792085886001587\n",
            "\n",
            "Epoch 361/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2033 - val_loss: 0.1958\n",
            "Loss: 0.20334090292453766\n",
            "Validation Loss: 0.19578789174556732\n",
            "\n",
            "Epoch 362/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2036 - val_loss: 0.1932\n",
            "Loss: 0.20361319184303284\n",
            "Validation Loss: 0.19322843849658966\n",
            "\n",
            "Epoch 363/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2046 - val_loss: 0.1944\n",
            "Loss: 0.20456382632255554\n",
            "Validation Loss: 0.1944437175989151\n",
            "\n",
            "Epoch 364/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2037 - val_loss: 0.1946\n",
            "Loss: 0.20370669662952423\n",
            "Validation Loss: 0.1946425586938858\n",
            "\n",
            "Epoch 365/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2039 - val_loss: 0.1975\n",
            "Loss: 0.20388378202915192\n",
            "Validation Loss: 0.19749239087104797\n",
            "\n",
            "Epoch 366/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2037 - val_loss: 0.1948\n",
            "Loss: 0.20373432338237762\n",
            "Validation Loss: 0.1947859525680542\n",
            "\n",
            "Epoch 367/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2042 - val_loss: 0.1961\n",
            "Loss: 0.20423072576522827\n",
            "Validation Loss: 0.1960824877023697\n",
            "\n",
            "Epoch 368/750\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.2032 - val_loss: 0.1939\n",
            "Loss: 0.20319148898124695\n",
            "Validation Loss: 0.1938556581735611\n",
            "\n",
            "Epoch 369/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2038 - val_loss: 0.1942\n",
            "Loss: 0.20378530025482178\n",
            "Validation Loss: 0.19416804611682892\n",
            "\n",
            "Epoch 370/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2036 - val_loss: 0.1963\n",
            "Loss: 0.20361386239528656\n",
            "Validation Loss: 0.19625478982925415\n",
            "\n",
            "Epoch 371/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2048 - val_loss: 0.1924\n",
            "Loss: 0.2047591656446457\n",
            "Validation Loss: 0.19242559373378754\n",
            "\n",
            "Epoch 372/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2034 - val_loss: 0.1976\n",
            "Loss: 0.20335493981838226\n",
            "Validation Loss: 0.19758391380310059\n",
            "\n",
            "Epoch 373/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2037 - val_loss: 0.1964\n",
            "Loss: 0.20372377336025238\n",
            "Validation Loss: 0.19641318917274475\n",
            "\n",
            "Epoch 374/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2031 - val_loss: 0.1931\n",
            "Loss: 0.20313267409801483\n",
            "Validation Loss: 0.19305481016635895\n",
            "\n",
            "Epoch 375/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2031 - val_loss: 0.1930\n",
            "Loss: 0.20307372510433197\n",
            "Validation Loss: 0.19296425580978394\n",
            "\n",
            "Epoch 376/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2035 - val_loss: 0.1931\n",
            "Loss: 0.2034999281167984\n",
            "Validation Loss: 0.19307047128677368\n",
            "\n",
            "Epoch 377/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2033 - val_loss: 0.1949\n",
            "Loss: 0.20329919457435608\n",
            "Validation Loss: 0.19488893449306488\n",
            "\n",
            "Epoch 378/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2041 - val_loss: 0.1922\n",
            "Loss: 0.20413951575756073\n",
            "Validation Loss: 0.1922101527452469\n",
            "\n",
            "Epoch 379/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2034 - val_loss: 0.1954\n",
            "Loss: 0.20336464047431946\n",
            "Validation Loss: 0.19539490342140198\n",
            "\n",
            "Epoch 380/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2029 - val_loss: 0.1946\n",
            "Loss: 0.20289936661720276\n",
            "Validation Loss: 0.19464150071144104\n",
            "\n",
            "Epoch 381/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2030 - val_loss: 0.1957\n",
            "Loss: 0.2030276507139206\n",
            "Validation Loss: 0.19572407007217407\n",
            "\n",
            "Epoch 382/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2024 - val_loss: 0.1951\n",
            "Loss: 0.20236925780773163\n",
            "Validation Loss: 0.19510512053966522\n",
            "\n",
            "Epoch 383/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2038 - val_loss: 0.1935\n",
            "Loss: 0.2037745863199234\n",
            "Validation Loss: 0.19351696968078613\n",
            "\n",
            "Epoch 384/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2022 - val_loss: 0.1964\n",
            "Loss: 0.20219506323337555\n",
            "Validation Loss: 0.19640304148197174\n",
            "\n",
            "Epoch 385/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2035 - val_loss: 0.1973\n",
            "Loss: 0.20350834727287292\n",
            "Validation Loss: 0.19734203815460205\n",
            "\n",
            "Epoch 386/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2032 - val_loss: 0.1946\n",
            "Loss: 0.20322903990745544\n",
            "Validation Loss: 0.194558247923851\n",
            "\n",
            "Epoch 387/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2025 - val_loss: 0.1925\n",
            "Loss: 0.20250852406024933\n",
            "Validation Loss: 0.19249173998832703\n",
            "\n",
            "Epoch 388/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2020 - val_loss: 0.1923\n",
            "Loss: 0.20196248590946198\n",
            "Validation Loss: 0.19228863716125488\n",
            "\n",
            "Epoch 389/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2028 - val_loss: 0.1947\n",
            "Loss: 0.20275409519672394\n",
            "Validation Loss: 0.19465143978595734\n",
            "\n",
            "Epoch 390/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2017 - val_loss: 0.1936\n",
            "Loss: 0.20167487859725952\n",
            "Validation Loss: 0.19361361861228943\n",
            "\n",
            "Epoch 391/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2030 - val_loss: 0.1951\n",
            "Loss: 0.20299287140369415\n",
            "Validation Loss: 0.19511911273002625\n",
            "\n",
            "Epoch 392/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2021 - val_loss: 0.1929\n",
            "Loss: 0.20210202038288116\n",
            "Validation Loss: 0.1929044872522354\n",
            "\n",
            "Epoch 393/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2024 - val_loss: 0.1955\n",
            "Loss: 0.2024272233247757\n",
            "Validation Loss: 0.19545245170593262\n",
            "\n",
            "Epoch 394/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2018 - val_loss: 0.1934\n",
            "Loss: 0.20178988575935364\n",
            "Validation Loss: 0.19341464340686798\n",
            "\n",
            "Epoch 395/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2017 - val_loss: 0.1939\n",
            "Loss: 0.20173494517803192\n",
            "Validation Loss: 0.19387930631637573\n",
            "\n",
            "Epoch 396/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2036 - val_loss: 0.1936\n",
            "Loss: 0.20358885824680328\n",
            "Validation Loss: 0.19356590509414673\n",
            "\n",
            "Epoch 397/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2018 - val_loss: 0.1915\n",
            "Loss: 0.20176048576831818\n",
            "Validation Loss: 0.19148294627666473\n",
            "\n",
            "Epoch 398/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2020 - val_loss: 0.1913\n",
            "Loss: 0.2019817978143692\n",
            "Validation Loss: 0.1912517249584198\n",
            "\n",
            "Epoch 399/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2013 - val_loss: 0.1933\n",
            "Loss: 0.2013462483882904\n",
            "Validation Loss: 0.19332653284072876\n",
            "\n",
            "Epoch 400/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2009 - val_loss: 0.1938\n",
            "Loss: 0.20086458325386047\n",
            "Validation Loss: 0.19380195438861847\n",
            "\n",
            "Epoch 401/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2008 - val_loss: 0.1946\n",
            "Loss: 0.20076684653759003\n",
            "Validation Loss: 0.19462087750434875\n",
            "\n",
            "Epoch 402/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2018 - val_loss: 0.1946\n",
            "Loss: 0.2018357813358307\n",
            "Validation Loss: 0.1945788860321045\n",
            "\n",
            "Epoch 403/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2016 - val_loss: 0.1912\n",
            "Loss: 0.20162655413150787\n",
            "Validation Loss: 0.19120770692825317\n",
            "\n",
            "Epoch 404/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2017 - val_loss: 0.1965\n",
            "Loss: 0.20165352523326874\n",
            "Validation Loss: 0.19646193087100983\n",
            "\n",
            "Epoch 405/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2031 - val_loss: 0.1930\n",
            "Loss: 0.20311661064624786\n",
            "Validation Loss: 0.19299650192260742\n",
            "\n",
            "Epoch 406/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2019 - val_loss: 0.1921\n",
            "Loss: 0.20186252892017365\n",
            "Validation Loss: 0.19205039739608765\n",
            "\n",
            "Epoch 407/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2009 - val_loss: 0.1962\n",
            "Loss: 0.20089735090732574\n",
            "Validation Loss: 0.19615039229393005\n",
            "\n",
            "Epoch 408/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2008 - val_loss: 0.1921\n",
            "Loss: 0.20080716907978058\n",
            "Validation Loss: 0.19214178621768951\n",
            "\n",
            "Epoch 409/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2012 - val_loss: 0.1953\n",
            "Loss: 0.20117591321468353\n",
            "Validation Loss: 0.19532661139965057\n",
            "\n",
            "Epoch 410/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2012 - val_loss: 0.1937\n",
            "Loss: 0.20120403170585632\n",
            "Validation Loss: 0.19373679161071777\n",
            "\n",
            "Epoch 411/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2008 - val_loss: 0.1924\n",
            "Loss: 0.2008303999900818\n",
            "Validation Loss: 0.19244584441184998\n",
            "\n",
            "Epoch 412/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2013 - val_loss: 0.1976\n",
            "Loss: 0.20131437480449677\n",
            "Validation Loss: 0.19758668541908264\n",
            "\n",
            "Epoch 413/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2015 - val_loss: 0.1942\n",
            "Loss: 0.20151366293430328\n",
            "Validation Loss: 0.19419288635253906\n",
            "\n",
            "Epoch 414/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2020 - val_loss: 0.1947\n",
            "Loss: 0.20203717052936554\n",
            "Validation Loss: 0.19471099972724915\n",
            "\n",
            "Epoch 415/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2006 - val_loss: 0.1935\n",
            "Loss: 0.20060518383979797\n",
            "Validation Loss: 0.19351661205291748\n",
            "\n",
            "Epoch 416/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2004 - val_loss: 0.1912\n",
            "Loss: 0.20038653910160065\n",
            "Validation Loss: 0.1911502182483673\n",
            "\n",
            "Epoch 417/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2016 - val_loss: 0.1941\n",
            "Loss: 0.20155061781406403\n",
            "Validation Loss: 0.19406676292419434\n",
            "\n",
            "Epoch 418/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1996 - val_loss: 0.1901\n",
            "Loss: 0.1995650827884674\n",
            "Validation Loss: 0.19008620083332062\n",
            "\n",
            "Epoch 419/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2008 - val_loss: 0.1909\n",
            "Loss: 0.20084168016910553\n",
            "Validation Loss: 0.19092200696468353\n",
            "\n",
            "Epoch 420/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2010 - val_loss: 0.1949\n",
            "Loss: 0.20099307596683502\n",
            "Validation Loss: 0.19487997889518738\n",
            "\n",
            "Epoch 421/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2013 - val_loss: 0.1983\n",
            "Loss: 0.2013005018234253\n",
            "Validation Loss: 0.19832421839237213\n",
            "\n",
            "Epoch 422/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2010 - val_loss: 0.1913\n",
            "Loss: 0.2010030597448349\n",
            "Validation Loss: 0.19129706919193268\n",
            "\n",
            "Epoch 423/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1998 - val_loss: 0.1944\n",
            "Loss: 0.19984173774719238\n",
            "Validation Loss: 0.19436313211917877\n",
            "\n",
            "Epoch 424/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2013 - val_loss: 0.1956\n",
            "Loss: 0.2012934684753418\n",
            "Validation Loss: 0.19563162326812744\n",
            "\n",
            "Epoch 425/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2000 - val_loss: 0.1947\n",
            "Loss: 0.19996878504753113\n",
            "Validation Loss: 0.19471845030784607\n",
            "\n",
            "Epoch 426/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1995 - val_loss: 0.1925\n",
            "Loss: 0.19945164024829865\n",
            "Validation Loss: 0.1924685835838318\n",
            "\n",
            "Epoch 427/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1996 - val_loss: 0.1929\n",
            "Loss: 0.19955791532993317\n",
            "Validation Loss: 0.19289466738700867\n",
            "\n",
            "Epoch 428/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2005 - val_loss: 0.1934\n",
            "Loss: 0.2004622519016266\n",
            "Validation Loss: 0.1934177130460739\n",
            "\n",
            "Epoch 429/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2003 - val_loss: 0.1933\n",
            "Loss: 0.2002674788236618\n",
            "Validation Loss: 0.19334734976291656\n",
            "\n",
            "Epoch 430/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2007 - val_loss: 0.1904\n",
            "Loss: 0.2006506621837616\n",
            "Validation Loss: 0.19042479991912842\n",
            "\n",
            "Epoch 431/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2001 - val_loss: 0.1930\n",
            "Loss: 0.2000579684972763\n",
            "Validation Loss: 0.19303379952907562\n",
            "\n",
            "Epoch 432/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1992 - val_loss: 0.1926\n",
            "Loss: 0.19918379187583923\n",
            "Validation Loss: 0.19258616864681244\n",
            "\n",
            "Epoch 433/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2007 - val_loss: 0.1923\n",
            "Loss: 0.20073284208774567\n",
            "Validation Loss: 0.19229286909103394\n",
            "\n",
            "Epoch 434/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1998 - val_loss: 0.1923\n",
            "Loss: 0.1998465210199356\n",
            "Validation Loss: 0.19226069748401642\n",
            "\n",
            "Epoch 435/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2006 - val_loss: 0.1885\n",
            "Loss: 0.20056627690792084\n",
            "Validation Loss: 0.18853111565113068\n",
            "\n",
            "Epoch 436/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2002 - val_loss: 0.1942\n",
            "Loss: 0.20022742450237274\n",
            "Validation Loss: 0.19421613216400146\n",
            "\n",
            "Epoch 437/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2009 - val_loss: 0.1898\n",
            "Loss: 0.2009202241897583\n",
            "Validation Loss: 0.18978071212768555\n",
            "\n",
            "Epoch 438/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1999 - val_loss: 0.1990\n",
            "Loss: 0.19992628693580627\n",
            "Validation Loss: 0.1989607810974121\n",
            "\n",
            "Epoch 439/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2001 - val_loss: 0.1898\n",
            "Loss: 0.20010913908481598\n",
            "Validation Loss: 0.1898268759250641\n",
            "\n",
            "Epoch 440/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1993 - val_loss: 0.1936\n",
            "Loss: 0.19925159215927124\n",
            "Validation Loss: 0.19355398416519165\n",
            "\n",
            "Epoch 441/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1988 - val_loss: 0.1899\n",
            "Loss: 0.19876959919929504\n",
            "Validation Loss: 0.18990473449230194\n",
            "\n",
            "Epoch 442/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1998 - val_loss: 0.1939\n",
            "Loss: 0.19981931149959564\n",
            "Validation Loss: 0.19389751553535461\n",
            "\n",
            "Epoch 443/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2005 - val_loss: 0.1920\n",
            "Loss: 0.20051449537277222\n",
            "Validation Loss: 0.19200314581394196\n",
            "\n",
            "Epoch 444/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1992 - val_loss: 0.1903\n",
            "Loss: 0.19917713105678558\n",
            "Validation Loss: 0.19025662541389465\n",
            "\n",
            "Epoch 445/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1994 - val_loss: 0.1928\n",
            "Loss: 0.19935010373592377\n",
            "Validation Loss: 0.19282792508602142\n",
            "\n",
            "Epoch 446/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1995 - val_loss: 0.1908\n",
            "Loss: 0.19950537383556366\n",
            "Validation Loss: 0.19080902636051178\n",
            "\n",
            "Epoch 447/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1994 - val_loss: 0.1914\n",
            "Loss: 0.19944632053375244\n",
            "Validation Loss: 0.1913686841726303\n",
            "\n",
            "Epoch 448/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2006 - val_loss: 0.1927\n",
            "Loss: 0.2005731463432312\n",
            "Validation Loss: 0.1926840990781784\n",
            "\n",
            "Epoch 449/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2008 - val_loss: 0.1893\n",
            "Loss: 0.20080234110355377\n",
            "Validation Loss: 0.18931196630001068\n",
            "\n",
            "Epoch 450/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1997 - val_loss: 0.1912\n",
            "Loss: 0.1996646225452423\n",
            "Validation Loss: 0.19115546345710754\n",
            "\n",
            "Epoch 451/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1995 - val_loss: 0.1922\n",
            "Loss: 0.19950638711452484\n",
            "Validation Loss: 0.19220291078090668\n",
            "\n",
            "Epoch 452/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1990 - val_loss: 0.1911\n",
            "Loss: 0.19900859892368317\n",
            "Validation Loss: 0.19112205505371094\n",
            "\n",
            "Epoch 453/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1977 - val_loss: 0.1921\n",
            "Loss: 0.19773051142692566\n",
            "Validation Loss: 0.19209833443164825\n",
            "\n",
            "Epoch 454/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1978 - val_loss: 0.1931\n",
            "Loss: 0.19779913127422333\n",
            "Validation Loss: 0.19308330118656158\n",
            "\n",
            "Epoch 455/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1992 - val_loss: 0.1913\n",
            "Loss: 0.1992434561252594\n",
            "Validation Loss: 0.19130152463912964\n",
            "\n",
            "Epoch 456/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1989 - val_loss: 0.1910\n",
            "Loss: 0.19885550439357758\n",
            "Validation Loss: 0.1910475641489029\n",
            "\n",
            "Epoch 457/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1985 - val_loss: 0.1911\n",
            "Loss: 0.1984894871711731\n",
            "Validation Loss: 0.1911439299583435\n",
            "\n",
            "Epoch 458/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1986 - val_loss: 0.1932\n",
            "Loss: 0.198627769947052\n",
            "Validation Loss: 0.19315281510353088\n",
            "\n",
            "Epoch 459/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1976 - val_loss: 0.1932\n",
            "Loss: 0.1975529044866562\n",
            "Validation Loss: 0.19316260516643524\n",
            "\n",
            "Epoch 460/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1976 - val_loss: 0.1890\n",
            "Loss: 0.19760532677173615\n",
            "Validation Loss: 0.18900734186172485\n",
            "\n",
            "Epoch 461/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1988 - val_loss: 0.1934\n",
            "Loss: 0.1988351047039032\n",
            "Validation Loss: 0.19339798390865326\n",
            "\n",
            "Epoch 462/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1992 - val_loss: 0.1908\n",
            "Loss: 0.19919177889823914\n",
            "Validation Loss: 0.1908453106880188\n",
            "\n",
            "Epoch 463/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1985 - val_loss: 0.1914\n",
            "Loss: 0.19854947924613953\n",
            "Validation Loss: 0.19141171872615814\n",
            "\n",
            "Epoch 464/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1989 - val_loss: 0.1916\n",
            "Loss: 0.19887156784534454\n",
            "Validation Loss: 0.19158141314983368\n",
            "\n",
            "Epoch 465/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2005 - val_loss: 0.1920\n",
            "Loss: 0.200456440448761\n",
            "Validation Loss: 0.191958487033844\n",
            "\n",
            "Epoch 466/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1983 - val_loss: 0.1914\n",
            "Loss: 0.19825226068496704\n",
            "Validation Loss: 0.19144293665885925\n",
            "\n",
            "Epoch 467/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1982 - val_loss: 0.1916\n",
            "Loss: 0.19823671877384186\n",
            "Validation Loss: 0.19156447052955627\n",
            "\n",
            "Epoch 468/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1990 - val_loss: 0.1923\n",
            "Loss: 0.1990056335926056\n",
            "Validation Loss: 0.1922895908355713\n",
            "\n",
            "Epoch 469/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1977 - val_loss: 0.1873\n",
            "Loss: 0.19772186875343323\n",
            "Validation Loss: 0.1872527003288269\n",
            "\n",
            "Epoch 470/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1978 - val_loss: 0.1921\n",
            "Loss: 0.19781744480133057\n",
            "Validation Loss: 0.1921081691980362\n",
            "\n",
            "Epoch 471/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1983 - val_loss: 0.1923\n",
            "Loss: 0.19832780957221985\n",
            "Validation Loss: 0.19233551621437073\n",
            "\n",
            "Epoch 472/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1983 - val_loss: 0.1917\n",
            "Loss: 0.19826920330524445\n",
            "Validation Loss: 0.19170714914798737\n",
            "\n",
            "Epoch 473/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1989 - val_loss: 0.1904\n",
            "Loss: 0.19891196489334106\n",
            "Validation Loss: 0.19035452604293823\n",
            "\n",
            "Epoch 474/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1994 - val_loss: 0.1900\n",
            "Loss: 0.1993636190891266\n",
            "Validation Loss: 0.1900479942560196\n",
            "\n",
            "Epoch 475/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1984 - val_loss: 0.1896\n",
            "Loss: 0.1984369158744812\n",
            "Validation Loss: 0.1896088570356369\n",
            "\n",
            "Epoch 476/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1971 - val_loss: 0.1900\n",
            "Loss: 0.1970728635787964\n",
            "Validation Loss: 0.18999330699443817\n",
            "\n",
            "Epoch 477/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1977 - val_loss: 0.1887\n",
            "Loss: 0.19766849279403687\n",
            "Validation Loss: 0.1887342780828476\n",
            "\n",
            "Epoch 478/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1986 - val_loss: 0.1910\n",
            "Loss: 0.19861441850662231\n",
            "Validation Loss: 0.1910422444343567\n",
            "\n",
            "Epoch 479/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1966 - val_loss: 0.1892\n",
            "Loss: 0.19656848907470703\n",
            "Validation Loss: 0.1892014890909195\n",
            "\n",
            "Epoch 480/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1973 - val_loss: 0.1911\n",
            "Loss: 0.19727207720279694\n",
            "Validation Loss: 0.19114041328430176\n",
            "\n",
            "Epoch 481/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1991 - val_loss: 0.1895\n",
            "Loss: 0.19907042384147644\n",
            "Validation Loss: 0.18946269154548645\n",
            "\n",
            "Epoch 482/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1988 - val_loss: 0.1910\n",
            "Loss: 0.19878239929676056\n",
            "Validation Loss: 0.19099363684654236\n",
            "\n",
            "Epoch 483/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1979 - val_loss: 0.1889\n",
            "Loss: 0.1979447603225708\n",
            "Validation Loss: 0.18885089457035065\n",
            "\n",
            "Epoch 484/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1981 - val_loss: 0.1905\n",
            "Loss: 0.19807763397693634\n",
            "Validation Loss: 0.19049453735351562\n",
            "\n",
            "Epoch 485/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1992 - val_loss: 0.1911\n",
            "Loss: 0.19922679662704468\n",
            "Validation Loss: 0.1911429762840271\n",
            "\n",
            "Epoch 486/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1969 - val_loss: 0.1896\n",
            "Loss: 0.19691291451454163\n",
            "Validation Loss: 0.18959839642047882\n",
            "\n",
            "Epoch 487/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1977 - val_loss: 0.1900\n",
            "Loss: 0.19770698249340057\n",
            "Validation Loss: 0.19003072381019592\n",
            "\n",
            "Epoch 488/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1977 - val_loss: 0.1886\n",
            "Loss: 0.1977190524339676\n",
            "Validation Loss: 0.18861174583435059\n",
            "\n",
            "Epoch 489/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1986 - val_loss: 0.1912\n",
            "Loss: 0.19860775768756866\n",
            "Validation Loss: 0.19117291271686554\n",
            "\n",
            "Epoch 490/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1971 - val_loss: 0.1899\n",
            "Loss: 0.19705542922019958\n",
            "Validation Loss: 0.18986523151397705\n",
            "\n",
            "Epoch 491/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1985 - val_loss: 0.1925\n",
            "Loss: 0.19845040142536163\n",
            "Validation Loss: 0.1924557238817215\n",
            "\n",
            "Epoch 492/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1973 - val_loss: 0.1887\n",
            "Loss: 0.19729158282279968\n",
            "Validation Loss: 0.18868763744831085\n",
            "\n",
            "Epoch 493/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1980 - val_loss: 0.1891\n",
            "Loss: 0.1980210691690445\n",
            "Validation Loss: 0.18905892968177795\n",
            "\n",
            "Epoch 494/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1975 - val_loss: 0.1901\n",
            "Loss: 0.19753500819206238\n",
            "Validation Loss: 0.1901109516620636\n",
            "\n",
            "Epoch 495/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1984 - val_loss: 0.1897\n",
            "Loss: 0.19835813343524933\n",
            "Validation Loss: 0.18969318270683289\n",
            "\n",
            "Epoch 496/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1982 - val_loss: 0.1935\n",
            "Loss: 0.19824352860450745\n",
            "Validation Loss: 0.19351035356521606\n",
            "\n",
            "Epoch 497/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1969 - val_loss: 0.1880\n",
            "Loss: 0.19686360657215118\n",
            "Validation Loss: 0.18801681697368622\n",
            "\n",
            "Epoch 498/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1967 - val_loss: 0.1905\n",
            "Loss: 0.1966731697320938\n",
            "Validation Loss: 0.1904989629983902\n",
            "\n",
            "Epoch 499/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1962 - val_loss: 0.1907\n",
            "Loss: 0.19624824821949005\n",
            "Validation Loss: 0.19074323773384094\n",
            "\n",
            "Epoch 500/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1965 - val_loss: 0.1914\n",
            "Loss: 0.19654442369937897\n",
            "Validation Loss: 0.1913703829050064\n",
            "\n",
            "Epoch 501/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1963 - val_loss: 0.1913\n",
            "Loss: 0.1963382512331009\n",
            "Validation Loss: 0.19130901992321014\n",
            "\n",
            "Epoch 502/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1962 - val_loss: 0.1886\n",
            "Loss: 0.19619208574295044\n",
            "Validation Loss: 0.1886240839958191\n",
            "\n",
            "Epoch 503/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1968 - val_loss: 0.1885\n",
            "Loss: 0.1967538595199585\n",
            "Validation Loss: 0.18846143782138824\n",
            "\n",
            "Epoch 504/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1971 - val_loss: 0.1905\n",
            "Loss: 0.197120800614357\n",
            "Validation Loss: 0.19049520790576935\n",
            "\n",
            "Epoch 505/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1965 - val_loss: 0.1919\n",
            "Loss: 0.1965106874704361\n",
            "Validation Loss: 0.19185008108615875\n",
            "\n",
            "Epoch 506/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1974 - val_loss: 0.1886\n",
            "Loss: 0.19739605486392975\n",
            "Validation Loss: 0.18863405287265778\n",
            "\n",
            "Epoch 507/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1972 - val_loss: 0.1908\n",
            "Loss: 0.1972348392009735\n",
            "Validation Loss: 0.19076290726661682\n",
            "\n",
            "Epoch 508/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1978 - val_loss: 0.1884\n",
            "Loss: 0.19776049256324768\n",
            "Validation Loss: 0.1884492039680481\n",
            "\n",
            "Epoch 509/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1965 - val_loss: 0.1897\n",
            "Loss: 0.1964624971151352\n",
            "Validation Loss: 0.18966880440711975\n",
            "\n",
            "Epoch 510/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1974 - val_loss: 0.1876\n",
            "Loss: 0.19738076627254486\n",
            "Validation Loss: 0.1875869482755661\n",
            "\n",
            "Epoch 511/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1957 - val_loss: 0.1922\n",
            "Loss: 0.19569703936576843\n",
            "Validation Loss: 0.19221200048923492\n",
            "\n",
            "Epoch 512/750\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.1984 - val_loss: 0.1898\n",
            "Loss: 0.19839872419834137\n",
            "Validation Loss: 0.18979434669017792\n",
            "\n",
            "Epoch 513/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1964 - val_loss: 0.1901\n",
            "Loss: 0.19643628597259521\n",
            "Validation Loss: 0.19012616574764252\n",
            "\n",
            "Epoch 514/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1959 - val_loss: 0.1870\n",
            "Loss: 0.19593599438667297\n",
            "Validation Loss: 0.18695186078548431\n",
            "\n",
            "Epoch 515/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1956 - val_loss: 0.1895\n",
            "Loss: 0.19559867680072784\n",
            "Validation Loss: 0.18952354788780212\n",
            "\n",
            "Epoch 516/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1965 - val_loss: 0.1876\n",
            "Loss: 0.19654352962970734\n",
            "Validation Loss: 0.18762505054473877\n",
            "\n",
            "Epoch 517/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1971 - val_loss: 0.1874\n",
            "Loss: 0.1970992535352707\n",
            "Validation Loss: 0.18743905425071716\n",
            "\n",
            "Epoch 518/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1968 - val_loss: 0.1876\n",
            "Loss: 0.1967771202325821\n",
            "Validation Loss: 0.18761691451072693\n",
            "\n",
            "Epoch 519/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1960 - val_loss: 0.1912\n",
            "Loss: 0.19600340723991394\n",
            "Validation Loss: 0.19122152030467987\n",
            "\n",
            "Epoch 520/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1975 - val_loss: 0.1852\n",
            "Loss: 0.19750149548053741\n",
            "Validation Loss: 0.18521980941295624\n",
            "\n",
            "Epoch 521/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1953 - val_loss: 0.1901\n",
            "Loss: 0.19534242153167725\n",
            "Validation Loss: 0.19006091356277466\n",
            "\n",
            "Epoch 522/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1979 - val_loss: 0.1877\n",
            "Loss: 0.19792181253433228\n",
            "Validation Loss: 0.18771977722644806\n",
            "\n",
            "Epoch 523/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1948 - val_loss: 0.1913\n",
            "Loss: 0.19482986629009247\n",
            "Validation Loss: 0.19131740927696228\n",
            "\n",
            "Epoch 524/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1964 - val_loss: 0.1893\n",
            "Loss: 0.1964167058467865\n",
            "Validation Loss: 0.1892891377210617\n",
            "\n",
            "Epoch 525/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1953 - val_loss: 0.1889\n",
            "Loss: 0.19534087181091309\n",
            "Validation Loss: 0.18886379897594452\n",
            "\n",
            "Epoch 526/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1961 - val_loss: 0.1911\n",
            "Loss: 0.19613228738307953\n",
            "Validation Loss: 0.19110925495624542\n",
            "\n",
            "Epoch 527/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1953 - val_loss: 0.1939\n",
            "Loss: 0.19525861740112305\n",
            "Validation Loss: 0.19387707114219666\n",
            "\n",
            "Epoch 528/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1962 - val_loss: 0.1898\n",
            "Loss: 0.19615399837493896\n",
            "Validation Loss: 0.18980476260185242\n",
            "\n",
            "Epoch 529/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1947 - val_loss: 0.1886\n",
            "Loss: 0.19466064870357513\n",
            "Validation Loss: 0.18863481283187866\n",
            "\n",
            "Epoch 530/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1961 - val_loss: 0.1901\n",
            "Loss: 0.19606798887252808\n",
            "Validation Loss: 0.1900528073310852\n",
            "\n",
            "Epoch 531/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1952 - val_loss: 0.1910\n",
            "Loss: 0.19521650671958923\n",
            "Validation Loss: 0.19098904728889465\n",
            "\n",
            "Epoch 532/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1949 - val_loss: 0.1879\n",
            "Loss: 0.19485114514827728\n",
            "Validation Loss: 0.1879137009382248\n",
            "\n",
            "Epoch 533/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1945 - val_loss: 0.1897\n",
            "Loss: 0.19453637301921844\n",
            "Validation Loss: 0.18973787128925323\n",
            "\n",
            "Epoch 534/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1965 - val_loss: 0.1876\n",
            "Loss: 0.19654859602451324\n",
            "Validation Loss: 0.18761976063251495\n",
            "\n",
            "Epoch 535/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1951 - val_loss: 0.1910\n",
            "Loss: 0.195072740316391\n",
            "Validation Loss: 0.19103026390075684\n",
            "\n",
            "Epoch 536/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1952 - val_loss: 0.1866\n",
            "Loss: 0.19522729516029358\n",
            "Validation Loss: 0.1866333931684494\n",
            "\n",
            "Epoch 537/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1969 - val_loss: 0.1911\n",
            "Loss: 0.19689218699932098\n",
            "Validation Loss: 0.19108407199382782\n",
            "\n",
            "Epoch 538/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1956 - val_loss: 0.1883\n",
            "Loss: 0.19564887881278992\n",
            "Validation Loss: 0.18828324973583221\n",
            "\n",
            "Epoch 539/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1952 - val_loss: 0.1884\n",
            "Loss: 0.19519197940826416\n",
            "Validation Loss: 0.18844911456108093\n",
            "\n",
            "Epoch 540/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1957 - val_loss: 0.1883\n",
            "Loss: 0.19567090272903442\n",
            "Validation Loss: 0.18833164870738983\n",
            "\n",
            "Epoch 541/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1954 - val_loss: 0.1881\n",
            "Loss: 0.19540338218212128\n",
            "Validation Loss: 0.1880558580160141\n",
            "\n",
            "Epoch 542/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1966 - val_loss: 0.1897\n",
            "Loss: 0.19658087193965912\n",
            "Validation Loss: 0.18974493443965912\n",
            "\n",
            "Epoch 543/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1950 - val_loss: 0.1892\n",
            "Loss: 0.19498176872730255\n",
            "Validation Loss: 0.18920846283435822\n",
            "\n",
            "Epoch 544/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1950 - val_loss: 0.1875\n",
            "Loss: 0.19496650993824005\n",
            "Validation Loss: 0.18753647804260254\n",
            "\n",
            "Epoch 545/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1944 - val_loss: 0.1861\n",
            "Loss: 0.19437047839164734\n",
            "Validation Loss: 0.18605399131774902\n",
            "\n",
            "Epoch 546/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1945 - val_loss: 0.1892\n",
            "Loss: 0.19449786841869354\n",
            "Validation Loss: 0.18920376896858215\n",
            "\n",
            "Epoch 547/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1944 - val_loss: 0.1906\n",
            "Loss: 0.1944286972284317\n",
            "Validation Loss: 0.19058340787887573\n",
            "\n",
            "Epoch 548/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1952 - val_loss: 0.1896\n",
            "Loss: 0.19516271352767944\n",
            "Validation Loss: 0.18957512080669403\n",
            "\n",
            "Epoch 549/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1964 - val_loss: 0.1898\n",
            "Loss: 0.1963845193386078\n",
            "Validation Loss: 0.18979249894618988\n",
            "\n",
            "Epoch 550/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1961 - val_loss: 0.1876\n",
            "Loss: 0.19605208933353424\n",
            "Validation Loss: 0.18759116530418396\n",
            "\n",
            "Epoch 551/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1958 - val_loss: 0.1878\n",
            "Loss: 0.19578349590301514\n",
            "Validation Loss: 0.1878255009651184\n",
            "\n",
            "Epoch 552/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1959 - val_loss: 0.1868\n",
            "Loss: 0.1959146112203598\n",
            "Validation Loss: 0.18679217994213104\n",
            "\n",
            "Epoch 553/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1940 - val_loss: 0.1871\n",
            "Loss: 0.19403554499149323\n",
            "Validation Loss: 0.18705645203590393\n",
            "\n",
            "Epoch 554/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1938 - val_loss: 0.1861\n",
            "Loss: 0.19382821023464203\n",
            "Validation Loss: 0.18613672256469727\n",
            "\n",
            "Epoch 555/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1945 - val_loss: 0.1887\n",
            "Loss: 0.1945357620716095\n",
            "Validation Loss: 0.18873444199562073\n",
            "\n",
            "Epoch 556/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1952 - val_loss: 0.1858\n",
            "Loss: 0.1951562613248825\n",
            "Validation Loss: 0.18580757081508636\n",
            "\n",
            "Epoch 557/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1944 - val_loss: 0.1889\n",
            "Loss: 0.1943984180688858\n",
            "Validation Loss: 0.18889057636260986\n",
            "\n",
            "Epoch 558/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1947 - val_loss: 0.1869\n",
            "Loss: 0.19473232328891754\n",
            "Validation Loss: 0.18686489760875702\n",
            "\n",
            "Epoch 559/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1959 - val_loss: 0.1871\n",
            "Loss: 0.19587767124176025\n",
            "Validation Loss: 0.18711942434310913\n",
            "\n",
            "Epoch 560/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1956 - val_loss: 0.1878\n",
            "Loss: 0.19559016823768616\n",
            "Validation Loss: 0.18780575692653656\n",
            "\n",
            "Epoch 561/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1955 - val_loss: 0.1880\n",
            "Loss: 0.1954791098833084\n",
            "Validation Loss: 0.18796969950199127\n",
            "\n",
            "Epoch 562/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1943 - val_loss: 0.1869\n",
            "Loss: 0.1942937672138214\n",
            "Validation Loss: 0.186853289604187\n",
            "\n",
            "Epoch 563/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1952 - val_loss: 0.1880\n",
            "Loss: 0.19517695903778076\n",
            "Validation Loss: 0.18797478079795837\n",
            "\n",
            "Epoch 564/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1948 - val_loss: 0.1864\n",
            "Loss: 0.1948440819978714\n",
            "Validation Loss: 0.18636451661586761\n",
            "\n",
            "Epoch 565/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1948 - val_loss: 0.1891\n",
            "Loss: 0.1947508156299591\n",
            "Validation Loss: 0.1890554130077362\n",
            "\n",
            "Epoch 566/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1953 - val_loss: 0.1879\n",
            "Loss: 0.19526666402816772\n",
            "Validation Loss: 0.18787367641925812\n",
            "\n",
            "Epoch 567/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1959 - val_loss: 0.1851\n",
            "Loss: 0.19593653082847595\n",
            "Validation Loss: 0.18506509065628052\n",
            "\n",
            "Epoch 568/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1955 - val_loss: 0.1904\n",
            "Loss: 0.19552376866340637\n",
            "Validation Loss: 0.1904420256614685\n",
            "\n",
            "Epoch 569/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1948 - val_loss: 0.1862\n",
            "Loss: 0.19475913047790527\n",
            "Validation Loss: 0.186158686876297\n",
            "\n",
            "Epoch 570/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1946 - val_loss: 0.1884\n",
            "Loss: 0.1945507824420929\n",
            "Validation Loss: 0.18835237622261047\n",
            "\n",
            "Epoch 571/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1944 - val_loss: 0.1873\n",
            "Loss: 0.19435854256153107\n",
            "Validation Loss: 0.1873248815536499\n",
            "\n",
            "Epoch 572/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1945 - val_loss: 0.1869\n",
            "Loss: 0.1944749653339386\n",
            "Validation Loss: 0.1868925392627716\n",
            "\n",
            "Epoch 573/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1929 - val_loss: 0.1890\n",
            "Loss: 0.19292566180229187\n",
            "Validation Loss: 0.18902285397052765\n",
            "\n",
            "Epoch 574/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1950 - val_loss: 0.1879\n",
            "Loss: 0.19503720104694366\n",
            "Validation Loss: 0.1878940314054489\n",
            "\n",
            "Epoch 575/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1945 - val_loss: 0.1864\n",
            "Loss: 0.19448664784431458\n",
            "Validation Loss: 0.1864366978406906\n",
            "\n",
            "Epoch 576/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1939 - val_loss: 0.1883\n",
            "Loss: 0.19386476278305054\n",
            "Validation Loss: 0.18830977380275726\n",
            "\n",
            "Epoch 577/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1955 - val_loss: 0.1892\n",
            "Loss: 0.19553038477897644\n",
            "Validation Loss: 0.18920393288135529\n",
            "\n",
            "Epoch 578/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1964 - val_loss: 0.1883\n",
            "Loss: 0.19638682901859283\n",
            "Validation Loss: 0.18831275403499603\n",
            "\n",
            "Epoch 579/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1954 - val_loss: 0.1894\n",
            "Loss: 0.19538822770118713\n",
            "Validation Loss: 0.18942521512508392\n",
            "\n",
            "Epoch 580/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1947 - val_loss: 0.1883\n",
            "Loss: 0.1946534365415573\n",
            "Validation Loss: 0.18829399347305298\n",
            "\n",
            "Epoch 581/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1947 - val_loss: 0.1887\n",
            "Loss: 0.19466398656368256\n",
            "Validation Loss: 0.1886691004037857\n",
            "\n",
            "Epoch 582/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1957 - val_loss: 0.1885\n",
            "Loss: 0.195680633187294\n",
            "Validation Loss: 0.18845461308956146\n",
            "\n",
            "Epoch 583/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1935 - val_loss: 0.1878\n",
            "Loss: 0.19348660111427307\n",
            "Validation Loss: 0.18783079087734222\n",
            "\n",
            "Epoch 584/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1945 - val_loss: 0.1883\n",
            "Loss: 0.19448012113571167\n",
            "Validation Loss: 0.18830740451812744\n",
            "\n",
            "Epoch 585/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1946 - val_loss: 0.1890\n",
            "Loss: 0.19462190568447113\n",
            "Validation Loss: 0.1890321671962738\n",
            "\n",
            "Epoch 586/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1940 - val_loss: 0.1860\n",
            "Loss: 0.19401250779628754\n",
            "Validation Loss: 0.1860194206237793\n",
            "\n",
            "Epoch 587/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1936 - val_loss: 0.1877\n",
            "Loss: 0.1935553401708603\n",
            "Validation Loss: 0.1876758188009262\n",
            "\n",
            "Epoch 588/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1934 - val_loss: 0.1869\n",
            "Loss: 0.19335022568702698\n",
            "Validation Loss: 0.18691761791706085\n",
            "\n",
            "Epoch 589/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1949 - val_loss: 0.1884\n",
            "Loss: 0.19485314190387726\n",
            "Validation Loss: 0.1883794516324997\n",
            "\n",
            "Epoch 590/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1947 - val_loss: 0.1911\n",
            "Loss: 0.19468936324119568\n",
            "Validation Loss: 0.1911357343196869\n",
            "\n",
            "Epoch 591/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1951 - val_loss: 0.1866\n",
            "Loss: 0.19510133564472198\n",
            "Validation Loss: 0.18663737177848816\n",
            "\n",
            "Epoch 592/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1946 - val_loss: 0.1877\n",
            "Loss: 0.19457265734672546\n",
            "Validation Loss: 0.1876560002565384\n",
            "\n",
            "Epoch 593/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1935 - val_loss: 0.1871\n",
            "Loss: 0.19347454607486725\n",
            "Validation Loss: 0.18708154559135437\n",
            "\n",
            "Epoch 594/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1945 - val_loss: 0.1875\n",
            "Loss: 0.19454070925712585\n",
            "Validation Loss: 0.1874712109565735\n",
            "\n",
            "Epoch 595/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1948 - val_loss: 0.1879\n",
            "Loss: 0.1947842389345169\n",
            "Validation Loss: 0.1879078894853592\n",
            "\n",
            "Epoch 596/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1933 - val_loss: 0.1864\n",
            "Loss: 0.1932988464832306\n",
            "Validation Loss: 0.1864350140094757\n",
            "\n",
            "Epoch 597/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1939 - val_loss: 0.1887\n",
            "Loss: 0.1939471960067749\n",
            "Validation Loss: 0.1886574774980545\n",
            "\n",
            "Epoch 598/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1941 - val_loss: 0.1868\n",
            "Loss: 0.19409862160682678\n",
            "Validation Loss: 0.18684455752372742\n",
            "\n",
            "Epoch 599/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1935 - val_loss: 0.1865\n",
            "Loss: 0.19348599016666412\n",
            "Validation Loss: 0.18652382493019104\n",
            "\n",
            "Epoch 600/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1940 - val_loss: 0.1864\n",
            "Loss: 0.19396072626113892\n",
            "Validation Loss: 0.18638068437576294\n",
            "\n",
            "Epoch 601/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1939 - val_loss: 0.1881\n",
            "Loss: 0.1939033567905426\n",
            "Validation Loss: 0.18805107474327087\n",
            "\n",
            "Epoch 602/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1934 - val_loss: 0.1880\n",
            "Loss: 0.1933984011411667\n",
            "Validation Loss: 0.18798282742500305\n",
            "\n",
            "Epoch 603/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1927 - val_loss: 0.1876\n",
            "Loss: 0.19269919395446777\n",
            "Validation Loss: 0.18764276802539825\n",
            "\n",
            "Epoch 604/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1940 - val_loss: 0.1871\n",
            "Loss: 0.19404591619968414\n",
            "Validation Loss: 0.18708068132400513\n",
            "\n",
            "Epoch 605/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1948 - val_loss: 0.1875\n",
            "Loss: 0.19480352103710175\n",
            "Validation Loss: 0.18752332031726837\n",
            "\n",
            "Epoch 606/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1935 - val_loss: 0.1865\n",
            "Loss: 0.19353225827217102\n",
            "Validation Loss: 0.1864732801914215\n",
            "\n",
            "Epoch 607/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1937 - val_loss: 0.1868\n",
            "Loss: 0.19366632401943207\n",
            "Validation Loss: 0.18677204847335815\n",
            "\n",
            "Epoch 608/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1937 - val_loss: 0.1865\n",
            "Loss: 0.19373339414596558\n",
            "Validation Loss: 0.18651749193668365\n",
            "\n",
            "Epoch 609/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1934 - val_loss: 0.1855\n",
            "Loss: 0.19337572157382965\n",
            "Validation Loss: 0.1855268031358719\n",
            "\n",
            "Epoch 610/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1948 - val_loss: 0.1854\n",
            "Loss: 0.19481472671031952\n",
            "Validation Loss: 0.18537752330303192\n",
            "\n",
            "Epoch 611/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1946 - val_loss: 0.1871\n",
            "Loss: 0.19456641376018524\n",
            "Validation Loss: 0.18708688020706177\n",
            "\n",
            "Epoch 612/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1930 - val_loss: 0.1885\n",
            "Loss: 0.19296874105930328\n",
            "Validation Loss: 0.18853385746479034\n",
            "\n",
            "Epoch 613/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1934 - val_loss: 0.1862\n",
            "Loss: 0.19344225525856018\n",
            "Validation Loss: 0.18617403507232666\n",
            "\n",
            "Epoch 614/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1932 - val_loss: 0.1848\n",
            "Loss: 0.1931847631931305\n",
            "Validation Loss: 0.18475478887557983\n",
            "\n",
            "Epoch 615/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1929 - val_loss: 0.1856\n",
            "Loss: 0.19293735921382904\n",
            "Validation Loss: 0.18560455739498138\n",
            "\n",
            "Epoch 616/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1939 - val_loss: 0.1865\n",
            "Loss: 0.1939326822757721\n",
            "Validation Loss: 0.1865043342113495\n",
            "\n",
            "Epoch 617/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1926 - val_loss: 0.1875\n",
            "Loss: 0.19263215363025665\n",
            "Validation Loss: 0.18749478459358215\n",
            "\n",
            "Epoch 618/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1929 - val_loss: 0.1876\n",
            "Loss: 0.19285237789154053\n",
            "Validation Loss: 0.18755213916301727\n",
            "\n",
            "Epoch 619/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1951 - val_loss: 0.1864\n",
            "Loss: 0.19506950676441193\n",
            "Validation Loss: 0.18643935024738312\n",
            "\n",
            "Epoch 620/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1944 - val_loss: 0.1863\n",
            "Loss: 0.19439247250556946\n",
            "Validation Loss: 0.18628573417663574\n",
            "\n",
            "Epoch 621/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1944 - val_loss: 0.1872\n",
            "Loss: 0.1944318562746048\n",
            "Validation Loss: 0.1872461885213852\n",
            "\n",
            "Epoch 622/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1942 - val_loss: 0.1865\n",
            "Loss: 0.19422881305217743\n",
            "Validation Loss: 0.1865299642086029\n",
            "\n",
            "Epoch 623/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1933 - val_loss: 0.1878\n",
            "Loss: 0.19333632290363312\n",
            "Validation Loss: 0.18775589764118195\n",
            "\n",
            "Epoch 624/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1930 - val_loss: 0.1855\n",
            "Loss: 0.19301459193229675\n",
            "Validation Loss: 0.18545570969581604\n",
            "\n",
            "Epoch 625/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1931 - val_loss: 0.1858\n",
            "Loss: 0.1931011974811554\n",
            "Validation Loss: 0.18579034507274628\n",
            "\n",
            "Epoch 626/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1934 - val_loss: 0.1874\n",
            "Loss: 0.19343416392803192\n",
            "Validation Loss: 0.18744681775569916\n",
            "\n",
            "Epoch 627/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1927 - val_loss: 0.1878\n",
            "Loss: 0.19273701310157776\n",
            "Validation Loss: 0.18782176077365875\n",
            "\n",
            "Epoch 628/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1937 - val_loss: 0.1861\n",
            "Loss: 0.19369301199913025\n",
            "Validation Loss: 0.18605120480060577\n",
            "\n",
            "Epoch 629/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1932 - val_loss: 0.1893\n",
            "Loss: 0.19321753084659576\n",
            "Validation Loss: 0.18927249312400818\n",
            "\n",
            "Epoch 630/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1923 - val_loss: 0.1856\n",
            "Loss: 0.19232645630836487\n",
            "Validation Loss: 0.18561112880706787\n",
            "\n",
            "Epoch 631/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1931 - val_loss: 0.1880\n",
            "Loss: 0.19310611486434937\n",
            "Validation Loss: 0.18797466158866882\n",
            "\n",
            "Epoch 632/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1933 - val_loss: 0.1853\n",
            "Loss: 0.19329197704792023\n",
            "Validation Loss: 0.1853162944316864\n",
            "\n",
            "Epoch 633/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1925 - val_loss: 0.1870\n",
            "Loss: 0.19250643253326416\n",
            "Validation Loss: 0.18701811134815216\n",
            "\n",
            "Epoch 634/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1929 - val_loss: 0.1864\n",
            "Loss: 0.19294284284114838\n",
            "Validation Loss: 0.18639081716537476\n",
            "\n",
            "Epoch 635/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1934 - val_loss: 0.1876\n",
            "Loss: 0.19341759383678436\n",
            "Validation Loss: 0.18755948543548584\n",
            "\n",
            "Epoch 636/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1950 - val_loss: 0.1866\n",
            "Loss: 0.19500412046909332\n",
            "Validation Loss: 0.18657946586608887\n",
            "\n",
            "Epoch 637/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1929 - val_loss: 0.1855\n",
            "Loss: 0.1929139494895935\n",
            "Validation Loss: 0.1854974776506424\n",
            "\n",
            "Epoch 638/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1939 - val_loss: 0.1839\n",
            "Loss: 0.1939050257205963\n",
            "Validation Loss: 0.18392354249954224\n",
            "\n",
            "Epoch 639/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1931 - val_loss: 0.1848\n",
            "Loss: 0.1930990070104599\n",
            "Validation Loss: 0.18481609225273132\n",
            "\n",
            "Epoch 640/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1932 - val_loss: 0.1848\n",
            "Loss: 0.1931883692741394\n",
            "Validation Loss: 0.1847527027130127\n",
            "\n",
            "Epoch 641/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1940 - val_loss: 0.1869\n",
            "Loss: 0.19400334358215332\n",
            "Validation Loss: 0.18687766790390015\n",
            "\n",
            "Epoch 642/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1921 - val_loss: 0.1853\n",
            "Loss: 0.19211046397686005\n",
            "Validation Loss: 0.18528102338314056\n",
            "\n",
            "Epoch 643/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1919 - val_loss: 0.1866\n",
            "Loss: 0.19189272820949554\n",
            "Validation Loss: 0.18657873570919037\n",
            "\n",
            "Epoch 644/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1923 - val_loss: 0.1848\n",
            "Loss: 0.19228655099868774\n",
            "Validation Loss: 0.18478886783123016\n",
            "\n",
            "Epoch 645/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1921 - val_loss: 0.1842\n",
            "Loss: 0.19211798906326294\n",
            "Validation Loss: 0.18423311412334442\n",
            "\n",
            "Epoch 646/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1914 - val_loss: 0.1871\n",
            "Loss: 0.19135910272598267\n",
            "Validation Loss: 0.1870870739221573\n",
            "\n",
            "Epoch 647/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1928 - val_loss: 0.1861\n",
            "Loss: 0.19283059239387512\n",
            "Validation Loss: 0.1861305683851242\n",
            "\n",
            "Epoch 648/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1925 - val_loss: 0.1870\n",
            "Loss: 0.19250011444091797\n",
            "Validation Loss: 0.18698720633983612\n",
            "\n",
            "Epoch 649/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1928 - val_loss: 0.1899\n",
            "Loss: 0.19278967380523682\n",
            "Validation Loss: 0.1899440586566925\n",
            "\n",
            "Epoch 650/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1922 - val_loss: 0.1843\n",
            "Loss: 0.19224664568901062\n",
            "Validation Loss: 0.18432722985744476\n",
            "\n",
            "Epoch 651/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1928 - val_loss: 0.1855\n",
            "Loss: 0.19284190237522125\n",
            "Validation Loss: 0.18546180427074432\n",
            "\n",
            "Epoch 652/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1932 - val_loss: 0.1877\n",
            "Loss: 0.19317461550235748\n",
            "Validation Loss: 0.1877228170633316\n",
            "\n",
            "Epoch 653/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1928 - val_loss: 0.1867\n",
            "Loss: 0.19277323782444\n",
            "Validation Loss: 0.1867143213748932\n",
            "\n",
            "Epoch 654/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1917 - val_loss: 0.1827\n",
            "Loss: 0.1917189061641693\n",
            "Validation Loss: 0.18265098333358765\n",
            "\n",
            "Epoch 655/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1936 - val_loss: 0.1866\n",
            "Loss: 0.19356797635555267\n",
            "Validation Loss: 0.18656475841999054\n",
            "\n",
            "Epoch 656/750\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1910 - val_loss: 0.1873\n",
            "Loss: 0.1909751445055008\n",
            "Validation Loss: 0.18729102611541748\n",
            "\n",
            "Epoch 657/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1931 - val_loss: 0.1848\n",
            "Loss: 0.19312725961208344\n",
            "Validation Loss: 0.18483522534370422\n",
            "\n",
            "Epoch 658/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1920 - val_loss: 0.1848\n",
            "Loss: 0.19196081161499023\n",
            "Validation Loss: 0.18481193482875824\n",
            "\n",
            "Epoch 659/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1926 - val_loss: 0.1874\n",
            "Loss: 0.1926155686378479\n",
            "Validation Loss: 0.18736091256141663\n",
            "\n",
            "Epoch 660/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1931 - val_loss: 0.1848\n",
            "Loss: 0.19313985109329224\n",
            "Validation Loss: 0.18475937843322754\n",
            "\n",
            "Epoch 661/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1923 - val_loss: 0.1886\n",
            "Loss: 0.19225957989692688\n",
            "Validation Loss: 0.18862394988536835\n",
            "\n",
            "Epoch 662/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1925 - val_loss: 0.1863\n",
            "Loss: 0.19250038266181946\n",
            "Validation Loss: 0.1862933188676834\n",
            "\n",
            "Epoch 663/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1922 - val_loss: 0.1845\n",
            "Loss: 0.19219060242176056\n",
            "Validation Loss: 0.18445615470409393\n",
            "\n",
            "Epoch 664/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1920 - val_loss: 0.1837\n",
            "Loss: 0.19197769463062286\n",
            "Validation Loss: 0.1836988776922226\n",
            "\n",
            "Epoch 665/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1925 - val_loss: 0.1894\n",
            "Loss: 0.192490816116333\n",
            "Validation Loss: 0.18941250443458557\n",
            "\n",
            "Epoch 666/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1924 - val_loss: 0.1859\n",
            "Loss: 0.19240069389343262\n",
            "Validation Loss: 0.1858522742986679\n",
            "\n",
            "Epoch 667/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1920 - val_loss: 0.1869\n",
            "Loss: 0.1919652819633484\n",
            "Validation Loss: 0.18693764507770538\n",
            "\n",
            "Epoch 668/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1916 - val_loss: 0.1843\n",
            "Loss: 0.19155701994895935\n",
            "Validation Loss: 0.1842944622039795\n",
            "\n",
            "Epoch 669/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1923 - val_loss: 0.1856\n",
            "Loss: 0.19229963421821594\n",
            "Validation Loss: 0.1855764240026474\n",
            "\n",
            "Epoch 670/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1926 - val_loss: 0.1872\n",
            "Loss: 0.19263094663619995\n",
            "Validation Loss: 0.18717005848884583\n",
            "\n",
            "Epoch 671/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1922 - val_loss: 0.1846\n",
            "Loss: 0.19223010540008545\n",
            "Validation Loss: 0.18455885350704193\n",
            "\n",
            "Epoch 672/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1920 - val_loss: 0.1856\n",
            "Loss: 0.19198456406593323\n",
            "Validation Loss: 0.18557731807231903\n",
            "\n",
            "Epoch 673/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1931 - val_loss: 0.1866\n",
            "Loss: 0.19309738278388977\n",
            "Validation Loss: 0.18660645186901093\n",
            "\n",
            "Epoch 674/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1921 - val_loss: 0.1870\n",
            "Loss: 0.19209358096122742\n",
            "Validation Loss: 0.18696124851703644\n",
            "\n",
            "Epoch 675/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1929 - val_loss: 0.1861\n",
            "Loss: 0.19291529059410095\n",
            "Validation Loss: 0.18613438308238983\n",
            "\n",
            "Epoch 676/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1909 - val_loss: 0.1840\n",
            "Loss: 0.19086173176765442\n",
            "Validation Loss: 0.1840401440858841\n",
            "\n",
            "Epoch 677/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1920 - val_loss: 0.1847\n",
            "Loss: 0.19203713536262512\n",
            "Validation Loss: 0.18465879559516907\n",
            "\n",
            "Epoch 678/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1927 - val_loss: 0.1853\n",
            "Loss: 0.1927015334367752\n",
            "Validation Loss: 0.18527859449386597\n",
            "\n",
            "Epoch 679/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1927 - val_loss: 0.1843\n",
            "Loss: 0.19268208742141724\n",
            "Validation Loss: 0.184250608086586\n",
            "\n",
            "Epoch 680/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1914 - val_loss: 0.1847\n",
            "Loss: 0.19142493605613708\n",
            "Validation Loss: 0.18473294377326965\n",
            "\n",
            "Epoch 681/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1921 - val_loss: 0.1841\n",
            "Loss: 0.19214293360710144\n",
            "Validation Loss: 0.18410925567150116\n",
            "\n",
            "Epoch 682/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1919 - val_loss: 0.1858\n",
            "Loss: 0.19193409383296967\n",
            "Validation Loss: 0.185837060213089\n",
            "\n",
            "Epoch 683/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1919 - val_loss: 0.1864\n",
            "Loss: 0.19186197221279144\n",
            "Validation Loss: 0.1864389032125473\n",
            "\n",
            "Epoch 684/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1920 - val_loss: 0.1864\n",
            "Loss: 0.19203773140907288\n",
            "Validation Loss: 0.18642713129520416\n",
            "\n",
            "Epoch 685/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1918 - val_loss: 0.1836\n",
            "Loss: 0.19184647500514984\n",
            "Validation Loss: 0.18358898162841797\n",
            "\n",
            "Epoch 686/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1915 - val_loss: 0.1857\n",
            "Loss: 0.19150124490261078\n",
            "Validation Loss: 0.1857190877199173\n",
            "\n",
            "Epoch 687/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1920 - val_loss: 0.1852\n",
            "Loss: 0.19195786118507385\n",
            "Validation Loss: 0.185181125998497\n",
            "\n",
            "Epoch 688/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1915 - val_loss: 0.1846\n",
            "Loss: 0.1915206015110016\n",
            "Validation Loss: 0.18463890254497528\n",
            "\n",
            "Epoch 689/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1923 - val_loss: 0.1842\n",
            "Loss: 0.19225160777568817\n",
            "Validation Loss: 0.1841576099395752\n",
            "\n",
            "Epoch 690/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1921 - val_loss: 0.1852\n",
            "Loss: 0.19212031364440918\n",
            "Validation Loss: 0.1852196604013443\n",
            "\n",
            "Epoch 691/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1913 - val_loss: 0.1856\n",
            "Loss: 0.19131863117218018\n",
            "Validation Loss: 0.18564395606517792\n",
            "\n",
            "Epoch 692/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1920 - val_loss: 0.1839\n",
            "Loss: 0.19203488528728485\n",
            "Validation Loss: 0.18388251960277557\n",
            "\n",
            "Epoch 693/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1914 - val_loss: 0.1837\n",
            "Loss: 0.19139672815799713\n",
            "Validation Loss: 0.18365031480789185\n",
            "\n",
            "Epoch 694/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1917 - val_loss: 0.1830\n",
            "Loss: 0.191684290766716\n",
            "Validation Loss: 0.18303599953651428\n",
            "\n",
            "Epoch 695/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1910 - val_loss: 0.1837\n",
            "Loss: 0.1909531056880951\n",
            "Validation Loss: 0.18372514843940735\n",
            "\n",
            "Epoch 696/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1918 - val_loss: 0.1844\n",
            "Loss: 0.19176623225212097\n",
            "Validation Loss: 0.18435980379581451\n",
            "\n",
            "Epoch 697/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1919 - val_loss: 0.1834\n",
            "Loss: 0.19194917380809784\n",
            "Validation Loss: 0.1833876520395279\n",
            "\n",
            "Epoch 698/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1923 - val_loss: 0.1836\n",
            "Loss: 0.19234350323677063\n",
            "Validation Loss: 0.18363824486732483\n",
            "\n",
            "Epoch 699/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1904 - val_loss: 0.1868\n",
            "Loss: 0.1904178112745285\n",
            "Validation Loss: 0.18678680062294006\n",
            "\n",
            "Epoch 700/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1918 - val_loss: 0.1829\n",
            "Loss: 0.19182364642620087\n",
            "Validation Loss: 0.18293114006519318\n",
            "\n",
            "Epoch 701/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1912 - val_loss: 0.1860\n",
            "Loss: 0.1912301778793335\n",
            "Validation Loss: 0.185980886220932\n",
            "\n",
            "Epoch 702/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1909 - val_loss: 0.1832\n",
            "Loss: 0.19090884923934937\n",
            "Validation Loss: 0.18319886922836304\n",
            "\n",
            "Epoch 703/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1906 - val_loss: 0.1819\n",
            "Loss: 0.1905956119298935\n",
            "Validation Loss: 0.18193234503269196\n",
            "\n",
            "Epoch 704/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1914 - val_loss: 0.1831\n",
            "Loss: 0.19144384562969208\n",
            "Validation Loss: 0.1830575317144394\n",
            "\n",
            "Epoch 705/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1909 - val_loss: 0.1832\n",
            "Loss: 0.19091953337192535\n",
            "Validation Loss: 0.18319618701934814\n",
            "\n",
            "Epoch 706/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1913 - val_loss: 0.1842\n",
            "Loss: 0.19126732647418976\n",
            "Validation Loss: 0.18423053622245789\n",
            "\n",
            "Epoch 707/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1909 - val_loss: 0.1843\n",
            "Loss: 0.19092169404029846\n",
            "Validation Loss: 0.1843034029006958\n",
            "\n",
            "Epoch 708/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1917 - val_loss: 0.1832\n",
            "Loss: 0.19173505902290344\n",
            "Validation Loss: 0.18320219218730927\n",
            "\n",
            "Epoch 709/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1904 - val_loss: 0.1842\n",
            "Loss: 0.19044464826583862\n",
            "Validation Loss: 0.18417401611804962\n",
            "\n",
            "Epoch 710/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1904 - val_loss: 0.1837\n",
            "Loss: 0.19044999778270721\n",
            "Validation Loss: 0.1837308257818222\n",
            "\n",
            "Epoch 711/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1915 - val_loss: 0.1831\n",
            "Loss: 0.19148650765419006\n",
            "Validation Loss: 0.18306614458560944\n",
            "\n",
            "Epoch 712/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1910 - val_loss: 0.1844\n",
            "Loss: 0.191012442111969\n",
            "Validation Loss: 0.18438418209552765\n",
            "\n",
            "Epoch 713/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1907 - val_loss: 0.1839\n",
            "Loss: 0.19071918725967407\n",
            "Validation Loss: 0.18386907875537872\n",
            "\n",
            "Epoch 714/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1905 - val_loss: 0.1848\n",
            "Loss: 0.19049304723739624\n",
            "Validation Loss: 0.18478761613368988\n",
            "\n",
            "Epoch 715/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1900 - val_loss: 0.1815\n",
            "Loss: 0.19000864028930664\n",
            "Validation Loss: 0.18151573836803436\n",
            "\n",
            "Epoch 716/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1901 - val_loss: 0.1859\n",
            "Loss: 0.19007620215415955\n",
            "Validation Loss: 0.18593885004520416\n",
            "\n",
            "Epoch 717/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1911 - val_loss: 0.1847\n",
            "Loss: 0.19105485081672668\n",
            "Validation Loss: 0.18474800884723663\n",
            "\n",
            "Epoch 718/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1917 - val_loss: 0.1853\n",
            "Loss: 0.19174015522003174\n",
            "Validation Loss: 0.18527904152870178\n",
            "\n",
            "Epoch 719/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1914 - val_loss: 0.1862\n",
            "Loss: 0.19141292572021484\n",
            "Validation Loss: 0.1862327754497528\n",
            "\n",
            "Epoch 720/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1917 - val_loss: 0.1838\n",
            "Loss: 0.19170260429382324\n",
            "Validation Loss: 0.18381913006305695\n",
            "\n",
            "Epoch 721/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1916 - val_loss: 0.1852\n",
            "Loss: 0.19160068035125732\n",
            "Validation Loss: 0.18516434729099274\n",
            "\n",
            "Epoch 722/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1911 - val_loss: 0.1840\n",
            "Loss: 0.19114795327186584\n",
            "Validation Loss: 0.18395531177520752\n",
            "\n",
            "Epoch 723/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1920 - val_loss: 0.1852\n",
            "Loss: 0.19204194843769073\n",
            "Validation Loss: 0.1851508617401123\n",
            "\n",
            "Epoch 724/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1913 - val_loss: 0.1858\n",
            "Loss: 0.19130854308605194\n",
            "Validation Loss: 0.18584409356117249\n",
            "\n",
            "Epoch 725/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1911 - val_loss: 0.1831\n",
            "Loss: 0.1910891830921173\n",
            "Validation Loss: 0.18312658369541168\n",
            "\n",
            "Epoch 726/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1909 - val_loss: 0.1835\n",
            "Loss: 0.1908756047487259\n",
            "Validation Loss: 0.18346039950847626\n",
            "\n",
            "Epoch 727/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1911 - val_loss: 0.1848\n",
            "Loss: 0.1910659372806549\n",
            "Validation Loss: 0.18482515215873718\n",
            "\n",
            "Epoch 728/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1912 - val_loss: 0.1851\n",
            "Loss: 0.19117386639118195\n",
            "Validation Loss: 0.18511544167995453\n",
            "\n",
            "Epoch 729/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1902 - val_loss: 0.1815\n",
            "Loss: 0.1901712566614151\n",
            "Validation Loss: 0.18145129084587097\n",
            "\n",
            "Epoch 730/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1910 - val_loss: 0.1870\n",
            "Loss: 0.19095763564109802\n",
            "Validation Loss: 0.1869746595621109\n",
            "\n",
            "Epoch 731/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1910 - val_loss: 0.1827\n",
            "Loss: 0.1909983903169632\n",
            "Validation Loss: 0.1826518177986145\n",
            "\n",
            "Epoch 732/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1907 - val_loss: 0.1830\n",
            "Loss: 0.19065876305103302\n",
            "Validation Loss: 0.18299241364002228\n",
            "\n",
            "Epoch 733/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1915 - val_loss: 0.1866\n",
            "Loss: 0.1914539635181427\n",
            "Validation Loss: 0.18664583563804626\n",
            "\n",
            "Epoch 734/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1913 - val_loss: 0.1820\n",
            "Loss: 0.19134730100631714\n",
            "Validation Loss: 0.18196842074394226\n",
            "\n",
            "Epoch 735/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1910 - val_loss: 0.1843\n",
            "Loss: 0.19104032218456268\n",
            "Validation Loss: 0.18434247374534607\n",
            "\n",
            "Epoch 736/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1908 - val_loss: 0.1831\n",
            "Loss: 0.1907782405614853\n",
            "Validation Loss: 0.18307338654994965\n",
            "\n",
            "Epoch 737/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1907 - val_loss: 0.1830\n",
            "Loss: 0.19072063267230988\n",
            "Validation Loss: 0.18299046158790588\n",
            "\n",
            "Epoch 738/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1914 - val_loss: 0.1851\n",
            "Loss: 0.1913503259420395\n",
            "Validation Loss: 0.18514761328697205\n",
            "\n",
            "Epoch 739/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1902 - val_loss: 0.1836\n",
            "Loss: 0.19017234444618225\n",
            "Validation Loss: 0.18361081182956696\n",
            "\n",
            "Epoch 740/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1908 - val_loss: 0.1848\n",
            "Loss: 0.19079062342643738\n",
            "Validation Loss: 0.18477578461170197\n",
            "\n",
            "Epoch 741/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1905 - val_loss: 0.1837\n",
            "Loss: 0.19050991535186768\n",
            "Validation Loss: 0.18372179567813873\n",
            "\n",
            "Epoch 742/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1903 - val_loss: 0.1847\n",
            "Loss: 0.19025851786136627\n",
            "Validation Loss: 0.18465791642665863\n",
            "\n",
            "Epoch 743/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1905 - val_loss: 0.1831\n",
            "Loss: 0.19048260152339935\n",
            "Validation Loss: 0.18307659029960632\n",
            "\n",
            "Epoch 744/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1910 - val_loss: 0.1827\n",
            "Loss: 0.19104580581188202\n",
            "Validation Loss: 0.18265298008918762\n",
            "\n",
            "Epoch 745/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1916 - val_loss: 0.1847\n",
            "Loss: 0.19164474308490753\n",
            "Validation Loss: 0.18469564616680145\n",
            "\n",
            "Epoch 746/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1907 - val_loss: 0.1830\n",
            "Loss: 0.19073915481567383\n",
            "Validation Loss: 0.18297047913074493\n",
            "\n",
            "Epoch 747/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1914 - val_loss: 0.1832\n",
            "Loss: 0.1914457231760025\n",
            "Validation Loss: 0.18316113948822021\n",
            "\n",
            "Epoch 748/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1905 - val_loss: 0.1823\n",
            "Loss: 0.19051922857761383\n",
            "Validation Loss: 0.18225760757923126\n",
            "\n",
            "Epoch 749/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1898 - val_loss: 0.1853\n",
            "Loss: 0.18977795541286469\n",
            "Validation Loss: 0.18526332080364227\n",
            "\n",
            "Epoch 750/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1905 - val_loss: 0.1831\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.19046834111213684\n",
            "Validation Loss: 0.18305104970932007\n",
            "\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_20 (LSTM)                 (None, 5, 128)       73216       ['input_21[0][0]']               \n",
            "                                                                                                  \n",
            " attention_layer_23 (AttentionL  (None, 128)         128         ['lstm_20[0][0]',                \n",
            " ayer)                                                            'lstm_20[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 128)       0           ['attention_layer_23[0][0]']     \n",
            "                                                                                                  \n",
            " time_distributed_7 (TimeDistri  (None, 1, 1)        129         ['reshape_6[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.3662 - val_loss: 0.2078\n",
            "Loss: 0.3661559522151947\n",
            "Validation Loss: 0.20784151554107666\n",
            "\n",
            "Epoch 2/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2222 - val_loss: 0.1338\n",
            "Loss: 0.22222378849983215\n",
            "Validation Loss: 0.13377700746059418\n",
            "\n",
            "Epoch 3/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2005 - val_loss: 0.1278\n",
            "Loss: 0.20051968097686768\n",
            "Validation Loss: 0.12784098088741302\n",
            "\n",
            "Epoch 4/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1963 - val_loss: 0.1249\n",
            "Loss: 0.19629929959774017\n",
            "Validation Loss: 0.12494876980781555\n",
            "\n",
            "Epoch 5/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1923 - val_loss: 0.1236\n",
            "Loss: 0.19226792454719543\n",
            "Validation Loss: 0.1235552653670311\n",
            "\n",
            "Epoch 6/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1903 - val_loss: 0.1244\n",
            "Loss: 0.19033505022525787\n",
            "Validation Loss: 0.12444446235895157\n",
            "\n",
            "Epoch 7/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1882 - val_loss: 0.1189\n",
            "Loss: 0.1882316917181015\n",
            "Validation Loss: 0.11890827119350433\n",
            "\n",
            "Epoch 8/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1825 - val_loss: 0.1195\n",
            "Loss: 0.1824977844953537\n",
            "Validation Loss: 0.11948037147521973\n",
            "\n",
            "Epoch 9/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1781 - val_loss: 0.1188\n",
            "Loss: 0.17805154621601105\n",
            "Validation Loss: 0.11878509819507599\n",
            "\n",
            "Epoch 10/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1744 - val_loss: 0.1180\n",
            "Loss: 0.1743995100259781\n",
            "Validation Loss: 0.11803805083036423\n",
            "\n",
            "Epoch 11/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1718 - val_loss: 0.1178\n",
            "Loss: 0.17175406217575073\n",
            "Validation Loss: 0.11780287325382233\n",
            "\n",
            "Epoch 12/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1708 - val_loss: 0.1165\n",
            "Loss: 0.1708163172006607\n",
            "Validation Loss: 0.1164916604757309\n",
            "\n",
            "Epoch 13/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1675 - val_loss: 0.1154\n",
            "Loss: 0.16750337183475494\n",
            "Validation Loss: 0.11538418382406235\n",
            "\n",
            "Epoch 14/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1642 - val_loss: 0.1140\n",
            "Loss: 0.16421417891979218\n",
            "Validation Loss: 0.11404509097337723\n",
            "\n",
            "Epoch 15/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1635 - val_loss: 0.1135\n",
            "Loss: 0.16354206204414368\n",
            "Validation Loss: 0.11346753686666489\n",
            "\n",
            "Epoch 16/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1599 - val_loss: 0.1140\n",
            "Loss: 0.15994137525558472\n",
            "Validation Loss: 0.11399848014116287\n",
            "\n",
            "Epoch 17/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1598 - val_loss: 0.1148\n",
            "Loss: 0.15980400145053864\n",
            "Validation Loss: 0.1147703155875206\n",
            "\n",
            "Epoch 18/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1597 - val_loss: 0.1147\n",
            "Loss: 0.15965569019317627\n",
            "Validation Loss: 0.11467234790325165\n",
            "\n",
            "Epoch 19/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1574 - val_loss: 0.1128\n",
            "Loss: 0.15735460817813873\n",
            "Validation Loss: 0.11281988024711609\n",
            "\n",
            "Epoch 20/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1567 - val_loss: 0.1122\n",
            "Loss: 0.15671230852603912\n",
            "Validation Loss: 0.1122119277715683\n",
            "\n",
            "Epoch 21/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1535 - val_loss: 0.1124\n",
            "Loss: 0.15349049866199493\n",
            "Validation Loss: 0.11244701594114304\n",
            "\n",
            "Epoch 22/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1564 - val_loss: 0.1131\n",
            "Loss: 0.1564197540283203\n",
            "Validation Loss: 0.11310359835624695\n",
            "\n",
            "Epoch 23/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1545 - val_loss: 0.1117\n",
            "Loss: 0.15453578531742096\n",
            "Validation Loss: 0.11168164759874344\n",
            "\n",
            "Epoch 24/750\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.1533 - val_loss: 0.1114\n",
            "Loss: 0.15332311391830444\n",
            "Validation Loss: 0.11142589151859283\n",
            "\n",
            "Epoch 25/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1529 - val_loss: 0.1121\n",
            "Loss: 0.1528666913509369\n",
            "Validation Loss: 0.11210773885250092\n",
            "\n",
            "Epoch 26/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1531 - val_loss: 0.1117\n",
            "Loss: 0.15308693051338196\n",
            "Validation Loss: 0.11165513098239899\n",
            "\n",
            "Epoch 27/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1523 - val_loss: 0.1112\n",
            "Loss: 0.15228763222694397\n",
            "Validation Loss: 0.11123134940862656\n",
            "\n",
            "Epoch 28/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1513 - val_loss: 0.1108\n",
            "Loss: 0.15131257474422455\n",
            "Validation Loss: 0.11083880811929703\n",
            "\n",
            "Epoch 29/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1506 - val_loss: 0.1109\n",
            "Loss: 0.15056796371936798\n",
            "Validation Loss: 0.11085187643766403\n",
            "\n",
            "Epoch 30/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1514 - val_loss: 0.1127\n",
            "Loss: 0.15139278769493103\n",
            "Validation Loss: 0.11267676204442978\n",
            "\n",
            "Epoch 31/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1501 - val_loss: 0.1102\n",
            "Loss: 0.15006019175052643\n",
            "Validation Loss: 0.11018296331167221\n",
            "\n",
            "Epoch 32/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1499 - val_loss: 0.1096\n",
            "Loss: 0.14993707835674286\n",
            "Validation Loss: 0.10956012457609177\n",
            "\n",
            "Epoch 33/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1492 - val_loss: 0.1104\n",
            "Loss: 0.14918887615203857\n",
            "Validation Loss: 0.11040046066045761\n",
            "\n",
            "Epoch 34/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1490 - val_loss: 0.1105\n",
            "Loss: 0.1490313708782196\n",
            "Validation Loss: 0.11054210364818573\n",
            "\n",
            "Epoch 35/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1490 - val_loss: 0.1116\n",
            "Loss: 0.1489996314048767\n",
            "Validation Loss: 0.11164803057909012\n",
            "\n",
            "Epoch 36/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1478 - val_loss: 0.1104\n",
            "Loss: 0.14782847464084625\n",
            "Validation Loss: 0.11044108867645264\n",
            "\n",
            "Epoch 37/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1481 - val_loss: 0.1112\n",
            "Loss: 0.14807908236980438\n",
            "Validation Loss: 0.11121318489313126\n",
            "\n",
            "Epoch 38/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1461 - val_loss: 0.1093\n",
            "Loss: 0.1460990309715271\n",
            "Validation Loss: 0.10928384959697723\n",
            "\n",
            "Epoch 39/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1470 - val_loss: 0.1104\n",
            "Loss: 0.14696449041366577\n",
            "Validation Loss: 0.1104310154914856\n",
            "\n",
            "Epoch 40/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1460 - val_loss: 0.1113\n",
            "Loss: 0.14597460627555847\n",
            "Validation Loss: 0.11125370115041733\n",
            "\n",
            "Epoch 41/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1453 - val_loss: 0.1092\n",
            "Loss: 0.1453421413898468\n",
            "Validation Loss: 0.10919128358364105\n",
            "\n",
            "Epoch 42/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1459 - val_loss: 0.1108\n",
            "Loss: 0.14586910605430603\n",
            "Validation Loss: 0.11084939539432526\n",
            "\n",
            "Epoch 43/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1460 - val_loss: 0.1097\n",
            "Loss: 0.14596375823020935\n",
            "Validation Loss: 0.10967005789279938\n",
            "\n",
            "Epoch 44/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1439 - val_loss: 0.1096\n",
            "Loss: 0.14388160407543182\n",
            "Validation Loss: 0.10956244170665741\n",
            "\n",
            "Epoch 45/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1441 - val_loss: 0.1090\n",
            "Loss: 0.1441294252872467\n",
            "Validation Loss: 0.10902739316225052\n",
            "\n",
            "Epoch 46/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1428 - val_loss: 0.1074\n",
            "Loss: 0.14280956983566284\n",
            "Validation Loss: 0.10742408782243729\n",
            "\n",
            "Epoch 47/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1429 - val_loss: 0.1088\n",
            "Loss: 0.14292600750923157\n",
            "Validation Loss: 0.10882730782032013\n",
            "\n",
            "Epoch 48/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1421 - val_loss: 0.1080\n",
            "Loss: 0.1421167552471161\n",
            "Validation Loss: 0.10798992216587067\n",
            "\n",
            "Epoch 49/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1415 - val_loss: 0.1081\n",
            "Loss: 0.1415225714445114\n",
            "Validation Loss: 0.10808508843183517\n",
            "\n",
            "Epoch 50/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1407 - val_loss: 0.1083\n",
            "Loss: 0.1407317966222763\n",
            "Validation Loss: 0.10828370600938797\n",
            "\n",
            "Epoch 51/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1409 - val_loss: 0.1085\n",
            "Loss: 0.14089082181453705\n",
            "Validation Loss: 0.10850629955530167\n",
            "\n",
            "Epoch 52/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1412 - val_loss: 0.1095\n",
            "Loss: 0.14115667343139648\n",
            "Validation Loss: 0.10951147973537445\n",
            "\n",
            "Epoch 53/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1412 - val_loss: 0.1098\n",
            "Loss: 0.14123086631298065\n",
            "Validation Loss: 0.10977768898010254\n",
            "\n",
            "Epoch 54/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1410 - val_loss: 0.1092\n",
            "Loss: 0.14098112285137177\n",
            "Validation Loss: 0.1091655045747757\n",
            "\n",
            "Epoch 55/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1403 - val_loss: 0.1088\n",
            "Loss: 0.14030127227306366\n",
            "Validation Loss: 0.10877779871225357\n",
            "\n",
            "Epoch 56/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1404 - val_loss: 0.1072\n",
            "Loss: 0.14041340351104736\n",
            "Validation Loss: 0.10724137723445892\n",
            "\n",
            "Epoch 57/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1380 - val_loss: 0.1074\n",
            "Loss: 0.13798336684703827\n",
            "Validation Loss: 0.10735652595758438\n",
            "\n",
            "Epoch 58/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1395 - val_loss: 0.1082\n",
            "Loss: 0.1394513100385666\n",
            "Validation Loss: 0.10823927819728851\n",
            "\n",
            "Epoch 59/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1375 - val_loss: 0.1061\n",
            "Loss: 0.13751786947250366\n",
            "Validation Loss: 0.1060548648238182\n",
            "\n",
            "Epoch 60/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1375 - val_loss: 0.1063\n",
            "Loss: 0.13750842213630676\n",
            "Validation Loss: 0.10632305592298508\n",
            "\n",
            "Epoch 61/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1377 - val_loss: 0.1065\n",
            "Loss: 0.1377006620168686\n",
            "Validation Loss: 0.10645834356546402\n",
            "\n",
            "Epoch 62/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1370 - val_loss: 0.1067\n",
            "Loss: 0.13695861399173737\n",
            "Validation Loss: 0.10673122853040695\n",
            "\n",
            "Epoch 63/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1367 - val_loss: 0.1070\n",
            "Loss: 0.13673682510852814\n",
            "Validation Loss: 0.10701408237218857\n",
            "\n",
            "Epoch 64/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1371 - val_loss: 0.1051\n",
            "Loss: 0.13707365095615387\n",
            "Validation Loss: 0.10507743805646896\n",
            "\n",
            "Epoch 65/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1378 - val_loss: 0.1065\n",
            "Loss: 0.1377565860748291\n",
            "Validation Loss: 0.10649316012859344\n",
            "\n",
            "Epoch 66/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1367 - val_loss: 0.1064\n",
            "Loss: 0.13671189546585083\n",
            "Validation Loss: 0.1063792034983635\n",
            "\n",
            "Epoch 67/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1365 - val_loss: 0.1046\n",
            "Loss: 0.13650423288345337\n",
            "Validation Loss: 0.10458999872207642\n",
            "\n",
            "Epoch 68/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1353 - val_loss: 0.1052\n",
            "Loss: 0.13525952398777008\n",
            "Validation Loss: 0.1052047535777092\n",
            "\n",
            "Epoch 69/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1353 - val_loss: 0.1054\n",
            "Loss: 0.13533827662467957\n",
            "Validation Loss: 0.10544513911008835\n",
            "\n",
            "Epoch 70/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1339 - val_loss: 0.1055\n",
            "Loss: 0.13389112055301666\n",
            "Validation Loss: 0.10545584559440613\n",
            "\n",
            "Epoch 71/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1334 - val_loss: 0.1049\n",
            "Loss: 0.13335084915161133\n",
            "Validation Loss: 0.10491842776536942\n",
            "\n",
            "Epoch 72/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1338 - val_loss: 0.1051\n",
            "Loss: 0.133761465549469\n",
            "Validation Loss: 0.1050746738910675\n",
            "\n",
            "Epoch 73/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1348 - val_loss: 0.1056\n",
            "Loss: 0.13483235239982605\n",
            "Validation Loss: 0.10557364672422409\n",
            "\n",
            "Epoch 74/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1353 - val_loss: 0.1041\n",
            "Loss: 0.1352643370628357\n",
            "Validation Loss: 0.10412874072790146\n",
            "\n",
            "Epoch 75/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1325 - val_loss: 0.1031\n",
            "Loss: 0.1324777901172638\n",
            "Validation Loss: 0.10309884697198868\n",
            "\n",
            "Epoch 76/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1324 - val_loss: 0.1053\n",
            "Loss: 0.1323811411857605\n",
            "Validation Loss: 0.10531645268201828\n",
            "\n",
            "Epoch 77/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1327 - val_loss: 0.1033\n",
            "Loss: 0.13266029953956604\n",
            "Validation Loss: 0.10328969359397888\n",
            "\n",
            "Epoch 78/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1331 - val_loss: 0.1057\n",
            "Loss: 0.1330944448709488\n",
            "Validation Loss: 0.10567066073417664\n",
            "\n",
            "Epoch 79/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1318 - val_loss: 0.1019\n",
            "Loss: 0.13175196945667267\n",
            "Validation Loss: 0.10186412930488586\n",
            "\n",
            "Epoch 80/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1304 - val_loss: 0.1031\n",
            "Loss: 0.13036981225013733\n",
            "Validation Loss: 0.10313025861978531\n",
            "\n",
            "Epoch 81/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1328 - val_loss: 0.1038\n",
            "Loss: 0.1328117549419403\n",
            "Validation Loss: 0.10384341329336166\n",
            "\n",
            "Epoch 82/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1303 - val_loss: 0.1041\n",
            "Loss: 0.13030202686786652\n",
            "Validation Loss: 0.10414272546768188\n",
            "\n",
            "Epoch 83/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1313 - val_loss: 0.1040\n",
            "Loss: 0.1313091516494751\n",
            "Validation Loss: 0.10395260155200958\n",
            "\n",
            "Epoch 84/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1308 - val_loss: 0.1016\n",
            "Loss: 0.13076429069042206\n",
            "Validation Loss: 0.1015615463256836\n",
            "\n",
            "Epoch 85/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1306 - val_loss: 0.1016\n",
            "Loss: 0.13061010837554932\n",
            "Validation Loss: 0.10159046202898026\n",
            "\n",
            "Epoch 86/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1291 - val_loss: 0.1011\n",
            "Loss: 0.12905310094356537\n",
            "Validation Loss: 0.1011199802160263\n",
            "\n",
            "Epoch 87/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1307 - val_loss: 0.1006\n",
            "Loss: 0.1307268887758255\n",
            "Validation Loss: 0.10061051696538925\n",
            "\n",
            "Epoch 88/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1280 - val_loss: 0.1019\n",
            "Loss: 0.12800121307373047\n",
            "Validation Loss: 0.10194825381040573\n",
            "\n",
            "Epoch 89/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1301 - val_loss: 0.1014\n",
            "Loss: 0.1300828456878662\n",
            "Validation Loss: 0.1014484241604805\n",
            "\n",
            "Epoch 90/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1290 - val_loss: 0.0998\n",
            "Loss: 0.128991961479187\n",
            "Validation Loss: 0.09977774322032928\n",
            "\n",
            "Epoch 91/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1289 - val_loss: 0.1005\n",
            "Loss: 0.12889021635055542\n",
            "Validation Loss: 0.10048964619636536\n",
            "\n",
            "Epoch 92/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1288 - val_loss: 0.1003\n",
            "Loss: 0.12882821261882782\n",
            "Validation Loss: 0.10027378052473068\n",
            "\n",
            "Epoch 93/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1266 - val_loss: 0.0996\n",
            "Loss: 0.12659846246242523\n",
            "Validation Loss: 0.09964627772569656\n",
            "\n",
            "Epoch 94/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1278 - val_loss: 0.1002\n",
            "Loss: 0.12781378626823425\n",
            "Validation Loss: 0.10018008947372437\n",
            "\n",
            "Epoch 95/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1276 - val_loss: 0.1018\n",
            "Loss: 0.12764103710651398\n",
            "Validation Loss: 0.10180789977312088\n",
            "\n",
            "Epoch 96/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1284 - val_loss: 0.1000\n",
            "Loss: 0.1284368485212326\n",
            "Validation Loss: 0.0999869704246521\n",
            "\n",
            "Epoch 97/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1275 - val_loss: 0.1015\n",
            "Loss: 0.12746618688106537\n",
            "Validation Loss: 0.10148013383150101\n",
            "\n",
            "Epoch 98/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1278 - val_loss: 0.1008\n",
            "Loss: 0.12777963280677795\n",
            "Validation Loss: 0.10079643875360489\n",
            "\n",
            "Epoch 99/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1274 - val_loss: 0.1000\n",
            "Loss: 0.12741349637508392\n",
            "Validation Loss: 0.1000429019331932\n",
            "\n",
            "Epoch 100/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1269 - val_loss: 0.1000\n",
            "Loss: 0.12689688801765442\n",
            "Validation Loss: 0.10004157572984695\n",
            "\n",
            "Epoch 101/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1272 - val_loss: 0.0993\n",
            "Loss: 0.12724345922470093\n",
            "Validation Loss: 0.09926759451627731\n",
            "\n",
            "Epoch 102/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1257 - val_loss: 0.1000\n",
            "Loss: 0.12574541568756104\n",
            "Validation Loss: 0.0999675914645195\n",
            "\n",
            "Epoch 103/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1253 - val_loss: 0.0974\n",
            "Loss: 0.12525802850723267\n",
            "Validation Loss: 0.09736723452806473\n",
            "\n",
            "Epoch 104/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1251 - val_loss: 0.0985\n",
            "Loss: 0.12509334087371826\n",
            "Validation Loss: 0.09852644801139832\n",
            "\n",
            "Epoch 105/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1256 - val_loss: 0.0976\n",
            "Loss: 0.1256469339132309\n",
            "Validation Loss: 0.09760315716266632\n",
            "\n",
            "Epoch 106/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1259 - val_loss: 0.0965\n",
            "Loss: 0.12586906552314758\n",
            "Validation Loss: 0.09648044407367706\n",
            "\n",
            "Epoch 107/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1262 - val_loss: 0.1001\n",
            "Loss: 0.12617529928684235\n",
            "Validation Loss: 0.10009141266345978\n",
            "\n",
            "Epoch 108/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1254 - val_loss: 0.0974\n",
            "Loss: 0.12543688714504242\n",
            "Validation Loss: 0.0973636582493782\n",
            "\n",
            "Epoch 109/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1244 - val_loss: 0.0959\n",
            "Loss: 0.12440142780542374\n",
            "Validation Loss: 0.09591716527938843\n",
            "\n",
            "Epoch 110/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1241 - val_loss: 0.0987\n",
            "Loss: 0.1240866482257843\n",
            "Validation Loss: 0.09872335195541382\n",
            "\n",
            "Epoch 111/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1258 - val_loss: 0.0981\n",
            "Loss: 0.12577475607395172\n",
            "Validation Loss: 0.09813624620437622\n",
            "\n",
            "Epoch 112/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1244 - val_loss: 0.0959\n",
            "Loss: 0.12443824112415314\n",
            "Validation Loss: 0.09587228298187256\n",
            "\n",
            "Epoch 113/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1252 - val_loss: 0.0972\n",
            "Loss: 0.1252463161945343\n",
            "Validation Loss: 0.09718278050422668\n",
            "\n",
            "Epoch 114/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1234 - val_loss: 0.0960\n",
            "Loss: 0.12344362586736679\n",
            "Validation Loss: 0.09601252526044846\n",
            "\n",
            "Epoch 115/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1233 - val_loss: 0.0959\n",
            "Loss: 0.12334403395652771\n",
            "Validation Loss: 0.0959310233592987\n",
            "\n",
            "Epoch 116/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1239 - val_loss: 0.0990\n",
            "Loss: 0.12389916926622391\n",
            "Validation Loss: 0.09903653711080551\n",
            "\n",
            "Epoch 117/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1231 - val_loss: 0.0957\n",
            "Loss: 0.12311991304159164\n",
            "Validation Loss: 0.09571541845798492\n",
            "\n",
            "Epoch 118/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1234 - val_loss: 0.0943\n",
            "Loss: 0.12344101816415787\n",
            "Validation Loss: 0.09434624761343002\n",
            "\n",
            "Epoch 119/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1243 - val_loss: 0.0963\n",
            "Loss: 0.12432326376438141\n",
            "Validation Loss: 0.09632273018360138\n",
            "\n",
            "Epoch 120/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1232 - val_loss: 0.0942\n",
            "Loss: 0.12322729080915451\n",
            "Validation Loss: 0.094211645424366\n",
            "\n",
            "Epoch 121/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1226 - val_loss: 0.0970\n",
            "Loss: 0.12261011451482773\n",
            "Validation Loss: 0.09703352302312851\n",
            "\n",
            "Epoch 122/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1228 - val_loss: 0.0967\n",
            "Loss: 0.12281525135040283\n",
            "Validation Loss: 0.0966818556189537\n",
            "\n",
            "Epoch 123/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1235 - val_loss: 0.0960\n",
            "Loss: 0.12345325946807861\n",
            "Validation Loss: 0.09602908045053482\n",
            "\n",
            "Epoch 124/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1225 - val_loss: 0.0962\n",
            "Loss: 0.12248344719409943\n",
            "Validation Loss: 0.09621024876832962\n",
            "\n",
            "Epoch 125/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1210 - val_loss: 0.0940\n",
            "Loss: 0.12101297080516815\n",
            "Validation Loss: 0.09400667995214462\n",
            "\n",
            "Epoch 126/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1219 - val_loss: 0.0946\n",
            "Loss: 0.12192082405090332\n",
            "Validation Loss: 0.09455264359712601\n",
            "\n",
            "Epoch 127/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1218 - val_loss: 0.0942\n",
            "Loss: 0.1218164786696434\n",
            "Validation Loss: 0.09420579671859741\n",
            "\n",
            "Epoch 128/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1209 - val_loss: 0.0947\n",
            "Loss: 0.12087811529636383\n",
            "Validation Loss: 0.094719797372818\n",
            "\n",
            "Epoch 129/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1217 - val_loss: 0.0937\n",
            "Loss: 0.12167729437351227\n",
            "Validation Loss: 0.0936872661113739\n",
            "\n",
            "Epoch 130/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1212 - val_loss: 0.0947\n",
            "Loss: 0.1211935430765152\n",
            "Validation Loss: 0.09473293274641037\n",
            "\n",
            "Epoch 131/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1217 - val_loss: 0.0935\n",
            "Loss: 0.12165164947509766\n",
            "Validation Loss: 0.09354917705059052\n",
            "\n",
            "Epoch 132/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1214 - val_loss: 0.0944\n",
            "Loss: 0.12137103080749512\n",
            "Validation Loss: 0.09440138190984726\n",
            "\n",
            "Epoch 133/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1208 - val_loss: 0.0940\n",
            "Loss: 0.12075310945510864\n",
            "Validation Loss: 0.093996062874794\n",
            "\n",
            "Epoch 134/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1200 - val_loss: 0.0932\n",
            "Loss: 0.12001541256904602\n",
            "Validation Loss: 0.0932321846485138\n",
            "\n",
            "Epoch 135/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1208 - val_loss: 0.0938\n",
            "Loss: 0.12083978950977325\n",
            "Validation Loss: 0.09382083266973495\n",
            "\n",
            "Epoch 136/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1194 - val_loss: 0.0929\n",
            "Loss: 0.11935076862573624\n",
            "Validation Loss: 0.09288303554058075\n",
            "\n",
            "Epoch 137/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1193 - val_loss: 0.0929\n",
            "Loss: 0.11925383657217026\n",
            "Validation Loss: 0.09285420179367065\n",
            "\n",
            "Epoch 138/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1204 - val_loss: 0.0944\n",
            "Loss: 0.12036101520061493\n",
            "Validation Loss: 0.09439025819301605\n",
            "\n",
            "Epoch 139/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1192 - val_loss: 0.0935\n",
            "Loss: 0.1192387044429779\n",
            "Validation Loss: 0.09348882734775543\n",
            "\n",
            "Epoch 140/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1204 - val_loss: 0.0939\n",
            "Loss: 0.12036164104938507\n",
            "Validation Loss: 0.09390091896057129\n",
            "\n",
            "Epoch 141/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1198 - val_loss: 0.0930\n",
            "Loss: 0.11980278789997101\n",
            "Validation Loss: 0.09303922206163406\n",
            "\n",
            "Epoch 142/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1192 - val_loss: 0.0923\n",
            "Loss: 0.1192319393157959\n",
            "Validation Loss: 0.09227056801319122\n",
            "\n",
            "Epoch 143/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1190 - val_loss: 0.0933\n",
            "Loss: 0.11898721009492874\n",
            "Validation Loss: 0.09333304315805435\n",
            "\n",
            "Epoch 144/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1193 - val_loss: 0.0938\n",
            "Loss: 0.11931686848402023\n",
            "Validation Loss: 0.09381993114948273\n",
            "\n",
            "Epoch 145/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1183 - val_loss: 0.0918\n",
            "Loss: 0.11829911917448044\n",
            "Validation Loss: 0.09181275963783264\n",
            "\n",
            "Epoch 146/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1192 - val_loss: 0.0927\n",
            "Loss: 0.11917527765035629\n",
            "Validation Loss: 0.09273228049278259\n",
            "\n",
            "Epoch 147/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1185 - val_loss: 0.0927\n",
            "Loss: 0.11850178986787796\n",
            "Validation Loss: 0.0927179828286171\n",
            "\n",
            "Epoch 148/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1188 - val_loss: 0.0915\n",
            "Loss: 0.11884503066539764\n",
            "Validation Loss: 0.09146907925605774\n",
            "\n",
            "Epoch 149/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1194 - val_loss: 0.0944\n",
            "Loss: 0.1194448173046112\n",
            "Validation Loss: 0.09440148621797562\n",
            "\n",
            "Epoch 150/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1190 - val_loss: 0.0936\n",
            "Loss: 0.11897297948598862\n",
            "Validation Loss: 0.09359592199325562\n",
            "\n",
            "Epoch 151/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1189 - val_loss: 0.0931\n",
            "Loss: 0.11886619031429291\n",
            "Validation Loss: 0.09305144846439362\n",
            "\n",
            "Epoch 152/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1179 - val_loss: 0.0949\n",
            "Loss: 0.11789189279079437\n",
            "Validation Loss: 0.09485428780317307\n",
            "\n",
            "Epoch 153/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1184 - val_loss: 0.0924\n",
            "Loss: 0.11838876456022263\n",
            "Validation Loss: 0.09242860972881317\n",
            "\n",
            "Epoch 154/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1177 - val_loss: 0.0922\n",
            "Loss: 0.11768965423107147\n",
            "Validation Loss: 0.09217208623886108\n",
            "\n",
            "Epoch 155/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1184 - val_loss: 0.0907\n",
            "Loss: 0.11842283606529236\n",
            "Validation Loss: 0.09067264944314957\n",
            "\n",
            "Epoch 156/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1174 - val_loss: 0.0922\n",
            "Loss: 0.11739356815814972\n",
            "Validation Loss: 0.0922190397977829\n",
            "\n",
            "Epoch 157/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1182 - val_loss: 0.0916\n",
            "Loss: 0.11822540313005447\n",
            "Validation Loss: 0.09159307926893234\n",
            "\n",
            "Epoch 158/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1175 - val_loss: 0.0948\n",
            "Loss: 0.11754640191793442\n",
            "Validation Loss: 0.09475556015968323\n",
            "\n",
            "Epoch 159/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1178 - val_loss: 0.0898\n",
            "Loss: 0.11780640482902527\n",
            "Validation Loss: 0.08980980515480042\n",
            "\n",
            "Epoch 160/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1177 - val_loss: 0.0907\n",
            "Loss: 0.11774692684412003\n",
            "Validation Loss: 0.09071767330169678\n",
            "\n",
            "Epoch 161/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1171 - val_loss: 0.0942\n",
            "Loss: 0.11710075289011002\n",
            "Validation Loss: 0.09421771764755249\n",
            "\n",
            "Epoch 162/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1178 - val_loss: 0.0916\n",
            "Loss: 0.1177712008357048\n",
            "Validation Loss: 0.09157636016607285\n",
            "\n",
            "Epoch 163/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1170 - val_loss: 0.0911\n",
            "Loss: 0.11697396636009216\n",
            "Validation Loss: 0.09113672375679016\n",
            "\n",
            "Epoch 164/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1164 - val_loss: 0.0913\n",
            "Loss: 0.11643298715353012\n",
            "Validation Loss: 0.09130243957042694\n",
            "\n",
            "Epoch 165/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1177 - val_loss: 0.0913\n",
            "Loss: 0.1177244558930397\n",
            "Validation Loss: 0.09133562445640564\n",
            "\n",
            "Epoch 166/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1169 - val_loss: 0.0897\n",
            "Loss: 0.11685413122177124\n",
            "Validation Loss: 0.08966172486543655\n",
            "\n",
            "Epoch 167/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1173 - val_loss: 0.0903\n",
            "Loss: 0.11725159734487534\n",
            "Validation Loss: 0.090260811150074\n",
            "\n",
            "Epoch 168/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1164 - val_loss: 0.0905\n",
            "Loss: 0.11639074981212616\n",
            "Validation Loss: 0.09052681922912598\n",
            "\n",
            "Epoch 169/750\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.1153 - val_loss: 0.0895\n",
            "Loss: 0.11529268324375153\n",
            "Validation Loss: 0.08947918564081192\n",
            "\n",
            "Epoch 170/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1164 - val_loss: 0.0901\n",
            "Loss: 0.11641816794872284\n",
            "Validation Loss: 0.09007702022790909\n",
            "\n",
            "Epoch 171/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1155 - val_loss: 0.0910\n",
            "Loss: 0.11548233777284622\n",
            "Validation Loss: 0.09101103991270065\n",
            "\n",
            "Epoch 172/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1149 - val_loss: 0.0905\n",
            "Loss: 0.11487144976854324\n",
            "Validation Loss: 0.09054182469844818\n",
            "\n",
            "Epoch 173/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1159 - val_loss: 0.0898\n",
            "Loss: 0.11591315269470215\n",
            "Validation Loss: 0.08981139212846756\n",
            "\n",
            "Epoch 174/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1164 - val_loss: 0.0896\n",
            "Loss: 0.1164189949631691\n",
            "Validation Loss: 0.08964864164590836\n",
            "\n",
            "Epoch 175/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1158 - val_loss: 0.0918\n",
            "Loss: 0.11580760031938553\n",
            "Validation Loss: 0.09178515523672104\n",
            "\n",
            "Epoch 176/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1152 - val_loss: 0.0904\n",
            "Loss: 0.11515003442764282\n",
            "Validation Loss: 0.09041079133749008\n",
            "\n",
            "Epoch 177/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1160 - val_loss: 0.0900\n",
            "Loss: 0.11599162220954895\n",
            "Validation Loss: 0.09003147482872009\n",
            "\n",
            "Epoch 178/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1146 - val_loss: 0.0910\n",
            "Loss: 0.11461571604013443\n",
            "Validation Loss: 0.09104102849960327\n",
            "\n",
            "Epoch 179/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1158 - val_loss: 0.0897\n",
            "Loss: 0.11583243310451508\n",
            "Validation Loss: 0.08965138345956802\n",
            "\n",
            "Epoch 180/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1158 - val_loss: 0.0921\n",
            "Loss: 0.11583157628774643\n",
            "Validation Loss: 0.09206578135490417\n",
            "\n",
            "Epoch 181/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1155 - val_loss: 0.0889\n",
            "Loss: 0.1154748946428299\n",
            "Validation Loss: 0.0889434963464737\n",
            "\n",
            "Epoch 182/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1152 - val_loss: 0.0894\n",
            "Loss: 0.11521884053945541\n",
            "Validation Loss: 0.08938188850879669\n",
            "\n",
            "Epoch 183/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1144 - val_loss: 0.0901\n",
            "Loss: 0.11438528448343277\n",
            "Validation Loss: 0.09010196477174759\n",
            "\n",
            "Epoch 184/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1137 - val_loss: 0.0916\n",
            "Loss: 0.11373601108789444\n",
            "Validation Loss: 0.0916416272521019\n",
            "\n",
            "Epoch 185/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1152 - val_loss: 0.0889\n",
            "Loss: 0.11515288054943085\n",
            "Validation Loss: 0.0889129713177681\n",
            "\n",
            "Epoch 186/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1150 - val_loss: 0.0894\n",
            "Loss: 0.11498668789863586\n",
            "Validation Loss: 0.0894404873251915\n",
            "\n",
            "Epoch 187/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1147 - val_loss: 0.0886\n",
            "Loss: 0.11467362195253372\n",
            "Validation Loss: 0.08864939957857132\n",
            "\n",
            "Epoch 188/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1144 - val_loss: 0.0895\n",
            "Loss: 0.11436590552330017\n",
            "Validation Loss: 0.08954191207885742\n",
            "\n",
            "Epoch 189/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1149 - val_loss: 0.0892\n",
            "Loss: 0.1149430200457573\n",
            "Validation Loss: 0.08918970823287964\n",
            "\n",
            "Epoch 190/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1155 - val_loss: 0.0901\n",
            "Loss: 0.11550737917423248\n",
            "Validation Loss: 0.09014663100242615\n",
            "\n",
            "Epoch 191/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1138 - val_loss: 0.0898\n",
            "Loss: 0.11381841450929642\n",
            "Validation Loss: 0.08981777727603912\n",
            "\n",
            "Epoch 192/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1150 - val_loss: 0.0884\n",
            "Loss: 0.11501070857048035\n",
            "Validation Loss: 0.08837488293647766\n",
            "\n",
            "Epoch 193/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1138 - val_loss: 0.0901\n",
            "Loss: 0.11380322277545929\n",
            "Validation Loss: 0.09008034318685532\n",
            "\n",
            "Epoch 194/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1146 - val_loss: 0.0890\n",
            "Loss: 0.11461164802312851\n",
            "Validation Loss: 0.08902105689048767\n",
            "\n",
            "Epoch 195/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1146 - val_loss: 0.0889\n",
            "Loss: 0.11459492892026901\n",
            "Validation Loss: 0.08893507719039917\n",
            "\n",
            "Epoch 196/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1138 - val_loss: 0.0872\n",
            "Loss: 0.11382817476987839\n",
            "Validation Loss: 0.08721812069416046\n",
            "\n",
            "Epoch 197/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1141 - val_loss: 0.0896\n",
            "Loss: 0.11414533108472824\n",
            "Validation Loss: 0.08964039385318756\n",
            "\n",
            "Epoch 198/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1143 - val_loss: 0.0887\n",
            "Loss: 0.11428901553153992\n",
            "Validation Loss: 0.08871888369321823\n",
            "\n",
            "Epoch 199/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1140 - val_loss: 0.0917\n",
            "Loss: 0.1139957383275032\n",
            "Validation Loss: 0.0916653424501419\n",
            "\n",
            "Epoch 200/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1135 - val_loss: 0.0875\n",
            "Loss: 0.11345238983631134\n",
            "Validation Loss: 0.08747811615467072\n",
            "\n",
            "Epoch 201/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1144 - val_loss: 0.0889\n",
            "Loss: 0.11444535106420517\n",
            "Validation Loss: 0.08889535814523697\n",
            "\n",
            "Epoch 202/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1132 - val_loss: 0.0891\n",
            "Loss: 0.11320001631975174\n",
            "Validation Loss: 0.08906833827495575\n",
            "\n",
            "Epoch 203/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1138 - val_loss: 0.0898\n",
            "Loss: 0.11376054584980011\n",
            "Validation Loss: 0.08975280076265335\n",
            "\n",
            "Epoch 204/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1139 - val_loss: 0.0883\n",
            "Loss: 0.1138652041554451\n",
            "Validation Loss: 0.08830229192972183\n",
            "\n",
            "Epoch 205/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1136 - val_loss: 0.0880\n",
            "Loss: 0.1136484295129776\n",
            "Validation Loss: 0.08801288157701492\n",
            "\n",
            "Epoch 206/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1127 - val_loss: 0.0875\n",
            "Loss: 0.11269893497228622\n",
            "Validation Loss: 0.08746781945228577\n",
            "\n",
            "Epoch 207/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1134 - val_loss: 0.0872\n",
            "Loss: 0.11341795325279236\n",
            "Validation Loss: 0.08719279617071152\n",
            "\n",
            "Epoch 208/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1123 - val_loss: 0.0885\n",
            "Loss: 0.11230012774467468\n",
            "Validation Loss: 0.08849562704563141\n",
            "\n",
            "Epoch 209/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1131 - val_loss: 0.0873\n",
            "Loss: 0.11309736967086792\n",
            "Validation Loss: 0.08733488619327545\n",
            "\n",
            "Epoch 210/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1119 - val_loss: 0.0887\n",
            "Loss: 0.11189275979995728\n",
            "Validation Loss: 0.0887349545955658\n",
            "\n",
            "Epoch 211/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1141 - val_loss: 0.0872\n",
            "Loss: 0.11407172679901123\n",
            "Validation Loss: 0.08720169961452484\n",
            "\n",
            "Epoch 212/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1120 - val_loss: 0.0879\n",
            "Loss: 0.11195529997348785\n",
            "Validation Loss: 0.08785463124513626\n",
            "\n",
            "Epoch 213/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1128 - val_loss: 0.0899\n",
            "Loss: 0.1127580776810646\n",
            "Validation Loss: 0.08986169099807739\n",
            "\n",
            "Epoch 214/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1127 - val_loss: 0.0893\n",
            "Loss: 0.11274340748786926\n",
            "Validation Loss: 0.0892711952328682\n",
            "\n",
            "Epoch 215/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1121 - val_loss: 0.0891\n",
            "Loss: 0.11213339120149612\n",
            "Validation Loss: 0.08906080573797226\n",
            "\n",
            "Epoch 216/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1119 - val_loss: 0.0868\n",
            "Loss: 0.11185437440872192\n",
            "Validation Loss: 0.08677788078784943\n",
            "\n",
            "Epoch 217/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1132 - val_loss: 0.0877\n",
            "Loss: 0.11319975554943085\n",
            "Validation Loss: 0.08774686604738235\n",
            "\n",
            "Epoch 218/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1127 - val_loss: 0.0861\n",
            "Loss: 0.1126769632101059\n",
            "Validation Loss: 0.0860784575343132\n",
            "\n",
            "Epoch 219/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1120 - val_loss: 0.0879\n",
            "Loss: 0.11197453737258911\n",
            "Validation Loss: 0.0878598541021347\n",
            "\n",
            "Epoch 220/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1122 - val_loss: 0.0857\n",
            "Loss: 0.11223674565553665\n",
            "Validation Loss: 0.08573919534683228\n",
            "\n",
            "Epoch 221/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1127 - val_loss: 0.0878\n",
            "Loss: 0.11272705346345901\n",
            "Validation Loss: 0.0877891331911087\n",
            "\n",
            "Epoch 222/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1122 - val_loss: 0.0874\n",
            "Loss: 0.11221460998058319\n",
            "Validation Loss: 0.0874130055308342\n",
            "\n",
            "Epoch 223/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1122 - val_loss: 0.0860\n",
            "Loss: 0.11216741800308228\n",
            "Validation Loss: 0.08595755696296692\n",
            "\n",
            "Epoch 224/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1120 - val_loss: 0.0863\n",
            "Loss: 0.11201605200767517\n",
            "Validation Loss: 0.0863196924328804\n",
            "\n",
            "Epoch 225/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1124 - val_loss: 0.0873\n",
            "Loss: 0.112434983253479\n",
            "Validation Loss: 0.08734164386987686\n",
            "\n",
            "Epoch 226/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1131 - val_loss: 0.0880\n",
            "Loss: 0.11310015618801117\n",
            "Validation Loss: 0.08798487484455109\n",
            "\n",
            "Epoch 227/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1111 - val_loss: 0.0869\n",
            "Loss: 0.11108973622322083\n",
            "Validation Loss: 0.08689594268798828\n",
            "\n",
            "Epoch 228/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1113 - val_loss: 0.0867\n",
            "Loss: 0.11130780726671219\n",
            "Validation Loss: 0.0867219790816307\n",
            "\n",
            "Epoch 229/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1121 - val_loss: 0.0854\n",
            "Loss: 0.1121276468038559\n",
            "Validation Loss: 0.0853554904460907\n",
            "\n",
            "Epoch 230/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1118 - val_loss: 0.0872\n",
            "Loss: 0.11179547756910324\n",
            "Validation Loss: 0.08723674714565277\n",
            "\n",
            "Epoch 231/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1110 - val_loss: 0.0858\n",
            "Loss: 0.11097561568021774\n",
            "Validation Loss: 0.08584100008010864\n",
            "\n",
            "Epoch 232/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1114 - val_loss: 0.0850\n",
            "Loss: 0.11143815517425537\n",
            "Validation Loss: 0.08495206385850906\n",
            "\n",
            "Epoch 233/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1119 - val_loss: 0.0846\n",
            "Loss: 0.11189937591552734\n",
            "Validation Loss: 0.08463484793901443\n",
            "\n",
            "Epoch 234/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1117 - val_loss: 0.0867\n",
            "Loss: 0.11172287166118622\n",
            "Validation Loss: 0.0867137610912323\n",
            "\n",
            "Epoch 235/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1115 - val_loss: 0.0862\n",
            "Loss: 0.11149520426988602\n",
            "Validation Loss: 0.08622083812952042\n",
            "\n",
            "Epoch 236/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1113 - val_loss: 0.0854\n",
            "Loss: 0.11132525652647018\n",
            "Validation Loss: 0.08537095785140991\n",
            "\n",
            "Epoch 237/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1118 - val_loss: 0.0870\n",
            "Loss: 0.11183217912912369\n",
            "Validation Loss: 0.0869624987244606\n",
            "\n",
            "Epoch 238/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1106 - val_loss: 0.0851\n",
            "Loss: 0.11064642667770386\n",
            "Validation Loss: 0.08508507907390594\n",
            "\n",
            "Epoch 239/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1117 - val_loss: 0.0877\n",
            "Loss: 0.11165870726108551\n",
            "Validation Loss: 0.08769063651561737\n",
            "\n",
            "Epoch 240/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1101 - val_loss: 0.0869\n",
            "Loss: 0.11006049811840057\n",
            "Validation Loss: 0.08694210648536682\n",
            "\n",
            "Epoch 241/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1111 - val_loss: 0.0852\n",
            "Loss: 0.11112085729837418\n",
            "Validation Loss: 0.08516968041658401\n",
            "\n",
            "Epoch 242/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1113 - val_loss: 0.0860\n",
            "Loss: 0.11126640439033508\n",
            "Validation Loss: 0.08595399558544159\n",
            "\n",
            "Epoch 243/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1107 - val_loss: 0.0860\n",
            "Loss: 0.11074928939342499\n",
            "Validation Loss: 0.08601632714271545\n",
            "\n",
            "Epoch 244/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1109 - val_loss: 0.0847\n",
            "Loss: 0.11088381707668304\n",
            "Validation Loss: 0.08474674820899963\n",
            "\n",
            "Epoch 245/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1105 - val_loss: 0.0870\n",
            "Loss: 0.11050102114677429\n",
            "Validation Loss: 0.0870446041226387\n",
            "\n",
            "Epoch 246/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1109 - val_loss: 0.0851\n",
            "Loss: 0.11087403446435928\n",
            "Validation Loss: 0.08510522544384003\n",
            "\n",
            "Epoch 247/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1102 - val_loss: 0.0874\n",
            "Loss: 0.11017828434705734\n",
            "Validation Loss: 0.08743855357170105\n",
            "\n",
            "Epoch 248/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1108 - val_loss: 0.0866\n",
            "Loss: 0.11082660406827927\n",
            "Validation Loss: 0.08660589158535004\n",
            "\n",
            "Epoch 249/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1102 - val_loss: 0.0847\n",
            "Loss: 0.11024732142686844\n",
            "Validation Loss: 0.08474823087453842\n",
            "\n",
            "Epoch 250/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1104 - val_loss: 0.0872\n",
            "Loss: 0.11041054874658585\n",
            "Validation Loss: 0.0871700793504715\n",
            "\n",
            "Epoch 251/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1103 - val_loss: 0.0858\n",
            "Loss: 0.11030271649360657\n",
            "Validation Loss: 0.08577613532543182\n",
            "\n",
            "Epoch 252/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1104 - val_loss: 0.0882\n",
            "Loss: 0.11036446690559387\n",
            "Validation Loss: 0.08815313875675201\n",
            "\n",
            "Epoch 253/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1109 - val_loss: 0.0870\n",
            "Loss: 0.11091186851263046\n",
            "Validation Loss: 0.08704044669866562\n",
            "\n",
            "Epoch 254/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1104 - val_loss: 0.0845\n",
            "Loss: 0.11035796999931335\n",
            "Validation Loss: 0.08448770642280579\n",
            "\n",
            "Epoch 255/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1099 - val_loss: 0.0838\n",
            "Loss: 0.10985299199819565\n",
            "Validation Loss: 0.0838470607995987\n",
            "\n",
            "Epoch 256/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1099 - val_loss: 0.0860\n",
            "Loss: 0.1098991334438324\n",
            "Validation Loss: 0.08604153245687485\n",
            "\n",
            "Epoch 257/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1098 - val_loss: 0.0845\n",
            "Loss: 0.10978290438652039\n",
            "Validation Loss: 0.08454538881778717\n",
            "\n",
            "Epoch 258/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1106 - val_loss: 0.0860\n",
            "Loss: 0.11059757322072983\n",
            "Validation Loss: 0.08595660328865051\n",
            "\n",
            "Epoch 259/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1102 - val_loss: 0.0859\n",
            "Loss: 0.11020845174789429\n",
            "Validation Loss: 0.08587640523910522\n",
            "\n",
            "Epoch 260/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1099 - val_loss: 0.0879\n",
            "Loss: 0.10992441326379776\n",
            "Validation Loss: 0.08790585398674011\n",
            "\n",
            "Epoch 261/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1091 - val_loss: 0.0838\n",
            "Loss: 0.10913657397031784\n",
            "Validation Loss: 0.08381354063749313\n",
            "\n",
            "Epoch 262/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1091 - val_loss: 0.0851\n",
            "Loss: 0.10907460004091263\n",
            "Validation Loss: 0.08509580045938492\n",
            "\n",
            "Epoch 263/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1097 - val_loss: 0.0851\n",
            "Loss: 0.10966838151216507\n",
            "Validation Loss: 0.08509629219770432\n",
            "\n",
            "Epoch 264/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1092 - val_loss: 0.0840\n",
            "Loss: 0.1092279702425003\n",
            "Validation Loss: 0.08399701863527298\n",
            "\n",
            "Epoch 265/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1106 - val_loss: 0.0844\n",
            "Loss: 0.11056389659643173\n",
            "Validation Loss: 0.08435191214084625\n",
            "\n",
            "Epoch 266/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1096 - val_loss: 0.0853\n",
            "Loss: 0.10964915156364441\n",
            "Validation Loss: 0.08534207195043564\n",
            "\n",
            "Epoch 267/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1097 - val_loss: 0.0850\n",
            "Loss: 0.10968559980392456\n",
            "Validation Loss: 0.0849943459033966\n",
            "\n",
            "Epoch 268/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1081 - val_loss: 0.0840\n",
            "Loss: 0.10814030468463898\n",
            "Validation Loss: 0.08402509242296219\n",
            "\n",
            "Epoch 269/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1090 - val_loss: 0.0851\n",
            "Loss: 0.10903849452733994\n",
            "Validation Loss: 0.08508939296007156\n",
            "\n",
            "Epoch 270/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1090 - val_loss: 0.0843\n",
            "Loss: 0.10903716087341309\n",
            "Validation Loss: 0.08425210416316986\n",
            "\n",
            "Epoch 271/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1095 - val_loss: 0.0848\n",
            "Loss: 0.10947803407907486\n",
            "Validation Loss: 0.08475559204816818\n",
            "\n",
            "Epoch 272/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1096 - val_loss: 0.0850\n",
            "Loss: 0.10963369160890579\n",
            "Validation Loss: 0.0850052759051323\n",
            "\n",
            "Epoch 273/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1094 - val_loss: 0.0837\n",
            "Loss: 0.10940106958150864\n",
            "Validation Loss: 0.08369383215904236\n",
            "\n",
            "Epoch 274/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1102 - val_loss: 0.0839\n",
            "Loss: 0.11015923321247101\n",
            "Validation Loss: 0.08388213068246841\n",
            "\n",
            "Epoch 275/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1090 - val_loss: 0.0827\n",
            "Loss: 0.10901292413473129\n",
            "Validation Loss: 0.08269496262073517\n",
            "\n",
            "Epoch 276/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1088 - val_loss: 0.0840\n",
            "Loss: 0.10882940143346786\n",
            "Validation Loss: 0.08396022021770477\n",
            "\n",
            "Epoch 277/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1087 - val_loss: 0.0843\n",
            "Loss: 0.10873828083276749\n",
            "Validation Loss: 0.08432696759700775\n",
            "\n",
            "Epoch 278/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1096 - val_loss: 0.0841\n",
            "Loss: 0.10962919890880585\n",
            "Validation Loss: 0.08410944789648056\n",
            "\n",
            "Epoch 279/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1093 - val_loss: 0.0836\n",
            "Loss: 0.1093447282910347\n",
            "Validation Loss: 0.08360522985458374\n",
            "\n",
            "Epoch 280/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1090 - val_loss: 0.0836\n",
            "Loss: 0.10904883593320847\n",
            "Validation Loss: 0.0836058184504509\n",
            "\n",
            "Epoch 281/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1086 - val_loss: 0.0826\n",
            "Loss: 0.10855478048324585\n",
            "Validation Loss: 0.082550548017025\n",
            "\n",
            "Epoch 282/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1081 - val_loss: 0.0839\n",
            "Loss: 0.10810486972332001\n",
            "Validation Loss: 0.08389443904161453\n",
            "\n",
            "Epoch 283/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1088 - val_loss: 0.0845\n",
            "Loss: 0.10883218050003052\n",
            "Validation Loss: 0.08449434489011765\n",
            "\n",
            "Epoch 284/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1084 - val_loss: 0.0840\n",
            "Loss: 0.10836490243673325\n",
            "Validation Loss: 0.0839819461107254\n",
            "\n",
            "Epoch 285/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1094 - val_loss: 0.0856\n",
            "Loss: 0.10937181115150452\n",
            "Validation Loss: 0.08555983752012253\n",
            "\n",
            "Epoch 286/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1087 - val_loss: 0.0860\n",
            "Loss: 0.10865392535924911\n",
            "Validation Loss: 0.08600816875696182\n",
            "\n",
            "Epoch 287/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1091 - val_loss: 0.0821\n",
            "Loss: 0.1090724915266037\n",
            "Validation Loss: 0.08209720999002457\n",
            "\n",
            "Epoch 288/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1082 - val_loss: 0.0841\n",
            "Loss: 0.10819611698389053\n",
            "Validation Loss: 0.08407550305128098\n",
            "\n",
            "Epoch 289/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1086 - val_loss: 0.0832\n",
            "Loss: 0.1085609570145607\n",
            "Validation Loss: 0.08315563201904297\n",
            "\n",
            "Epoch 290/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1090 - val_loss: 0.0845\n",
            "Loss: 0.10900790244340897\n",
            "Validation Loss: 0.08447001874446869\n",
            "\n",
            "Epoch 291/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1087 - val_loss: 0.0844\n",
            "Loss: 0.10871005803346634\n",
            "Validation Loss: 0.08438323438167572\n",
            "\n",
            "Epoch 292/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1084 - val_loss: 0.0840\n",
            "Loss: 0.10843086242675781\n",
            "Validation Loss: 0.08398782461881638\n",
            "\n",
            "Epoch 293/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1078 - val_loss: 0.0832\n",
            "Loss: 0.10779603570699692\n",
            "Validation Loss: 0.08321229368448257\n",
            "\n",
            "Epoch 294/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1087 - val_loss: 0.0845\n",
            "Loss: 0.10867936164140701\n",
            "Validation Loss: 0.08446183055639267\n",
            "\n",
            "Epoch 295/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1086 - val_loss: 0.0831\n",
            "Loss: 0.10861948132514954\n",
            "Validation Loss: 0.08306729048490524\n",
            "\n",
            "Epoch 296/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1079 - val_loss: 0.0827\n",
            "Loss: 0.10786953568458557\n",
            "Validation Loss: 0.08272899687290192\n",
            "\n",
            "Epoch 297/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1083 - val_loss: 0.0844\n",
            "Loss: 0.10832559317350388\n",
            "Validation Loss: 0.0844479352235794\n",
            "\n",
            "Epoch 298/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1083 - val_loss: 0.0836\n",
            "Loss: 0.10826793313026428\n",
            "Validation Loss: 0.0836496651172638\n",
            "\n",
            "Epoch 299/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1086 - val_loss: 0.0848\n",
            "Loss: 0.10857502371072769\n",
            "Validation Loss: 0.08480324596166611\n",
            "\n",
            "Epoch 300/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1080 - val_loss: 0.0837\n",
            "Loss: 0.10801815986633301\n",
            "Validation Loss: 0.08370192348957062\n",
            "\n",
            "Epoch 301/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1075 - val_loss: 0.0840\n",
            "Loss: 0.10750903934240341\n",
            "Validation Loss: 0.08402033895254135\n",
            "\n",
            "Epoch 302/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1079 - val_loss: 0.0822\n",
            "Loss: 0.10787270218133926\n",
            "Validation Loss: 0.08221448957920074\n",
            "\n",
            "Epoch 303/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1079 - val_loss: 0.0837\n",
            "Loss: 0.10791196674108505\n",
            "Validation Loss: 0.08371996879577637\n",
            "\n",
            "Epoch 304/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1078 - val_loss: 0.0822\n",
            "Loss: 0.107753686606884\n",
            "Validation Loss: 0.08224078267812729\n",
            "\n",
            "Epoch 305/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1069 - val_loss: 0.0826\n",
            "Loss: 0.10686518996953964\n",
            "Validation Loss: 0.08258319646120071\n",
            "\n",
            "Epoch 306/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1086 - val_loss: 0.0839\n",
            "Loss: 0.10859677940607071\n",
            "Validation Loss: 0.08391468226909637\n",
            "\n",
            "Epoch 307/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1080 - val_loss: 0.0820\n",
            "Loss: 0.10804202407598495\n",
            "Validation Loss: 0.08204307407140732\n",
            "\n",
            "Epoch 308/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1068 - val_loss: 0.0830\n",
            "Loss: 0.10683009773492813\n",
            "Validation Loss: 0.08303182572126389\n",
            "\n",
            "Epoch 309/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1082 - val_loss: 0.0820\n",
            "Loss: 0.10820957273244858\n",
            "Validation Loss: 0.0819908156991005\n",
            "\n",
            "Epoch 310/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1073 - val_loss: 0.0830\n",
            "Loss: 0.10729783773422241\n",
            "Validation Loss: 0.08304434269666672\n",
            "\n",
            "Epoch 311/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1077 - val_loss: 0.0817\n",
            "Loss: 0.10773982107639313\n",
            "Validation Loss: 0.08168793469667435\n",
            "\n",
            "Epoch 312/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1078 - val_loss: 0.0824\n",
            "Loss: 0.10778733342885971\n",
            "Validation Loss: 0.08236638456583023\n",
            "\n",
            "Epoch 313/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1074 - val_loss: 0.0819\n",
            "Loss: 0.10738066583871841\n",
            "Validation Loss: 0.08192387968301773\n",
            "\n",
            "Epoch 314/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1067 - val_loss: 0.0830\n",
            "Loss: 0.10674162954092026\n",
            "Validation Loss: 0.08303625881671906\n",
            "\n",
            "Epoch 315/750\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.1075 - val_loss: 0.0820\n",
            "Loss: 0.10746175050735474\n",
            "Validation Loss: 0.08195959776639938\n",
            "\n",
            "Epoch 316/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1071 - val_loss: 0.0831\n",
            "Loss: 0.10709251463413239\n",
            "Validation Loss: 0.08309928327798843\n",
            "\n",
            "Epoch 317/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1064 - val_loss: 0.0825\n",
            "Loss: 0.10644631832838058\n",
            "Validation Loss: 0.08245326578617096\n",
            "\n",
            "Epoch 318/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1069 - val_loss: 0.0818\n",
            "Loss: 0.10686603933572769\n",
            "Validation Loss: 0.08178012073040009\n",
            "\n",
            "Epoch 319/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1068 - val_loss: 0.0833\n",
            "Loss: 0.10684158653020859\n",
            "Validation Loss: 0.08325664699077606\n",
            "\n",
            "Epoch 320/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1068 - val_loss: 0.0830\n",
            "Loss: 0.10679662227630615\n",
            "Validation Loss: 0.08302322030067444\n",
            "\n",
            "Epoch 321/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1068 - val_loss: 0.0824\n",
            "Loss: 0.10677631944417953\n",
            "Validation Loss: 0.08243843913078308\n",
            "\n",
            "Epoch 322/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1066 - val_loss: 0.0825\n",
            "Loss: 0.10664291679859161\n",
            "Validation Loss: 0.08246476948261261\n",
            "\n",
            "Epoch 323/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1070 - val_loss: 0.0821\n",
            "Loss: 0.1070161834359169\n",
            "Validation Loss: 0.08213519304990768\n",
            "\n",
            "Epoch 324/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1081 - val_loss: 0.0822\n",
            "Loss: 0.10814749449491501\n",
            "Validation Loss: 0.08222639560699463\n",
            "\n",
            "Epoch 325/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1060 - val_loss: 0.0810\n",
            "Loss: 0.10600022226572037\n",
            "Validation Loss: 0.08102331310510635\n",
            "\n",
            "Epoch 326/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1078 - val_loss: 0.0808\n",
            "Loss: 0.10781344026327133\n",
            "Validation Loss: 0.08084723353385925\n",
            "\n",
            "Epoch 327/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1069 - val_loss: 0.0831\n",
            "Loss: 0.10692577064037323\n",
            "Validation Loss: 0.08311250060796738\n",
            "\n",
            "Epoch 328/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1065 - val_loss: 0.0830\n",
            "Loss: 0.10653548687696457\n",
            "Validation Loss: 0.0829664021730423\n",
            "\n",
            "Epoch 329/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1064 - val_loss: 0.0829\n",
            "Loss: 0.10638492554426193\n",
            "Validation Loss: 0.08290194720029831\n",
            "\n",
            "Epoch 330/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1064 - val_loss: 0.0835\n",
            "Loss: 0.10641145706176758\n",
            "Validation Loss: 0.08349703252315521\n",
            "\n",
            "Epoch 331/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1068 - val_loss: 0.0814\n",
            "Loss: 0.10676084458827972\n",
            "Validation Loss: 0.08135532587766647\n",
            "\n",
            "Epoch 332/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1064 - val_loss: 0.0810\n",
            "Loss: 0.10640646517276764\n",
            "Validation Loss: 0.08101487159729004\n",
            "\n",
            "Epoch 333/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1067 - val_loss: 0.0818\n",
            "Loss: 0.10668882727622986\n",
            "Validation Loss: 0.08182085305452347\n",
            "\n",
            "Epoch 334/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1059 - val_loss: 0.0810\n",
            "Loss: 0.10593470185995102\n",
            "Validation Loss: 0.08101987093687057\n",
            "\n",
            "Epoch 335/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1063 - val_loss: 0.0818\n",
            "Loss: 0.10631369054317474\n",
            "Validation Loss: 0.08175535500049591\n",
            "\n",
            "Epoch 336/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1065 - val_loss: 0.0810\n",
            "Loss: 0.10647203773260117\n",
            "Validation Loss: 0.08095625042915344\n",
            "\n",
            "Epoch 337/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1061 - val_loss: 0.0814\n",
            "Loss: 0.10609514266252518\n",
            "Validation Loss: 0.08144969493150711\n",
            "\n",
            "Epoch 338/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1067 - val_loss: 0.0804\n",
            "Loss: 0.10668865591287613\n",
            "Validation Loss: 0.08039144426584244\n",
            "\n",
            "Epoch 339/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1061 - val_loss: 0.0839\n",
            "Loss: 0.1061016097664833\n",
            "Validation Loss: 0.08386893570423126\n",
            "\n",
            "Epoch 340/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1068 - val_loss: 0.0814\n",
            "Loss: 0.10680439323186874\n",
            "Validation Loss: 0.08139229565858841\n",
            "\n",
            "Epoch 341/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1060 - val_loss: 0.0806\n",
            "Loss: 0.10603513568639755\n",
            "Validation Loss: 0.08060157299041748\n",
            "\n",
            "Epoch 342/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1061 - val_loss: 0.0806\n",
            "Loss: 0.1061096042394638\n",
            "Validation Loss: 0.08059567958116531\n",
            "\n",
            "Epoch 343/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1063 - val_loss: 0.0828\n",
            "Loss: 0.10631211847066879\n",
            "Validation Loss: 0.08283389359712601\n",
            "\n",
            "Epoch 344/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1061 - val_loss: 0.0817\n",
            "Loss: 0.10613388568162918\n",
            "Validation Loss: 0.08169225603342056\n",
            "\n",
            "Epoch 345/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1064 - val_loss: 0.0804\n",
            "Loss: 0.10643064230680466\n",
            "Validation Loss: 0.08041121810674667\n",
            "\n",
            "Epoch 346/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1062 - val_loss: 0.0809\n",
            "Loss: 0.10618104040622711\n",
            "Validation Loss: 0.08085351437330246\n",
            "\n",
            "Epoch 347/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1071 - val_loss: 0.0830\n",
            "Loss: 0.10714931786060333\n",
            "Validation Loss: 0.08296039700508118\n",
            "\n",
            "Epoch 348/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1067 - val_loss: 0.0811\n",
            "Loss: 0.10667970776557922\n",
            "Validation Loss: 0.08107850700616837\n",
            "\n",
            "Epoch 349/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1060 - val_loss: 0.0828\n",
            "Loss: 0.10598534345626831\n",
            "Validation Loss: 0.08282416313886642\n",
            "\n",
            "Epoch 350/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1055 - val_loss: 0.0808\n",
            "Loss: 0.10552354156970978\n",
            "Validation Loss: 0.08080662786960602\n",
            "\n",
            "Epoch 351/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1065 - val_loss: 0.0812\n",
            "Loss: 0.10645180195569992\n",
            "Validation Loss: 0.08116882294416428\n",
            "\n",
            "Epoch 352/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1058 - val_loss: 0.0814\n",
            "Loss: 0.1057550311088562\n",
            "Validation Loss: 0.08139088749885559\n",
            "\n",
            "Epoch 353/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1053 - val_loss: 0.0794\n",
            "Loss: 0.10525548458099365\n",
            "Validation Loss: 0.07944611459970474\n",
            "\n",
            "Epoch 354/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1059 - val_loss: 0.0814\n",
            "Loss: 0.10587099194526672\n",
            "Validation Loss: 0.08136513084173203\n",
            "\n",
            "Epoch 355/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1063 - val_loss: 0.0799\n",
            "Loss: 0.10629166662693024\n",
            "Validation Loss: 0.0798746645450592\n",
            "\n",
            "Epoch 356/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1057 - val_loss: 0.0822\n",
            "Loss: 0.10567275434732437\n",
            "Validation Loss: 0.0821654424071312\n",
            "\n",
            "Epoch 357/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1053 - val_loss: 0.0811\n",
            "Loss: 0.10525835305452347\n",
            "Validation Loss: 0.08110809326171875\n",
            "\n",
            "Epoch 358/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1059 - val_loss: 0.0799\n",
            "Loss: 0.10587051510810852\n",
            "Validation Loss: 0.07994101196527481\n",
            "\n",
            "Epoch 359/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1056 - val_loss: 0.0831\n",
            "Loss: 0.10562926530838013\n",
            "Validation Loss: 0.08308938890695572\n",
            "\n",
            "Epoch 360/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1057 - val_loss: 0.0801\n",
            "Loss: 0.10567637532949448\n",
            "Validation Loss: 0.08011908084154129\n",
            "\n",
            "Epoch 361/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1053 - val_loss: 0.0840\n",
            "Loss: 0.10533027350902557\n",
            "Validation Loss: 0.08400391787290573\n",
            "\n",
            "Epoch 362/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1060 - val_loss: 0.0813\n",
            "Loss: 0.105972521007061\n",
            "Validation Loss: 0.08134815096855164\n",
            "\n",
            "Epoch 363/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1056 - val_loss: 0.0821\n",
            "Loss: 0.10563516616821289\n",
            "Validation Loss: 0.08214341104030609\n",
            "\n",
            "Epoch 364/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1057 - val_loss: 0.0816\n",
            "Loss: 0.10568985342979431\n",
            "Validation Loss: 0.08155590295791626\n",
            "\n",
            "Epoch 365/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1049 - val_loss: 0.0827\n",
            "Loss: 0.1049191877245903\n",
            "Validation Loss: 0.08272324502468109\n",
            "\n",
            "Epoch 366/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1058 - val_loss: 0.0826\n",
            "Loss: 0.10583561658859253\n",
            "Validation Loss: 0.08259892463684082\n",
            "\n",
            "Epoch 367/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1054 - val_loss: 0.0809\n",
            "Loss: 0.10537806898355484\n",
            "Validation Loss: 0.08094675093889236\n",
            "\n",
            "Epoch 368/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1054 - val_loss: 0.0821\n",
            "Loss: 0.10542743653059006\n",
            "Validation Loss: 0.08209295570850372\n",
            "\n",
            "Epoch 369/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1063 - val_loss: 0.0797\n",
            "Loss: 0.10625189542770386\n",
            "Validation Loss: 0.07973922789096832\n",
            "\n",
            "Epoch 370/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1056 - val_loss: 0.0804\n",
            "Loss: 0.10557256639003754\n",
            "Validation Loss: 0.08035781979560852\n",
            "\n",
            "Epoch 371/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1053 - val_loss: 0.0798\n",
            "Loss: 0.1053345575928688\n",
            "Validation Loss: 0.07976110279560089\n",
            "\n",
            "Epoch 372/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1060 - val_loss: 0.0802\n",
            "Loss: 0.10597018897533417\n",
            "Validation Loss: 0.08017680794000626\n",
            "\n",
            "Epoch 373/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1051 - val_loss: 0.0822\n",
            "Loss: 0.10509374737739563\n",
            "Validation Loss: 0.08219527453184128\n",
            "\n",
            "Epoch 374/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1051 - val_loss: 0.0797\n",
            "Loss: 0.10511983931064606\n",
            "Validation Loss: 0.07968845963478088\n",
            "\n",
            "Epoch 375/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1049 - val_loss: 0.0815\n",
            "Loss: 0.10489775985479355\n",
            "Validation Loss: 0.08145497739315033\n",
            "\n",
            "Epoch 376/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1049 - val_loss: 0.0800\n",
            "Loss: 0.10485184192657471\n",
            "Validation Loss: 0.08003433048725128\n",
            "\n",
            "Epoch 377/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1045 - val_loss: 0.0811\n",
            "Loss: 0.10454156994819641\n",
            "Validation Loss: 0.08107849210500717\n",
            "\n",
            "Epoch 378/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1059 - val_loss: 0.0791\n",
            "Loss: 0.10587909817695618\n",
            "Validation Loss: 0.07905562967061996\n",
            "\n",
            "Epoch 379/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1048 - val_loss: 0.0806\n",
            "Loss: 0.10483759641647339\n",
            "Validation Loss: 0.08063995838165283\n",
            "\n",
            "Epoch 380/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1054 - val_loss: 0.0807\n",
            "Loss: 0.10535842180252075\n",
            "Validation Loss: 0.08071993291378021\n",
            "\n",
            "Epoch 381/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1053 - val_loss: 0.0792\n",
            "Loss: 0.10526765882968903\n",
            "Validation Loss: 0.07921965420246124\n",
            "\n",
            "Epoch 382/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1048 - val_loss: 0.0803\n",
            "Loss: 0.10484077036380768\n",
            "Validation Loss: 0.08029523491859436\n",
            "\n",
            "Epoch 383/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1048 - val_loss: 0.0790\n",
            "Loss: 0.1048155203461647\n",
            "Validation Loss: 0.07902912050485611\n",
            "\n",
            "Epoch 384/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1045 - val_loss: 0.0802\n",
            "Loss: 0.1044805720448494\n",
            "Validation Loss: 0.0801822692155838\n",
            "\n",
            "Epoch 385/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1050 - val_loss: 0.0815\n",
            "Loss: 0.10502105206251144\n",
            "Validation Loss: 0.08150749653577805\n",
            "\n",
            "Epoch 386/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1054 - val_loss: 0.0797\n",
            "Loss: 0.10543249547481537\n",
            "Validation Loss: 0.07974567264318466\n",
            "\n",
            "Epoch 387/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1049 - val_loss: 0.0811\n",
            "Loss: 0.10494142770767212\n",
            "Validation Loss: 0.08106742799282074\n",
            "\n",
            "Epoch 388/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1053 - val_loss: 0.0806\n",
            "Loss: 0.1053016185760498\n",
            "Validation Loss: 0.0805838331580162\n",
            "\n",
            "Epoch 389/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1047 - val_loss: 0.0797\n",
            "Loss: 0.10473717004060745\n",
            "Validation Loss: 0.07967054098844528\n",
            "\n",
            "Epoch 390/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1057 - val_loss: 0.0820\n",
            "Loss: 0.10566074401140213\n",
            "Validation Loss: 0.08201708644628525\n",
            "\n",
            "Epoch 391/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1041 - val_loss: 0.0787\n",
            "Loss: 0.10405418276786804\n",
            "Validation Loss: 0.07868798822164536\n",
            "\n",
            "Epoch 392/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1043 - val_loss: 0.0790\n",
            "Loss: 0.10433339327573776\n",
            "Validation Loss: 0.07901597023010254\n",
            "\n",
            "Epoch 393/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1049 - val_loss: 0.0786\n",
            "Loss: 0.10487999022006989\n",
            "Validation Loss: 0.07864508032798767\n",
            "\n",
            "Epoch 394/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1057 - val_loss: 0.0799\n",
            "Loss: 0.10569029301404953\n",
            "Validation Loss: 0.07988953590393066\n",
            "\n",
            "Epoch 395/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1046 - val_loss: 0.0799\n",
            "Loss: 0.10455971956253052\n",
            "Validation Loss: 0.07985790818929672\n",
            "\n",
            "Epoch 396/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1049 - val_loss: 0.0788\n",
            "Loss: 0.10490207374095917\n",
            "Validation Loss: 0.07880658656358719\n",
            "\n",
            "Epoch 397/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1051 - val_loss: 0.0801\n",
            "Loss: 0.10507304966449738\n",
            "Validation Loss: 0.08012989163398743\n",
            "\n",
            "Epoch 398/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1043 - val_loss: 0.0787\n",
            "Loss: 0.10427530854940414\n",
            "Validation Loss: 0.07869963347911835\n",
            "\n",
            "Epoch 399/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1052 - val_loss: 0.0802\n",
            "Loss: 0.10515641421079636\n",
            "Validation Loss: 0.08023440092802048\n",
            "\n",
            "Epoch 400/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1043 - val_loss: 0.0787\n",
            "Loss: 0.10425291210412979\n",
            "Validation Loss: 0.07870826870203018\n",
            "\n",
            "Epoch 401/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1051 - val_loss: 0.0788\n",
            "Loss: 0.10508165508508682\n",
            "Validation Loss: 0.0788111761212349\n",
            "\n",
            "Epoch 402/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1040 - val_loss: 0.0794\n",
            "Loss: 0.10403592884540558\n",
            "Validation Loss: 0.07938140630722046\n",
            "\n",
            "Epoch 403/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1041 - val_loss: 0.0785\n",
            "Loss: 0.10408976674079895\n",
            "Validation Loss: 0.07846240699291229\n",
            "\n",
            "Epoch 404/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1043 - val_loss: 0.0789\n",
            "Loss: 0.10434707254171371\n",
            "Validation Loss: 0.07885764539241791\n",
            "\n",
            "Epoch 405/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1048 - val_loss: 0.0795\n",
            "Loss: 0.1047823429107666\n",
            "Validation Loss: 0.07946714758872986\n",
            "\n",
            "Epoch 406/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1049 - val_loss: 0.0793\n",
            "Loss: 0.10489536821842194\n",
            "Validation Loss: 0.07929843664169312\n",
            "\n",
            "Epoch 407/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1044 - val_loss: 0.0806\n",
            "Loss: 0.10444598644971848\n",
            "Validation Loss: 0.08062312006950378\n",
            "\n",
            "Epoch 408/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1042 - val_loss: 0.0792\n",
            "Loss: 0.10418573766946793\n",
            "Validation Loss: 0.07922987639904022\n",
            "\n",
            "Epoch 409/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1041 - val_loss: 0.0795\n",
            "Loss: 0.10408784449100494\n",
            "Validation Loss: 0.07951315492391586\n",
            "\n",
            "Epoch 410/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1039 - val_loss: 0.0800\n",
            "Loss: 0.10387273132801056\n",
            "Validation Loss: 0.07996772229671478\n",
            "\n",
            "Epoch 411/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1043 - val_loss: 0.0789\n",
            "Loss: 0.10427284240722656\n",
            "Validation Loss: 0.07891824841499329\n",
            "\n",
            "Epoch 412/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1034 - val_loss: 0.0783\n",
            "Loss: 0.10337772220373154\n",
            "Validation Loss: 0.07834433019161224\n",
            "\n",
            "Epoch 413/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1041 - val_loss: 0.0803\n",
            "Loss: 0.10405885428190231\n",
            "Validation Loss: 0.08034587651491165\n",
            "\n",
            "Epoch 414/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1040 - val_loss: 0.0810\n",
            "Loss: 0.10404456406831741\n",
            "Validation Loss: 0.08097001165151596\n",
            "\n",
            "Epoch 415/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1042 - val_loss: 0.0785\n",
            "Loss: 0.10419990122318268\n",
            "Validation Loss: 0.07845042645931244\n",
            "\n",
            "Epoch 416/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1042 - val_loss: 0.0794\n",
            "Loss: 0.10423333942890167\n",
            "Validation Loss: 0.07939977943897247\n",
            "\n",
            "Epoch 417/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1046 - val_loss: 0.0816\n",
            "Loss: 0.10462551563978195\n",
            "Validation Loss: 0.08155984431505203\n",
            "\n",
            "Epoch 418/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1042 - val_loss: 0.0805\n",
            "Loss: 0.10421954095363617\n",
            "Validation Loss: 0.08048521727323532\n",
            "\n",
            "Epoch 419/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1050 - val_loss: 0.0795\n",
            "Loss: 0.10498702526092529\n",
            "Validation Loss: 0.07954791933298111\n",
            "\n",
            "Epoch 420/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1032 - val_loss: 0.0785\n",
            "Loss: 0.10316801071166992\n",
            "Validation Loss: 0.07847167551517487\n",
            "\n",
            "Epoch 421/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1051 - val_loss: 0.0792\n",
            "Loss: 0.10513684153556824\n",
            "Validation Loss: 0.0792032927274704\n",
            "\n",
            "Epoch 422/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1045 - val_loss: 0.0799\n",
            "Loss: 0.1045117974281311\n",
            "Validation Loss: 0.07989437133073807\n",
            "\n",
            "Epoch 423/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1042 - val_loss: 0.0797\n",
            "Loss: 0.10416581481695175\n",
            "Validation Loss: 0.07965037971735\n",
            "\n",
            "Epoch 424/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1046 - val_loss: 0.0794\n",
            "Loss: 0.10455343872308731\n",
            "Validation Loss: 0.07937603443861008\n",
            "\n",
            "Epoch 425/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1041 - val_loss: 0.0781\n",
            "Loss: 0.10408183932304382\n",
            "Validation Loss: 0.07814445346593857\n",
            "\n",
            "Epoch 426/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1031 - val_loss: 0.0789\n",
            "Loss: 0.10313603281974792\n",
            "Validation Loss: 0.07892081886529922\n",
            "\n",
            "Epoch 427/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1037 - val_loss: 0.0788\n",
            "Loss: 0.10369119793176651\n",
            "Validation Loss: 0.07883700728416443\n",
            "\n",
            "Epoch 428/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1036 - val_loss: 0.0784\n",
            "Loss: 0.10360179841518402\n",
            "Validation Loss: 0.0783817395567894\n",
            "\n",
            "Epoch 429/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1036 - val_loss: 0.0795\n",
            "Loss: 0.10361731052398682\n",
            "Validation Loss: 0.07946512848138809\n",
            "\n",
            "Epoch 430/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1031 - val_loss: 0.0800\n",
            "Loss: 0.10305171459913254\n",
            "Validation Loss: 0.08000498265028\n",
            "\n",
            "Epoch 431/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1034 - val_loss: 0.0781\n",
            "Loss: 0.10336623340845108\n",
            "Validation Loss: 0.07811903208494186\n",
            "\n",
            "Epoch 432/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1043 - val_loss: 0.0791\n",
            "Loss: 0.10428787022829056\n",
            "Validation Loss: 0.07912682741880417\n",
            "\n",
            "Epoch 433/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1032 - val_loss: 0.0782\n",
            "Loss: 0.10315626114606857\n",
            "Validation Loss: 0.07823269069194794\n",
            "\n",
            "Epoch 434/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1032 - val_loss: 0.0784\n",
            "Loss: 0.10317546129226685\n",
            "Validation Loss: 0.07839944213628769\n",
            "\n",
            "Epoch 435/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1040 - val_loss: 0.0796\n",
            "Loss: 0.10401955246925354\n",
            "Validation Loss: 0.07959919422864914\n",
            "\n",
            "Epoch 436/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1037 - val_loss: 0.0804\n",
            "Loss: 0.10371267795562744\n",
            "Validation Loss: 0.08037281036376953\n",
            "\n",
            "Epoch 437/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1038 - val_loss: 0.0767\n",
            "Loss: 0.1038360670208931\n",
            "Validation Loss: 0.07669385522603989\n",
            "\n",
            "Epoch 438/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1032 - val_loss: 0.0792\n",
            "Loss: 0.10317593812942505\n",
            "Validation Loss: 0.07919825613498688\n",
            "\n",
            "Epoch 439/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1040 - val_loss: 0.0781\n",
            "Loss: 0.10395713150501251\n",
            "Validation Loss: 0.07811951637268066\n",
            "\n",
            "Epoch 440/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1038 - val_loss: 0.0782\n",
            "Loss: 0.10377991944551468\n",
            "Validation Loss: 0.07816337794065475\n",
            "\n",
            "Epoch 441/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1036 - val_loss: 0.0795\n",
            "Loss: 0.10358870029449463\n",
            "Validation Loss: 0.07950662821531296\n",
            "\n",
            "Epoch 442/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1035 - val_loss: 0.0797\n",
            "Loss: 0.10346928983926773\n",
            "Validation Loss: 0.07965216785669327\n",
            "\n",
            "Epoch 443/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1035 - val_loss: 0.0776\n",
            "Loss: 0.10350847989320755\n",
            "Validation Loss: 0.07759646326303482\n",
            "\n",
            "Epoch 444/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1034 - val_loss: 0.0785\n",
            "Loss: 0.10343310236930847\n",
            "Validation Loss: 0.07854198664426804\n",
            "\n",
            "Epoch 445/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1033 - val_loss: 0.0782\n",
            "Loss: 0.10326538980007172\n",
            "Validation Loss: 0.07817477732896805\n",
            "\n",
            "Epoch 446/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1035 - val_loss: 0.0791\n",
            "Loss: 0.103543721139431\n",
            "Validation Loss: 0.07909982651472092\n",
            "\n",
            "Epoch 447/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1029 - val_loss: 0.0775\n",
            "Loss: 0.10292509198188782\n",
            "Validation Loss: 0.07750523835420609\n",
            "\n",
            "Epoch 448/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1033 - val_loss: 0.0784\n",
            "Loss: 0.1032755970954895\n",
            "Validation Loss: 0.0784248411655426\n",
            "\n",
            "Epoch 449/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1043 - val_loss: 0.0778\n",
            "Loss: 0.10431580245494843\n",
            "Validation Loss: 0.0778309777379036\n",
            "\n",
            "Epoch 450/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1036 - val_loss: 0.0795\n",
            "Loss: 0.10356353968381882\n",
            "Validation Loss: 0.07953866571187973\n",
            "\n",
            "Epoch 451/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1032 - val_loss: 0.0791\n",
            "Loss: 0.10315986722707748\n",
            "Validation Loss: 0.07912050187587738\n",
            "\n",
            "Epoch 452/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1036 - val_loss: 0.0785\n",
            "Loss: 0.10362747311592102\n",
            "Validation Loss: 0.07847891747951508\n",
            "\n",
            "Epoch 453/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1028 - val_loss: 0.0778\n",
            "Loss: 0.10282082855701447\n",
            "Validation Loss: 0.07780534029006958\n",
            "\n",
            "Epoch 454/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1028 - val_loss: 0.0788\n",
            "Loss: 0.10275616496801376\n",
            "Validation Loss: 0.07882580161094666\n",
            "\n",
            "Epoch 455/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1033 - val_loss: 0.0792\n",
            "Loss: 0.10325531661510468\n",
            "Validation Loss: 0.0792127177119255\n",
            "\n",
            "Epoch 456/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1036 - val_loss: 0.0763\n",
            "Loss: 0.10362817347049713\n",
            "Validation Loss: 0.07633085548877716\n",
            "\n",
            "Epoch 457/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1029 - val_loss: 0.0793\n",
            "Loss: 0.1029144898056984\n",
            "Validation Loss: 0.07926959544420242\n",
            "\n",
            "Epoch 458/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1033 - val_loss: 0.0792\n",
            "Loss: 0.10325921326875687\n",
            "Validation Loss: 0.07918765395879745\n",
            "\n",
            "Epoch 459/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1027 - val_loss: 0.0796\n",
            "Loss: 0.10270706564188004\n",
            "Validation Loss: 0.07963474839925766\n",
            "\n",
            "Epoch 460/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1024 - val_loss: 0.0787\n",
            "Loss: 0.10240711271762848\n",
            "Validation Loss: 0.07868155092000961\n",
            "\n",
            "Epoch 461/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1034 - val_loss: 0.0792\n",
            "Loss: 0.10337277501821518\n",
            "Validation Loss: 0.0791843831539154\n",
            "\n",
            "Epoch 462/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1023 - val_loss: 0.0795\n",
            "Loss: 0.10227816551923752\n",
            "Validation Loss: 0.0795346200466156\n",
            "\n",
            "Epoch 463/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1031 - val_loss: 0.0788\n",
            "Loss: 0.10306777060031891\n",
            "Validation Loss: 0.07883649319410324\n",
            "\n",
            "Epoch 464/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1035 - val_loss: 0.0783\n",
            "Loss: 0.1035006195306778\n",
            "Validation Loss: 0.07827864587306976\n",
            "\n",
            "Epoch 465/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1037 - val_loss: 0.0792\n",
            "Loss: 0.10365462303161621\n",
            "Validation Loss: 0.07919967919588089\n",
            "\n",
            "Epoch 466/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1030 - val_loss: 0.0778\n",
            "Loss: 0.10301969200372696\n",
            "Validation Loss: 0.07784529030323029\n",
            "\n",
            "Epoch 467/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1030 - val_loss: 0.0793\n",
            "Loss: 0.10296355932950974\n",
            "Validation Loss: 0.0793367475271225\n",
            "\n",
            "Epoch 468/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1033 - val_loss: 0.0781\n",
            "Loss: 0.10332531481981277\n",
            "Validation Loss: 0.07807058095932007\n",
            "\n",
            "Epoch 469/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1029 - val_loss: 0.0788\n",
            "Loss: 0.10292333364486694\n",
            "Validation Loss: 0.07876637578010559\n",
            "\n",
            "Epoch 470/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1022 - val_loss: 0.0782\n",
            "Loss: 0.1022002324461937\n",
            "Validation Loss: 0.07824093848466873\n",
            "\n",
            "Epoch 471/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1027 - val_loss: 0.0785\n",
            "Loss: 0.10269304364919662\n",
            "Validation Loss: 0.07850261777639389\n",
            "\n",
            "Epoch 472/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1036 - val_loss: 0.0789\n",
            "Loss: 0.10361635684967041\n",
            "Validation Loss: 0.07886699587106705\n",
            "\n",
            "Epoch 473/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1030 - val_loss: 0.0781\n",
            "Loss: 0.10295860469341278\n",
            "Validation Loss: 0.07810690253973007\n",
            "\n",
            "Epoch 474/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1032 - val_loss: 0.0803\n",
            "Loss: 0.10317196696996689\n",
            "Validation Loss: 0.08031401038169861\n",
            "\n",
            "Epoch 475/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1028 - val_loss: 0.0796\n",
            "Loss: 0.10275138914585114\n",
            "Validation Loss: 0.07957158237695694\n",
            "\n",
            "Epoch 476/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1030 - val_loss: 0.0789\n",
            "Loss: 0.10300148278474808\n",
            "Validation Loss: 0.07885755598545074\n",
            "\n",
            "Epoch 477/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1029 - val_loss: 0.0787\n",
            "Loss: 0.10293035954236984\n",
            "Validation Loss: 0.07869691401720047\n",
            "\n",
            "Epoch 478/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1031 - val_loss: 0.0773\n",
            "Loss: 0.10307849943637848\n",
            "Validation Loss: 0.07734755426645279\n",
            "\n",
            "Epoch 479/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1029 - val_loss: 0.0795\n",
            "Loss: 0.10291360318660736\n",
            "Validation Loss: 0.07951251417398453\n",
            "\n",
            "Epoch 480/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1027 - val_loss: 0.0780\n",
            "Loss: 0.1027221530675888\n",
            "Validation Loss: 0.07800257205963135\n",
            "\n",
            "Epoch 481/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1025 - val_loss: 0.0774\n",
            "Loss: 0.10253369063138962\n",
            "Validation Loss: 0.07739816606044769\n",
            "\n",
            "Epoch 482/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1028 - val_loss: 0.0786\n",
            "Loss: 0.10275875777006149\n",
            "Validation Loss: 0.07859394699335098\n",
            "\n",
            "Epoch 483/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1026 - val_loss: 0.0796\n",
            "Loss: 0.10262462496757507\n",
            "Validation Loss: 0.07958008348941803\n",
            "\n",
            "Epoch 484/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1035 - val_loss: 0.0768\n",
            "Loss: 0.10352487862110138\n",
            "Validation Loss: 0.07683511078357697\n",
            "\n",
            "Epoch 485/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1022 - val_loss: 0.0766\n",
            "Loss: 0.10217070579528809\n",
            "Validation Loss: 0.07664481550455093\n",
            "\n",
            "Epoch 486/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1025 - val_loss: 0.0787\n",
            "Loss: 0.10254723578691483\n",
            "Validation Loss: 0.07872924208641052\n",
            "\n",
            "Epoch 487/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1024 - val_loss: 0.0781\n",
            "Loss: 0.10241677612066269\n",
            "Validation Loss: 0.07807035744190216\n",
            "\n",
            "Epoch 488/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1025 - val_loss: 0.0792\n",
            "Loss: 0.10245209187269211\n",
            "Validation Loss: 0.07915515452623367\n",
            "\n",
            "Epoch 489/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1027 - val_loss: 0.0788\n",
            "Loss: 0.10270529240369797\n",
            "Validation Loss: 0.07881303876638412\n",
            "\n",
            "Epoch 490/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1030 - val_loss: 0.0801\n",
            "Loss: 0.10299459099769592\n",
            "Validation Loss: 0.08014756441116333\n",
            "\n",
            "Epoch 491/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1028 - val_loss: 0.0781\n",
            "Loss: 0.10283086448907852\n",
            "Validation Loss: 0.0780518427491188\n",
            "\n",
            "Epoch 492/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1020 - val_loss: 0.0787\n",
            "Loss: 0.10201296210289001\n",
            "Validation Loss: 0.07873352617025375\n",
            "\n",
            "Epoch 493/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1022 - val_loss: 0.0767\n",
            "Loss: 0.10221842676401138\n",
            "Validation Loss: 0.07671979814767838\n",
            "\n",
            "Epoch 494/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1029 - val_loss: 0.0777\n",
            "Loss: 0.10285406559705734\n",
            "Validation Loss: 0.07766968011856079\n",
            "\n",
            "Epoch 495/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1027 - val_loss: 0.0787\n",
            "Loss: 0.10269395262002945\n",
            "Validation Loss: 0.07869486510753632\n",
            "\n",
            "Epoch 496/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1029 - val_loss: 0.0775\n",
            "Loss: 0.10294761508703232\n",
            "Validation Loss: 0.07747416943311691\n",
            "\n",
            "Epoch 497/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1026 - val_loss: 0.0785\n",
            "Loss: 0.10260365158319473\n",
            "Validation Loss: 0.0784984827041626\n",
            "\n",
            "Epoch 498/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1024 - val_loss: 0.0787\n",
            "Loss: 0.10242723673582077\n",
            "Validation Loss: 0.07865669578313828\n",
            "\n",
            "Epoch 499/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1029 - val_loss: 0.0779\n",
            "Loss: 0.10288495570421219\n",
            "Validation Loss: 0.07790511101484299\n",
            "\n",
            "Epoch 500/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1023 - val_loss: 0.0784\n",
            "Loss: 0.10234267264604568\n",
            "Validation Loss: 0.078409843146801\n",
            "\n",
            "Epoch 501/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1023 - val_loss: 0.0762\n",
            "Loss: 0.10229174047708511\n",
            "Validation Loss: 0.07615258544683456\n",
            "\n",
            "Epoch 502/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1024 - val_loss: 0.0782\n",
            "Loss: 0.10240712761878967\n",
            "Validation Loss: 0.07819309830665588\n",
            "\n",
            "Epoch 503/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1021 - val_loss: 0.0768\n",
            "Loss: 0.10212629288434982\n",
            "Validation Loss: 0.07681484520435333\n",
            "\n",
            "Epoch 504/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1024 - val_loss: 0.0775\n",
            "Loss: 0.10239481180906296\n",
            "Validation Loss: 0.07747558504343033\n",
            "\n",
            "Epoch 505/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1019 - val_loss: 0.0767\n",
            "Loss: 0.10194726288318634\n",
            "Validation Loss: 0.07665597647428513\n",
            "\n",
            "Epoch 506/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1019 - val_loss: 0.0769\n",
            "Loss: 0.10185059159994125\n",
            "Validation Loss: 0.07688874006271362\n",
            "\n",
            "Epoch 507/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1018 - val_loss: 0.0782\n",
            "Loss: 0.10176710039377213\n",
            "Validation Loss: 0.07820359617471695\n",
            "\n",
            "Epoch 508/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1020 - val_loss: 0.0787\n",
            "Loss: 0.10202653706073761\n",
            "Validation Loss: 0.07866937667131424\n",
            "\n",
            "Epoch 509/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1025 - val_loss: 0.0794\n",
            "Loss: 0.10252082347869873\n",
            "Validation Loss: 0.07940538972616196\n",
            "\n",
            "Epoch 510/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1020 - val_loss: 0.0786\n",
            "Loss: 0.10198718309402466\n",
            "Validation Loss: 0.07860911637544632\n",
            "\n",
            "Epoch 511/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1019 - val_loss: 0.0782\n",
            "Loss: 0.10185755044221878\n",
            "Validation Loss: 0.07822133600711823\n",
            "\n",
            "Epoch 512/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1020 - val_loss: 0.0783\n",
            "Loss: 0.10204876214265823\n",
            "Validation Loss: 0.07832607626914978\n",
            "\n",
            "Epoch 513/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1026 - val_loss: 0.0773\n",
            "Loss: 0.10257832705974579\n",
            "Validation Loss: 0.07733616232872009\n",
            "\n",
            "Epoch 514/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1018 - val_loss: 0.0770\n",
            "Loss: 0.1017640009522438\n",
            "Validation Loss: 0.07704022526741028\n",
            "\n",
            "Epoch 515/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1016 - val_loss: 0.0786\n",
            "Loss: 0.10163713991641998\n",
            "Validation Loss: 0.0786130279302597\n",
            "\n",
            "Epoch 516/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1022 - val_loss: 0.0781\n",
            "Loss: 0.10223884880542755\n",
            "Validation Loss: 0.07813386619091034\n",
            "\n",
            "Epoch 517/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1018 - val_loss: 0.0779\n",
            "Loss: 0.10182040929794312\n",
            "Validation Loss: 0.07792466133832932\n",
            "\n",
            "Epoch 518/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1019 - val_loss: 0.0780\n",
            "Loss: 0.10189194977283478\n",
            "Validation Loss: 0.07802364975214005\n",
            "\n",
            "Epoch 519/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1022 - val_loss: 0.0773\n",
            "Loss: 0.10217384248971939\n",
            "Validation Loss: 0.07731110602617264\n",
            "\n",
            "Epoch 520/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1017 - val_loss: 0.0777\n",
            "Loss: 0.1016705259680748\n",
            "Validation Loss: 0.07768642157316208\n",
            "\n",
            "Epoch 521/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1020 - val_loss: 0.0779\n",
            "Loss: 0.10200893878936768\n",
            "Validation Loss: 0.07790551334619522\n",
            "\n",
            "Epoch 522/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1021 - val_loss: 0.0779\n",
            "Loss: 0.10210020840167999\n",
            "Validation Loss: 0.07786322385072708\n",
            "\n",
            "Epoch 523/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1019 - val_loss: 0.0769\n",
            "Loss: 0.1018657311797142\n",
            "Validation Loss: 0.07694852352142334\n",
            "\n",
            "Epoch 524/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1011 - val_loss: 0.0768\n",
            "Loss: 0.10110650956630707\n",
            "Validation Loss: 0.07679235935211182\n",
            "\n",
            "Epoch 525/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1017 - val_loss: 0.0776\n",
            "Loss: 0.10172167420387268\n",
            "Validation Loss: 0.07758894562721252\n",
            "\n",
            "Epoch 526/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1018 - val_loss: 0.0779\n",
            "Loss: 0.10179003328084946\n",
            "Validation Loss: 0.0778956338763237\n",
            "\n",
            "Epoch 527/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1016 - val_loss: 0.0768\n",
            "Loss: 0.10162130743265152\n",
            "Validation Loss: 0.076765276491642\n",
            "\n",
            "Epoch 528/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1017 - val_loss: 0.0784\n",
            "Loss: 0.10167162865400314\n",
            "Validation Loss: 0.07835416495800018\n",
            "\n",
            "Epoch 529/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1014 - val_loss: 0.0784\n",
            "Loss: 0.10143785178661346\n",
            "Validation Loss: 0.0784454420208931\n",
            "\n",
            "Epoch 530/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1015 - val_loss: 0.0785\n",
            "Loss: 0.10152637213468552\n",
            "Validation Loss: 0.07846011221408844\n",
            "\n",
            "Epoch 531/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1015 - val_loss: 0.0797\n",
            "Loss: 0.1015419289469719\n",
            "Validation Loss: 0.07966773211956024\n",
            "\n",
            "Epoch 532/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1019 - val_loss: 0.0775\n",
            "Loss: 0.10192613303661346\n",
            "Validation Loss: 0.07754025608301163\n",
            "\n",
            "Epoch 533/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1016 - val_loss: 0.0765\n",
            "Loss: 0.10162872821092606\n",
            "Validation Loss: 0.0764756128191948\n",
            "\n",
            "Epoch 534/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1014 - val_loss: 0.0784\n",
            "Loss: 0.10139017552137375\n",
            "Validation Loss: 0.07842756062746048\n",
            "\n",
            "Epoch 535/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1009 - val_loss: 0.0785\n",
            "Loss: 0.10094593465328217\n",
            "Validation Loss: 0.07854162901639938\n",
            "\n",
            "Epoch 536/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1013 - val_loss: 0.0778\n",
            "Loss: 0.10128659754991531\n",
            "Validation Loss: 0.07775890827178955\n",
            "\n",
            "Epoch 537/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1015 - val_loss: 0.0779\n",
            "Loss: 0.10154040902853012\n",
            "Validation Loss: 0.07788818329572678\n",
            "\n",
            "Epoch 538/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1014 - val_loss: 0.0775\n",
            "Loss: 0.10140445083379745\n",
            "Validation Loss: 0.07750263065099716\n",
            "\n",
            "Epoch 539/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1022 - val_loss: 0.0765\n",
            "Loss: 0.10223271697759628\n",
            "Validation Loss: 0.07647848129272461\n",
            "\n",
            "Epoch 540/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1014 - val_loss: 0.0771\n",
            "Loss: 0.10142005234956741\n",
            "Validation Loss: 0.07710140198469162\n",
            "\n",
            "Epoch 541/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1011 - val_loss: 0.0770\n",
            "Loss: 0.10114072263240814\n",
            "Validation Loss: 0.07699255645275116\n",
            "\n",
            "Epoch 542/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1011 - val_loss: 0.0783\n",
            "Loss: 0.10106536000967026\n",
            "Validation Loss: 0.07827866822481155\n",
            "\n",
            "Epoch 543/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1015 - val_loss: 0.0774\n",
            "Loss: 0.10148690640926361\n",
            "Validation Loss: 0.07742666453123093\n",
            "\n",
            "Epoch 544/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1012 - val_loss: 0.0767\n",
            "Loss: 0.1012144386768341\n",
            "Validation Loss: 0.07668599486351013\n",
            "\n",
            "Epoch 545/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1012 - val_loss: 0.0766\n",
            "Loss: 0.10120811313390732\n",
            "Validation Loss: 0.07658050954341888\n",
            "\n",
            "Epoch 546/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1011 - val_loss: 0.0784\n",
            "Loss: 0.10108977556228638\n",
            "Validation Loss: 0.07840254157781601\n",
            "\n",
            "Epoch 547/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1013 - val_loss: 0.0759\n",
            "Loss: 0.10128956288099289\n",
            "Validation Loss: 0.07588709890842438\n",
            "\n",
            "Epoch 548/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1011 - val_loss: 0.0767\n",
            "Loss: 0.10110785812139511\n",
            "Validation Loss: 0.07668349891901016\n",
            "\n",
            "Epoch 549/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1011 - val_loss: 0.0763\n",
            "Loss: 0.10110747814178467\n",
            "Validation Loss: 0.0763358473777771\n",
            "\n",
            "Epoch 550/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1016 - val_loss: 0.0785\n",
            "Loss: 0.10160936415195465\n",
            "Validation Loss: 0.0785108357667923\n",
            "\n",
            "Epoch 551/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1011 - val_loss: 0.0769\n",
            "Loss: 0.10107550024986267\n",
            "Validation Loss: 0.076869897544384\n",
            "\n",
            "Epoch 552/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1010 - val_loss: 0.0764\n",
            "Loss: 0.10097163170576096\n",
            "Validation Loss: 0.07636817544698715\n",
            "\n",
            "Epoch 553/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1013 - val_loss: 0.0754\n",
            "Loss: 0.10133855044841766\n",
            "Validation Loss: 0.07543827593326569\n",
            "\n",
            "Epoch 554/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1011 - val_loss: 0.0797\n",
            "Loss: 0.10109370201826096\n",
            "Validation Loss: 0.07967594265937805\n",
            "\n",
            "Epoch 555/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1012 - val_loss: 0.0760\n",
            "Loss: 0.10115320235490799\n",
            "Validation Loss: 0.07596390694379807\n",
            "\n",
            "Epoch 556/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1010 - val_loss: 0.0767\n",
            "Loss: 0.10097582638263702\n",
            "Validation Loss: 0.07665903866291046\n",
            "\n",
            "Epoch 557/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1016 - val_loss: 0.0779\n",
            "Loss: 0.10159258544445038\n",
            "Validation Loss: 0.07793047279119492\n",
            "\n",
            "Epoch 558/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1020 - val_loss: 0.0764\n",
            "Loss: 0.10202761739492416\n",
            "Validation Loss: 0.07639738917350769\n",
            "\n",
            "Epoch 559/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1010 - val_loss: 0.0774\n",
            "Loss: 0.10102822631597519\n",
            "Validation Loss: 0.07737661898136139\n",
            "\n",
            "Epoch 560/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1007 - val_loss: 0.0781\n",
            "Loss: 0.10067606717348099\n",
            "Validation Loss: 0.0781007930636406\n",
            "\n",
            "Epoch 561/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1009 - val_loss: 0.0767\n",
            "Loss: 0.10089736431837082\n",
            "Validation Loss: 0.07667829841375351\n",
            "\n",
            "Epoch 562/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1016 - val_loss: 0.0769\n",
            "Loss: 0.10157809406518936\n",
            "Validation Loss: 0.07685771584510803\n",
            "\n",
            "Epoch 563/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1005 - val_loss: 0.0756\n",
            "Loss: 0.10051386058330536\n",
            "Validation Loss: 0.07558538019657135\n",
            "\n",
            "Epoch 564/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1010 - val_loss: 0.0774\n",
            "Loss: 0.10103986412286758\n",
            "Validation Loss: 0.07736831903457642\n",
            "\n",
            "Epoch 565/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1008 - val_loss: 0.0772\n",
            "Loss: 0.10076110064983368\n",
            "Validation Loss: 0.07720721513032913\n",
            "\n",
            "Epoch 566/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1008 - val_loss: 0.0771\n",
            "Loss: 0.10084206610918045\n",
            "Validation Loss: 0.0770883858203888\n",
            "\n",
            "Epoch 567/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1013 - val_loss: 0.0755\n",
            "Loss: 0.10131332278251648\n",
            "Validation Loss: 0.07554507255554199\n",
            "\n",
            "Epoch 568/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1010 - val_loss: 0.0777\n",
            "Loss: 0.10098756104707718\n",
            "Validation Loss: 0.07773537933826447\n",
            "\n",
            "Epoch 569/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1007 - val_loss: 0.0789\n",
            "Loss: 0.10071077197790146\n",
            "Validation Loss: 0.07890837639570236\n",
            "\n",
            "Epoch 570/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1010 - val_loss: 0.0762\n",
            "Loss: 0.1010199636220932\n",
            "Validation Loss: 0.07619365304708481\n",
            "\n",
            "Epoch 571/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1011 - val_loss: 0.0775\n",
            "Loss: 0.10107071697711945\n",
            "Validation Loss: 0.0774887353181839\n",
            "\n",
            "Epoch 572/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1014 - val_loss: 0.0767\n",
            "Loss: 0.10138355195522308\n",
            "Validation Loss: 0.07668598741292953\n",
            "\n",
            "Epoch 573/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1013 - val_loss: 0.0764\n",
            "Loss: 0.10133039206266403\n",
            "Validation Loss: 0.07635221630334854\n",
            "\n",
            "Epoch 574/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1014 - val_loss: 0.0767\n",
            "Loss: 0.10138043761253357\n",
            "Validation Loss: 0.0766579657793045\n",
            "\n",
            "Epoch 575/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1016 - val_loss: 0.0769\n",
            "Loss: 0.10155551880598068\n",
            "Validation Loss: 0.07690823823213577\n",
            "\n",
            "Epoch 576/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1014 - val_loss: 0.0776\n",
            "Loss: 0.10138360410928726\n",
            "Validation Loss: 0.07760334014892578\n",
            "\n",
            "Epoch 577/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1015 - val_loss: 0.0757\n",
            "Loss: 0.10148218274116516\n",
            "Validation Loss: 0.07571335881948471\n",
            "\n",
            "Epoch 578/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1010 - val_loss: 0.0766\n",
            "Loss: 0.10099095106124878\n",
            "Validation Loss: 0.07657036930322647\n",
            "\n",
            "Epoch 579/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1016 - val_loss: 0.0780\n",
            "Loss: 0.10159917175769806\n",
            "Validation Loss: 0.07797486335039139\n",
            "\n",
            "Epoch 580/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1008 - val_loss: 0.0774\n",
            "Loss: 0.10080257058143616\n",
            "Validation Loss: 0.0773954913020134\n",
            "\n",
            "Epoch 581/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1015 - val_loss: 0.0778\n",
            "Loss: 0.1015230193734169\n",
            "Validation Loss: 0.07781757414340973\n",
            "\n",
            "Epoch 582/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1004 - val_loss: 0.0763\n",
            "Loss: 0.10038217902183533\n",
            "Validation Loss: 0.07627519965171814\n",
            "\n",
            "Epoch 583/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1005 - val_loss: 0.0766\n",
            "Loss: 0.10049740225076675\n",
            "Validation Loss: 0.07662224024534225\n",
            "\n",
            "Epoch 584/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1010 - val_loss: 0.0771\n",
            "Loss: 0.1010432168841362\n",
            "Validation Loss: 0.07710536569356918\n",
            "\n",
            "Epoch 585/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1011 - val_loss: 0.0771\n",
            "Loss: 0.10114354640245438\n",
            "Validation Loss: 0.07710578292608261\n",
            "\n",
            "Epoch 586/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1012 - val_loss: 0.0773\n",
            "Loss: 0.10121241956949234\n",
            "Validation Loss: 0.0772528350353241\n",
            "\n",
            "Epoch 587/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1012 - val_loss: 0.0771\n",
            "Loss: 0.10116540640592575\n",
            "Validation Loss: 0.07711464911699295\n",
            "\n",
            "Epoch 588/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1008 - val_loss: 0.0766\n",
            "Loss: 0.10083064436912537\n",
            "Validation Loss: 0.07663501799106598\n",
            "\n",
            "Epoch 589/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1007 - val_loss: 0.0754\n",
            "Loss: 0.1006501242518425\n",
            "Validation Loss: 0.07536706328392029\n",
            "\n",
            "Epoch 590/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1007 - val_loss: 0.0770\n",
            "Loss: 0.10074664652347565\n",
            "Validation Loss: 0.07699050009250641\n",
            "\n",
            "Epoch 591/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1009 - val_loss: 0.0770\n",
            "Loss: 0.10085810720920563\n",
            "Validation Loss: 0.07699387520551682\n",
            "\n",
            "Epoch 592/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1010 - val_loss: 0.0771\n",
            "Loss: 0.10100745409727097\n",
            "Validation Loss: 0.0771409124135971\n",
            "\n",
            "Epoch 593/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1001 - val_loss: 0.0766\n",
            "Loss: 0.10006251931190491\n",
            "Validation Loss: 0.07658351957798004\n",
            "\n",
            "Epoch 594/750\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1005 - val_loss: 0.0765\n",
            "Loss: 0.10050486028194427\n",
            "Validation Loss: 0.07648629695177078\n",
            "\n",
            "Epoch 595/750\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1009 - val_loss: 0.0755\n",
            "Loss: 0.1008574366569519\n",
            "Validation Loss: 0.0755091980099678\n",
            "\n",
            "Epoch 596/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1005 - val_loss: 0.0778\n",
            "Loss: 0.1005418598651886\n",
            "Validation Loss: 0.0777788907289505\n",
            "\n",
            "Epoch 597/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1002 - val_loss: 0.0758\n",
            "Loss: 0.10021879523992538\n",
            "Validation Loss: 0.07584155350923538\n",
            "\n",
            "Epoch 598/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1011 - val_loss: 0.0778\n",
            "Loss: 0.10108684003353119\n",
            "Validation Loss: 0.07776544243097305\n",
            "\n",
            "Epoch 599/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0773\n",
            "Loss: 0.10042723268270493\n",
            "Validation Loss: 0.07727301865816116\n",
            "\n",
            "Epoch 600/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1012 - val_loss: 0.0754\n",
            "Loss: 0.10124662518501282\n",
            "Validation Loss: 0.07535689324140549\n",
            "\n",
            "Epoch 601/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1005 - val_loss: 0.0764\n",
            "Loss: 0.10052556544542313\n",
            "Validation Loss: 0.0764099508523941\n",
            "\n",
            "Epoch 602/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1015 - val_loss: 0.0763\n",
            "Loss: 0.10153233259916306\n",
            "Validation Loss: 0.0763302892446518\n",
            "\n",
            "Epoch 603/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1010 - val_loss: 0.0758\n",
            "Loss: 0.10096370428800583\n",
            "Validation Loss: 0.07580562680959702\n",
            "\n",
            "Epoch 604/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1009 - val_loss: 0.0759\n",
            "Loss: 0.10087042301893234\n",
            "Validation Loss: 0.07588181644678116\n",
            "\n",
            "Epoch 605/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0765\n",
            "Loss: 0.10040747374296188\n",
            "Validation Loss: 0.07653031498193741\n",
            "\n",
            "Epoch 606/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0763\n",
            "Loss: 0.10040568560361862\n",
            "Validation Loss: 0.07627841085195541\n",
            "\n",
            "Epoch 607/750\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.1011 - val_loss: 0.0756\n",
            "Loss: 0.10105996578931808\n",
            "Validation Loss: 0.07564429193735123\n",
            "\n",
            "Epoch 608/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1008 - val_loss: 0.0764\n",
            "Loss: 0.1007833406329155\n",
            "Validation Loss: 0.07642669230699539\n",
            "\n",
            "Epoch 609/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1001 - val_loss: 0.0751\n",
            "Loss: 0.10011182725429535\n",
            "Validation Loss: 0.07512243837118149\n",
            "\n",
            "Epoch 610/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1000 - val_loss: 0.0765\n",
            "Loss: 0.10002788156270981\n",
            "Validation Loss: 0.07652433961629868\n",
            "\n",
            "Epoch 611/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0764\n",
            "Loss: 0.10044384747743607\n",
            "Validation Loss: 0.07639136165380478\n",
            "\n",
            "Epoch 612/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1006 - val_loss: 0.0756\n",
            "Loss: 0.10062482208013535\n",
            "Validation Loss: 0.07558445632457733\n",
            "\n",
            "Epoch 613/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1002 - val_loss: 0.0758\n",
            "Loss: 0.10016883909702301\n",
            "Validation Loss: 0.07578229159116745\n",
            "\n",
            "Epoch 614/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0999 - val_loss: 0.0762\n",
            "Loss: 0.0998603031039238\n",
            "Validation Loss: 0.07617607712745667\n",
            "\n",
            "Epoch 615/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0997 - val_loss: 0.0766\n",
            "Loss: 0.09969788044691086\n",
            "Validation Loss: 0.0766274705529213\n",
            "\n",
            "Epoch 616/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1001 - val_loss: 0.0790\n",
            "Loss: 0.10013800114393234\n",
            "Validation Loss: 0.07901743054389954\n",
            "\n",
            "Epoch 617/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1005 - val_loss: 0.0770\n",
            "Loss: 0.10046937316656113\n",
            "Validation Loss: 0.07704263925552368\n",
            "\n",
            "Epoch 618/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1001 - val_loss: 0.0760\n",
            "Loss: 0.10011852532625198\n",
            "Validation Loss: 0.07595755159854889\n",
            "\n",
            "Epoch 619/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1007 - val_loss: 0.0767\n",
            "Loss: 0.10073977708816528\n",
            "Validation Loss: 0.07667431235313416\n",
            "\n",
            "Epoch 620/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1005 - val_loss: 0.0765\n",
            "Loss: 0.10045202076435089\n",
            "Validation Loss: 0.07654927670955658\n",
            "\n",
            "Epoch 621/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1002 - val_loss: 0.0762\n",
            "Loss: 0.10018376260995865\n",
            "Validation Loss: 0.07622315734624863\n",
            "\n",
            "Epoch 622/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1008 - val_loss: 0.0784\n",
            "Loss: 0.10084911435842514\n",
            "Validation Loss: 0.07838478684425354\n",
            "\n",
            "Epoch 623/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1005 - val_loss: 0.0767\n",
            "Loss: 0.10052941739559174\n",
            "Validation Loss: 0.07666711509227753\n",
            "\n",
            "Epoch 624/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1005 - val_loss: 0.0760\n",
            "Loss: 0.10050684213638306\n",
            "Validation Loss: 0.07598529011011124\n",
            "\n",
            "Epoch 625/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1002 - val_loss: 0.0763\n",
            "Loss: 0.10022840648889542\n",
            "Validation Loss: 0.07634659856557846\n",
            "\n",
            "Epoch 626/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1000 - val_loss: 0.0776\n",
            "Loss: 0.09998536854982376\n",
            "Validation Loss: 0.07757839560508728\n",
            "\n",
            "Epoch 627/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0998 - val_loss: 0.0761\n",
            "Loss: 0.09982001781463623\n",
            "Validation Loss: 0.07611443847417831\n",
            "\n",
            "Epoch 628/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1000 - val_loss: 0.0798\n",
            "Loss: 0.09998808056116104\n",
            "Validation Loss: 0.07983168959617615\n",
            "\n",
            "Epoch 629/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0997 - val_loss: 0.0752\n",
            "Loss: 0.09966083616018295\n",
            "Validation Loss: 0.07522988319396973\n",
            "\n",
            "Epoch 630/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1002 - val_loss: 0.0767\n",
            "Loss: 0.10016188770532608\n",
            "Validation Loss: 0.07674887031316757\n",
            "\n",
            "Epoch 631/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0998 - val_loss: 0.0756\n",
            "Loss: 0.09984910488128662\n",
            "Validation Loss: 0.07559284567832947\n",
            "\n",
            "Epoch 632/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0997 - val_loss: 0.0758\n",
            "Loss: 0.0997130498290062\n",
            "Validation Loss: 0.07575856894254684\n",
            "\n",
            "Epoch 633/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1001 - val_loss: 0.0764\n",
            "Loss: 0.10013793408870697\n",
            "Validation Loss: 0.07636260986328125\n",
            "\n",
            "Epoch 634/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1010 - val_loss: 0.0760\n",
            "Loss: 0.10096675902605057\n",
            "Validation Loss: 0.07597161829471588\n",
            "\n",
            "Epoch 635/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1009 - val_loss: 0.0761\n",
            "Loss: 0.10085560381412506\n",
            "Validation Loss: 0.07613503932952881\n",
            "\n",
            "Epoch 636/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1004 - val_loss: 0.0776\n",
            "Loss: 0.10042059421539307\n",
            "Validation Loss: 0.07762925326824188\n",
            "\n",
            "Epoch 637/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1003 - val_loss: 0.0777\n",
            "Loss: 0.1002742350101471\n",
            "Validation Loss: 0.07773067057132721\n",
            "\n",
            "Epoch 638/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0998 - val_loss: 0.0764\n",
            "Loss: 0.09976843744516373\n",
            "Validation Loss: 0.07638484984636307\n",
            "\n",
            "Epoch 639/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1006 - val_loss: 0.0761\n",
            "Loss: 0.10060332715511322\n",
            "Validation Loss: 0.07612961530685425\n",
            "\n",
            "Epoch 640/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1001 - val_loss: 0.0760\n",
            "Loss: 0.10006736218929291\n",
            "Validation Loss: 0.07600840926170349\n",
            "\n",
            "Epoch 641/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1007 - val_loss: 0.0758\n",
            "Loss: 0.10069392621517181\n",
            "Validation Loss: 0.07584535330533981\n",
            "\n",
            "Epoch 642/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1005 - val_loss: 0.0769\n",
            "Loss: 0.10047819465398788\n",
            "Validation Loss: 0.07693216949701309\n",
            "\n",
            "Epoch 643/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0998 - val_loss: 0.0751\n",
            "Loss: 0.09975448995828629\n",
            "Validation Loss: 0.07507602870464325\n",
            "\n",
            "Epoch 644/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0997 - val_loss: 0.0760\n",
            "Loss: 0.09972809255123138\n",
            "Validation Loss: 0.07603897154331207\n",
            "\n",
            "Epoch 645/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1001 - val_loss: 0.0765\n",
            "Loss: 0.1001303493976593\n",
            "Validation Loss: 0.07652416080236435\n",
            "\n",
            "Epoch 646/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1002 - val_loss: 0.0764\n",
            "Loss: 0.10015588253736496\n",
            "Validation Loss: 0.07638270407915115\n",
            "\n",
            "Epoch 647/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1000 - val_loss: 0.0749\n",
            "Loss: 0.10000432282686234\n",
            "Validation Loss: 0.07494737207889557\n",
            "\n",
            "Epoch 648/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1002 - val_loss: 0.0753\n",
            "Loss: 0.1001981869339943\n",
            "Validation Loss: 0.0752844586968422\n",
            "\n",
            "Epoch 649/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0997 - val_loss: 0.0757\n",
            "Loss: 0.09967584162950516\n",
            "Validation Loss: 0.07565075904130936\n",
            "\n",
            "Epoch 650/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1005 - val_loss: 0.0761\n",
            "Loss: 0.10051357001066208\n",
            "Validation Loss: 0.07613938301801682\n",
            "\n",
            "Epoch 651/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0998 - val_loss: 0.0756\n",
            "Loss: 0.09984394162893295\n",
            "Validation Loss: 0.07556100934743881\n",
            "\n",
            "Epoch 652/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0999 - val_loss: 0.0761\n",
            "Loss: 0.09985947608947754\n",
            "Validation Loss: 0.07609467953443527\n",
            "\n",
            "Epoch 653/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0993 - val_loss: 0.0765\n",
            "Loss: 0.09932248294353485\n",
            "Validation Loss: 0.07651317864656448\n",
            "\n",
            "Epoch 654/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1000 - val_loss: 0.0746\n",
            "Loss: 0.10003111511468887\n",
            "Validation Loss: 0.07463614642620087\n",
            "\n",
            "Epoch 655/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0999 - val_loss: 0.0767\n",
            "Loss: 0.09985899180173874\n",
            "Validation Loss: 0.07666879147291183\n",
            "\n",
            "Epoch 656/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1007 - val_loss: 0.0799\n",
            "Loss: 0.10069726407527924\n",
            "Validation Loss: 0.07993669807910919\n",
            "\n",
            "Epoch 657/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1004 - val_loss: 0.0771\n",
            "Loss: 0.10043364018201828\n",
            "Validation Loss: 0.07713386416435242\n",
            "\n",
            "Epoch 658/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0997 - val_loss: 0.0770\n",
            "Loss: 0.0997098758816719\n",
            "Validation Loss: 0.07702190428972244\n",
            "\n",
            "Epoch 659/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0997 - val_loss: 0.0773\n",
            "Loss: 0.0996602401137352\n",
            "Validation Loss: 0.07731430232524872\n",
            "\n",
            "Epoch 660/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0996 - val_loss: 0.0759\n",
            "Loss: 0.09963659197092056\n",
            "Validation Loss: 0.0758504718542099\n",
            "\n",
            "Epoch 661/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0993 - val_loss: 0.0763\n",
            "Loss: 0.09934292733669281\n",
            "Validation Loss: 0.07629261910915375\n",
            "\n",
            "Epoch 662/750\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0992 - val_loss: 0.0768\n",
            "Loss: 0.09921851754188538\n",
            "Validation Loss: 0.07680900394916534\n",
            "\n",
            "Epoch 663/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0994 - val_loss: 0.0767\n",
            "Loss: 0.09938104450702667\n",
            "Validation Loss: 0.07666236162185669\n",
            "\n",
            "Epoch 664/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0998 - val_loss: 0.0751\n",
            "Loss: 0.09982910007238388\n",
            "Validation Loss: 0.07511913031339645\n",
            "\n",
            "Epoch 665/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0994 - val_loss: 0.0766\n",
            "Loss: 0.09940988570451736\n",
            "Validation Loss: 0.07663914561271667\n",
            "\n",
            "Epoch 666/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0999 - val_loss: 0.0773\n",
            "Loss: 0.09991195052862167\n",
            "Validation Loss: 0.07733992487192154\n",
            "\n",
            "Epoch 667/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0999 - val_loss: 0.0758\n",
            "Loss: 0.09987152367830276\n",
            "Validation Loss: 0.0758337527513504\n",
            "\n",
            "Epoch 668/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0994 - val_loss: 0.0762\n",
            "Loss: 0.09938279539346695\n",
            "Validation Loss: 0.07619846612215042\n",
            "\n",
            "Epoch 669/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0993 - val_loss: 0.0746\n",
            "Loss: 0.09925349801778793\n",
            "Validation Loss: 0.07464023679494858\n",
            "\n",
            "Epoch 670/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0992 - val_loss: 0.0777\n",
            "Loss: 0.0991852805018425\n",
            "Validation Loss: 0.07772413641214371\n",
            "\n",
            "Epoch 671/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0999 - val_loss: 0.0764\n",
            "Loss: 0.09994497895240784\n",
            "Validation Loss: 0.07640815526247025\n",
            "\n",
            "Epoch 672/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0997 - val_loss: 0.0760\n",
            "Loss: 0.09973673522472382\n",
            "Validation Loss: 0.07602185755968094\n",
            "\n",
            "Epoch 673/750\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1000 - val_loss: 0.0778\n",
            "Loss: 0.09997149556875229\n",
            "Validation Loss: 0.0778496190905571\n",
            "\n",
            "Epoch 674/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1001 - val_loss: 0.0773\n",
            "Loss: 0.10007826238870621\n",
            "Validation Loss: 0.07732224464416504\n",
            "\n",
            "Epoch 675/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0996 - val_loss: 0.0746\n",
            "Loss: 0.09960804879665375\n",
            "Validation Loss: 0.0745835229754448\n",
            "\n",
            "Epoch 676/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0999 - val_loss: 0.0755\n",
            "Loss: 0.09987322241067886\n",
            "Validation Loss: 0.07549991458654404\n",
            "\n",
            "Epoch 677/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1001 - val_loss: 0.0763\n",
            "Loss: 0.10005929321050644\n",
            "Validation Loss: 0.07625880837440491\n",
            "\n",
            "Epoch 678/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0758\n",
            "Loss: 0.10036823153495789\n",
            "Validation Loss: 0.07577472180128098\n",
            "\n",
            "Epoch 679/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0992 - val_loss: 0.0756\n",
            "Loss: 0.09920717775821686\n",
            "Validation Loss: 0.07560419291257858\n",
            "\n",
            "Epoch 680/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0995 - val_loss: 0.0749\n",
            "Loss: 0.09945254027843475\n",
            "Validation Loss: 0.07487858086824417\n",
            "\n",
            "Epoch 681/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0995 - val_loss: 0.0772\n",
            "Loss: 0.09948844462633133\n",
            "Validation Loss: 0.07723413407802582\n",
            "\n",
            "Epoch 682/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0999 - val_loss: 0.0764\n",
            "Loss: 0.09993015974760056\n",
            "Validation Loss: 0.0763620063662529\n",
            "\n",
            "Epoch 683/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0992 - val_loss: 0.0758\n",
            "Loss: 0.09924406558275223\n",
            "Validation Loss: 0.07583291083574295\n",
            "\n",
            "Epoch 684/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0999 - val_loss: 0.0750\n",
            "Loss: 0.09989870339632034\n",
            "Validation Loss: 0.07497256994247437\n",
            "\n",
            "Epoch 685/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0768\n",
            "Loss: 0.100429967045784\n",
            "Validation Loss: 0.07684413343667984\n",
            "\n",
            "Epoch 686/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0998 - val_loss: 0.0758\n",
            "Loss: 0.0998489186167717\n",
            "Validation Loss: 0.07579024136066437\n",
            "\n",
            "Epoch 687/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0995 - val_loss: 0.0754\n",
            "Loss: 0.09949120134115219\n",
            "Validation Loss: 0.07543026655912399\n",
            "\n",
            "Epoch 688/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0999 - val_loss: 0.0762\n",
            "Loss: 0.0998808965086937\n",
            "Validation Loss: 0.07621675729751587\n",
            "\n",
            "Epoch 689/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0998 - val_loss: 0.0771\n",
            "Loss: 0.09984179586172104\n",
            "Validation Loss: 0.07711503654718399\n",
            "\n",
            "Epoch 690/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0995 - val_loss: 0.0761\n",
            "Loss: 0.09946196526288986\n",
            "Validation Loss: 0.07611890882253647\n",
            "\n",
            "Epoch 691/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0997 - val_loss: 0.0754\n",
            "Loss: 0.09968072921037674\n",
            "Validation Loss: 0.07536818832159042\n",
            "\n",
            "Epoch 692/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0991 - val_loss: 0.0767\n",
            "Loss: 0.09907347708940506\n",
            "Validation Loss: 0.07666642963886261\n",
            "\n",
            "Epoch 693/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0987 - val_loss: 0.0758\n",
            "Loss: 0.09870322048664093\n",
            "Validation Loss: 0.07577280700206757\n",
            "\n",
            "Epoch 694/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0988 - val_loss: 0.0766\n",
            "Loss: 0.09881395101547241\n",
            "Validation Loss: 0.07660950720310211\n",
            "\n",
            "Epoch 695/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0992 - val_loss: 0.0751\n",
            "Loss: 0.09922228008508682\n",
            "Validation Loss: 0.07514358311891556\n",
            "\n",
            "Epoch 696/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0996 - val_loss: 0.0760\n",
            "Loss: 0.09958252310752869\n",
            "Validation Loss: 0.07597616314888\n",
            "\n",
            "Epoch 697/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0996 - val_loss: 0.0769\n",
            "Loss: 0.09958703070878983\n",
            "Validation Loss: 0.07692863792181015\n",
            "\n",
            "Epoch 698/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0991 - val_loss: 0.0756\n",
            "Loss: 0.09912987798452377\n",
            "Validation Loss: 0.07562717795372009\n",
            "\n",
            "Epoch 699/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0994 - val_loss: 0.0761\n",
            "Loss: 0.09937569499015808\n",
            "Validation Loss: 0.07609434425830841\n",
            "\n",
            "Epoch 700/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0999 - val_loss: 0.0764\n",
            "Loss: 0.0998740866780281\n",
            "Validation Loss: 0.07638532668352127\n",
            "\n",
            "Epoch 701/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0993 - val_loss: 0.0754\n",
            "Loss: 0.09927697479724884\n",
            "Validation Loss: 0.07541996240615845\n",
            "\n",
            "Epoch 702/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0988 - val_loss: 0.0765\n",
            "Loss: 0.09880650788545609\n",
            "Validation Loss: 0.0764581486582756\n",
            "\n",
            "Epoch 703/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0993 - val_loss: 0.0757\n",
            "Loss: 0.09929893910884857\n",
            "Validation Loss: 0.07570701837539673\n",
            "\n",
            "Epoch 704/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0993 - val_loss: 0.0761\n",
            "Loss: 0.09933709353208542\n",
            "Validation Loss: 0.0761166512966156\n",
            "\n",
            "Epoch 705/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0991 - val_loss: 0.0756\n",
            "Loss: 0.09907222539186478\n",
            "Validation Loss: 0.07556130737066269\n",
            "\n",
            "Epoch 706/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0995 - val_loss: 0.0751\n",
            "Loss: 0.09948772937059402\n",
            "Validation Loss: 0.07508832961320877\n",
            "\n",
            "Epoch 707/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0998 - val_loss: 0.0758\n",
            "Loss: 0.09977665543556213\n",
            "Validation Loss: 0.07577086985111237\n",
            "\n",
            "Epoch 708/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0994 - val_loss: 0.0763\n",
            "Loss: 0.09935911744832993\n",
            "Validation Loss: 0.07629355043172836\n",
            "\n",
            "Epoch 709/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0992 - val_loss: 0.0753\n",
            "Loss: 0.09923599660396576\n",
            "Validation Loss: 0.07531380653381348\n",
            "\n",
            "Epoch 710/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0998 - val_loss: 0.0757\n",
            "Loss: 0.09975164383649826\n",
            "Validation Loss: 0.07566346228122711\n",
            "\n",
            "Epoch 711/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0994 - val_loss: 0.0766\n",
            "Loss: 0.09941653907299042\n",
            "Validation Loss: 0.07657286524772644\n",
            "\n",
            "Epoch 712/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0994 - val_loss: 0.0762\n",
            "Loss: 0.09935960918664932\n",
            "Validation Loss: 0.0761931911110878\n",
            "\n",
            "Epoch 713/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0988 - val_loss: 0.0768\n",
            "Loss: 0.09875606000423431\n",
            "Validation Loss: 0.07681135833263397\n",
            "\n",
            "Epoch 714/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0990 - val_loss: 0.0774\n",
            "Loss: 0.0990491658449173\n",
            "Validation Loss: 0.07741662859916687\n",
            "\n",
            "Epoch 715/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0990 - val_loss: 0.0759\n",
            "Loss: 0.09904561191797256\n",
            "Validation Loss: 0.07591162621974945\n",
            "\n",
            "Epoch 716/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0991 - val_loss: 0.0770\n",
            "Loss: 0.09912832081317902\n",
            "Validation Loss: 0.07695496082305908\n",
            "\n",
            "Epoch 717/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0992 - val_loss: 0.0755\n",
            "Loss: 0.09920214116573334\n",
            "Validation Loss: 0.07554055750370026\n",
            "\n",
            "Epoch 718/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1002 - val_loss: 0.0761\n",
            "Loss: 0.10019209235906601\n",
            "Validation Loss: 0.07605915516614914\n",
            "\n",
            "Epoch 719/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0998 - val_loss: 0.0749\n",
            "Loss: 0.09975867718458176\n",
            "Validation Loss: 0.07485168427228928\n",
            "\n",
            "Epoch 720/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0993 - val_loss: 0.0753\n",
            "Loss: 0.09927878528833389\n",
            "Validation Loss: 0.07529303431510925\n",
            "\n",
            "Epoch 721/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0987 - val_loss: 0.0757\n",
            "Loss: 0.0986909344792366\n",
            "Validation Loss: 0.07574170082807541\n",
            "\n",
            "Epoch 722/750\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0996 - val_loss: 0.0755\n",
            "Loss: 0.09957233816385269\n",
            "Validation Loss: 0.07551666349172592\n",
            "\n",
            "Epoch 723/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0989 - val_loss: 0.0762\n",
            "Loss: 0.09886222332715988\n",
            "Validation Loss: 0.07624760270118713\n",
            "\n",
            "Epoch 724/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0987 - val_loss: 0.0757\n",
            "Loss: 0.09867151826620102\n",
            "Validation Loss: 0.0757497251033783\n",
            "\n",
            "Epoch 725/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0989 - val_loss: 0.0750\n",
            "Loss: 0.09890812635421753\n",
            "Validation Loss: 0.0749751403927803\n",
            "\n",
            "Epoch 726/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0991 - val_loss: 0.0763\n",
            "Loss: 0.09908545017242432\n",
            "Validation Loss: 0.07631399482488632\n",
            "\n",
            "Epoch 727/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0988 - val_loss: 0.0761\n",
            "Loss: 0.09879541397094727\n",
            "Validation Loss: 0.07607119530439377\n",
            "\n",
            "Epoch 728/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0991 - val_loss: 0.0761\n",
            "Loss: 0.09909579902887344\n",
            "Validation Loss: 0.07606365531682968\n",
            "\n",
            "Epoch 729/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0993 - val_loss: 0.0754\n",
            "Loss: 0.09926410019397736\n",
            "Validation Loss: 0.07543633133172989\n",
            "\n",
            "Epoch 730/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0984 - val_loss: 0.0768\n",
            "Loss: 0.09843719005584717\n",
            "Validation Loss: 0.07675444334745407\n",
            "\n",
            "Epoch 731/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0992 - val_loss: 0.0760\n",
            "Loss: 0.09918557852506638\n",
            "Validation Loss: 0.0760008916258812\n",
            "\n",
            "Epoch 732/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0988 - val_loss: 0.0750\n",
            "Loss: 0.09876403212547302\n",
            "Validation Loss: 0.0750126838684082\n",
            "\n",
            "Epoch 733/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0983 - val_loss: 0.0759\n",
            "Loss: 0.09834636002779007\n",
            "Validation Loss: 0.07591921091079712\n",
            "\n",
            "Epoch 734/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0991 - val_loss: 0.0748\n",
            "Loss: 0.09914924949407578\n",
            "Validation Loss: 0.0747770443558693\n",
            "\n",
            "Epoch 735/750\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0994 - val_loss: 0.0763\n",
            "Loss: 0.099369116127491\n",
            "Validation Loss: 0.07630061358213425\n",
            "\n",
            "Epoch 736/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0991 - val_loss: 0.0744\n",
            "Loss: 0.09907714277505875\n",
            "Validation Loss: 0.07444554567337036\n",
            "\n",
            "Epoch 737/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0989 - val_loss: 0.0750\n",
            "Loss: 0.09885729104280472\n",
            "Validation Loss: 0.07499527186155319\n",
            "\n",
            "Epoch 738/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0991 - val_loss: 0.0744\n",
            "Loss: 0.09906134009361267\n",
            "Validation Loss: 0.0744122862815857\n",
            "\n",
            "Epoch 739/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0985 - val_loss: 0.0761\n",
            "Loss: 0.09846919029951096\n",
            "Validation Loss: 0.0761483907699585\n",
            "\n",
            "Epoch 740/750\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.0989 - val_loss: 0.0744\n",
            "Loss: 0.09889295697212219\n",
            "Validation Loss: 0.07442035526037216\n",
            "\n",
            "Epoch 741/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0996 - val_loss: 0.0752\n",
            "Loss: 0.09957171231508255\n",
            "Validation Loss: 0.07523840665817261\n",
            "\n",
            "Epoch 742/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1000 - val_loss: 0.0758\n",
            "Loss: 0.09995643049478531\n",
            "Validation Loss: 0.07579539716243744\n",
            "\n",
            "Epoch 743/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0988 - val_loss: 0.0735\n",
            "Loss: 0.09880487620830536\n",
            "Validation Loss: 0.0734984278678894\n",
            "\n",
            "Epoch 744/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0993 - val_loss: 0.0749\n",
            "Loss: 0.09926430135965347\n",
            "Validation Loss: 0.0749029889702797\n",
            "\n",
            "Epoch 745/750\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0991 - val_loss: 0.0760\n",
            "Loss: 0.0990726500749588\n",
            "Validation Loss: 0.07603258639574051\n",
            "\n",
            "Epoch 746/750\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0989 - val_loss: 0.0750\n",
            "Loss: 0.09892381727695465\n",
            "Validation Loss: 0.07502233982086182\n",
            "\n",
            "Epoch 747/750\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0992 - val_loss: 0.0746\n",
            "Loss: 0.09915437549352646\n",
            "Validation Loss: 0.0745534598827362\n",
            "\n",
            "Epoch 748/750\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0988 - val_loss: 0.0745\n",
            "Loss: 0.0988234356045723\n",
            "Validation Loss: 0.07451437413692474\n",
            "\n",
            "Epoch 749/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0993 - val_loss: 0.0767\n",
            "Loss: 0.09930576384067535\n",
            "Validation Loss: 0.07673922926187515\n",
            "\n",
            "Epoch 750/750\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0988 - val_loss: 0.0758\n",
            "Loss: 0.09875776618719101\n",
            "Validation Loss: 0.07580913603305817\n",
            "\n",
            "History for Model 1\n",
            "Loss: [0.1700247973203659]\n",
            "Validation Loss: [0.17052045464515686]\n",
            "\n",
            "History for Model 2\n",
            "Loss: [0.19046834111213684]\n",
            "Validation Loss: [0.18305104970932007]\n",
            "\n",
            "History for Model 3\n",
            "Loss: [0.09875776618719101]\n",
            "Validation Loss: [0.07580913603305817]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras.layers import TimeDistributed, Reshape, Bidirectional\n",
        "\n",
        "def attention_layer(inputs):\n",
        "    hidden_states, context_vector = inputs\n",
        "    \n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    \n",
        "    # Reshape context vector to perform element-wise multiplication\n",
        "    context_vector = Dense(hidden_size)(context_vector)\n",
        "    context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[1], axis=1)\n",
        "    \n",
        "    # Attention mechanism\n",
        "    attention_weights = tf.keras.layers.Attention()([hidden_states, context_vector])\n",
        "    attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "    \n",
        "    # Weighted sum of hidden states\n",
        "    weighted_sum = tf.reduce_sum(attention_weights * hidden_states, axis=1)\n",
        "    \n",
        "    return weighted_sum\n",
        "\n",
        "\n",
        "def build_model(input_shape, hidden_units, output_dim, dropout_rate=0.15, recurrent_dropout_rate=0.15):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    lstm_output = LSTM(hidden_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)(inputs)\n",
        "    attention_output = AttentionLayer(hidden_units)([lstm_output, lstm_output])\n",
        "    \n",
        "    # Add a time step dimension\n",
        "    reshaped_output = Reshape((-1, hidden_units))(attention_output)\n",
        "    \n",
        "    time_distributed_output = TimeDistributed(Dense(output_dim))(reshaped_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=time_distributed_output)\n",
        "    return model\n",
        "\n",
        "def train_model(X_train, X_test, y_train, y_test, output_dim, n_epochs):\n",
        "    input_shape = X_train.shape[1:]\n",
        "    hidden_units = 128\n",
        "\n",
        "    model = build_model(input_shape, hidden_units, output_dim)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(n_epochs):\n",
        "        # Early stopping\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        history = model.fit(X_train, y_train, epochs=1, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
        "        print(\"Loss:\", history.history['loss'][0])\n",
        "        loss.append(history.history['loss'][0])\n",
        "        print(\"Validation Loss:\", history.history['val_loss'][0])\n",
        "        val_loss.append(history.history['val_loss'][0])\n",
        "        print()\n",
        "\n",
        "    return model, history, loss, val_loss\n",
        "\n",
        "# Create our cross-validation data structure\n",
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(processed_data['x'], processed_data['y'], train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "# Define the features to train for\n",
        "features = [2, 0, 1]  # Specify the indices of the features to train for\n",
        "\n",
        "# Train multiple models\n",
        "models = []\n",
        "histories = []\n",
        "losses = []\n",
        "val_losses = []\n",
        "n_epochs = 750\n",
        "\n",
        "for feature_idx in features:\n",
        "    y_train_feature = np.array([[[features[feature_idx]] for features in y] for y in y_train], dtype=np.float64)\n",
        "    y_valid_feature = np.array([[[features[feature_idx]] for features in y] for y in y_valid], dtype=np.float64)\n",
        "    \n",
        "    model, history, loss, val_loss = train_model(X_train, X_valid, y_train_feature, y_valid_feature, output_dim=1, n_epochs=n_epochs)\n",
        "    \n",
        "    models.append(model)\n",
        "    histories.append(history)\n",
        "    losses.append(loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "# Access the history of each model\n",
        "for i, history in enumerate(histories):\n",
        "    print(f\"History for Model {i+1}\")\n",
        "    print(\"Loss:\", history.history['loss'])\n",
        "    print(\"Validation Loss:\", history.history['val_loss'])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model \n",
        "wind_model = models[0]\n",
        "lat_model = models[1]\n",
        "long_model = models[2]\n",
        "\n",
        "wind_loss = np.array(losses[0])\n",
        "lat_loss = np.array(losses[1])\n",
        "long_loss = np.array(losses[2])\n",
        "\n",
        "wind_val_loss = np.array(val_losses[0])\n",
        "lat_val_loss = np.array(val_losses[1])\n",
        "long_val_loss = np.array(val_losses[2])\n",
        "\n",
        "folder_path_loss = '/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/losses'\n",
        "folder_path_val_loss = '/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/val_losses'\n",
        "\n",
        "np.save(f'{folder_path_loss}/wind_loss.npy', wind_loss)\n",
        "np.save(f'{folder_path_loss}/lat_loss.npy', lat_loss)\n",
        "np.save(f'{folder_path_loss}/long_loss.npy', long_loss)\n",
        "\n",
        "np.save(f'{folder_path_val_loss}/wind_loss.npy', wind_val_loss)\n",
        "np.save(f'{folder_path_val_loss}/lat_loss.npy', lat_val_loss)\n",
        "np.save(f'{folder_path_val_loss}/long_loss.npy', long_val_loss)\n",
        "\n",
        "wind_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/wind_model.h5')\n",
        "lat_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/lat_model.h5')\n",
        "long_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/long_model.h5')"
      ],
      "metadata": {
        "id": "9fYjKBxPXcGp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Predict values\n",
        "wind_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/wind_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "lat_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/lat_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "long_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/long_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "wind_predictions = models[0].predict(X_test)\n",
        "lat_predictions = models[1].predict(X_test)\n",
        "long_predictions = models[2].predict(X_test)"
      ],
      "metadata": {
        "id": "7Dl_hKCGKi9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005becf0-5635-4817-b899-c62a56a07922"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 2s 49ms/step\n",
            "42/42 [==============================] - 3s 51ms/step\n",
            "42/42 [==============================] - 2s 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wind_loss = np.load(f'{folder_path_loss}/wind_loss.npy')\n",
        "lat_loss = np.load(f'{folder_path_loss}/lat_loss.npy')\n",
        "long_loss = np.load(f'{folder_path_loss}/long_loss.npy')\n",
        "\n",
        "wind_val_loss = np.load(f'{folder_path_val_loss}/wind_loss.npy')\n",
        "lat_val_loss = np.load(f'{folder_path_val_loss}/lat_loss.npy')\n",
        "long_val_loss = np.load(f'{folder_path_val_loss}/long_loss.npy')"
      ],
      "metadata": {
        "id": "gQSnRwHTc5yE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses[0], label=\"Wind Model\")\n",
        "plt.plot(losses[1], label=\"Lat Model\")\n",
        "plt.plot(losses[2], label=\"Long Model\")\n",
        "plt.title(\"Loss Over Time\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation loss over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(val_losses[0], label=\"Wind Model\")\n",
        "plt.plot(val_losses[1], label=\"Lat Model\")\n",
        "plt.plot(val_losses[2], label=\"Long Model\")\n",
        "plt.title(\"Validation Loss Over Time\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FXrlj3V-MWhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55c13557-6bb6-4634-d522-ea72a9d82046"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}