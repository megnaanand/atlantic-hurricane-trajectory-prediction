{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FoYl6itUaG8M",
        "outputId": "a619fe39-7d7a-447e-f8f3-67920b3cf043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IKZpPn-6aSjm",
        "outputId": "92a9ed1f-be98-4bbf-c9f8-1f4109156884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wksjVxR-cZph",
        "outputId": "ebb8d285-9c53-4659-bc1a-157a1bce19dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  errors\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wU6pXh5ycf8N",
        "outputId": "89c2d616-b2e1-4563-bffe-71991e50b326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "elmYIsXechGh"
      },
      "outputs": [],
      "source": [
        "# Import various libraries throughout the software\n",
        "from pprint import pprint\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from geopy.distance import great_circle as vc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math as Math\n",
        "import datetime\n",
        "import dateutil\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IaLbuPxDdnVL"
      },
      "outputs": [],
      "source": [
        "# data cleaning/processing: (from hurricane-net, hammad)\n",
        "db = []\n",
        "with open('data/hurdat2-1851-2022-050423.txt') as raw: \n",
        "    for line in raw: \n",
        "        line = line.replace(' ', '').split(',')\n",
        "    \n",
        "        # Identify atlantic storm, first 2 letters should be AL\n",
        "        if (line[0][:2] == 'AL') :\n",
        "            storm_id = line[0]\n",
        "            storm_name = line[1]\n",
        "            storm_entries = line[2]\n",
        "\n",
        "            # Iterate and read through best track entries\n",
        "            for i in range(int(storm_entries)) :\n",
        "                entry = raw.readline().replace(' ', '').split(',')\n",
        "                # Filter -999 placeholder for missing central pressure\n",
        "                entry = [None if x == \"-999\" else x for x in entry]\n",
        "                # Construct date and time based on first two columns\n",
        "                timestamp = datetime.datetime(int(entry[0][:4]), int(entry[0][4:6]), int(entry[0][6:8]), int(entry[1][:2]), int(entry[1][3:]))\n",
        "                # Add entry into our current database\n",
        "                db.append([storm_id, storm_name, timestamp] + entry[2:-1])\n",
        "        else :\n",
        "            print(\"Error, unidentified storm \".join(str(line[0])))\n",
        "\n",
        "# Return DataFrame\n",
        "dataset = pd.DataFrame(db, columns = ['storm_id', 'storm_name', 'entry_time', 'entry_id', 'entry_status', 'lat', 'long','max_wind', 'min_pressure', '34kt_ne', '34kt_se', '34kt_sw', '34kt_nw', '50kt_ne', '50kt_se', '50kt_sw', '50kt_nw', '64kt_ne', '64kt_se', '64kt_sw', '64kt_nw'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YVqCzNzDmg0R"
      },
      "outputs": [],
      "source": [
        "models = dict()\n",
        "class model :\n",
        "  '''\n",
        "  PURPOSE: To create a class for each model included in the forecast error database\n",
        "  METHOD: Provide an API\n",
        "  OUTOUT: A class with a DataFrame and associated operations\n",
        "  '''\n",
        "  name = None\n",
        "  # Dictionary key: STMID\n",
        "  storm = dict()\n",
        "  def __init__(self, model_name) :\n",
        "    self.name = model_name\n",
        "    return\n",
        "\n",
        "with open('errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt') as raw :\n",
        "    lines = raw.readlines()\n",
        "    \n",
        "    # Get model names and declare model objects\n",
        "    line = lines[1].split()\n",
        "    model_names = line[2:]\n",
        "    for model_name in model_names :\n",
        "        models[model_name] = model(model_name)\n",
        "    \n",
        "    # Data starts at line 9 \n",
        "    for line in lines[9:] :\n",
        "        line = line.split()\n",
        "        # Identify atlantic storm date, storm id, associated sample sizes, latitude and longitude, and windspeed\n",
        "        timestamp = datetime.datetime.strptime(line[0], \"%d-%m-%Y/%H:%M:%S\")\n",
        "        storm_id = line[1]\n",
        "        sample_sizes = {\"F012\": float(line[2]), \"F024\": float(line[3]),\"F036\": float(line[4]), \"F048\": float(line[5]), \"F072\": float(line[6]), \"F096\": float(line[7]), \"F120\": float(line[8]), \"F144\": float(line[9]), \"F168\": float(line[10])} \n",
        "        latitude = float(line[11])\n",
        "        longitude = float(line[12])\n",
        "        wind_speed = float(line[13])\n",
        "    \n",
        "                \n",
        "        # Iterate through model forecast track and intensity errors \n",
        "        for i in range(len(model_names)) :\n",
        "            intensity_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[14 + (20 * i) : 24 + (20 * i)]])))\n",
        "            track_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[24 + (20 * i) : 34 + (20 * i)]])))\n",
        "        \n",
        "        # Add forecast to model and storm, initialize if storm id does not exist\n",
        "        if storm_id not in models[model_names[i]].storm.keys() :\n",
        "            models[model_names[i]].storm[storm_id] = dict()\n",
        "\n",
        "        models[model_names[i]].storm[storm_id].update({\n",
        "            timestamp : {\n",
        "            \"sample_sizes\" : sample_sizes,\n",
        "            \"lat\" : latitude,\n",
        "            \"long\" : longitude,\n",
        "            \"wind_speed\" : wind_speed,\n",
        "            \"intensity_forecast\" : intensity_forecast,\n",
        "            \"track_forecast\" : track_forecast,\n",
        "            }\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hG4AXCzkl7Sw",
        "outputId": "b9a26698-d45a-4110-d577-cbebac26f067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 30, 6, 0): 0.0,\n",
            "                                      datetime.datetime(2005, 8, 30, 18, 0): 20.9,\n",
            "                                      datetime.datetime(2005, 8, 31, 18, 0): 93.6,\n",
            "                                      datetime.datetime(2005, 9, 1, 18, 0): 170.2,\n",
            "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'lat': 0.0,\n",
            "        'long': 26.3,\n",
            "        'sample_sizes': {       'F012': 0.33,\n",
            "                                'F024': 0.33,\n",
            "                                'F036': 0.33,\n",
            "                                'F048': 0.0,\n",
            "                                'F072': 0.0,\n",
            "                                'F096': 0.0,\n",
            "                                'F120': 0.0,\n",
            "                                'F144': 0.0,\n",
            "                                'F168': 0.0},\n",
            "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 18, 0): 0.0,\n",
            "                                  datetime.datetime(2005, 8, 31, 18, 0): 28.0,\n",
            "                                  datetime.datetime(2005, 9, 1, 18, 0): 32.0,\n",
            "                                  datetime.datetime(2005, 9, 2, 18, 0): 17.0,\n",
            "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'wind_speed': 88.6}\n"
          ]
        }
      ],
      "source": [
        "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
        "pprint(models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6jC4jkJSG7-C",
        "outputId": "d8fa08f6-949b-4e0b-9ab7-6985c77414c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
              "44681  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
              "44682  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
              "44683  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
              "44684  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
              "44685  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
              "\n",
              "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
              "44681  75.1W       30         1008       0  ...       0       0       0   \n",
              "44682  75.7W       30         1007       0  ...       0       0       0   \n",
              "44683  76.2W       30         1007       0  ...       0       0       0   \n",
              "44684  76.5W       35         1006      60  ...       0       0       0   \n",
              "44685  76.9W       40         1003      60  ...       0       0       0   \n",
              "\n",
              "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
              "44681       0       0       0       0       0       0       0  \n",
              "44682       0       0       0       0       0       0       0  \n",
              "44683       0       0       0       0       0       0       0  \n",
              "44684       0       0       0       0       0       0       0  \n",
              "44685       0       0       0       0       0       0       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_id</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>34kt_ne</th>\n",
              "      <th>...</th>\n",
              "      <th>34kt_sw</th>\n",
              "      <th>34kt_nw</th>\n",
              "      <th>50kt_ne</th>\n",
              "      <th>50kt_se</th>\n",
              "      <th>50kt_sw</th>\n",
              "      <th>50kt_nw</th>\n",
              "      <th>64kt_ne</th>\n",
              "      <th>64kt_se</th>\n",
              "      <th>64kt_sw</th>\n",
              "      <th>64kt_nw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44681</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-23 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.1N</td>\n",
              "      <td>75.1W</td>\n",
              "      <td>30</td>\n",
              "      <td>1008</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44682</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.4N</td>\n",
              "      <td>75.7W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44683</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.8N</td>\n",
              "      <td>76.2W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44684</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>24.5N</td>\n",
              "      <td>76.5W</td>\n",
              "      <td>35</td>\n",
              "      <td>1006</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44685</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>25.4N</td>\n",
              "      <td>76.9W</td>\n",
              "      <td>40</td>\n",
              "      <td>1003</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-593b694a-d0bf-47b8-b99c-3d6c98e68ad9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
        "dataset.query('storm_id == \"AL122005\"').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1USsREqJHDnG"
      },
      "source": [
        "# Transform Data\n",
        "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a storm_id dictionary to store storm names matched with ID's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o_Db-7PBHHBR",
        "outputId": "cd866b54-4b2e-4237-d2dd-bbba48efba4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming HURDAT2 into objects . . .\n",
            "Transforming 53976/53976 entries from HURDAT2\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Create hurricane class\n",
        "class hurricane(object) : \n",
        "    def __init__(self, name, id) :\n",
        "        # Set instance variables\n",
        "        self.name = name\n",
        "        self.id = id\n",
        "        self.entries = dict()\n",
        "        self.models = dict()\n",
        "        \n",
        "        return\n",
        "    # Add hurricane track entry based on standard HURDAT2 format\n",
        "    def add_entry(self, array) :\n",
        "        entry = {\n",
        "            array[0] : { # dateteime of entry\n",
        "                'entry_time' : array[0], \n",
        "                'entry_id' : array[1],\n",
        "                'entry_status' : array[2],\n",
        "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
        "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
        "                'max_wind' : float(array[5]),\n",
        "                'min_pressure' : 980 if array[6] is None else float(array[6]), # Early records are -999 or None\n",
        "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
        "                'distance': 0,\n",
        "                'direction': 0\n",
        "            }\n",
        "        }\n",
        "        self.entries.update(entry)\n",
        "        \n",
        "        return\n",
        "    # Add hurricane model errors\n",
        "    def add_model(self, name, model) :\n",
        "        self.models[name] = model\n",
        "        \n",
        "        return\n",
        "\n",
        "\n",
        "    def update_dist_direc(self):\n",
        "      t = pd.DataFrame(self.entries.values())\n",
        "      dst = 0\n",
        "      prev = (0,0)\n",
        "      \n",
        "      # For all latitude and longitude points of hurricane, calculate the angle of travel and distance\n",
        "      for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "          \n",
        "          if prev == (0,0):\n",
        "              prev = p\n",
        "              continue \n",
        "          # Stores the distance into the DataFrame\n",
        "          list(self.entries.values())[index]['distance'] = vc(prev,p).miles\n",
        "          \n",
        "          dLon = p[1] - prev[1];  \n",
        "          temp = float(p[0]) # p[0] is a str?\n",
        "          y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "          \n",
        "          x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "          brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "          if (brng < 0):\n",
        "              brng+= 360;\n",
        "          \n",
        "          # Stores the angle of travel into the DataFrame\n",
        "          list(self.entries.values())[index]['direction'] = brng\n",
        "          # if self.id == 'AL122005' and index==2:\n",
        "          if self.id == 'AL081994' and index==2:\n",
        "            print(f'p[1]:{p[1]}')\n",
        "            print(f'prev[1]:{prev[1]}')\n",
        "            print(f'dLon:{dLon}')\n",
        "            print(f'temp:{temp}')\n",
        "            print(f'y_x:{y_x}')\n",
        "            print(f'x_x:{x_x}')\n",
        "            print(f'brng:{brng}')\n",
        "          dst += vc(prev,p).miles\n",
        "          prev = p\n",
        "\n",
        "# Storm ID Key for matching between datasets\n",
        "storm_ids = dict()\n",
        "# Parse in hurricanes\n",
        "hurricanes = dict()\n",
        "\n",
        "print(\"Transforming HURDAT2 into objects . . .\")\n",
        "for index, entry in dataset.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset)), end = \"\\r\")\n",
        "    # New hurricane\n",
        "    if entry['storm_id'] not in hurricanes :\n",
        "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxGx5Rg-uN_"
      },
      "source": [
        "# Load Data\n",
        "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lPbnSHF8-s9O",
        "outputId": "c23c6148-8307-4991-b403-bcc7042fe2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n"
          ]
        }
      ],
      "source": [
        "# Get all available model errors\n",
        "# Load model errors into hurricanes\n",
        "for id in storm_ids :\n",
        "    for model in models :\n",
        "        # Skip if this hurricane does not have the model\n",
        "        if id not in models[model].storm :\n",
        "            continue\n",
        "        hurricanes[id].add_model(model, models[model].storm[id])\n",
        "    hurricanes[id].update_dist_direc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LZL5n_PJCTh1",
        "outputId": "3a55b651-816d-489f-caf5-5c99cfe14d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction  \n",
              "0    0.000000  \n",
              "1  306.719439  \n",
              "2  259.483425  \n",
              "3  214.647871  \n",
              "4  205.375417  \n",
              "5  220.828574  \n",
              "6  226.705956  \n",
              "7  284.940686  \n",
              "8  332.536353  \n",
              "9  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdab8448-71f3-4f8c-a851-d1f4fc875833\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdab8448-71f3-4f8c-a851-d1f4fc875833')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdab8448-71f3-4f8c-a851-d1f4fc875833 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdab8448-71f3-4f8c-a851-d1f4fc875833');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#will test distance and direction of the bulk update vs individual update\n",
        "t=pd.DataFrame(hurricanes['AL081994'].entries.values())\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z3EhCEBPDa_j"
      },
      "outputs": [],
      "source": [
        "t['dist']=0\n",
        "t['direc']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uPUaZqElDiHF",
        "outputId": "2b0c6a07-38b4-411b-f129-c7c7852bc484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:0,prev:(16.0, 84.5)\n",
            "1 306.71943856277255\n",
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n",
            "2 259.4834249123352\n",
            "3 214.6478709156233\n",
            "4 205.37541693715318\n",
            "5 220.82857383503298\n",
            "6 226.7059563604921\n",
            "7 284.9406861076747\n",
            "8 332.53635339353264\n",
            "9 342.17177270335054\n"
          ]
        }
      ],
      "source": [
        "#testing for one hurricane\n",
        "prev=(0,0)\n",
        "for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "  if prev == (0,0):\n",
        "    prev = p\n",
        "    print(f'index:{index},prev:{prev}')\n",
        "    continue \n",
        "  # Stores the distance into the DataFrame\n",
        "  t.at[index,'dist'] = vc(prev,p).miles\n",
        "\n",
        "  dLon = p[1] - prev[1];  \n",
        "  temp = float(p[0]) # p[0] is a str?\n",
        "  y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "\n",
        "  x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "  brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "  if (brng < 0):\n",
        "    brng+= 360;\n",
        "  t.at[index,'direc'] = brng\n",
        "  if index==2:\n",
        "    print(f'p[1]:{p[1]}')\n",
        "    print(f'prev[1]:{prev[1]}')\n",
        "    print(f'dLon:{dLon}')\n",
        "    print(f'temp:{temp}')\n",
        "    print(f'y_x:{y_x}')\n",
        "    print(f'x_x:{x_x}')\n",
        "    print(f'brng:{brng}')\n",
        "  print(index,t.at[index,'direc'])\n",
        "  prev = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A-6f67phDjvJ",
        "outputId": "64290a44-b16e-46c7-c03f-2f462a6ef827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction       dist       direc  \n",
              "0    0.000000   0.000000    0.000000  \n",
              "1  306.719439  44.891903  306.719439  \n",
              "2  259.483425  54.796781  259.483425  \n",
              "3  214.647871  53.433344  214.647871  \n",
              "4  205.375417  59.976134  205.375417  \n",
              "5  220.828574  53.406014  220.828574  \n",
              "6  226.705956  19.864134  226.705956  \n",
              "7  284.940686  13.242757  284.940686  \n",
              "8  332.536353  21.036343  332.536353  \n",
              "9  342.171773  19.874439  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "      <th>dist</th>\n",
              "      <th>direc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d9f56e9-7c7d-4d0d-a4d0-bfefaa5ee08a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t #to check that distance calculation and direction calculation from bulk vs individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PwdLRdvVDrxM",
        "outputId": "71b0decf-e9f8-46bd-99d0-2563d291d5c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['OFCL', 'BCD5'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "models.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt3z6MwrD23n"
      },
      "source": [
        "# Feature Engineering & Data Augmentation\n",
        "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
        "\n",
        "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
        "1. Date Information\n",
        "2. Zonal Speed Of The Storm (U) (kt)\n",
        "3. Meridional Speed Of The Storm (V) (kt)\n",
        "4. 12-h Change In Intensity (DVMX) (kt)\n",
        "\n",
        "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LE9LxW_OD7q8",
        "outputId": "4f5e60a4-d6cd-460a-b49a-22ea65655d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineered 1944/1952 hurricanes for 5 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Scaling Data . . . (1 timestep for unqiue data)\n",
            "Feature engineered 1952/1952 hurricanes for 1 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Done scaling.\n"
          ]
        }
      ],
      "source": [
        "def feature_extraction(timestep, previous) :\n",
        "    '''\n",
        "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
        "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
        "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
        "            previous - previous timestep dictionary of features in the hurricane object format\n",
        "    OUTPUT: Dictionary of features\n",
        "    \n",
        "    timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'entry-time' : datetime\n",
        "    }\n",
        "    '''\n",
        "    features = {\n",
        "        'lat' : timestep['lat'],\n",
        "        'long' : timestep['long'],\n",
        "        'max_wind' : timestep['max_wind'],\n",
        "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'min_pressure' : timestep['min_pressure'], \n",
        "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'year' : timestep['entry_time'].year,\n",
        "        'month' : timestep['entry_time'].month,\n",
        "        'day' : timestep['entry_time'].day,\n",
        "        'hour' : timestep['entry_time'].hour,\n",
        "        'delta_pressure': (timestep['min_pressure'] - previous['min_pressure']) /\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'distance': timestep['distance'],\n",
        "        'direction': timestep['direction']\n",
        "    }\n",
        "    return features\n",
        "    \n",
        "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
        "    '''\n",
        "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
        "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
        "    INPUT:  storm - hurricane object\n",
        "            timesteps - (default = 1) number of timesteps to calculate\n",
        "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
        "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
        "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
        "    '''\n",
        "    x = []\n",
        "    # Create testing data structure with a dictionary\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    y = dict([(time,[]) for time in times])\n",
        "    \n",
        "    # Sort by entry time\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
        "    \n",
        "    for index in range(len(entries)) :\n",
        "        if index < timesteps : # Flag for insufficient initial time steps\n",
        "            continue\n",
        "\n",
        "        # If we're not including None values, check to see if there will be any\n",
        "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
        "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
        "            \n",
        "        # Calculate time steps and their features for independent values\n",
        "        sample = []\n",
        "        for step in range(timesteps) :\n",
        "            # Training sample\n",
        "            timestep = entries[index - step]\n",
        "            previous = entries[index - step - 1]\n",
        "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
        "        x.append(sample) # Add our constructed sample\n",
        "        \n",
        "        # Calculate time steps and their features for dependent values\n",
        "        for future in times :\n",
        "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
        "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
        "            \n",
        "            if timestep and previous: \n",
        "                y[future].append(feature_extraction(timestep, previous))\n",
        "            else :\n",
        "                y[future].append(None)\n",
        "    \n",
        "    # Return output, if there is no output, return None.\n",
        "    if len(x) == 0 :\n",
        "        return None\n",
        "    else:\n",
        "        return {'x': x, 'y': y}\n",
        "def shape(hurricanes, timesteps, remove_missing = True) :\n",
        "    '''\n",
        "    PURPOSE: Shape our data for input into machine learning models\n",
        "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            timesteps - number of timesteps for the shape\n",
        "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
        "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
        "    '''\n",
        "    x = []\n",
        "    y = []\n",
        "    lag = 24 # lag time in hours\n",
        "    precision = np.float64 # defines the precision of our data type\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    count = 0\n",
        "    for hurricane in hurricanes.values() :\n",
        "        count += 1\n",
        "        result = storm_x_y(hurricane, timesteps, lag)\n",
        "        if result is None :\n",
        "            continue\n",
        "        # Extract only the values from the strom features using our specified precision\n",
        "        hurricane_x = np.array(\n",
        "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
        "            dtype = precision)\n",
        "        hurricane_y = np.array(\n",
        "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
        "            dtype = precision)\n",
        "        # Disregard if algorithm requires no missing values\n",
        "        if remove_missing :\n",
        "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
        "                continue\n",
        "        # Add to our results\n",
        "        x.extend(hurricane_x)\n",
        "        y.extend(hurricane_y)\n",
        "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
        "    print(\"\\nDone feature engineering hurricanes.\")\n",
        "    \n",
        "    return {'x': np.array(x), 'y': np.array(y)}\n",
        "def scaler(processed_data, hurricanes) :\n",
        "    '''\n",
        "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
        "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
        "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
        "            2) RobustScaler object fit with appropriate data\n",
        "    '''\n",
        "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
        "    # Create our scaler\n",
        "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
        "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
        "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(x)\n",
        "    \n",
        "    # Scale our data\n",
        "    for index in range(len(processed_data['x'])) :\n",
        "        # Scale our x\n",
        "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
        "        # Scale our y\n",
        "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
        "    print(\"Done scaling.\")\n",
        "    return processed_data, scaler\n",
        "# Finalize and scale procesed data into a dictionary\n",
        "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
        "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NapGhxs0vKF4"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda, Attention, Layer, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.context_vector = self.add_weight(shape=(self.hidden_size,),\n",
        "                                              initializer='random_normal',\n",
        "                                              trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hidden_states, _ = inputs\n",
        "\n",
        "        context_vector = tf.expand_dims(self.context_vector, axis=0)\n",
        "        context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[0], axis=0)\n",
        "\n",
        "        attention_weights = tf.einsum('ijk,ik->ij', hidden_states, context_vector)\n",
        "        attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "\n",
        "        weighted_sum = tf.einsum('ij,ijk->ik', attention_weights, hidden_states)\n",
        "\n",
        "        return weighted_sum"
      ],
      "metadata": {
        "id": "1_LGW5zSQpeV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Wd7P0bXwvg97",
        "outputId": "e5678f92-e98c-4069-e4fe-c55e1ee511a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 5, 128)       73216       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer_3 (AttentionLa  (None, 128)         128         ['lstm_3[0][0]',                 \n",
            " yer)                                                             'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 128)       0           ['attention_layer_3[0][0]']      \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 1, 1)        129         ['reshape[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 7s 125ms/step - loss: 0.4155 - val_loss: 0.3225\n",
            "Loss: 0.4155099093914032\n",
            "Validation Loss: 0.322491317987442\n",
            "\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3297 - val_loss: 0.3093\n",
            "Loss: 0.32965436577796936\n",
            "Validation Loss: 0.3093377351760864\n",
            "\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3171 - val_loss: 0.3012\n",
            "Loss: 0.31710511445999146\n",
            "Validation Loss: 0.30124691128730774\n",
            "\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3098 - val_loss: 0.2973\n",
            "Loss: 0.30982062220573425\n",
            "Validation Loss: 0.2972593307495117\n",
            "\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3089 - val_loss: 0.2914\n",
            "Loss: 0.3089469373226166\n",
            "Validation Loss: 0.29137635231018066\n",
            "\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.3039 - val_loss: 0.2890\n",
            "Loss: 0.3039233684539795\n",
            "Validation Loss: 0.28898563981056213\n",
            "\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2999 - val_loss: 0.2851\n",
            "Loss: 0.2998571991920471\n",
            "Validation Loss: 0.2851444184780121\n",
            "\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2994 - val_loss: 0.2844\n",
            "Loss: 0.2994111180305481\n",
            "Validation Loss: 0.28444167971611023\n",
            "\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2944 - val_loss: 0.2801\n",
            "Loss: 0.2944185733795166\n",
            "Validation Loss: 0.2801060080528259\n",
            "\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2929 - val_loss: 0.2805\n",
            "Loss: 0.29288744926452637\n",
            "Validation Loss: 0.28046032786369324\n",
            "\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2902 - val_loss: 0.2774\n",
            "Loss: 0.29021766781806946\n",
            "Validation Loss: 0.27737072110176086\n",
            "\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2896 - val_loss: 0.2759\n",
            "Loss: 0.28961503505706787\n",
            "Validation Loss: 0.27592334151268005\n",
            "\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2871 - val_loss: 0.2742\n",
            "Loss: 0.28707271814346313\n",
            "Validation Loss: 0.2741824686527252\n",
            "\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2868 - val_loss: 0.2752\n",
            "Loss: 0.2868100106716156\n",
            "Validation Loss: 0.2752467095851898\n",
            "\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2852 - val_loss: 0.2740\n",
            "Loss: 0.2852170169353485\n",
            "Validation Loss: 0.2739827036857605\n",
            "\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2870 - val_loss: 0.2723\n",
            "Loss: 0.2869504392147064\n",
            "Validation Loss: 0.2722700536251068\n",
            "\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2826 - val_loss: 0.2728\n",
            "Loss: 0.28255370259284973\n",
            "Validation Loss: 0.27276891469955444\n",
            "\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2827 - val_loss: 0.2745\n",
            "Loss: 0.2826710045337677\n",
            "Validation Loss: 0.2745184898376465\n",
            "\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2805 - val_loss: 0.2678\n",
            "Loss: 0.2804858982563019\n",
            "Validation Loss: 0.2678402364253998\n",
            "\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2794 - val_loss: 0.2699\n",
            "Loss: 0.2794319987297058\n",
            "Validation Loss: 0.2698591947555542\n",
            "\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2773 - val_loss: 0.2683\n",
            "Loss: 0.27730250358581543\n",
            "Validation Loss: 0.2683071494102478\n",
            "\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2802 - val_loss: 0.2701\n",
            "Loss: 0.2801755368709564\n",
            "Validation Loss: 0.270140141248703\n",
            "\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2774 - val_loss: 0.2691\n",
            "Loss: 0.2774016261100769\n",
            "Validation Loss: 0.26911917328834534\n",
            "\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2767 - val_loss: 0.2704\n",
            "Loss: 0.27668899297714233\n",
            "Validation Loss: 0.2703510820865631\n",
            "\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2736 - val_loss: 0.2651\n",
            "Loss: 0.27359044551849365\n",
            "Validation Loss: 0.2650810480117798\n",
            "\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2748 - val_loss: 0.2711\n",
            "Loss: 0.2747856676578522\n",
            "Validation Loss: 0.2711217999458313\n",
            "\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2746 - val_loss: 0.2708\n",
            "Loss: 0.27460813522338867\n",
            "Validation Loss: 0.2708476185798645\n",
            "\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2708 - val_loss: 0.2638\n",
            "Loss: 0.2708475887775421\n",
            "Validation Loss: 0.26375025510787964\n",
            "\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2703 - val_loss: 0.2659\n",
            "Loss: 0.2702758312225342\n",
            "Validation Loss: 0.2659025490283966\n",
            "\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2680 - val_loss: 0.2650\n",
            "Loss: 0.2679600119590759\n",
            "Validation Loss: 0.26496589183807373\n",
            "\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2698 - val_loss: 0.2662\n",
            "Loss: 0.26984962821006775\n",
            "Validation Loss: 0.2661952078342438\n",
            "\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2677 - val_loss: 0.2614\n",
            "Loss: 0.26770856976509094\n",
            "Validation Loss: 0.26144111156463623\n",
            "\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2673 - val_loss: 0.2627\n",
            "Loss: 0.2672957479953766\n",
            "Validation Loss: 0.26269203424453735\n",
            "\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2666 - val_loss: 0.2617\n",
            "Loss: 0.26662304997444153\n",
            "Validation Loss: 0.26166868209838867\n",
            "\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2641 - val_loss: 0.2587\n",
            "Loss: 0.2641431391239166\n",
            "Validation Loss: 0.258734792470932\n",
            "\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2659 - val_loss: 0.2597\n",
            "Loss: 0.2658880054950714\n",
            "Validation Loss: 0.25965553522109985\n",
            "\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2644 - val_loss: 0.2596\n",
            "Loss: 0.26439154148101807\n",
            "Validation Loss: 0.2596178650856018\n",
            "\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2637 - val_loss: 0.2611\n",
            "Loss: 0.2637048661708832\n",
            "Validation Loss: 0.26106375455856323\n",
            "\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2632 - val_loss: 0.2604\n",
            "Loss: 0.26320067048072815\n",
            "Validation Loss: 0.26036933064460754\n",
            "\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2636 - val_loss: 0.2595\n",
            "Loss: 0.26358214020729065\n",
            "Validation Loss: 0.25948795676231384\n",
            "\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2597 - val_loss: 0.2596\n",
            "Loss: 0.25965240597724915\n",
            "Validation Loss: 0.259628027677536\n",
            "\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2612 - val_loss: 0.2575\n",
            "Loss: 0.2612110674381256\n",
            "Validation Loss: 0.2574949562549591\n",
            "\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2590 - val_loss: 0.2578\n",
            "Loss: 0.25902777910232544\n",
            "Validation Loss: 0.2578415274620056\n",
            "\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2576 - val_loss: 0.2552\n",
            "Loss: 0.2576330304145813\n",
            "Validation Loss: 0.25521188974380493\n",
            "\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2575 - val_loss: 0.2564\n",
            "Loss: 0.2575230002403259\n",
            "Validation Loss: 0.2564297914505005\n",
            "\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2576 - val_loss: 0.2556\n",
            "Loss: 0.25764432549476624\n",
            "Validation Loss: 0.25556209683418274\n",
            "\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2580 - val_loss: 0.2548\n",
            "Loss: 0.258029967546463\n",
            "Validation Loss: 0.25482818484306335\n",
            "\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2562 - val_loss: 0.2528\n",
            "Loss: 0.25621071457862854\n",
            "Validation Loss: 0.2528218626976013\n",
            "\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2550 - val_loss: 0.2531\n",
            "Loss: 0.25502103567123413\n",
            "Validation Loss: 0.25307074189186096\n",
            "\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2547 - val_loss: 0.2536\n",
            "Loss: 0.25469568371772766\n",
            "Validation Loss: 0.25362956523895264\n",
            "\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2548 - val_loss: 0.2541\n",
            "Loss: 0.2547980546951294\n",
            "Validation Loss: 0.25407031178474426\n",
            "\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2529 - val_loss: 0.2548\n",
            "Loss: 0.252850741147995\n",
            "Validation Loss: 0.2548004686832428\n",
            "\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2530 - val_loss: 0.2509\n",
            "Loss: 0.25302359461784363\n",
            "Validation Loss: 0.25094494223594666\n",
            "\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2513 - val_loss: 0.2521\n",
            "Loss: 0.25129538774490356\n",
            "Validation Loss: 0.25207555294036865\n",
            "\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2520 - val_loss: 0.2513\n",
            "Loss: 0.25201675295829773\n",
            "Validation Loss: 0.2513119876384735\n",
            "\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2510 - val_loss: 0.2517\n",
            "Loss: 0.2509700357913971\n",
            "Validation Loss: 0.25170230865478516\n",
            "\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2514 - val_loss: 0.2474\n",
            "Loss: 0.2514277994632721\n",
            "Validation Loss: 0.2474401593208313\n",
            "\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2498 - val_loss: 0.2489\n",
            "Loss: 0.24981440603733063\n",
            "Validation Loss: 0.24892915785312653\n",
            "\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2493 - val_loss: 0.2482\n",
            "Loss: 0.2493363916873932\n",
            "Validation Loss: 0.24817915260791779\n",
            "\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2487 - val_loss: 0.2493\n",
            "Loss: 0.2486736923456192\n",
            "Validation Loss: 0.2493050992488861\n",
            "\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2477 - val_loss: 0.2499\n",
            "Loss: 0.24772822856903076\n",
            "Validation Loss: 0.24992628395557404\n",
            "\n",
            "Epoch 62/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2466 - val_loss: 0.2452\n",
            "Loss: 0.24659353494644165\n",
            "Validation Loss: 0.245223268866539\n",
            "\n",
            "Epoch 63/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2469 - val_loss: 0.2455\n",
            "Loss: 0.24692755937576294\n",
            "Validation Loss: 0.24551266431808472\n",
            "\n",
            "Epoch 64/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2473 - val_loss: 0.2484\n",
            "Loss: 0.24731621146202087\n",
            "Validation Loss: 0.24837864935398102\n",
            "\n",
            "Epoch 65/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2472 - val_loss: 0.2458\n",
            "Loss: 0.24718452990055084\n",
            "Validation Loss: 0.24579623341560364\n",
            "\n",
            "Epoch 66/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2446 - val_loss: 0.2461\n",
            "Loss: 0.24457000195980072\n",
            "Validation Loss: 0.2460678368806839\n",
            "\n",
            "Epoch 67/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2457 - val_loss: 0.2464\n",
            "Loss: 0.2456940859556198\n",
            "Validation Loss: 0.246351957321167\n",
            "\n",
            "Epoch 68/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2435 - val_loss: 0.2418\n",
            "Loss: 0.24353864789009094\n",
            "Validation Loss: 0.24183478951454163\n",
            "\n",
            "Epoch 69/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2463 - val_loss: 0.2464\n",
            "Loss: 0.2463313639163971\n",
            "Validation Loss: 0.24638691544532776\n",
            "\n",
            "Epoch 70/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2449 - val_loss: 0.2463\n",
            "Loss: 0.24487465620040894\n",
            "Validation Loss: 0.24628591537475586\n",
            "\n",
            "Epoch 71/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2441 - val_loss: 0.2441\n",
            "Loss: 0.2441135048866272\n",
            "Validation Loss: 0.24411171674728394\n",
            "\n",
            "Epoch 72/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2427 - val_loss: 0.2424\n",
            "Loss: 0.2427183985710144\n",
            "Validation Loss: 0.24242885410785675\n",
            "\n",
            "Epoch 73/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2393 - val_loss: 0.2416\n",
            "Loss: 0.23926785588264465\n",
            "Validation Loss: 0.2415822446346283\n",
            "\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2398 - val_loss: 0.2414\n",
            "Loss: 0.2398327738046646\n",
            "Validation Loss: 0.24141186475753784\n",
            "\n",
            "Epoch 75/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2400 - val_loss: 0.2411\n",
            "Loss: 0.24003830552101135\n",
            "Validation Loss: 0.2411031275987625\n",
            "\n",
            "Epoch 76/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2416 - val_loss: 0.2440\n",
            "Loss: 0.24157503247261047\n",
            "Validation Loss: 0.2439848631620407\n",
            "\n",
            "Epoch 77/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2408 - val_loss: 0.2412\n",
            "Loss: 0.2407778948545456\n",
            "Validation Loss: 0.24122881889343262\n",
            "\n",
            "Epoch 78/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2389 - val_loss: 0.2431\n",
            "Loss: 0.2388576865196228\n",
            "Validation Loss: 0.24308042228221893\n",
            "\n",
            "Epoch 79/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2397 - val_loss: 0.2395\n",
            "Loss: 0.23968057334423065\n",
            "Validation Loss: 0.239485502243042\n",
            "\n",
            "Epoch 80/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2386 - val_loss: 0.2390\n",
            "Loss: 0.2385898381471634\n",
            "Validation Loss: 0.23902609944343567\n",
            "\n",
            "Epoch 81/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2386 - val_loss: 0.2411\n",
            "Loss: 0.23858201503753662\n",
            "Validation Loss: 0.24109333753585815\n",
            "\n",
            "Epoch 82/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2371 - val_loss: 0.2381\n",
            "Loss: 0.23705987632274628\n",
            "Validation Loss: 0.23808684945106506\n",
            "\n",
            "Epoch 83/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2389 - val_loss: 0.2379\n",
            "Loss: 0.2388618290424347\n",
            "Validation Loss: 0.23786193132400513\n",
            "\n",
            "Epoch 84/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2380 - val_loss: 0.2377\n",
            "Loss: 0.23800182342529297\n",
            "Validation Loss: 0.2376926988363266\n",
            "\n",
            "Epoch 85/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2353 - val_loss: 0.2375\n",
            "Loss: 0.23531422019004822\n",
            "Validation Loss: 0.2375161200761795\n",
            "\n",
            "Epoch 86/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2357 - val_loss: 0.2360\n",
            "Loss: 0.2357393354177475\n",
            "Validation Loss: 0.23599454760551453\n",
            "\n",
            "Epoch 87/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2336 - val_loss: 0.2365\n",
            "Loss: 0.23363059759140015\n",
            "Validation Loss: 0.23646579682826996\n",
            "\n",
            "Epoch 88/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2345 - val_loss: 0.2338\n",
            "Loss: 0.23454347252845764\n",
            "Validation Loss: 0.2338259369134903\n",
            "\n",
            "Epoch 89/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2340 - val_loss: 0.2346\n",
            "Loss: 0.23397545516490936\n",
            "Validation Loss: 0.23456324636936188\n",
            "\n",
            "Epoch 90/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2345 - val_loss: 0.2339\n",
            "Loss: 0.23454265296459198\n",
            "Validation Loss: 0.2338852882385254\n",
            "\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2327 - val_loss: 0.2346\n",
            "Loss: 0.232658252120018\n",
            "Validation Loss: 0.2346232384443283\n",
            "\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2325 - val_loss: 0.2340\n",
            "Loss: 0.23247241973876953\n",
            "Validation Loss: 0.23404580354690552\n",
            "\n",
            "Epoch 93/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2323 - val_loss: 0.2321\n",
            "Loss: 0.23234549164772034\n",
            "Validation Loss: 0.232060045003891\n",
            "\n",
            "Epoch 94/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2317 - val_loss: 0.2331\n",
            "Loss: 0.23166395723819733\n",
            "Validation Loss: 0.2331046760082245\n",
            "\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2313 - val_loss: 0.2314\n",
            "Loss: 0.23131968080997467\n",
            "Validation Loss: 0.2313746213912964\n",
            "\n",
            "Epoch 96/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2317 - val_loss: 0.2320\n",
            "Loss: 0.23172464966773987\n",
            "Validation Loss: 0.2319701910018921\n",
            "\n",
            "Epoch 97/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2334 - val_loss: 0.2298\n",
            "Loss: 0.2334296703338623\n",
            "Validation Loss: 0.22982147336006165\n",
            "\n",
            "Epoch 98/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2307 - val_loss: 0.2319\n",
            "Loss: 0.2307431548833847\n",
            "Validation Loss: 0.23188021779060364\n",
            "\n",
            "Epoch 99/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2285 - val_loss: 0.2308\n",
            "Loss: 0.22846247255802155\n",
            "Validation Loss: 0.23079313337802887\n",
            "\n",
            "Epoch 100/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2295 - val_loss: 0.2285\n",
            "Loss: 0.22950133681297302\n",
            "Validation Loss: 0.22853346168994904\n",
            "\n",
            "Epoch 101/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2287 - val_loss: 0.2302\n",
            "Loss: 0.2287147492170334\n",
            "Validation Loss: 0.23020240664482117\n",
            "\n",
            "Epoch 102/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2279 - val_loss: 0.2300\n",
            "Loss: 0.22789256274700165\n",
            "Validation Loss: 0.22999346256256104\n",
            "\n",
            "Epoch 103/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2279 - val_loss: 0.2328\n",
            "Loss: 0.22793081402778625\n",
            "Validation Loss: 0.23282091319561005\n",
            "\n",
            "Epoch 104/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2261 - val_loss: 0.2271\n",
            "Loss: 0.22609366476535797\n",
            "Validation Loss: 0.22709259390830994\n",
            "\n",
            "Epoch 105/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2259 - val_loss: 0.2260\n",
            "Loss: 0.22588960826396942\n",
            "Validation Loss: 0.22596892714500427\n",
            "\n",
            "Epoch 106/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2277 - val_loss: 0.2290\n",
            "Loss: 0.2276623398065567\n",
            "Validation Loss: 0.2290417104959488\n",
            "\n",
            "Epoch 107/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2263 - val_loss: 0.2277\n",
            "Loss: 0.22627674043178558\n",
            "Validation Loss: 0.22768297791481018\n",
            "\n",
            "Epoch 108/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2245 - val_loss: 0.2297\n",
            "Loss: 0.22454461455345154\n",
            "Validation Loss: 0.22966256737709045\n",
            "\n",
            "Epoch 109/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2270 - val_loss: 0.2294\n",
            "Loss: 0.2270413041114807\n",
            "Validation Loss: 0.22943279147148132\n",
            "\n",
            "Epoch 110/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2235 - val_loss: 0.2285\n",
            "Loss: 0.2235325574874878\n",
            "Validation Loss: 0.2285461723804474\n",
            "\n",
            "Epoch 111/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2247 - val_loss: 0.2263\n",
            "Loss: 0.22469176352024078\n",
            "Validation Loss: 0.22629491984844208\n",
            "\n",
            "Epoch 112/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2236 - val_loss: 0.2297\n",
            "Loss: 0.2235979437828064\n",
            "Validation Loss: 0.2297036498785019\n",
            "\n",
            "Epoch 113/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2243 - val_loss: 0.2283\n",
            "Loss: 0.22432729601860046\n",
            "Validation Loss: 0.22830621898174286\n",
            "\n",
            "Epoch 114/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2228 - val_loss: 0.2243\n",
            "Loss: 0.22276243567466736\n",
            "Validation Loss: 0.22428317368030548\n",
            "\n",
            "Epoch 115/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2241 - val_loss: 0.2257\n",
            "Loss: 0.224077045917511\n",
            "Validation Loss: 0.22572258114814758\n",
            "\n",
            "Epoch 116/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2212 - val_loss: 0.2248\n",
            "Loss: 0.22120288014411926\n",
            "Validation Loss: 0.22476942837238312\n",
            "\n",
            "Epoch 117/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2229 - val_loss: 0.2255\n",
            "Loss: 0.22291097044944763\n",
            "Validation Loss: 0.22554577887058258\n",
            "\n",
            "Epoch 118/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2207 - val_loss: 0.2250\n",
            "Loss: 0.2206576019525528\n",
            "Validation Loss: 0.22495399415493011\n",
            "\n",
            "Epoch 119/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2222 - val_loss: 0.2228\n",
            "Loss: 0.2222028374671936\n",
            "Validation Loss: 0.2227710336446762\n",
            "\n",
            "Epoch 120/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2225 - val_loss: 0.2258\n",
            "Loss: 0.22252652049064636\n",
            "Validation Loss: 0.22581680119037628\n",
            "\n",
            "Epoch 121/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2205 - val_loss: 0.2240\n",
            "Loss: 0.22048744559288025\n",
            "Validation Loss: 0.22403572499752045\n",
            "\n",
            "Epoch 122/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2212 - val_loss: 0.2202\n",
            "Loss: 0.22120118141174316\n",
            "Validation Loss: 0.22022874653339386\n",
            "\n",
            "Epoch 123/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2216 - val_loss: 0.2217\n",
            "Loss: 0.22162319719791412\n",
            "Validation Loss: 0.2217288464307785\n",
            "\n",
            "Epoch 124/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2206 - val_loss: 0.2211\n",
            "Loss: 0.2205609679222107\n",
            "Validation Loss: 0.22106187045574188\n",
            "\n",
            "Epoch 125/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2196 - val_loss: 0.2197\n",
            "Loss: 0.2195657640695572\n",
            "Validation Loss: 0.21966107189655304\n",
            "\n",
            "Epoch 126/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2184 - val_loss: 0.2196\n",
            "Loss: 0.2183675765991211\n",
            "Validation Loss: 0.21955054998397827\n",
            "\n",
            "Epoch 127/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2179 - val_loss: 0.2216\n",
            "Loss: 0.21786533296108246\n",
            "Validation Loss: 0.22159366309642792\n",
            "\n",
            "Epoch 128/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2200 - val_loss: 0.2204\n",
            "Loss: 0.22000852227210999\n",
            "Validation Loss: 0.22044123709201813\n",
            "\n",
            "Epoch 129/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2187 - val_loss: 0.2199\n",
            "Loss: 0.21872064471244812\n",
            "Validation Loss: 0.21993492543697357\n",
            "\n",
            "Epoch 130/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2194 - val_loss: 0.2162\n",
            "Loss: 0.21942642331123352\n",
            "Validation Loss: 0.21617576479911804\n",
            "\n",
            "Epoch 131/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2188 - val_loss: 0.2189\n",
            "Loss: 0.2188408076763153\n",
            "Validation Loss: 0.21894840896129608\n",
            "\n",
            "Epoch 132/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2176 - val_loss: 0.2190\n",
            "Loss: 0.21758203208446503\n",
            "Validation Loss: 0.21898053586483002\n",
            "\n",
            "Epoch 133/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2157 - val_loss: 0.2206\n",
            "Loss: 0.21567828953266144\n",
            "Validation Loss: 0.2205781489610672\n",
            "\n",
            "Epoch 134/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2186 - val_loss: 0.2176\n",
            "Loss: 0.21860039234161377\n",
            "Validation Loss: 0.2175978422164917\n",
            "\n",
            "Epoch 135/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2168 - val_loss: 0.2164\n",
            "Loss: 0.21684549748897552\n",
            "Validation Loss: 0.21637114882469177\n",
            "\n",
            "Epoch 136/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2171 - val_loss: 0.2195\n",
            "Loss: 0.21712642908096313\n",
            "Validation Loss: 0.21954728662967682\n",
            "\n",
            "Epoch 137/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2155 - val_loss: 0.2191\n",
            "Loss: 0.2155170738697052\n",
            "Validation Loss: 0.21914659440517426\n",
            "\n",
            "Epoch 138/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2165 - val_loss: 0.2148\n",
            "Loss: 0.21651071310043335\n",
            "Validation Loss: 0.21476702392101288\n",
            "\n",
            "Epoch 139/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2161 - val_loss: 0.2152\n",
            "Loss: 0.21613414585590363\n",
            "Validation Loss: 0.21519117057323456\n",
            "\n",
            "Epoch 140/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2158 - val_loss: 0.2221\n",
            "Loss: 0.21580538153648376\n",
            "Validation Loss: 0.22214235365390778\n",
            "\n",
            "Epoch 141/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2157 - val_loss: 0.2182\n",
            "Loss: 0.2156951129436493\n",
            "Validation Loss: 0.21821607649326324\n",
            "\n",
            "Epoch 142/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2175 - val_loss: 0.2199\n",
            "Loss: 0.21750755608081818\n",
            "Validation Loss: 0.21987371146678925\n",
            "\n",
            "Epoch 143/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2183 - val_loss: 0.2141\n",
            "Loss: 0.21825556457042694\n",
            "Validation Loss: 0.21407940983772278\n",
            "\n",
            "Epoch 144/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2139 - val_loss: 0.2175\n",
            "Loss: 0.21391715109348297\n",
            "Validation Loss: 0.2175392061471939\n",
            "\n",
            "Epoch 145/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2149 - val_loss: 0.2206\n",
            "Loss: 0.21493422985076904\n",
            "Validation Loss: 0.22059302031993866\n",
            "\n",
            "Epoch 146/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2130 - val_loss: 0.2165\n",
            "Loss: 0.21298468112945557\n",
            "Validation Loss: 0.21654309332370758\n",
            "\n",
            "Epoch 147/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2143 - val_loss: 0.2154\n",
            "Loss: 0.21429720520973206\n",
            "Validation Loss: 0.21542298793792725\n",
            "\n",
            "Epoch 148/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2130 - val_loss: 0.2178\n",
            "Loss: 0.21301031112670898\n",
            "Validation Loss: 0.21778090298175812\n",
            "\n",
            "Epoch 149/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2133 - val_loss: 0.2175\n",
            "Loss: 0.2133389711380005\n",
            "Validation Loss: 0.2175333946943283\n",
            "\n",
            "Epoch 150/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2126 - val_loss: 0.2145\n",
            "Loss: 0.21259455382823944\n",
            "Validation Loss: 0.21445457637310028\n",
            "\n",
            "Epoch 151/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2109 - val_loss: 0.2157\n",
            "Loss: 0.21089811623096466\n",
            "Validation Loss: 0.21572847664356232\n",
            "\n",
            "Epoch 152/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2130 - val_loss: 0.2152\n",
            "Loss: 0.21298129856586456\n",
            "Validation Loss: 0.21522000432014465\n",
            "\n",
            "Epoch 153/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2123 - val_loss: 0.2120\n",
            "Loss: 0.21231919527053833\n",
            "Validation Loss: 0.21199622750282288\n",
            "\n",
            "Epoch 154/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2115 - val_loss: 0.2136\n",
            "Loss: 0.21148864924907684\n",
            "Validation Loss: 0.21363858878612518\n",
            "\n",
            "Epoch 155/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2117 - val_loss: 0.2132\n",
            "Loss: 0.21169023215770721\n",
            "Validation Loss: 0.21321047842502594\n",
            "\n",
            "Epoch 156/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2098 - val_loss: 0.2124\n",
            "Loss: 0.20984892547130585\n",
            "Validation Loss: 0.2124374955892563\n",
            "\n",
            "Epoch 157/500\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2113 - val_loss: 0.2128\n",
            "Loss: 0.2113446295261383\n",
            "Validation Loss: 0.21279767155647278\n",
            "\n",
            "Epoch 158/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2117 - val_loss: 0.2107\n",
            "Loss: 0.21172267198562622\n",
            "Validation Loss: 0.21068871021270752\n",
            "\n",
            "Epoch 159/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2115 - val_loss: 0.2110\n",
            "Loss: 0.21148620545864105\n",
            "Validation Loss: 0.2110464721918106\n",
            "\n",
            "Epoch 160/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2114 - val_loss: 0.2103\n",
            "Loss: 0.21141833066940308\n",
            "Validation Loss: 0.21027716994285583\n",
            "\n",
            "Epoch 161/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2111 - val_loss: 0.2121\n",
            "Loss: 0.21110203862190247\n",
            "Validation Loss: 0.21210232377052307\n",
            "\n",
            "Epoch 162/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2078 - val_loss: 0.2099\n",
            "Loss: 0.2078096717596054\n",
            "Validation Loss: 0.20989644527435303\n",
            "\n",
            "Epoch 163/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2099 - val_loss: 0.2111\n",
            "Loss: 0.20991942286491394\n",
            "Validation Loss: 0.21107609570026398\n",
            "\n",
            "Epoch 164/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2085 - val_loss: 0.2111\n",
            "Loss: 0.20854350924491882\n",
            "Validation Loss: 0.21105802059173584\n",
            "\n",
            "Epoch 165/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2067 - val_loss: 0.2142\n",
            "Loss: 0.2067374885082245\n",
            "Validation Loss: 0.21423693001270294\n",
            "\n",
            "Epoch 166/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2099 - val_loss: 0.2080\n",
            "Loss: 0.20991763472557068\n",
            "Validation Loss: 0.2080467939376831\n",
            "\n",
            "Epoch 167/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2070 - val_loss: 0.2105\n",
            "Loss: 0.20695461332798004\n",
            "Validation Loss: 0.21054048836231232\n",
            "\n",
            "Epoch 168/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2076 - val_loss: 0.2094\n",
            "Loss: 0.20760418474674225\n",
            "Validation Loss: 0.2094074934720993\n",
            "\n",
            "Epoch 169/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2081 - val_loss: 0.2115\n",
            "Loss: 0.20806346833705902\n",
            "Validation Loss: 0.2115357220172882\n",
            "\n",
            "Epoch 170/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2056 - val_loss: 0.2096\n",
            "Loss: 0.20555110275745392\n",
            "Validation Loss: 0.20960256457328796\n",
            "\n",
            "Epoch 171/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2065 - val_loss: 0.2101\n",
            "Loss: 0.20646631717681885\n",
            "Validation Loss: 0.2100841999053955\n",
            "\n",
            "Epoch 172/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2076 - val_loss: 0.2114\n",
            "Loss: 0.2076287716627121\n",
            "Validation Loss: 0.21143606305122375\n",
            "\n",
            "Epoch 173/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2076 - val_loss: 0.2072\n",
            "Loss: 0.2076215147972107\n",
            "Validation Loss: 0.20716041326522827\n",
            "\n",
            "Epoch 174/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2055 - val_loss: 0.2100\n",
            "Loss: 0.20552372932434082\n",
            "Validation Loss: 0.20996025204658508\n",
            "\n",
            "Epoch 175/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2058 - val_loss: 0.2096\n",
            "Loss: 0.20582573115825653\n",
            "Validation Loss: 0.2096269428730011\n",
            "\n",
            "Epoch 176/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2080 - val_loss: 0.2081\n",
            "Loss: 0.2080465853214264\n",
            "Validation Loss: 0.2080594003200531\n",
            "\n",
            "Epoch 177/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2059 - val_loss: 0.2099\n",
            "Loss: 0.2059408724308014\n",
            "Validation Loss: 0.2098635733127594\n",
            "\n",
            "Epoch 178/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2066 - val_loss: 0.2066\n",
            "Loss: 0.2066279500722885\n",
            "Validation Loss: 0.2066206932067871\n",
            "\n",
            "Epoch 179/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2058 - val_loss: 0.2062\n",
            "Loss: 0.20580577850341797\n",
            "Validation Loss: 0.2061651349067688\n",
            "\n",
            "Epoch 180/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2071 - val_loss: 0.2105\n",
            "Loss: 0.20708027482032776\n",
            "Validation Loss: 0.2104560136795044\n",
            "\n",
            "Epoch 181/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2051 - val_loss: 0.2072\n",
            "Loss: 0.20513267815113068\n",
            "Validation Loss: 0.2071511298418045\n",
            "\n",
            "Epoch 182/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2052 - val_loss: 0.2063\n",
            "Loss: 0.20523016154766083\n",
            "Validation Loss: 0.20629829168319702\n",
            "\n",
            "Epoch 183/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2047 - val_loss: 0.2051\n",
            "Loss: 0.20471657812595367\n",
            "Validation Loss: 0.2051280289888382\n",
            "\n",
            "Epoch 184/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2045 - val_loss: 0.2056\n",
            "Loss: 0.20447209477424622\n",
            "Validation Loss: 0.20559380948543549\n",
            "\n",
            "Epoch 185/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2042 - val_loss: 0.2107\n",
            "Loss: 0.20416881144046783\n",
            "Validation Loss: 0.2107122838497162\n",
            "\n",
            "Epoch 186/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2050 - val_loss: 0.2050\n",
            "Loss: 0.20498116314411163\n",
            "Validation Loss: 0.2050139307975769\n",
            "\n",
            "Epoch 187/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2044 - val_loss: 0.2058\n",
            "Loss: 0.2043803632259369\n",
            "Validation Loss: 0.20576442778110504\n",
            "\n",
            "Epoch 188/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2032 - val_loss: 0.2092\n",
            "Loss: 0.20321062207221985\n",
            "Validation Loss: 0.20918822288513184\n",
            "\n",
            "Epoch 189/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2037 - val_loss: 0.2051\n",
            "Loss: 0.2036833018064499\n",
            "Validation Loss: 0.2050878256559372\n",
            "\n",
            "Epoch 190/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2037 - val_loss: 0.2069\n",
            "Loss: 0.2037481814622879\n",
            "Validation Loss: 0.20692181587219238\n",
            "\n",
            "Epoch 191/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2028 - val_loss: 0.2072\n",
            "Loss: 0.20283760130405426\n",
            "Validation Loss: 0.20720115303993225\n",
            "\n",
            "Epoch 192/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2032 - val_loss: 0.2049\n",
            "Loss: 0.20319312810897827\n",
            "Validation Loss: 0.2049136459827423\n",
            "\n",
            "Epoch 193/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2040 - val_loss: 0.2045\n",
            "Loss: 0.2040155977010727\n",
            "Validation Loss: 0.2044852375984192\n",
            "\n",
            "Epoch 194/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2032 - val_loss: 0.2046\n",
            "Loss: 0.20321358740329742\n",
            "Validation Loss: 0.20463819801807404\n",
            "\n",
            "Epoch 195/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2038 - val_loss: 0.2039\n",
            "Loss: 0.20377019047737122\n",
            "Validation Loss: 0.20394644141197205\n",
            "\n",
            "Epoch 196/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2026 - val_loss: 0.2060\n",
            "Loss: 0.2026328444480896\n",
            "Validation Loss: 0.2059815526008606\n",
            "\n",
            "Epoch 197/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2028 - val_loss: 0.2058\n",
            "Loss: 0.20283183455467224\n",
            "Validation Loss: 0.20579251646995544\n",
            "\n",
            "Epoch 198/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2023 - val_loss: 0.2060\n",
            "Loss: 0.2022920846939087\n",
            "Validation Loss: 0.20597317814826965\n",
            "\n",
            "Epoch 199/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2012 - val_loss: 0.2035\n",
            "Loss: 0.20116345584392548\n",
            "Validation Loss: 0.20346377789974213\n",
            "\n",
            "Epoch 200/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2032 - val_loss: 0.2076\n",
            "Loss: 0.2031812071800232\n",
            "Validation Loss: 0.2075531780719757\n",
            "\n",
            "Epoch 201/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2015 - val_loss: 0.2088\n",
            "Loss: 0.20147369801998138\n",
            "Validation Loss: 0.20877400040626526\n",
            "\n",
            "Epoch 202/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2019 - val_loss: 0.2021\n",
            "Loss: 0.20185795426368713\n",
            "Validation Loss: 0.20209287106990814\n",
            "\n",
            "Epoch 203/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2019 - val_loss: 0.2010\n",
            "Loss: 0.2018810212612152\n",
            "Validation Loss: 0.20104524493217468\n",
            "\n",
            "Epoch 204/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2032 - val_loss: 0.2062\n",
            "Loss: 0.20323215425014496\n",
            "Validation Loss: 0.20622050762176514\n",
            "\n",
            "Epoch 205/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2006 - val_loss: 0.2053\n",
            "Loss: 0.20056381821632385\n",
            "Validation Loss: 0.20526063442230225\n",
            "\n",
            "Epoch 206/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2015 - val_loss: 0.2037\n",
            "Loss: 0.20146770775318146\n",
            "Validation Loss: 0.2036963552236557\n",
            "\n",
            "Epoch 207/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2004 - val_loss: 0.2027\n",
            "Loss: 0.2004043012857437\n",
            "Validation Loss: 0.20267000794410706\n",
            "\n",
            "Epoch 208/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1998 - val_loss: 0.2019\n",
            "Loss: 0.19975967705249786\n",
            "Validation Loss: 0.20187386870384216\n",
            "\n",
            "Epoch 209/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2013 - val_loss: 0.2054\n",
            "Loss: 0.20125767588615417\n",
            "Validation Loss: 0.20541271567344666\n",
            "\n",
            "Epoch 210/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2006 - val_loss: 0.2025\n",
            "Loss: 0.200633242726326\n",
            "Validation Loss: 0.20253461599349976\n",
            "\n",
            "Epoch 211/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2003 - val_loss: 0.2036\n",
            "Loss: 0.20029127597808838\n",
            "Validation Loss: 0.2036309391260147\n",
            "\n",
            "Epoch 212/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2003 - val_loss: 0.2051\n",
            "Loss: 0.20034809410572052\n",
            "Validation Loss: 0.20509663224220276\n",
            "\n",
            "Epoch 213/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1979 - val_loss: 0.2034\n",
            "Loss: 0.19787366688251495\n",
            "Validation Loss: 0.2033667415380478\n",
            "\n",
            "Epoch 214/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1979 - val_loss: 0.2046\n",
            "Loss: 0.19788463413715363\n",
            "Validation Loss: 0.20457807183265686\n",
            "\n",
            "Epoch 215/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1997 - val_loss: 0.2033\n",
            "Loss: 0.19967344403266907\n",
            "Validation Loss: 0.2033473402261734\n",
            "\n",
            "Epoch 216/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1993 - val_loss: 0.2033\n",
            "Loss: 0.19931310415267944\n",
            "Validation Loss: 0.2033066302537918\n",
            "\n",
            "Epoch 217/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1984 - val_loss: 0.2043\n",
            "Loss: 0.19836677610874176\n",
            "Validation Loss: 0.2043209671974182\n",
            "\n",
            "Epoch 218/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1987 - val_loss: 0.2025\n",
            "Loss: 0.19868995249271393\n",
            "Validation Loss: 0.20251034200191498\n",
            "\n",
            "Epoch 219/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1996 - val_loss: 0.2031\n",
            "Loss: 0.19956450164318085\n",
            "Validation Loss: 0.2031189203262329\n",
            "\n",
            "Epoch 220/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2018 - val_loss: 0.2014\n",
            "Loss: 0.20180365443229675\n",
            "Validation Loss: 0.20139102637767792\n",
            "\n",
            "Epoch 221/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1993 - val_loss: 0.2013\n",
            "Loss: 0.1992582529783249\n",
            "Validation Loss: 0.20131665468215942\n",
            "\n",
            "Epoch 222/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1996 - val_loss: 0.2019\n",
            "Loss: 0.19959218800067902\n",
            "Validation Loss: 0.20187421143054962\n",
            "\n",
            "Epoch 223/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2001 - val_loss: 0.2039\n",
            "Loss: 0.20007961988449097\n",
            "Validation Loss: 0.2038976401090622\n",
            "\n",
            "Epoch 224/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1986 - val_loss: 0.2019\n",
            "Loss: 0.19855305552482605\n",
            "Validation Loss: 0.2018941044807434\n",
            "\n",
            "Epoch 225/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1991 - val_loss: 0.2018\n",
            "Loss: 0.1991267055273056\n",
            "Validation Loss: 0.20181629061698914\n",
            "\n",
            "Epoch 226/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1987 - val_loss: 0.2039\n",
            "Loss: 0.19874344766139984\n",
            "Validation Loss: 0.20391221344470978\n",
            "\n",
            "Epoch 227/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1971 - val_loss: 0.2054\n",
            "Loss: 0.19712531566619873\n",
            "Validation Loss: 0.20537090301513672\n",
            "\n",
            "Epoch 228/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1989 - val_loss: 0.2040\n",
            "Loss: 0.19894656538963318\n",
            "Validation Loss: 0.20400317013263702\n",
            "\n",
            "Epoch 229/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1990 - val_loss: 0.2029\n",
            "Loss: 0.1989721655845642\n",
            "Validation Loss: 0.20287762582302094\n",
            "\n",
            "Epoch 230/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1975 - val_loss: 0.2006\n",
            "Loss: 0.19747819006443024\n",
            "Validation Loss: 0.20057936012744904\n",
            "\n",
            "Epoch 231/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1973 - val_loss: 0.2016\n",
            "Loss: 0.19727866351604462\n",
            "Validation Loss: 0.2016463428735733\n",
            "\n",
            "Epoch 232/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1964 - val_loss: 0.2004\n",
            "Loss: 0.19642233848571777\n",
            "Validation Loss: 0.20038017630577087\n",
            "\n",
            "Epoch 233/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1975 - val_loss: 0.2001\n",
            "Loss: 0.19754669070243835\n",
            "Validation Loss: 0.20009322464466095\n",
            "\n",
            "Epoch 234/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1952 - val_loss: 0.2000\n",
            "Loss: 0.19519269466400146\n",
            "Validation Loss: 0.19995054602622986\n",
            "\n",
            "Epoch 235/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1953 - val_loss: 0.2011\n",
            "Loss: 0.19531460106372833\n",
            "Validation Loss: 0.20113259553909302\n",
            "\n",
            "Epoch 236/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1954 - val_loss: 0.2007\n",
            "Loss: 0.19539833068847656\n",
            "Validation Loss: 0.20068824291229248\n",
            "\n",
            "Epoch 237/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1969 - val_loss: 0.1991\n",
            "Loss: 0.19689415395259857\n",
            "Validation Loss: 0.19909818470478058\n",
            "\n",
            "Epoch 238/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1966 - val_loss: 0.1987\n",
            "Loss: 0.19661878049373627\n",
            "Validation Loss: 0.19869697093963623\n",
            "\n",
            "Epoch 239/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1948 - val_loss: 0.2011\n",
            "Loss: 0.19484661519527435\n",
            "Validation Loss: 0.201120063662529\n",
            "\n",
            "Epoch 240/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1966 - val_loss: 0.2028\n",
            "Loss: 0.19658729434013367\n",
            "Validation Loss: 0.20281991362571716\n",
            "\n",
            "Epoch 241/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1957 - val_loss: 0.2010\n",
            "Loss: 0.19568774104118347\n",
            "Validation Loss: 0.20099622011184692\n",
            "\n",
            "Epoch 242/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1954 - val_loss: 0.1967\n",
            "Loss: 0.19537903368473053\n",
            "Validation Loss: 0.19674044847488403\n",
            "\n",
            "Epoch 243/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1954 - val_loss: 0.1991\n",
            "Loss: 0.19540677964687347\n",
            "Validation Loss: 0.19907750189304352\n",
            "\n",
            "Epoch 244/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1972 - val_loss: 0.2020\n",
            "Loss: 0.19716675579547882\n",
            "Validation Loss: 0.20204393565654755\n",
            "\n",
            "Epoch 245/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1946 - val_loss: 0.1997\n",
            "Loss: 0.1945759803056717\n",
            "Validation Loss: 0.19971998035907745\n",
            "\n",
            "Epoch 246/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1954 - val_loss: 0.1995\n",
            "Loss: 0.19543175399303436\n",
            "Validation Loss: 0.1994630992412567\n",
            "\n",
            "Epoch 247/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1971 - val_loss: 0.2018\n",
            "Loss: 0.1970708966255188\n",
            "Validation Loss: 0.2017984837293625\n",
            "\n",
            "Epoch 248/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1952 - val_loss: 0.1997\n",
            "Loss: 0.195247620344162\n",
            "Validation Loss: 0.19969426095485687\n",
            "\n",
            "Epoch 249/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1956 - val_loss: 0.1981\n",
            "Loss: 0.1955968290567398\n",
            "Validation Loss: 0.19809503853321075\n",
            "\n",
            "Epoch 250/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1977 - val_loss: 0.1996\n",
            "Loss: 0.1976591795682907\n",
            "Validation Loss: 0.1995900273323059\n",
            "\n",
            "Epoch 251/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1963 - val_loss: 0.1991\n",
            "Loss: 0.19627678394317627\n",
            "Validation Loss: 0.19912701845169067\n",
            "\n",
            "Epoch 252/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1944 - val_loss: 0.1988\n",
            "Loss: 0.19437964260578156\n",
            "Validation Loss: 0.1988394856452942\n",
            "\n",
            "Epoch 253/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1945 - val_loss: 0.1981\n",
            "Loss: 0.19447258114814758\n",
            "Validation Loss: 0.19812235236167908\n",
            "\n",
            "Epoch 254/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1940 - val_loss: 0.1991\n",
            "Loss: 0.19400331377983093\n",
            "Validation Loss: 0.19912652671337128\n",
            "\n",
            "Epoch 255/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1944 - val_loss: 0.1986\n",
            "Loss: 0.19438450038433075\n",
            "Validation Loss: 0.1986032873392105\n",
            "\n",
            "Epoch 256/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1951 - val_loss: 0.1979\n",
            "Loss: 0.19510138034820557\n",
            "Validation Loss: 0.19793039560317993\n",
            "\n",
            "Epoch 257/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1937 - val_loss: 0.1977\n",
            "Loss: 0.1937035471200943\n",
            "Validation Loss: 0.19769421219825745\n",
            "\n",
            "Epoch 258/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1931 - val_loss: 0.1969\n",
            "Loss: 0.19310325384140015\n",
            "Validation Loss: 0.19685856997966766\n",
            "\n",
            "Epoch 259/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1935 - val_loss: 0.1967\n",
            "Loss: 0.19347530603408813\n",
            "Validation Loss: 0.19670838117599487\n",
            "\n",
            "Epoch 260/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1936 - val_loss: 0.1985\n",
            "Loss: 0.19359415769577026\n",
            "Validation Loss: 0.19849930703639984\n",
            "\n",
            "Epoch 261/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1935 - val_loss: 0.1967\n",
            "Loss: 0.19346210360527039\n",
            "Validation Loss: 0.19665250182151794\n",
            "\n",
            "Epoch 262/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1934 - val_loss: 0.1984\n",
            "Loss: 0.19338664412498474\n",
            "Validation Loss: 0.19838778674602509\n",
            "\n",
            "Epoch 263/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1940 - val_loss: 0.1979\n",
            "Loss: 0.19399328529834747\n",
            "Validation Loss: 0.197883740067482\n",
            "\n",
            "Epoch 264/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1932 - val_loss: 0.1976\n",
            "Loss: 0.19321975111961365\n",
            "Validation Loss: 0.1975652426481247\n",
            "\n",
            "Epoch 265/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1935 - val_loss: 0.1965\n",
            "Loss: 0.1934809684753418\n",
            "Validation Loss: 0.19645898044109344\n",
            "\n",
            "Epoch 266/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1932 - val_loss: 0.1970\n",
            "Loss: 0.19315765798091888\n",
            "Validation Loss: 0.1969958245754242\n",
            "\n",
            "Epoch 267/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1927 - val_loss: 0.1961\n",
            "Loss: 0.19266527891159058\n",
            "Validation Loss: 0.1960957944393158\n",
            "\n",
            "Epoch 268/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1935 - val_loss: 0.1942\n",
            "Loss: 0.19349515438079834\n",
            "Validation Loss: 0.194231778383255\n",
            "\n",
            "Epoch 269/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1929 - val_loss: 0.1962\n",
            "Loss: 0.19285078346729279\n",
            "Validation Loss: 0.1962449848651886\n",
            "\n",
            "Epoch 270/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1935 - val_loss: 0.1987\n",
            "Loss: 0.1934892237186432\n",
            "Validation Loss: 0.198668971657753\n",
            "\n",
            "Epoch 271/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1919 - val_loss: 0.1979\n",
            "Loss: 0.19193202257156372\n",
            "Validation Loss: 0.19786202907562256\n",
            "\n",
            "Epoch 272/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1922 - val_loss: 0.1937\n",
            "Loss: 0.1922401487827301\n",
            "Validation Loss: 0.19371120631694794\n",
            "\n",
            "Epoch 273/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1923 - val_loss: 0.1970\n",
            "Loss: 0.19229722023010254\n",
            "Validation Loss: 0.19701921939849854\n",
            "\n",
            "Epoch 274/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1931 - val_loss: 0.1944\n",
            "Loss: 0.19308842718601227\n",
            "Validation Loss: 0.19439508020877838\n",
            "\n",
            "Epoch 275/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1923 - val_loss: 0.1949\n",
            "Loss: 0.19231069087982178\n",
            "Validation Loss: 0.19492672383785248\n",
            "\n",
            "Epoch 276/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1920 - val_loss: 0.1946\n",
            "Loss: 0.19195781648159027\n",
            "Validation Loss: 0.19461417198181152\n",
            "\n",
            "Epoch 277/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1910 - val_loss: 0.1978\n",
            "Loss: 0.19104035198688507\n",
            "Validation Loss: 0.19777405261993408\n",
            "\n",
            "Epoch 278/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1929 - val_loss: 0.1969\n",
            "Loss: 0.19289211928844452\n",
            "Validation Loss: 0.19685246050357819\n",
            "\n",
            "Epoch 279/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1919 - val_loss: 0.1963\n",
            "Loss: 0.1919465959072113\n",
            "Validation Loss: 0.19634006917476654\n",
            "\n",
            "Epoch 280/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1908 - val_loss: 0.1955\n",
            "Loss: 0.19079871475696564\n",
            "Validation Loss: 0.1955190896987915\n",
            "\n",
            "Epoch 281/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1897 - val_loss: 0.1971\n",
            "Loss: 0.1896935999393463\n",
            "Validation Loss: 0.19710734486579895\n",
            "\n",
            "Epoch 282/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1914 - val_loss: 0.1974\n",
            "Loss: 0.19143995642662048\n",
            "Validation Loss: 0.19740530848503113\n",
            "\n",
            "Epoch 283/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1911 - val_loss: 0.1941\n",
            "Loss: 0.19114147126674652\n",
            "Validation Loss: 0.19413825869560242\n",
            "\n",
            "Epoch 284/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1914 - val_loss: 0.1953\n",
            "Loss: 0.19137831032276154\n",
            "Validation Loss: 0.19534039497375488\n",
            "\n",
            "Epoch 285/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1912 - val_loss: 0.1938\n",
            "Loss: 0.19115500152111053\n",
            "Validation Loss: 0.19384896755218506\n",
            "\n",
            "Epoch 286/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1907 - val_loss: 0.1950\n",
            "Loss: 0.19072099030017853\n",
            "Validation Loss: 0.19499631226062775\n",
            "\n",
            "Epoch 287/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1894 - val_loss: 0.1923\n",
            "Loss: 0.18935728073120117\n",
            "Validation Loss: 0.19227658212184906\n",
            "\n",
            "Epoch 288/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1915 - val_loss: 0.1957\n",
            "Loss: 0.19154781103134155\n",
            "Validation Loss: 0.1957145482301712\n",
            "\n",
            "Epoch 289/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1897 - val_loss: 0.1950\n",
            "Loss: 0.1896819919347763\n",
            "Validation Loss: 0.19501660764217377\n",
            "\n",
            "Epoch 290/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1903 - val_loss: 0.1959\n",
            "Loss: 0.1902579814195633\n",
            "Validation Loss: 0.19594113528728485\n",
            "\n",
            "Epoch 291/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1905 - val_loss: 0.1944\n",
            "Loss: 0.19050638377666473\n",
            "Validation Loss: 0.19442874193191528\n",
            "\n",
            "Epoch 292/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1906 - val_loss: 0.1953\n",
            "Loss: 0.19061078131198883\n",
            "Validation Loss: 0.1953054964542389\n",
            "\n",
            "Epoch 293/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1922 - val_loss: 0.1994\n",
            "Loss: 0.19215483963489532\n",
            "Validation Loss: 0.19935211539268494\n",
            "\n",
            "Epoch 294/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1909 - val_loss: 0.1961\n",
            "Loss: 0.19093406200408936\n",
            "Validation Loss: 0.19614477455615997\n",
            "\n",
            "Epoch 295/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1900 - val_loss: 0.1950\n",
            "Loss: 0.1900271475315094\n",
            "Validation Loss: 0.19495919346809387\n",
            "\n",
            "Epoch 296/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1909 - val_loss: 0.1925\n",
            "Loss: 0.19088707864284515\n",
            "Validation Loss: 0.19253648817539215\n",
            "\n",
            "Epoch 297/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1905 - val_loss: 0.1973\n",
            "Loss: 0.1905423402786255\n",
            "Validation Loss: 0.19725732505321503\n",
            "\n",
            "Epoch 298/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1897 - val_loss: 0.1952\n",
            "Loss: 0.18974263966083527\n",
            "Validation Loss: 0.19517897069454193\n",
            "\n",
            "Epoch 299/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1898 - val_loss: 0.1939\n",
            "Loss: 0.18982566893100739\n",
            "Validation Loss: 0.19394679367542267\n",
            "\n",
            "Epoch 300/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1886 - val_loss: 0.1930\n",
            "Loss: 0.18861381709575653\n",
            "Validation Loss: 0.19297920167446136\n",
            "\n",
            "Epoch 301/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1899 - val_loss: 0.1927\n",
            "Loss: 0.18989744782447815\n",
            "Validation Loss: 0.19273212552070618\n",
            "\n",
            "Epoch 302/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1888 - val_loss: 0.1956\n",
            "Loss: 0.18878066539764404\n",
            "Validation Loss: 0.19561775028705597\n",
            "\n",
            "Epoch 303/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1903 - val_loss: 0.1967\n",
            "Loss: 0.19030199944972992\n",
            "Validation Loss: 0.19667339324951172\n",
            "\n",
            "Epoch 304/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1884 - val_loss: 0.1953\n",
            "Loss: 0.18835225701332092\n",
            "Validation Loss: 0.195296511054039\n",
            "\n",
            "Epoch 305/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1884 - val_loss: 0.1945\n",
            "Loss: 0.18843600153923035\n",
            "Validation Loss: 0.19453944265842438\n",
            "\n",
            "Epoch 306/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1896 - val_loss: 0.1956\n",
            "Loss: 0.18964360654354095\n",
            "Validation Loss: 0.19563661515712738\n",
            "\n",
            "Epoch 307/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1895 - val_loss: 0.1938\n",
            "Loss: 0.1895287036895752\n",
            "Validation Loss: 0.19375698268413544\n",
            "\n",
            "Epoch 308/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1890 - val_loss: 0.1969\n",
            "Loss: 0.18901677429676056\n",
            "Validation Loss: 0.19687309861183167\n",
            "\n",
            "Epoch 309/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1881 - val_loss: 0.1933\n",
            "Loss: 0.18812412023544312\n",
            "Validation Loss: 0.19327394664287567\n",
            "\n",
            "Epoch 310/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1898 - val_loss: 0.1926\n",
            "Loss: 0.18982455134391785\n",
            "Validation Loss: 0.19255226850509644\n",
            "\n",
            "Epoch 311/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1908 - val_loss: 0.1953\n",
            "Loss: 0.19079932570457458\n",
            "Validation Loss: 0.19532397389411926\n",
            "\n",
            "Epoch 312/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1890 - val_loss: 0.1943\n",
            "Loss: 0.18897436559200287\n",
            "Validation Loss: 0.1943095624446869\n",
            "\n",
            "Epoch 313/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1874 - val_loss: 0.1923\n",
            "Loss: 0.1873762160539627\n",
            "Validation Loss: 0.1922932118177414\n",
            "\n",
            "Epoch 314/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1882 - val_loss: 0.1922\n",
            "Loss: 0.188229501247406\n",
            "Validation Loss: 0.19218496978282928\n",
            "\n",
            "Epoch 315/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1898 - val_loss: 0.1957\n",
            "Loss: 0.18977560102939606\n",
            "Validation Loss: 0.1956881880760193\n",
            "\n",
            "Epoch 316/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1887 - val_loss: 0.1924\n",
            "Loss: 0.18867240846157074\n",
            "Validation Loss: 0.19235019385814667\n",
            "\n",
            "Epoch 317/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1876 - val_loss: 0.1924\n",
            "Loss: 0.1875779628753662\n",
            "Validation Loss: 0.19241319596767426\n",
            "\n",
            "Epoch 318/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1884 - val_loss: 0.1951\n",
            "Loss: 0.18842174112796783\n",
            "Validation Loss: 0.19508096575737\n",
            "\n",
            "Epoch 319/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1860 - val_loss: 0.1943\n",
            "Loss: 0.18597620725631714\n",
            "Validation Loss: 0.19426730275154114\n",
            "\n",
            "Epoch 320/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1882 - val_loss: 0.1928\n",
            "Loss: 0.18817242980003357\n",
            "Validation Loss: 0.19276894629001617\n",
            "\n",
            "Epoch 321/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1869 - val_loss: 0.1928\n",
            "Loss: 0.18686576187610626\n",
            "Validation Loss: 0.19284212589263916\n",
            "\n",
            "Epoch 322/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1881 - val_loss: 0.1906\n",
            "Loss: 0.18814770877361298\n",
            "Validation Loss: 0.19062304496765137\n",
            "\n",
            "Epoch 323/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1879 - val_loss: 0.1944\n",
            "Loss: 0.18787240982055664\n",
            "Validation Loss: 0.19436131417751312\n",
            "\n",
            "Epoch 324/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1881 - val_loss: 0.1910\n",
            "Loss: 0.18806888163089752\n",
            "Validation Loss: 0.1910114735364914\n",
            "\n",
            "Epoch 325/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1877 - val_loss: 0.1924\n",
            "Loss: 0.1876750886440277\n",
            "Validation Loss: 0.19235818088054657\n",
            "\n",
            "Epoch 326/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1890 - val_loss: 0.1926\n",
            "Loss: 0.18899789452552795\n",
            "Validation Loss: 0.19255709648132324\n",
            "\n",
            "Epoch 327/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1866 - val_loss: 0.1925\n",
            "Loss: 0.18655945360660553\n",
            "Validation Loss: 0.1924525499343872\n",
            "\n",
            "Epoch 328/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1889 - val_loss: 0.1907\n",
            "Loss: 0.18885570764541626\n",
            "Validation Loss: 0.19071020185947418\n",
            "\n",
            "Epoch 329/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1863 - val_loss: 0.1930\n",
            "Loss: 0.18632559478282928\n",
            "Validation Loss: 0.1930038332939148\n",
            "\n",
            "Epoch 330/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1871 - val_loss: 0.1929\n",
            "Loss: 0.1871204376220703\n",
            "Validation Loss: 0.19289174675941467\n",
            "\n",
            "Epoch 331/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1868 - val_loss: 0.1920\n",
            "Loss: 0.18678033351898193\n",
            "Validation Loss: 0.19203543663024902\n",
            "\n",
            "Epoch 332/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1891 - val_loss: 0.1913\n",
            "Loss: 0.18914133310317993\n",
            "Validation Loss: 0.19132569432258606\n",
            "\n",
            "Epoch 333/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1865 - val_loss: 0.1920\n",
            "Loss: 0.1865355521440506\n",
            "Validation Loss: 0.19199371337890625\n",
            "\n",
            "Epoch 334/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1852 - val_loss: 0.1901\n",
            "Loss: 0.18515169620513916\n",
            "Validation Loss: 0.1900947391986847\n",
            "\n",
            "Epoch 335/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1873 - val_loss: 0.1937\n",
            "Loss: 0.1873050481081009\n",
            "Validation Loss: 0.19369016587734222\n",
            "\n",
            "Epoch 336/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1869 - val_loss: 0.1922\n",
            "Loss: 0.18690620362758636\n",
            "Validation Loss: 0.1921873241662979\n",
            "\n",
            "Epoch 337/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1861 - val_loss: 0.1932\n",
            "Loss: 0.1861114203929901\n",
            "Validation Loss: 0.19319196045398712\n",
            "\n",
            "Epoch 338/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1858 - val_loss: 0.1904\n",
            "Loss: 0.1857537478208542\n",
            "Validation Loss: 0.19043876230716705\n",
            "\n",
            "Epoch 339/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1875 - val_loss: 0.1908\n",
            "Loss: 0.1875019371509552\n",
            "Validation Loss: 0.19079343974590302\n",
            "\n",
            "Epoch 340/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1862 - val_loss: 0.1920\n",
            "Loss: 0.18616050481796265\n",
            "Validation Loss: 0.1919766515493393\n",
            "\n",
            "Epoch 341/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1848 - val_loss: 0.1928\n",
            "Loss: 0.18478812277317047\n",
            "Validation Loss: 0.1927652806043625\n",
            "\n",
            "Epoch 342/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1858 - val_loss: 0.1913\n",
            "Loss: 0.18580204248428345\n",
            "Validation Loss: 0.19134534895420074\n",
            "\n",
            "Epoch 343/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1874 - val_loss: 0.1927\n",
            "Loss: 0.18744780123233795\n",
            "Validation Loss: 0.19274379312992096\n",
            "\n",
            "Epoch 344/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1854 - val_loss: 0.1906\n",
            "Loss: 0.1853645294904709\n",
            "Validation Loss: 0.19056320190429688\n",
            "\n",
            "Epoch 345/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1857 - val_loss: 0.1888\n",
            "Loss: 0.1857006996870041\n",
            "Validation Loss: 0.1888144612312317\n",
            "\n",
            "Epoch 346/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1855 - val_loss: 0.1927\n",
            "Loss: 0.1855277121067047\n",
            "Validation Loss: 0.19267219305038452\n",
            "\n",
            "Epoch 347/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1865 - val_loss: 0.1920\n",
            "Loss: 0.18653230369091034\n",
            "Validation Loss: 0.1920367032289505\n",
            "\n",
            "Epoch 348/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1866 - val_loss: 0.1897\n",
            "Loss: 0.186612069606781\n",
            "Validation Loss: 0.18968462944030762\n",
            "\n",
            "Epoch 349/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1847 - val_loss: 0.1915\n",
            "Loss: 0.18474745750427246\n",
            "Validation Loss: 0.1914803832769394\n",
            "\n",
            "Epoch 350/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1858 - val_loss: 0.1900\n",
            "Loss: 0.18581832945346832\n",
            "Validation Loss: 0.1899608075618744\n",
            "\n",
            "Epoch 351/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1879 - val_loss: 0.1914\n",
            "Loss: 0.18785421550273895\n",
            "Validation Loss: 0.19137342274188995\n",
            "\n",
            "Epoch 352/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1850 - val_loss: 0.1922\n",
            "Loss: 0.18497036397457123\n",
            "Validation Loss: 0.19220995903015137\n",
            "\n",
            "Epoch 353/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1852 - val_loss: 0.1922\n",
            "Loss: 0.1852121651172638\n",
            "Validation Loss: 0.1921772062778473\n",
            "\n",
            "Epoch 354/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1855 - val_loss: 0.1931\n",
            "Loss: 0.18554240465164185\n",
            "Validation Loss: 0.1931174397468567\n",
            "\n",
            "Epoch 355/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1853 - val_loss: 0.1925\n",
            "Loss: 0.18526309728622437\n",
            "Validation Loss: 0.19245223701000214\n",
            "\n",
            "Epoch 356/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1848 - val_loss: 0.1914\n",
            "Loss: 0.18481430411338806\n",
            "Validation Loss: 0.19144466519355774\n",
            "\n",
            "Epoch 357/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1844 - val_loss: 0.1916\n",
            "Loss: 0.18439902365207672\n",
            "Validation Loss: 0.191562682390213\n",
            "\n",
            "Epoch 358/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1856 - val_loss: 0.1936\n",
            "Loss: 0.18557962775230408\n",
            "Validation Loss: 0.19361630082130432\n",
            "\n",
            "Epoch 359/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1843 - val_loss: 0.1897\n",
            "Loss: 0.18429909646511078\n",
            "Validation Loss: 0.1896529197692871\n",
            "\n",
            "Epoch 360/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1847 - val_loss: 0.1894\n",
            "Loss: 0.18472535908222198\n",
            "Validation Loss: 0.18938429653644562\n",
            "\n",
            "Epoch 361/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1842 - val_loss: 0.1918\n",
            "Loss: 0.1841781586408615\n",
            "Validation Loss: 0.1918143928050995\n",
            "\n",
            "Epoch 362/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1834 - val_loss: 0.1901\n",
            "Loss: 0.18340259790420532\n",
            "Validation Loss: 0.19006624817848206\n",
            "\n",
            "Epoch 363/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1854 - val_loss: 0.1891\n",
            "Loss: 0.18543031811714172\n",
            "Validation Loss: 0.18906618654727936\n",
            "\n",
            "Epoch 364/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1862 - val_loss: 0.1898\n",
            "Loss: 0.18616947531700134\n",
            "Validation Loss: 0.18984520435333252\n",
            "\n",
            "Epoch 365/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1844 - val_loss: 0.1908\n",
            "Loss: 0.1843508780002594\n",
            "Validation Loss: 0.19083279371261597\n",
            "\n",
            "Epoch 366/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1848 - val_loss: 0.1914\n",
            "Loss: 0.18481071293354034\n",
            "Validation Loss: 0.19144439697265625\n",
            "\n",
            "Epoch 367/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1834 - val_loss: 0.1892\n",
            "Loss: 0.18343938887119293\n",
            "Validation Loss: 0.18917076289653778\n",
            "\n",
            "Epoch 368/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1849 - val_loss: 0.1905\n",
            "Loss: 0.1848554164171219\n",
            "Validation Loss: 0.19051414728164673\n",
            "\n",
            "Epoch 369/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1843 - val_loss: 0.1918\n",
            "Loss: 0.18427437543869019\n",
            "Validation Loss: 0.1918065845966339\n",
            "\n",
            "Epoch 370/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1843 - val_loss: 0.1881\n",
            "Loss: 0.18432456254959106\n",
            "Validation Loss: 0.18805697560310364\n",
            "\n",
            "Epoch 371/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1837 - val_loss: 0.1910\n",
            "Loss: 0.18370674550533295\n",
            "Validation Loss: 0.1910221129655838\n",
            "\n",
            "Epoch 372/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1836 - val_loss: 0.1927\n",
            "Loss: 0.18364685773849487\n",
            "Validation Loss: 0.19274111092090607\n",
            "\n",
            "Epoch 373/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1842 - val_loss: 0.1869\n",
            "Loss: 0.1842448115348816\n",
            "Validation Loss: 0.1869148164987564\n",
            "\n",
            "Epoch 374/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1836 - val_loss: 0.1886\n",
            "Loss: 0.18360470235347748\n",
            "Validation Loss: 0.1885548084974289\n",
            "\n",
            "Epoch 375/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1837 - val_loss: 0.1902\n",
            "Loss: 0.18374082446098328\n",
            "Validation Loss: 0.19024145603179932\n",
            "\n",
            "Epoch 376/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1836 - val_loss: 0.1901\n",
            "Loss: 0.18357600271701813\n",
            "Validation Loss: 0.1901474893093109\n",
            "\n",
            "Epoch 377/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1855 - val_loss: 0.1907\n",
            "Loss: 0.18553131818771362\n",
            "Validation Loss: 0.19068752229213715\n",
            "\n",
            "Epoch 378/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1852 - val_loss: 0.1920\n",
            "Loss: 0.18517303466796875\n",
            "Validation Loss: 0.19200801849365234\n",
            "\n",
            "Epoch 379/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1840 - val_loss: 0.1905\n",
            "Loss: 0.18396763503551483\n",
            "Validation Loss: 0.19046510756015778\n",
            "\n",
            "Epoch 380/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1838 - val_loss: 0.1897\n",
            "Loss: 0.18376095592975616\n",
            "Validation Loss: 0.18968400359153748\n",
            "\n",
            "Epoch 381/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1836 - val_loss: 0.1901\n",
            "Loss: 0.18363207578659058\n",
            "Validation Loss: 0.19012361764907837\n",
            "\n",
            "Epoch 382/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1841 - val_loss: 0.1898\n",
            "Loss: 0.18406109511852264\n",
            "Validation Loss: 0.1897628754377365\n",
            "\n",
            "Epoch 383/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1826 - val_loss: 0.1917\n",
            "Loss: 0.18256449699401855\n",
            "Validation Loss: 0.1917177438735962\n",
            "\n",
            "Epoch 384/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1831 - val_loss: 0.1889\n",
            "Loss: 0.18314680457115173\n",
            "Validation Loss: 0.18891070783138275\n",
            "\n",
            "Epoch 385/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1843 - val_loss: 0.1895\n",
            "Loss: 0.18429714441299438\n",
            "Validation Loss: 0.18953891098499298\n",
            "\n",
            "Epoch 386/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1826 - val_loss: 0.1903\n",
            "Loss: 0.18260008096694946\n",
            "Validation Loss: 0.1902766078710556\n",
            "\n",
            "Epoch 387/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1845 - val_loss: 0.1915\n",
            "Loss: 0.18445760011672974\n",
            "Validation Loss: 0.1915387511253357\n",
            "\n",
            "Epoch 388/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1831 - val_loss: 0.1899\n",
            "Loss: 0.1830512434244156\n",
            "Validation Loss: 0.1899428516626358\n",
            "\n",
            "Epoch 389/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1832 - val_loss: 0.1878\n",
            "Loss: 0.18324217200279236\n",
            "Validation Loss: 0.18776552379131317\n",
            "\n",
            "Epoch 390/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1847 - val_loss: 0.1899\n",
            "Loss: 0.184665247797966\n",
            "Validation Loss: 0.18986020982265472\n",
            "\n",
            "Epoch 391/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1836 - val_loss: 0.1919\n",
            "Loss: 0.183595210313797\n",
            "Validation Loss: 0.19185768067836761\n",
            "\n",
            "Epoch 392/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1825 - val_loss: 0.1910\n",
            "Loss: 0.18253451585769653\n",
            "Validation Loss: 0.19102641940116882\n",
            "\n",
            "Epoch 393/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1825 - val_loss: 0.1910\n",
            "Loss: 0.1825496405363083\n",
            "Validation Loss: 0.19101598858833313\n",
            "\n",
            "Epoch 394/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1820 - val_loss: 0.1903\n",
            "Loss: 0.18204154074192047\n",
            "Validation Loss: 0.19031862914562225\n",
            "\n",
            "Epoch 395/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1821 - val_loss: 0.1887\n",
            "Loss: 0.18209625780582428\n",
            "Validation Loss: 0.18869780004024506\n",
            "\n",
            "Epoch 396/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1831 - val_loss: 0.1878\n",
            "Loss: 0.18312183022499084\n",
            "Validation Loss: 0.18776896595954895\n",
            "\n",
            "Epoch 397/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1836 - val_loss: 0.1899\n",
            "Loss: 0.18355488777160645\n",
            "Validation Loss: 0.1898837387561798\n",
            "\n",
            "Epoch 398/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1824 - val_loss: 0.1903\n",
            "Loss: 0.1823740452528\n",
            "Validation Loss: 0.19028358161449432\n",
            "\n",
            "Epoch 399/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1833 - val_loss: 0.1891\n",
            "Loss: 0.18333333730697632\n",
            "Validation Loss: 0.18906374275684357\n",
            "\n",
            "Epoch 400/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1822 - val_loss: 0.1897\n",
            "Loss: 0.18215703964233398\n",
            "Validation Loss: 0.18968340754508972\n",
            "\n",
            "Epoch 401/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1818 - val_loss: 0.1898\n",
            "Loss: 0.18178698420524597\n",
            "Validation Loss: 0.18982043862342834\n",
            "\n",
            "Epoch 402/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1828 - val_loss: 0.1886\n",
            "Loss: 0.18282826244831085\n",
            "Validation Loss: 0.18860125541687012\n",
            "\n",
            "Epoch 403/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1833 - val_loss: 0.1901\n",
            "Loss: 0.18332991003990173\n",
            "Validation Loss: 0.190081387758255\n",
            "\n",
            "Epoch 404/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1832 - val_loss: 0.1903\n",
            "Loss: 0.18323875963687897\n",
            "Validation Loss: 0.19027720391750336\n",
            "\n",
            "Epoch 405/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1818 - val_loss: 0.1884\n",
            "Loss: 0.18179868161678314\n",
            "Validation Loss: 0.1883828490972519\n",
            "\n",
            "Epoch 406/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1815 - val_loss: 0.1880\n",
            "Loss: 0.18149209022521973\n",
            "Validation Loss: 0.1879749745130539\n",
            "\n",
            "Epoch 407/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1819 - val_loss: 0.1867\n",
            "Loss: 0.1819029450416565\n",
            "Validation Loss: 0.18666864931583405\n",
            "\n",
            "Epoch 408/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1823 - val_loss: 0.1913\n",
            "Loss: 0.18234795331954956\n",
            "Validation Loss: 0.19134387373924255\n",
            "\n",
            "Epoch 409/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1827 - val_loss: 0.1895\n",
            "Loss: 0.1826818436384201\n",
            "Validation Loss: 0.18948611617088318\n",
            "\n",
            "Epoch 410/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1826 - val_loss: 0.1889\n",
            "Loss: 0.18262992799282074\n",
            "Validation Loss: 0.18894177675247192\n",
            "\n",
            "Epoch 411/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1818 - val_loss: 0.1873\n",
            "Loss: 0.18175587058067322\n",
            "Validation Loss: 0.1873069405555725\n",
            "\n",
            "Epoch 412/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1825 - val_loss: 0.1904\n",
            "Loss: 0.1825381964445114\n",
            "Validation Loss: 0.19036288559436798\n",
            "\n",
            "Epoch 413/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1828 - val_loss: 0.1898\n",
            "Loss: 0.18276259303092957\n",
            "Validation Loss: 0.18977364897727966\n",
            "\n",
            "Epoch 414/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1829 - val_loss: 0.1898\n",
            "Loss: 0.18293970823287964\n",
            "Validation Loss: 0.18982170522212982\n",
            "\n",
            "Epoch 415/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1833 - val_loss: 0.1890\n",
            "Loss: 0.1832519769668579\n",
            "Validation Loss: 0.18900826573371887\n",
            "\n",
            "Epoch 416/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1828 - val_loss: 0.1883\n",
            "Loss: 0.18283016979694366\n",
            "Validation Loss: 0.18830405175685883\n",
            "\n",
            "Epoch 417/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1818 - val_loss: 0.1899\n",
            "Loss: 0.1818399429321289\n",
            "Validation Loss: 0.18993674218654633\n",
            "\n",
            "Epoch 418/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1808 - val_loss: 0.1878\n",
            "Loss: 0.18083302676677704\n",
            "Validation Loss: 0.1877540796995163\n",
            "\n",
            "Epoch 419/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1812 - val_loss: 0.1884\n",
            "Loss: 0.18116338551044464\n",
            "Validation Loss: 0.18836534023284912\n",
            "\n",
            "Epoch 420/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1809 - val_loss: 0.1887\n",
            "Loss: 0.18089592456817627\n",
            "Validation Loss: 0.18874557316303253\n",
            "\n",
            "Epoch 421/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1801 - val_loss: 0.1917\n",
            "Loss: 0.1800617128610611\n",
            "Validation Loss: 0.1917012333869934\n",
            "\n",
            "Epoch 422/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1808 - val_loss: 0.1868\n",
            "Loss: 0.1808117926120758\n",
            "Validation Loss: 0.1867574006319046\n",
            "\n",
            "Epoch 423/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1809 - val_loss: 0.1871\n",
            "Loss: 0.1808856576681137\n",
            "Validation Loss: 0.1870635598897934\n",
            "\n",
            "Epoch 424/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1820 - val_loss: 0.1876\n",
            "Loss: 0.18197277188301086\n",
            "Validation Loss: 0.1876419186592102\n",
            "\n",
            "Epoch 425/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1801 - val_loss: 0.1863\n",
            "Loss: 0.18005605041980743\n",
            "Validation Loss: 0.18630877137184143\n",
            "\n",
            "Epoch 426/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1804 - val_loss: 0.1884\n",
            "Loss: 0.18041174113750458\n",
            "Validation Loss: 0.18837669491767883\n",
            "\n",
            "Epoch 427/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1807 - val_loss: 0.1883\n",
            "Loss: 0.18065020442008972\n",
            "Validation Loss: 0.18825006484985352\n",
            "\n",
            "Epoch 428/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1820 - val_loss: 0.1860\n",
            "Loss: 0.18195846676826477\n",
            "Validation Loss: 0.18598878383636475\n",
            "\n",
            "Epoch 429/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1805 - val_loss: 0.1893\n",
            "Loss: 0.18047644197940826\n",
            "Validation Loss: 0.1893090009689331\n",
            "\n",
            "Epoch 430/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1795 - val_loss: 0.1897\n",
            "Loss: 0.17954884469509125\n",
            "Validation Loss: 0.18970535695552826\n",
            "\n",
            "Epoch 431/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1804 - val_loss: 0.1876\n",
            "Loss: 0.18037444353103638\n",
            "Validation Loss: 0.18757863342761993\n",
            "\n",
            "Epoch 432/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1799 - val_loss: 0.1887\n",
            "Loss: 0.1798669695854187\n",
            "Validation Loss: 0.18869201838970184\n",
            "\n",
            "Epoch 433/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1797 - val_loss: 0.1870\n",
            "Loss: 0.17968952655792236\n",
            "Validation Loss: 0.18697398900985718\n",
            "\n",
            "Epoch 434/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1816 - val_loss: 0.1868\n",
            "Loss: 0.18160448968410492\n",
            "Validation Loss: 0.18682421743869781\n",
            "\n",
            "Epoch 435/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1799 - val_loss: 0.1851\n",
            "Loss: 0.17992576956748962\n",
            "Validation Loss: 0.18514816462993622\n",
            "\n",
            "Epoch 436/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1796 - val_loss: 0.1870\n",
            "Loss: 0.1796264499425888\n",
            "Validation Loss: 0.1869557499885559\n",
            "\n",
            "Epoch 437/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1803 - val_loss: 0.1862\n",
            "Loss: 0.18034851551055908\n",
            "Validation Loss: 0.18617546558380127\n",
            "\n",
            "Epoch 438/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1805 - val_loss: 0.1871\n",
            "Loss: 0.18049171566963196\n",
            "Validation Loss: 0.1870844066143036\n",
            "\n",
            "Epoch 439/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1801 - val_loss: 0.1871\n",
            "Loss: 0.18014124035835266\n",
            "Validation Loss: 0.18710502982139587\n",
            "\n",
            "Epoch 440/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1815 - val_loss: 0.1861\n",
            "Loss: 0.18146799504756927\n",
            "Validation Loss: 0.1861056238412857\n",
            "\n",
            "Epoch 441/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1799 - val_loss: 0.1851\n",
            "Loss: 0.17985473573207855\n",
            "Validation Loss: 0.18506748974323273\n",
            "\n",
            "Epoch 442/500\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.1820 - val_loss: 0.1866\n",
            "Loss: 0.18200314044952393\n",
            "Validation Loss: 0.18657082319259644\n",
            "\n",
            "Epoch 443/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1798 - val_loss: 0.1867\n",
            "Loss: 0.17979271709918976\n",
            "Validation Loss: 0.1866634339094162\n",
            "\n",
            "Epoch 444/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1808 - val_loss: 0.1865\n",
            "Loss: 0.18078236281871796\n",
            "Validation Loss: 0.18654154241085052\n",
            "\n",
            "Epoch 445/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1796 - val_loss: 0.1897\n",
            "Loss: 0.17957241833209991\n",
            "Validation Loss: 0.1896851807832718\n",
            "\n",
            "Epoch 446/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1805 - val_loss: 0.1882\n",
            "Loss: 0.180460587143898\n",
            "Validation Loss: 0.18819938600063324\n",
            "\n",
            "Epoch 447/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1792 - val_loss: 0.1857\n",
            "Loss: 0.1792488694190979\n",
            "Validation Loss: 0.18568547070026398\n",
            "\n",
            "Epoch 448/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1811 - val_loss: 0.1850\n",
            "Loss: 0.18113861978054047\n",
            "Validation Loss: 0.18501797318458557\n",
            "\n",
            "Epoch 449/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1809 - val_loss: 0.1878\n",
            "Loss: 0.1809265911579132\n",
            "Validation Loss: 0.18777208030223846\n",
            "\n",
            "Epoch 450/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1788 - val_loss: 0.1847\n",
            "Loss: 0.17877870798110962\n",
            "Validation Loss: 0.18472808599472046\n",
            "\n",
            "Epoch 451/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1797 - val_loss: 0.1858\n",
            "Loss: 0.1797371357679367\n",
            "Validation Loss: 0.1858174204826355\n",
            "\n",
            "Epoch 452/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1809 - val_loss: 0.1854\n",
            "Loss: 0.18086233735084534\n",
            "Validation Loss: 0.1853911578655243\n",
            "\n",
            "Epoch 453/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1788 - val_loss: 0.1892\n",
            "Loss: 0.17880378663539886\n",
            "Validation Loss: 0.18922489881515503\n",
            "\n",
            "Epoch 454/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1799 - val_loss: 0.1849\n",
            "Loss: 0.17990002036094666\n",
            "Validation Loss: 0.18492476642131805\n",
            "\n",
            "Epoch 455/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1786 - val_loss: 0.1873\n",
            "Loss: 0.17856794595718384\n",
            "Validation Loss: 0.18734638392925262\n",
            "\n",
            "Epoch 456/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1797 - val_loss: 0.1858\n",
            "Loss: 0.17973659932613373\n",
            "Validation Loss: 0.18577350676059723\n",
            "\n",
            "Epoch 457/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1795 - val_loss: 0.1880\n",
            "Loss: 0.1795172244310379\n",
            "Validation Loss: 0.18799945712089539\n",
            "\n",
            "Epoch 458/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1789 - val_loss: 0.1840\n",
            "Loss: 0.17887695133686066\n",
            "Validation Loss: 0.18400144577026367\n",
            "\n",
            "Epoch 459/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1804 - val_loss: 0.1866\n",
            "Loss: 0.18043525516986847\n",
            "Validation Loss: 0.186647430062294\n",
            "\n",
            "Epoch 460/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1777 - val_loss: 0.1871\n",
            "Loss: 0.17773285508155823\n",
            "Validation Loss: 0.1871388703584671\n",
            "\n",
            "Epoch 461/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1801 - val_loss: 0.1876\n",
            "Loss: 0.1800915151834488\n",
            "Validation Loss: 0.18762104213237762\n",
            "\n",
            "Epoch 462/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1806 - val_loss: 0.1861\n",
            "Loss: 0.1805667281150818\n",
            "Validation Loss: 0.1861288696527481\n",
            "\n",
            "Epoch 463/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1789 - val_loss: 0.1848\n",
            "Loss: 0.178910493850708\n",
            "Validation Loss: 0.18481971323490143\n",
            "\n",
            "Epoch 464/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1784 - val_loss: 0.1870\n",
            "Loss: 0.17844903469085693\n",
            "Validation Loss: 0.18696530163288116\n",
            "\n",
            "Epoch 465/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1793 - val_loss: 0.1858\n",
            "Loss: 0.1792742908000946\n",
            "Validation Loss: 0.1857510209083557\n",
            "\n",
            "Epoch 466/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1785 - val_loss: 0.1865\n",
            "Loss: 0.17850714921951294\n",
            "Validation Loss: 0.18654440343379974\n",
            "\n",
            "Epoch 467/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1788 - val_loss: 0.1865\n",
            "Loss: 0.1787710040807724\n",
            "Validation Loss: 0.18647463619709015\n",
            "\n",
            "Epoch 468/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1797 - val_loss: 0.1854\n",
            "Loss: 0.1797003448009491\n",
            "Validation Loss: 0.18535323441028595\n",
            "\n",
            "Epoch 469/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1786 - val_loss: 0.1859\n",
            "Loss: 0.17855490744113922\n",
            "Validation Loss: 0.18588438630104065\n",
            "\n",
            "Epoch 470/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1795 - val_loss: 0.1865\n",
            "Loss: 0.17948316037654877\n",
            "Validation Loss: 0.18650399148464203\n",
            "\n",
            "Epoch 471/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1789 - val_loss: 0.1862\n",
            "Loss: 0.17888787388801575\n",
            "Validation Loss: 0.1861865222454071\n",
            "\n",
            "Epoch 472/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1782 - val_loss: 0.1875\n",
            "Loss: 0.1781539022922516\n",
            "Validation Loss: 0.1874666064977646\n",
            "\n",
            "Epoch 473/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1793 - val_loss: 0.1846\n",
            "Loss: 0.17928385734558105\n",
            "Validation Loss: 0.18455879390239716\n",
            "\n",
            "Epoch 474/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1784 - val_loss: 0.1887\n",
            "Loss: 0.1784386932849884\n",
            "Validation Loss: 0.18872922658920288\n",
            "\n",
            "Epoch 475/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1798 - val_loss: 0.1857\n",
            "Loss: 0.17980307340621948\n",
            "Validation Loss: 0.18566922843456268\n",
            "\n",
            "Epoch 476/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1782 - val_loss: 0.1853\n",
            "Loss: 0.17822469770908356\n",
            "Validation Loss: 0.18534930050373077\n",
            "\n",
            "Epoch 477/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1782 - val_loss: 0.1861\n",
            "Loss: 0.17822332680225372\n",
            "Validation Loss: 0.1860630065202713\n",
            "\n",
            "Epoch 478/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1798 - val_loss: 0.1868\n",
            "Loss: 0.17977647483348846\n",
            "Validation Loss: 0.18682120740413666\n",
            "\n",
            "Epoch 479/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1789 - val_loss: 0.1869\n",
            "Loss: 0.17892229557037354\n",
            "Validation Loss: 0.1869247704744339\n",
            "\n",
            "Epoch 480/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1787 - val_loss: 0.1861\n",
            "Loss: 0.17872631549835205\n",
            "Validation Loss: 0.18609417974948883\n",
            "\n",
            "Epoch 481/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1798 - val_loss: 0.1852\n",
            "Loss: 0.17981268465518951\n",
            "Validation Loss: 0.18524529039859772\n",
            "\n",
            "Epoch 482/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1778 - val_loss: 0.1874\n",
            "Loss: 0.1777707040309906\n",
            "Validation Loss: 0.18738825619220734\n",
            "\n",
            "Epoch 483/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1791 - val_loss: 0.1853\n",
            "Loss: 0.1791207194328308\n",
            "Validation Loss: 0.18527036905288696\n",
            "\n",
            "Epoch 484/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1781 - val_loss: 0.1839\n",
            "Loss: 0.1780521273612976\n",
            "Validation Loss: 0.18394772708415985\n",
            "\n",
            "Epoch 485/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1780 - val_loss: 0.1857\n",
            "Loss: 0.17797710001468658\n",
            "Validation Loss: 0.18573443591594696\n",
            "\n",
            "Epoch 486/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1788 - val_loss: 0.1859\n",
            "Loss: 0.17875653505325317\n",
            "Validation Loss: 0.1859091818332672\n",
            "\n",
            "Epoch 487/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1789 - val_loss: 0.1853\n",
            "Loss: 0.17891009151935577\n",
            "Validation Loss: 0.18531356751918793\n",
            "\n",
            "Epoch 488/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1790 - val_loss: 0.1868\n",
            "Loss: 0.17901252210140228\n",
            "Validation Loss: 0.18675728142261505\n",
            "\n",
            "Epoch 489/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1777 - val_loss: 0.1840\n",
            "Loss: 0.177679643034935\n",
            "Validation Loss: 0.18400871753692627\n",
            "\n",
            "Epoch 490/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1784 - val_loss: 0.1867\n",
            "Loss: 0.17842286825180054\n",
            "Validation Loss: 0.18667925894260406\n",
            "\n",
            "Epoch 491/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1774 - val_loss: 0.1863\n",
            "Loss: 0.17744536697864532\n",
            "Validation Loss: 0.18633845448493958\n",
            "\n",
            "Epoch 492/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1798 - val_loss: 0.1856\n",
            "Loss: 0.1797829121351242\n",
            "Validation Loss: 0.18562470376491547\n",
            "\n",
            "Epoch 493/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1775 - val_loss: 0.1859\n",
            "Loss: 0.17750194668769836\n",
            "Validation Loss: 0.18589405715465546\n",
            "\n",
            "Epoch 494/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1776 - val_loss: 0.1866\n",
            "Loss: 0.17761822044849396\n",
            "Validation Loss: 0.18662147223949432\n",
            "\n",
            "Epoch 495/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1779 - val_loss: 0.1863\n",
            "Loss: 0.1779094934463501\n",
            "Validation Loss: 0.18625250458717346\n",
            "\n",
            "Epoch 496/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1770 - val_loss: 0.1852\n",
            "Loss: 0.17697955667972565\n",
            "Validation Loss: 0.1851813942193985\n",
            "\n",
            "Epoch 497/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1785 - val_loss: 0.1837\n",
            "Loss: 0.17847740650177002\n",
            "Validation Loss: 0.1836986243724823\n",
            "\n",
            "Epoch 498/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1773 - val_loss: 0.1856\n",
            "Loss: 0.17733629047870636\n",
            "Validation Loss: 0.18559513986110687\n",
            "\n",
            "Epoch 499/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1773 - val_loss: 0.1884\n",
            "Loss: 0.17725242674350739\n",
            "Validation Loss: 0.18835380673408508\n",
            "\n",
            "Epoch 500/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1768 - val_loss: 0.1874\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1767531782388687\n",
            "Validation Loss: 0.1874268651008606\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 5, 128)       73216       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer_4 (AttentionLa  (None, 128)         128         ['lstm_4[0][0]',                 \n",
            " yer)                                                             'lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 128)       0           ['attention_layer_4[0][0]']      \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 1, 1)        129         ['reshape_1[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.7496 - val_loss: 0.4399\n",
            "Loss: 0.7496250867843628\n",
            "Validation Loss: 0.4399423599243164\n",
            "\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.4158 - val_loss: 0.3517\n",
            "Loss: 0.41578441858291626\n",
            "Validation Loss: 0.35169392824172974\n",
            "\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3693 - val_loss: 0.3196\n",
            "Loss: 0.3693224787712097\n",
            "Validation Loss: 0.31964126229286194\n",
            "\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.3551 - val_loss: 0.3097\n",
            "Loss: 0.35510706901550293\n",
            "Validation Loss: 0.3097466826438904\n",
            "\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.3447 - val_loss: 0.3033\n",
            "Loss: 0.34470149874687195\n",
            "Validation Loss: 0.30333057045936584\n",
            "\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3326 - val_loss: 0.2961\n",
            "Loss: 0.3325590491294861\n",
            "Validation Loss: 0.29605579376220703\n",
            "\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3236 - val_loss: 0.2884\n",
            "Loss: 0.32363319396972656\n",
            "Validation Loss: 0.2884400188922882\n",
            "\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3253 - val_loss: 0.2882\n",
            "Loss: 0.3253323435783386\n",
            "Validation Loss: 0.28824782371520996\n",
            "\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.3278 - val_loss: 0.2864\n",
            "Loss: 0.3277934491634369\n",
            "Validation Loss: 0.2863534986972809\n",
            "\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3197 - val_loss: 0.2822\n",
            "Loss: 0.3197358548641205\n",
            "Validation Loss: 0.2822158634662628\n",
            "\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3184 - val_loss: 0.2781\n",
            "Loss: 0.3183741569519043\n",
            "Validation Loss: 0.2780594825744629\n",
            "\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.3142 - val_loss: 0.2782\n",
            "Loss: 0.3141510784626007\n",
            "Validation Loss: 0.2782445251941681\n",
            "\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.3104 - val_loss: 0.2774\n",
            "Loss: 0.31038960814476013\n",
            "Validation Loss: 0.2773786783218384\n",
            "\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3113 - val_loss: 0.2765\n",
            "Loss: 0.31133532524108887\n",
            "Validation Loss: 0.27649328112602234\n",
            "\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3104 - val_loss: 0.2752\n",
            "Loss: 0.31038761138916016\n",
            "Validation Loss: 0.2752108871936798\n",
            "\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3060 - val_loss: 0.2748\n",
            "Loss: 0.30601391196250916\n",
            "Validation Loss: 0.2747856080532074\n",
            "\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.3046 - val_loss: 0.2733\n",
            "Loss: 0.3046344816684723\n",
            "Validation Loss: 0.27326467633247375\n",
            "\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3020 - val_loss: 0.2727\n",
            "Loss: 0.30201706290245056\n",
            "Validation Loss: 0.27272677421569824\n",
            "\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.3032 - val_loss: 0.2738\n",
            "Loss: 0.30321356654167175\n",
            "Validation Loss: 0.2738180160522461\n",
            "\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2984 - val_loss: 0.2691\n",
            "Loss: 0.2984078526496887\n",
            "Validation Loss: 0.2690528631210327\n",
            "\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2963 - val_loss: 0.2696\n",
            "Loss: 0.29625052213668823\n",
            "Validation Loss: 0.26964354515075684\n",
            "\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2964 - val_loss: 0.2694\n",
            "Loss: 0.29640933871269226\n",
            "Validation Loss: 0.26943573355674744\n",
            "\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2948 - val_loss: 0.2692\n",
            "Loss: 0.2947552502155304\n",
            "Validation Loss: 0.269168883562088\n",
            "\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2905 - val_loss: 0.2663\n",
            "Loss: 0.2904936373233795\n",
            "Validation Loss: 0.26626354455947876\n",
            "\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2923 - val_loss: 0.2716\n",
            "Loss: 0.2922695279121399\n",
            "Validation Loss: 0.27158769965171814\n",
            "\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2893 - val_loss: 0.2640\n",
            "Loss: 0.28932979702949524\n",
            "Validation Loss: 0.26404112577438354\n",
            "\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2864 - val_loss: 0.2644\n",
            "Loss: 0.28644493222236633\n",
            "Validation Loss: 0.2644363343715668\n",
            "\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2880 - val_loss: 0.2625\n",
            "Loss: 0.2880460321903229\n",
            "Validation Loss: 0.2624656856060028\n",
            "\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2850 - val_loss: 0.2621\n",
            "Loss: 0.2850450873374939\n",
            "Validation Loss: 0.2621229588985443\n",
            "\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2834 - val_loss: 0.2607\n",
            "Loss: 0.2833802103996277\n",
            "Validation Loss: 0.2606944739818573\n",
            "\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2853 - val_loss: 0.2599\n",
            "Loss: 0.28531157970428467\n",
            "Validation Loss: 0.25994399189949036\n",
            "\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2824 - val_loss: 0.2587\n",
            "Loss: 0.28237202763557434\n",
            "Validation Loss: 0.2586835026741028\n",
            "\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2852 - val_loss: 0.2612\n",
            "Loss: 0.28522706031799316\n",
            "Validation Loss: 0.26119476556777954\n",
            "\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2845 - val_loss: 0.2591\n",
            "Loss: 0.28449898958206177\n",
            "Validation Loss: 0.25905460119247437\n",
            "\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2791 - val_loss: 0.2573\n",
            "Loss: 0.27905043959617615\n",
            "Validation Loss: 0.2572631239891052\n",
            "\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2791 - val_loss: 0.2545\n",
            "Loss: 0.279084712266922\n",
            "Validation Loss: 0.25449320673942566\n",
            "\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2790 - val_loss: 0.2546\n",
            "Loss: 0.2790302038192749\n",
            "Validation Loss: 0.25464361906051636\n",
            "\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2774 - val_loss: 0.2607\n",
            "Loss: 0.27743247151374817\n",
            "Validation Loss: 0.26067930459976196\n",
            "\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2762 - val_loss: 0.2558\n",
            "Loss: 0.2762022614479065\n",
            "Validation Loss: 0.25581151247024536\n",
            "\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2757 - val_loss: 0.2533\n",
            "Loss: 0.27570033073425293\n",
            "Validation Loss: 0.25329673290252686\n",
            "\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2777 - val_loss: 0.2562\n",
            "Loss: 0.2776767611503601\n",
            "Validation Loss: 0.2561523914337158\n",
            "\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2770 - val_loss: 0.2536\n",
            "Loss: 0.2770395576953888\n",
            "Validation Loss: 0.2535954713821411\n",
            "\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2739 - val_loss: 0.2550\n",
            "Loss: 0.2739277184009552\n",
            "Validation Loss: 0.25504690408706665\n",
            "\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2756 - val_loss: 0.2514\n",
            "Loss: 0.27562928199768066\n",
            "Validation Loss: 0.2513968348503113\n",
            "\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2735 - val_loss: 0.2520\n",
            "Loss: 0.27354806661605835\n",
            "Validation Loss: 0.2520061731338501\n",
            "\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2718 - val_loss: 0.2483\n",
            "Loss: 0.27182623744010925\n",
            "Validation Loss: 0.2482909858226776\n",
            "\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2725 - val_loss: 0.2526\n",
            "Loss: 0.2725127637386322\n",
            "Validation Loss: 0.2525738775730133\n",
            "\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2700 - val_loss: 0.2537\n",
            "Loss: 0.27000242471694946\n",
            "Validation Loss: 0.25369319319725037\n",
            "\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2723 - val_loss: 0.2508\n",
            "Loss: 0.27225548028945923\n",
            "Validation Loss: 0.250788152217865\n",
            "\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2689 - val_loss: 0.2487\n",
            "Loss: 0.2688884139060974\n",
            "Validation Loss: 0.24870969355106354\n",
            "\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2690 - val_loss: 0.2487\n",
            "Loss: 0.2689633369445801\n",
            "Validation Loss: 0.2486599236726761\n",
            "\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2681 - val_loss: 0.2487\n",
            "Loss: 0.2681281864643097\n",
            "Validation Loss: 0.2486761510372162\n",
            "\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2671 - val_loss: 0.2494\n",
            "Loss: 0.26706773042678833\n",
            "Validation Loss: 0.24943846464157104\n",
            "\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2682 - val_loss: 0.2475\n",
            "Loss: 0.2681657671928406\n",
            "Validation Loss: 0.24750687181949615\n",
            "\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2653 - val_loss: 0.2458\n",
            "Loss: 0.2652551233768463\n",
            "Validation Loss: 0.24575012922286987\n",
            "\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2653 - val_loss: 0.2488\n",
            "Loss: 0.2653437554836273\n",
            "Validation Loss: 0.24875342845916748\n",
            "\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2643 - val_loss: 0.2452\n",
            "Loss: 0.26434335112571716\n",
            "Validation Loss: 0.24519601464271545\n",
            "\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2632 - val_loss: 0.2448\n",
            "Loss: 0.26321330666542053\n",
            "Validation Loss: 0.24484102427959442\n",
            "\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2622 - val_loss: 0.2487\n",
            "Loss: 0.26221540570259094\n",
            "Validation Loss: 0.2487359344959259\n",
            "\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2624 - val_loss: 0.2457\n",
            "Loss: 0.2623889446258545\n",
            "Validation Loss: 0.24568311870098114\n",
            "\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2656 - val_loss: 0.2447\n",
            "Loss: 0.26563766598701477\n",
            "Validation Loss: 0.24469642341136932\n",
            "\n",
            "Epoch 62/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2625 - val_loss: 0.2428\n",
            "Loss: 0.2624529302120209\n",
            "Validation Loss: 0.24281451106071472\n",
            "\n",
            "Epoch 63/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2592 - val_loss: 0.2449\n",
            "Loss: 0.25921571254730225\n",
            "Validation Loss: 0.24491149187088013\n",
            "\n",
            "Epoch 64/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2613 - val_loss: 0.2462\n",
            "Loss: 0.26128000020980835\n",
            "Validation Loss: 0.24616524577140808\n",
            "\n",
            "Epoch 65/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2601 - val_loss: 0.2429\n",
            "Loss: 0.2600618302822113\n",
            "Validation Loss: 0.24294458329677582\n",
            "\n",
            "Epoch 66/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2590 - val_loss: 0.2450\n",
            "Loss: 0.25901755690574646\n",
            "Validation Loss: 0.2449830323457718\n",
            "\n",
            "Epoch 67/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2603 - val_loss: 0.2414\n",
            "Loss: 0.26025840640068054\n",
            "Validation Loss: 0.24140819907188416\n",
            "\n",
            "Epoch 68/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2601 - val_loss: 0.2432\n",
            "Loss: 0.2601171135902405\n",
            "Validation Loss: 0.24316322803497314\n",
            "\n",
            "Epoch 69/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2606 - val_loss: 0.2399\n",
            "Loss: 0.26055294275283813\n",
            "Validation Loss: 0.23992520570755005\n",
            "\n",
            "Epoch 70/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2550 - val_loss: 0.2402\n",
            "Loss: 0.25501835346221924\n",
            "Validation Loss: 0.2402474284172058\n",
            "\n",
            "Epoch 71/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2565 - val_loss: 0.2442\n",
            "Loss: 0.25653210282325745\n",
            "Validation Loss: 0.24415327608585358\n",
            "\n",
            "Epoch 72/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2567 - val_loss: 0.2431\n",
            "Loss: 0.25672009587287903\n",
            "Validation Loss: 0.24309615790843964\n",
            "\n",
            "Epoch 73/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2545 - val_loss: 0.2425\n",
            "Loss: 0.25446629524230957\n",
            "Validation Loss: 0.2424951195716858\n",
            "\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2557 - val_loss: 0.2407\n",
            "Loss: 0.2556779682636261\n",
            "Validation Loss: 0.24067671597003937\n",
            "\n",
            "Epoch 75/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2543 - val_loss: 0.2408\n",
            "Loss: 0.25425276160240173\n",
            "Validation Loss: 0.24083270132541656\n",
            "\n",
            "Epoch 76/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2565 - val_loss: 0.2393\n",
            "Loss: 0.25652626156806946\n",
            "Validation Loss: 0.23926164209842682\n",
            "\n",
            "Epoch 77/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2542 - val_loss: 0.2392\n",
            "Loss: 0.2542165219783783\n",
            "Validation Loss: 0.23918834328651428\n",
            "\n",
            "Epoch 78/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2553 - val_loss: 0.2465\n",
            "Loss: 0.25527089834213257\n",
            "Validation Loss: 0.2464873492717743\n",
            "\n",
            "Epoch 79/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2555 - val_loss: 0.2424\n",
            "Loss: 0.25549444556236267\n",
            "Validation Loss: 0.24242231249809265\n",
            "\n",
            "Epoch 80/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2529 - val_loss: 0.2358\n",
            "Loss: 0.2529488503932953\n",
            "Validation Loss: 0.23578770458698273\n",
            "\n",
            "Epoch 81/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2520 - val_loss: 0.2369\n",
            "Loss: 0.2520201802253723\n",
            "Validation Loss: 0.23688633739948273\n",
            "\n",
            "Epoch 82/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2511 - val_loss: 0.2385\n",
            "Loss: 0.25107795000076294\n",
            "Validation Loss: 0.23846974968910217\n",
            "\n",
            "Epoch 83/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2508 - val_loss: 0.2348\n",
            "Loss: 0.25083619356155396\n",
            "Validation Loss: 0.23480422794818878\n",
            "\n",
            "Epoch 84/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2521 - val_loss: 0.2364\n",
            "Loss: 0.2520674467086792\n",
            "Validation Loss: 0.23643405735492706\n",
            "\n",
            "Epoch 85/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2519 - val_loss: 0.2360\n",
            "Loss: 0.25189849734306335\n",
            "Validation Loss: 0.2360140085220337\n",
            "\n",
            "Epoch 86/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2501 - val_loss: 0.2377\n",
            "Loss: 0.2500686049461365\n",
            "Validation Loss: 0.23772889375686646\n",
            "\n",
            "Epoch 87/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2489 - val_loss: 0.2348\n",
            "Loss: 0.24888759851455688\n",
            "Validation Loss: 0.23475798964500427\n",
            "\n",
            "Epoch 88/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2489 - val_loss: 0.2340\n",
            "Loss: 0.24890147149562836\n",
            "Validation Loss: 0.23399163782596588\n",
            "\n",
            "Epoch 89/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2496 - val_loss: 0.2351\n",
            "Loss: 0.24962110817432404\n",
            "Validation Loss: 0.23511099815368652\n",
            "\n",
            "Epoch 90/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2481 - val_loss: 0.2351\n",
            "Loss: 0.2481178343296051\n",
            "Validation Loss: 0.23511171340942383\n",
            "\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2485 - val_loss: 0.2372\n",
            "Loss: 0.2484593540430069\n",
            "Validation Loss: 0.2372152954339981\n",
            "\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2488 - val_loss: 0.2334\n",
            "Loss: 0.2488371729850769\n",
            "Validation Loss: 0.23335924744606018\n",
            "\n",
            "Epoch 93/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2489 - val_loss: 0.2319\n",
            "Loss: 0.2489277869462967\n",
            "Validation Loss: 0.231864333152771\n",
            "\n",
            "Epoch 94/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2461 - val_loss: 0.2340\n",
            "Loss: 0.2460828423500061\n",
            "Validation Loss: 0.2340347021818161\n",
            "\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2473 - val_loss: 0.2325\n",
            "Loss: 0.2472507208585739\n",
            "Validation Loss: 0.23247018456459045\n",
            "\n",
            "Epoch 96/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2470 - val_loss: 0.2320\n",
            "Loss: 0.24696387350559235\n",
            "Validation Loss: 0.23199516534805298\n",
            "\n",
            "Epoch 97/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2451 - val_loss: 0.2326\n",
            "Loss: 0.24511930346488953\n",
            "Validation Loss: 0.232574924826622\n",
            "\n",
            "Epoch 98/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2454 - val_loss: 0.2357\n",
            "Loss: 0.24538283050060272\n",
            "Validation Loss: 0.23568707704544067\n",
            "\n",
            "Epoch 99/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2456 - val_loss: 0.2320\n",
            "Loss: 0.24559660255908966\n",
            "Validation Loss: 0.2319694608449936\n",
            "\n",
            "Epoch 100/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2462 - val_loss: 0.2311\n",
            "Loss: 0.2462080717086792\n",
            "Validation Loss: 0.23110786080360413\n",
            "\n",
            "Epoch 101/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2453 - val_loss: 0.2352\n",
            "Loss: 0.24529573321342468\n",
            "Validation Loss: 0.23515555262565613\n",
            "\n",
            "Epoch 102/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2438 - val_loss: 0.2323\n",
            "Loss: 0.24377582967281342\n",
            "Validation Loss: 0.23232799768447876\n",
            "\n",
            "Epoch 103/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2428 - val_loss: 0.2333\n",
            "Loss: 0.24279449880123138\n",
            "Validation Loss: 0.23325031995773315\n",
            "\n",
            "Epoch 104/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2440 - val_loss: 0.2314\n",
            "Loss: 0.24395161867141724\n",
            "Validation Loss: 0.2314290851354599\n",
            "\n",
            "Epoch 105/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2435 - val_loss: 0.2338\n",
            "Loss: 0.24353936314582825\n",
            "Validation Loss: 0.23376935720443726\n",
            "\n",
            "Epoch 106/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2450 - val_loss: 0.2283\n",
            "Loss: 0.24497368931770325\n",
            "Validation Loss: 0.2283380776643753\n",
            "\n",
            "Epoch 107/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2428 - val_loss: 0.2264\n",
            "Loss: 0.24283374845981598\n",
            "Validation Loss: 0.22639891505241394\n",
            "\n",
            "Epoch 108/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2426 - val_loss: 0.2325\n",
            "Loss: 0.242619127035141\n",
            "Validation Loss: 0.23249273002147675\n",
            "\n",
            "Epoch 109/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2446 - val_loss: 0.2317\n",
            "Loss: 0.24462419748306274\n",
            "Validation Loss: 0.23166707158088684\n",
            "\n",
            "Epoch 110/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2413 - val_loss: 0.2325\n",
            "Loss: 0.2412647008895874\n",
            "Validation Loss: 0.2324685901403427\n",
            "\n",
            "Epoch 111/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2434 - val_loss: 0.2284\n",
            "Loss: 0.24343319237232208\n",
            "Validation Loss: 0.2283681333065033\n",
            "\n",
            "Epoch 112/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2408 - val_loss: 0.2287\n",
            "Loss: 0.24080759286880493\n",
            "Validation Loss: 0.2287053018808365\n",
            "\n",
            "Epoch 113/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2416 - val_loss: 0.2276\n",
            "Loss: 0.2416197955608368\n",
            "Validation Loss: 0.22758638858795166\n",
            "\n",
            "Epoch 114/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2408 - val_loss: 0.2341\n",
            "Loss: 0.24078670144081116\n",
            "Validation Loss: 0.2340814620256424\n",
            "\n",
            "Epoch 115/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2410 - val_loss: 0.2256\n",
            "Loss: 0.24102024734020233\n",
            "Validation Loss: 0.2256360948085785\n",
            "\n",
            "Epoch 116/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2391 - val_loss: 0.2277\n",
            "Loss: 0.23906861245632172\n",
            "Validation Loss: 0.2276531308889389\n",
            "\n",
            "Epoch 117/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2395 - val_loss: 0.2258\n",
            "Loss: 0.239545539021492\n",
            "Validation Loss: 0.2258022129535675\n",
            "\n",
            "Epoch 118/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2393 - val_loss: 0.2284\n",
            "Loss: 0.2393091320991516\n",
            "Validation Loss: 0.22838492691516876\n",
            "\n",
            "Epoch 119/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2404 - val_loss: 0.2265\n",
            "Loss: 0.2404051274061203\n",
            "Validation Loss: 0.2265496850013733\n",
            "\n",
            "Epoch 120/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2378 - val_loss: 0.2258\n",
            "Loss: 0.23778900504112244\n",
            "Validation Loss: 0.22584664821624756\n",
            "\n",
            "Epoch 121/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2388 - val_loss: 0.2240\n",
            "Loss: 0.2388477474451065\n",
            "Validation Loss: 0.22401027381420135\n",
            "\n",
            "Epoch 122/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2375 - val_loss: 0.2258\n",
            "Loss: 0.23749937117099762\n",
            "Validation Loss: 0.22576040029525757\n",
            "\n",
            "Epoch 123/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2400 - val_loss: 0.2267\n",
            "Loss: 0.24003702402114868\n",
            "Validation Loss: 0.22671785950660706\n",
            "\n",
            "Epoch 124/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2382 - val_loss: 0.2270\n",
            "Loss: 0.2381746768951416\n",
            "Validation Loss: 0.22703038156032562\n",
            "\n",
            "Epoch 125/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2380 - val_loss: 0.2264\n",
            "Loss: 0.23802930116653442\n",
            "Validation Loss: 0.22642740607261658\n",
            "\n",
            "Epoch 126/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2374 - val_loss: 0.2252\n",
            "Loss: 0.2373592108488083\n",
            "Validation Loss: 0.22523415088653564\n",
            "\n",
            "Epoch 127/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2360 - val_loss: 0.2264\n",
            "Loss: 0.23599663376808167\n",
            "Validation Loss: 0.22636565566062927\n",
            "\n",
            "Epoch 128/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2375 - val_loss: 0.2296\n",
            "Loss: 0.23747670650482178\n",
            "Validation Loss: 0.22958286106586456\n",
            "\n",
            "Epoch 129/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2358 - val_loss: 0.2229\n",
            "Loss: 0.23582227528095245\n",
            "Validation Loss: 0.22286729514598846\n",
            "\n",
            "Epoch 130/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2355 - val_loss: 0.2219\n",
            "Loss: 0.23550522327423096\n",
            "Validation Loss: 0.22186055779457092\n",
            "\n",
            "Epoch 131/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2364 - val_loss: 0.2238\n",
            "Loss: 0.23640187084674835\n",
            "Validation Loss: 0.22381660342216492\n",
            "\n",
            "Epoch 132/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2348 - val_loss: 0.2241\n",
            "Loss: 0.23482248187065125\n",
            "Validation Loss: 0.2240564227104187\n",
            "\n",
            "Epoch 133/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2349 - val_loss: 0.2227\n",
            "Loss: 0.2349144071340561\n",
            "Validation Loss: 0.22268925607204437\n",
            "\n",
            "Epoch 134/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2353 - val_loss: 0.2223\n",
            "Loss: 0.2353001832962036\n",
            "Validation Loss: 0.22228030860424042\n",
            "\n",
            "Epoch 135/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2355 - val_loss: 0.2232\n",
            "Loss: 0.23553697764873505\n",
            "Validation Loss: 0.22317872941493988\n",
            "\n",
            "Epoch 136/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2326 - val_loss: 0.2240\n",
            "Loss: 0.23261158168315887\n",
            "Validation Loss: 0.22397258877754211\n",
            "\n",
            "Epoch 137/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2336 - val_loss: 0.2223\n",
            "Loss: 0.23359666764736176\n",
            "Validation Loss: 0.22231566905975342\n",
            "\n",
            "Epoch 138/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2345 - val_loss: 0.2209\n",
            "Loss: 0.2344621866941452\n",
            "Validation Loss: 0.22087311744689941\n",
            "\n",
            "Epoch 139/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2329 - val_loss: 0.2223\n",
            "Loss: 0.23294374346733093\n",
            "Validation Loss: 0.2222823202610016\n",
            "\n",
            "Epoch 140/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2341 - val_loss: 0.2227\n",
            "Loss: 0.23411276936531067\n",
            "Validation Loss: 0.2226881980895996\n",
            "\n",
            "Epoch 141/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2335 - val_loss: 0.2237\n",
            "Loss: 0.233475923538208\n",
            "Validation Loss: 0.22374022006988525\n",
            "\n",
            "Epoch 142/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2337 - val_loss: 0.2210\n",
            "Loss: 0.23367410898208618\n",
            "Validation Loss: 0.22095969319343567\n",
            "\n",
            "Epoch 143/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2322 - val_loss: 0.2235\n",
            "Loss: 0.232181578874588\n",
            "Validation Loss: 0.2235470414161682\n",
            "\n",
            "Epoch 144/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2321 - val_loss: 0.2199\n",
            "Loss: 0.2320862114429474\n",
            "Validation Loss: 0.21994495391845703\n",
            "\n",
            "Epoch 145/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2336 - val_loss: 0.2221\n",
            "Loss: 0.23364414274692535\n",
            "Validation Loss: 0.2221062034368515\n",
            "\n",
            "Epoch 146/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2312 - val_loss: 0.2199\n",
            "Loss: 0.23117251694202423\n",
            "Validation Loss: 0.2199074774980545\n",
            "\n",
            "Epoch 147/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2304 - val_loss: 0.2195\n",
            "Loss: 0.2303718775510788\n",
            "Validation Loss: 0.21947188675403595\n",
            "\n",
            "Epoch 148/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2315 - val_loss: 0.2213\n",
            "Loss: 0.2314898669719696\n",
            "Validation Loss: 0.2212645709514618\n",
            "\n",
            "Epoch 149/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2295 - val_loss: 0.2220\n",
            "Loss: 0.22947371006011963\n",
            "Validation Loss: 0.22198495268821716\n",
            "\n",
            "Epoch 150/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2315 - val_loss: 0.2176\n",
            "Loss: 0.23152491450309753\n",
            "Validation Loss: 0.2176402360200882\n",
            "\n",
            "Epoch 151/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2312 - val_loss: 0.2214\n",
            "Loss: 0.23123130202293396\n",
            "Validation Loss: 0.22138063609600067\n",
            "\n",
            "Epoch 152/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2294 - val_loss: 0.2206\n",
            "Loss: 0.22943420708179474\n",
            "Validation Loss: 0.22062624990940094\n",
            "\n",
            "Epoch 153/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2297 - val_loss: 0.2186\n",
            "Loss: 0.22966605424880981\n",
            "Validation Loss: 0.2185756117105484\n",
            "\n",
            "Epoch 154/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2303 - val_loss: 0.2195\n",
            "Loss: 0.2302786111831665\n",
            "Validation Loss: 0.2195155918598175\n",
            "\n",
            "Epoch 155/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2289 - val_loss: 0.2176\n",
            "Loss: 0.22894369065761566\n",
            "Validation Loss: 0.2175920307636261\n",
            "\n",
            "Epoch 156/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2287 - val_loss: 0.2161\n",
            "Loss: 0.22866562008857727\n",
            "Validation Loss: 0.2161085456609726\n",
            "\n",
            "Epoch 157/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2283 - val_loss: 0.2210\n",
            "Loss: 0.22826890647411346\n",
            "Validation Loss: 0.2210082709789276\n",
            "\n",
            "Epoch 158/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2285 - val_loss: 0.2173\n",
            "Loss: 0.22853180766105652\n",
            "Validation Loss: 0.21733759343624115\n",
            "\n",
            "Epoch 159/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2299 - val_loss: 0.2170\n",
            "Loss: 0.22985202074050903\n",
            "Validation Loss: 0.2169995903968811\n",
            "\n",
            "Epoch 160/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2269 - val_loss: 0.2180\n",
            "Loss: 0.22694231569766998\n",
            "Validation Loss: 0.2180279940366745\n",
            "\n",
            "Epoch 161/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2295 - val_loss: 0.2177\n",
            "Loss: 0.22954535484313965\n",
            "Validation Loss: 0.21767577528953552\n",
            "\n",
            "Epoch 162/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2264 - val_loss: 0.2170\n",
            "Loss: 0.22637556493282318\n",
            "Validation Loss: 0.21698057651519775\n",
            "\n",
            "Epoch 163/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2263 - val_loss: 0.2148\n",
            "Loss: 0.22627414762973785\n",
            "Validation Loss: 0.2148095667362213\n",
            "\n",
            "Epoch 164/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2265 - val_loss: 0.2167\n",
            "Loss: 0.22648224234580994\n",
            "Validation Loss: 0.21668656170368195\n",
            "\n",
            "Epoch 165/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2270 - val_loss: 0.2199\n",
            "Loss: 0.2270219475030899\n",
            "Validation Loss: 0.2198839634656906\n",
            "\n",
            "Epoch 166/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2278 - val_loss: 0.2166\n",
            "Loss: 0.2277878075838089\n",
            "Validation Loss: 0.21661116182804108\n",
            "\n",
            "Epoch 167/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2277 - val_loss: 0.2167\n",
            "Loss: 0.22767803072929382\n",
            "Validation Loss: 0.21667295694351196\n",
            "\n",
            "Epoch 168/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2246 - val_loss: 0.2159\n",
            "Loss: 0.22457201778888702\n",
            "Validation Loss: 0.21594440937042236\n",
            "\n",
            "Epoch 169/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2270 - val_loss: 0.2166\n",
            "Loss: 0.22697851061820984\n",
            "Validation Loss: 0.2165786623954773\n",
            "\n",
            "Epoch 170/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2245 - val_loss: 0.2141\n",
            "Loss: 0.22447365522384644\n",
            "Validation Loss: 0.21407347917556763\n",
            "\n",
            "Epoch 171/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2255 - val_loss: 0.2148\n",
            "Loss: 0.2255200892686844\n",
            "Validation Loss: 0.21483680605888367\n",
            "\n",
            "Epoch 172/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2256 - val_loss: 0.2145\n",
            "Loss: 0.2256442755460739\n",
            "Validation Loss: 0.21445974707603455\n",
            "\n",
            "Epoch 173/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2256 - val_loss: 0.2149\n",
            "Loss: 0.22556735575199127\n",
            "Validation Loss: 0.2149272859096527\n",
            "\n",
            "Epoch 174/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2257 - val_loss: 0.2147\n",
            "Loss: 0.22568944096565247\n",
            "Validation Loss: 0.21469871699810028\n",
            "\n",
            "Epoch 175/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2242 - val_loss: 0.2131\n",
            "Loss: 0.22415217757225037\n",
            "Validation Loss: 0.21312937140464783\n",
            "\n",
            "Epoch 176/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2242 - val_loss: 0.2180\n",
            "Loss: 0.22420355677604675\n",
            "Validation Loss: 0.21798637509346008\n",
            "\n",
            "Epoch 177/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2251 - val_loss: 0.2151\n",
            "Loss: 0.225139781832695\n",
            "Validation Loss: 0.21507491171360016\n",
            "\n",
            "Epoch 178/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2250 - val_loss: 0.2171\n",
            "Loss: 0.22498908638954163\n",
            "Validation Loss: 0.21710842847824097\n",
            "\n",
            "Epoch 179/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2252 - val_loss: 0.2143\n",
            "Loss: 0.22516654431819916\n",
            "Validation Loss: 0.21431370079517365\n",
            "\n",
            "Epoch 180/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2238 - val_loss: 0.2145\n",
            "Loss: 0.2238205522298813\n",
            "Validation Loss: 0.21452559530735016\n",
            "\n",
            "Epoch 181/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2241 - val_loss: 0.2121\n",
            "Loss: 0.22413572669029236\n",
            "Validation Loss: 0.21208089590072632\n",
            "\n",
            "Epoch 182/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2232 - val_loss: 0.2142\n",
            "Loss: 0.22315195202827454\n",
            "Validation Loss: 0.21419820189476013\n",
            "\n",
            "Epoch 183/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2236 - val_loss: 0.2133\n",
            "Loss: 0.22356370091438293\n",
            "Validation Loss: 0.21327424049377441\n",
            "\n",
            "Epoch 184/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2239 - val_loss: 0.2151\n",
            "Loss: 0.2238650768995285\n",
            "Validation Loss: 0.21512430906295776\n",
            "\n",
            "Epoch 185/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2215 - val_loss: 0.2148\n",
            "Loss: 0.22148862481117249\n",
            "Validation Loss: 0.2148071527481079\n",
            "\n",
            "Epoch 186/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2236 - val_loss: 0.2155\n",
            "Loss: 0.22360676527023315\n",
            "Validation Loss: 0.21552929282188416\n",
            "\n",
            "Epoch 187/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2230 - val_loss: 0.2149\n",
            "Loss: 0.22299325466156006\n",
            "Validation Loss: 0.21485251188278198\n",
            "\n",
            "Epoch 188/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2216 - val_loss: 0.2146\n",
            "Loss: 0.2216193675994873\n",
            "Validation Loss: 0.2145889401435852\n",
            "\n",
            "Epoch 189/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2230 - val_loss: 0.2132\n",
            "Loss: 0.2230396270751953\n",
            "Validation Loss: 0.2132459580898285\n",
            "\n",
            "Epoch 190/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2225 - val_loss: 0.2127\n",
            "Loss: 0.22248803079128265\n",
            "Validation Loss: 0.21269351243972778\n",
            "\n",
            "Epoch 191/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2223 - val_loss: 0.2134\n",
            "Loss: 0.22234755754470825\n",
            "Validation Loss: 0.21342144906520844\n",
            "\n",
            "Epoch 192/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2219 - val_loss: 0.2098\n",
            "Loss: 0.22189545631408691\n",
            "Validation Loss: 0.20981909334659576\n",
            "\n",
            "Epoch 193/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2222 - val_loss: 0.2138\n",
            "Loss: 0.22223229706287384\n",
            "Validation Loss: 0.2137935608625412\n",
            "\n",
            "Epoch 194/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2221 - val_loss: 0.2115\n",
            "Loss: 0.22206218540668488\n",
            "Validation Loss: 0.21154305338859558\n",
            "\n",
            "Epoch 195/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2210 - val_loss: 0.2123\n",
            "Loss: 0.2210322469472885\n",
            "Validation Loss: 0.2122945338487625\n",
            "\n",
            "Epoch 196/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2211 - val_loss: 0.2108\n",
            "Loss: 0.22105026245117188\n",
            "Validation Loss: 0.2108120173215866\n",
            "\n",
            "Epoch 197/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2211 - val_loss: 0.2127\n",
            "Loss: 0.22108207643032074\n",
            "Validation Loss: 0.2126522958278656\n",
            "\n",
            "Epoch 198/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2212 - val_loss: 0.2108\n",
            "Loss: 0.22121182084083557\n",
            "Validation Loss: 0.21076937019824982\n",
            "\n",
            "Epoch 199/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2217 - val_loss: 0.2120\n",
            "Loss: 0.22174875438213348\n",
            "Validation Loss: 0.21201375126838684\n",
            "\n",
            "Epoch 200/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2215 - val_loss: 0.2128\n",
            "Loss: 0.22148938477039337\n",
            "Validation Loss: 0.21277610957622528\n",
            "\n",
            "Epoch 201/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2204 - val_loss: 0.2110\n",
            "Loss: 0.22038179636001587\n",
            "Validation Loss: 0.21095740795135498\n",
            "\n",
            "Epoch 202/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2198 - val_loss: 0.2095\n",
            "Loss: 0.21977461874485016\n",
            "Validation Loss: 0.20951047539710999\n",
            "\n",
            "Epoch 203/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2188 - val_loss: 0.2119\n",
            "Loss: 0.21878622472286224\n",
            "Validation Loss: 0.21186824142932892\n",
            "\n",
            "Epoch 204/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2211 - val_loss: 0.2071\n",
            "Loss: 0.2210749089717865\n",
            "Validation Loss: 0.20711492002010345\n",
            "\n",
            "Epoch 205/500\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2191 - val_loss: 0.2066\n",
            "Loss: 0.21905510127544403\n",
            "Validation Loss: 0.20663857460021973\n",
            "\n",
            "Epoch 206/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2202 - val_loss: 0.2111\n",
            "Loss: 0.22021576762199402\n",
            "Validation Loss: 0.21106137335300446\n",
            "\n",
            "Epoch 207/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2198 - val_loss: 0.2070\n",
            "Loss: 0.21979907155036926\n",
            "Validation Loss: 0.20704858005046844\n",
            "\n",
            "Epoch 208/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2205 - val_loss: 0.2148\n",
            "Loss: 0.22047263383865356\n",
            "Validation Loss: 0.2147640436887741\n",
            "\n",
            "Epoch 209/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2195 - val_loss: 0.2140\n",
            "Loss: 0.2194899618625641\n",
            "Validation Loss: 0.2140120267868042\n",
            "\n",
            "Epoch 210/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2182 - val_loss: 0.2114\n",
            "Loss: 0.21817460656166077\n",
            "Validation Loss: 0.21139079332351685\n",
            "\n",
            "Epoch 211/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2172 - val_loss: 0.2088\n",
            "Loss: 0.2172202318906784\n",
            "Validation Loss: 0.2087620347738266\n",
            "\n",
            "Epoch 212/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2176 - val_loss: 0.2099\n",
            "Loss: 0.21756593883037567\n",
            "Validation Loss: 0.20994122326374054\n",
            "\n",
            "Epoch 213/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2173 - val_loss: 0.2086\n",
            "Loss: 0.21732263267040253\n",
            "Validation Loss: 0.2085781991481781\n",
            "\n",
            "Epoch 214/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2189 - val_loss: 0.2092\n",
            "Loss: 0.2189074605703354\n",
            "Validation Loss: 0.20923514664173126\n",
            "\n",
            "Epoch 215/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2189 - val_loss: 0.2086\n",
            "Loss: 0.21888618171215057\n",
            "Validation Loss: 0.208622545003891\n",
            "\n",
            "Epoch 216/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2168 - val_loss: 0.2096\n",
            "Loss: 0.2168373167514801\n",
            "Validation Loss: 0.20958153903484344\n",
            "\n",
            "Epoch 217/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2169 - val_loss: 0.2076\n",
            "Loss: 0.21694102883338928\n",
            "Validation Loss: 0.20759890973567963\n",
            "\n",
            "Epoch 218/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2173 - val_loss: 0.2113\n",
            "Loss: 0.2172996997833252\n",
            "Validation Loss: 0.21133287250995636\n",
            "\n",
            "Epoch 219/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2171 - val_loss: 0.2091\n",
            "Loss: 0.21707887947559357\n",
            "Validation Loss: 0.2090989351272583\n",
            "\n",
            "Epoch 220/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2171 - val_loss: 0.2103\n",
            "Loss: 0.21707648038864136\n",
            "Validation Loss: 0.2102743685245514\n",
            "\n",
            "Epoch 221/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2160 - val_loss: 0.2087\n",
            "Loss: 0.21600647270679474\n",
            "Validation Loss: 0.20867499709129333\n",
            "\n",
            "Epoch 222/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2161 - val_loss: 0.2076\n",
            "Loss: 0.21605804562568665\n",
            "Validation Loss: 0.20764097571372986\n",
            "\n",
            "Epoch 223/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2161 - val_loss: 0.2094\n",
            "Loss: 0.21612456440925598\n",
            "Validation Loss: 0.2094292789697647\n",
            "\n",
            "Epoch 224/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2167 - val_loss: 0.2074\n",
            "Loss: 0.21665190160274506\n",
            "Validation Loss: 0.2073994129896164\n",
            "\n",
            "Epoch 225/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2145 - val_loss: 0.2066\n",
            "Loss: 0.21450205147266388\n",
            "Validation Loss: 0.2066487818956375\n",
            "\n",
            "Epoch 226/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2160 - val_loss: 0.2104\n",
            "Loss: 0.215989887714386\n",
            "Validation Loss: 0.2103593498468399\n",
            "\n",
            "Epoch 227/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2167 - val_loss: 0.2117\n",
            "Loss: 0.21666023135185242\n",
            "Validation Loss: 0.21172286570072174\n",
            "\n",
            "Epoch 228/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2155 - val_loss: 0.2047\n",
            "Loss: 0.21547605097293854\n",
            "Validation Loss: 0.2046862542629242\n",
            "\n",
            "Epoch 229/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2161 - val_loss: 0.2119\n",
            "Loss: 0.2160675823688507\n",
            "Validation Loss: 0.21185807883739471\n",
            "\n",
            "Epoch 230/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2154 - val_loss: 0.2066\n",
            "Loss: 0.21536941826343536\n",
            "Validation Loss: 0.2066006362438202\n",
            "\n",
            "Epoch 231/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2162 - val_loss: 0.2078\n",
            "Loss: 0.21618326008319855\n",
            "Validation Loss: 0.20775887370109558\n",
            "\n",
            "Epoch 232/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2163 - val_loss: 0.2062\n",
            "Loss: 0.21627187728881836\n",
            "Validation Loss: 0.20622673630714417\n",
            "\n",
            "Epoch 233/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2148 - val_loss: 0.2070\n",
            "Loss: 0.21476711332798004\n",
            "Validation Loss: 0.2069619596004486\n",
            "\n",
            "Epoch 234/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2155 - val_loss: 0.2049\n",
            "Loss: 0.21548132598400116\n",
            "Validation Loss: 0.2048696130514145\n",
            "\n",
            "Epoch 235/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2136 - val_loss: 0.2072\n",
            "Loss: 0.21362709999084473\n",
            "Validation Loss: 0.20716844499111176\n",
            "\n",
            "Epoch 236/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2146 - val_loss: 0.2048\n",
            "Loss: 0.21456946432590485\n",
            "Validation Loss: 0.2047932744026184\n",
            "\n",
            "Epoch 237/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2148 - val_loss: 0.2076\n",
            "Loss: 0.2147957682609558\n",
            "Validation Loss: 0.20758165419101715\n",
            "\n",
            "Epoch 238/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2138 - val_loss: 0.2040\n",
            "Loss: 0.2138022929430008\n",
            "Validation Loss: 0.20404478907585144\n",
            "\n",
            "Epoch 239/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2137 - val_loss: 0.2075\n",
            "Loss: 0.21369358897209167\n",
            "Validation Loss: 0.20746752619743347\n",
            "\n",
            "Epoch 240/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2144 - val_loss: 0.2059\n",
            "Loss: 0.21437402069568634\n",
            "Validation Loss: 0.20592999458312988\n",
            "\n",
            "Epoch 241/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2129 - val_loss: 0.2064\n",
            "Loss: 0.2129395753145218\n",
            "Validation Loss: 0.20640353858470917\n",
            "\n",
            "Epoch 242/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2147 - val_loss: 0.2062\n",
            "Loss: 0.21469071507453918\n",
            "Validation Loss: 0.20624834299087524\n",
            "\n",
            "Epoch 243/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2134 - val_loss: 0.2034\n",
            "Loss: 0.21340790390968323\n",
            "Validation Loss: 0.20337849855422974\n",
            "\n",
            "Epoch 244/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2136 - val_loss: 0.2052\n",
            "Loss: 0.2135649472475052\n",
            "Validation Loss: 0.20521055161952972\n",
            "\n",
            "Epoch 245/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2130 - val_loss: 0.2041\n",
            "Loss: 0.21299070119857788\n",
            "Validation Loss: 0.20411063730716705\n",
            "\n",
            "Epoch 246/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2141 - val_loss: 0.2066\n",
            "Loss: 0.214076429605484\n",
            "Validation Loss: 0.20662955939769745\n",
            "\n",
            "Epoch 247/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2132 - val_loss: 0.2052\n",
            "Loss: 0.21319982409477234\n",
            "Validation Loss: 0.20522351562976837\n",
            "\n",
            "Epoch 248/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2142 - val_loss: 0.2074\n",
            "Loss: 0.21420033276081085\n",
            "Validation Loss: 0.20742923021316528\n",
            "\n",
            "Epoch 249/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2123 - val_loss: 0.2046\n",
            "Loss: 0.21231304109096527\n",
            "Validation Loss: 0.20455873012542725\n",
            "\n",
            "Epoch 250/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2133 - val_loss: 0.2082\n",
            "Loss: 0.21332460641860962\n",
            "Validation Loss: 0.20816907286643982\n",
            "\n",
            "Epoch 251/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2133 - val_loss: 0.2051\n",
            "Loss: 0.21328212320804596\n",
            "Validation Loss: 0.2050943225622177\n",
            "\n",
            "Epoch 252/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2115 - val_loss: 0.2041\n",
            "Loss: 0.21152345836162567\n",
            "Validation Loss: 0.2040950357913971\n",
            "\n",
            "Epoch 253/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2129 - val_loss: 0.2051\n",
            "Loss: 0.21286381781101227\n",
            "Validation Loss: 0.20514780282974243\n",
            "\n",
            "Epoch 254/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2120 - val_loss: 0.2053\n",
            "Loss: 0.21197094023227692\n",
            "Validation Loss: 0.20525546371936798\n",
            "\n",
            "Epoch 255/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2130 - val_loss: 0.2049\n",
            "Loss: 0.21297237277030945\n",
            "Validation Loss: 0.2049390971660614\n",
            "\n",
            "Epoch 256/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2128 - val_loss: 0.2023\n",
            "Loss: 0.21278707683086395\n",
            "Validation Loss: 0.2023472636938095\n",
            "\n",
            "Epoch 257/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2126 - val_loss: 0.2059\n",
            "Loss: 0.21259984374046326\n",
            "Validation Loss: 0.2059384286403656\n",
            "\n",
            "Epoch 258/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2111 - val_loss: 0.2035\n",
            "Loss: 0.21111759543418884\n",
            "Validation Loss: 0.20348961651325226\n",
            "\n",
            "Epoch 259/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2112 - val_loss: 0.2046\n",
            "Loss: 0.21119078993797302\n",
            "Validation Loss: 0.2046234905719757\n",
            "\n",
            "Epoch 260/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2111 - val_loss: 0.2031\n",
            "Loss: 0.2111487239599228\n",
            "Validation Loss: 0.2030857503414154\n",
            "\n",
            "Epoch 261/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2111 - val_loss: 0.2038\n",
            "Loss: 0.21114499866962433\n",
            "Validation Loss: 0.2037528157234192\n",
            "\n",
            "Epoch 262/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2123 - val_loss: 0.2046\n",
            "Loss: 0.21230734884738922\n",
            "Validation Loss: 0.2046365886926651\n",
            "\n",
            "Epoch 263/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2128 - val_loss: 0.2002\n",
            "Loss: 0.21284180879592896\n",
            "Validation Loss: 0.20015783607959747\n",
            "\n",
            "Epoch 264/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2106 - val_loss: 0.2030\n",
            "Loss: 0.21061721444129944\n",
            "Validation Loss: 0.20296014845371246\n",
            "\n",
            "Epoch 265/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2111 - val_loss: 0.2046\n",
            "Loss: 0.21113702654838562\n",
            "Validation Loss: 0.20455679297447205\n",
            "\n",
            "Epoch 266/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2108 - val_loss: 0.2028\n",
            "Loss: 0.2108120322227478\n",
            "Validation Loss: 0.20276574790477753\n",
            "\n",
            "Epoch 267/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2105 - val_loss: 0.2024\n",
            "Loss: 0.2104891985654831\n",
            "Validation Loss: 0.20239140093326569\n",
            "\n",
            "Epoch 268/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2105 - val_loss: 0.2026\n",
            "Loss: 0.21054229140281677\n",
            "Validation Loss: 0.20264750719070435\n",
            "\n",
            "Epoch 269/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2112 - val_loss: 0.2026\n",
            "Loss: 0.2111736387014389\n",
            "Validation Loss: 0.20255780220031738\n",
            "\n",
            "Epoch 270/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2098 - val_loss: 0.2033\n",
            "Loss: 0.2097780406475067\n",
            "Validation Loss: 0.20332080125808716\n",
            "\n",
            "Epoch 271/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2095 - val_loss: 0.2034\n",
            "Loss: 0.2095099538564682\n",
            "Validation Loss: 0.20343004167079926\n",
            "\n",
            "Epoch 272/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2112 - val_loss: 0.2069\n",
            "Loss: 0.21115842461585999\n",
            "Validation Loss: 0.20693501830101013\n",
            "\n",
            "Epoch 273/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2107 - val_loss: 0.2044\n",
            "Loss: 0.21070756018161774\n",
            "Validation Loss: 0.20440129935741425\n",
            "\n",
            "Epoch 274/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2095 - val_loss: 0.2042\n",
            "Loss: 0.20952484011650085\n",
            "Validation Loss: 0.204184427857399\n",
            "\n",
            "Epoch 275/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2099 - val_loss: 0.2024\n",
            "Loss: 0.20988884568214417\n",
            "Validation Loss: 0.20235878229141235\n",
            "\n",
            "Epoch 276/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2093 - val_loss: 0.2020\n",
            "Loss: 0.20928332209587097\n",
            "Validation Loss: 0.20199990272521973\n",
            "\n",
            "Epoch 277/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2089 - val_loss: 0.2008\n",
            "Loss: 0.2088763266801834\n",
            "Validation Loss: 0.2007848024368286\n",
            "\n",
            "Epoch 278/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2084 - val_loss: 0.2034\n",
            "Loss: 0.20838727056980133\n",
            "Validation Loss: 0.20341044664382935\n",
            "\n",
            "Epoch 279/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2085 - val_loss: 0.2028\n",
            "Loss: 0.20853735506534576\n",
            "Validation Loss: 0.2028288096189499\n",
            "\n",
            "Epoch 280/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2092 - val_loss: 0.2011\n",
            "Loss: 0.2091900259256363\n",
            "Validation Loss: 0.20114439725875854\n",
            "\n",
            "Epoch 281/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2090 - val_loss: 0.2059\n",
            "Loss: 0.20903067290782928\n",
            "Validation Loss: 0.20594310760498047\n",
            "\n",
            "Epoch 282/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2093 - val_loss: 0.1994\n",
            "Loss: 0.20926304161548615\n",
            "Validation Loss: 0.1994042545557022\n",
            "\n",
            "Epoch 283/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2107 - val_loss: 0.2041\n",
            "Loss: 0.21068744361400604\n",
            "Validation Loss: 0.20405064523220062\n",
            "\n",
            "Epoch 284/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2096 - val_loss: 0.2015\n",
            "Loss: 0.2096206247806549\n",
            "Validation Loss: 0.2014579176902771\n",
            "\n",
            "Epoch 285/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2098 - val_loss: 0.2025\n",
            "Loss: 0.2097507268190384\n",
            "Validation Loss: 0.20254184305667877\n",
            "\n",
            "Epoch 286/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2090 - val_loss: 0.2015\n",
            "Loss: 0.2090229094028473\n",
            "Validation Loss: 0.20146432518959045\n",
            "\n",
            "Epoch 287/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2081 - val_loss: 0.2033\n",
            "Loss: 0.20812299847602844\n",
            "Validation Loss: 0.20333103835582733\n",
            "\n",
            "Epoch 288/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2079 - val_loss: 0.2012\n",
            "Loss: 0.20792430639266968\n",
            "Validation Loss: 0.20124053955078125\n",
            "\n",
            "Epoch 289/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2089 - val_loss: 0.2037\n",
            "Loss: 0.20887860655784607\n",
            "Validation Loss: 0.20373041927814484\n",
            "\n",
            "Epoch 290/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2099 - val_loss: 0.2025\n",
            "Loss: 0.20992620289325714\n",
            "Validation Loss: 0.20245470106601715\n",
            "\n",
            "Epoch 291/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2096 - val_loss: 0.2020\n",
            "Loss: 0.20962418615818024\n",
            "Validation Loss: 0.20198549330234528\n",
            "\n",
            "Epoch 292/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2079 - val_loss: 0.2029\n",
            "Loss: 0.2078850120306015\n",
            "Validation Loss: 0.202851340174675\n",
            "\n",
            "Epoch 293/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2077 - val_loss: 0.2008\n",
            "Loss: 0.20767180621623993\n",
            "Validation Loss: 0.2008158266544342\n",
            "\n",
            "Epoch 294/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2083 - val_loss: 0.2035\n",
            "Loss: 0.20825055241584778\n",
            "Validation Loss: 0.20351071655750275\n",
            "\n",
            "Epoch 295/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2068 - val_loss: 0.2014\n",
            "Loss: 0.206758052110672\n",
            "Validation Loss: 0.20142380893230438\n",
            "\n",
            "Epoch 296/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2084 - val_loss: 0.1989\n",
            "Loss: 0.20841042697429657\n",
            "Validation Loss: 0.1989467889070511\n",
            "\n",
            "Epoch 297/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2083 - val_loss: 0.2030\n",
            "Loss: 0.2083318531513214\n",
            "Validation Loss: 0.20303118228912354\n",
            "\n",
            "Epoch 298/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2092 - val_loss: 0.1992\n",
            "Loss: 0.20919808745384216\n",
            "Validation Loss: 0.19918975234031677\n",
            "\n",
            "Epoch 299/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2068 - val_loss: 0.2032\n",
            "Loss: 0.20681852102279663\n",
            "Validation Loss: 0.203165665268898\n",
            "\n",
            "Epoch 300/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2076 - val_loss: 0.1996\n",
            "Loss: 0.2076159119606018\n",
            "Validation Loss: 0.1996394544839859\n",
            "\n",
            "Epoch 301/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2073 - val_loss: 0.2013\n",
            "Loss: 0.20732487738132477\n",
            "Validation Loss: 0.2013426423072815\n",
            "\n",
            "Epoch 302/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2077 - val_loss: 0.2012\n",
            "Loss: 0.20770666003227234\n",
            "Validation Loss: 0.20119287073612213\n",
            "\n",
            "Epoch 303/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2068 - val_loss: 0.2002\n",
            "Loss: 0.2068222165107727\n",
            "Validation Loss: 0.20018132030963898\n",
            "\n",
            "Epoch 304/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2076 - val_loss: 0.2020\n",
            "Loss: 0.20764128863811493\n",
            "Validation Loss: 0.20198093354701996\n",
            "\n",
            "Epoch 305/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2072 - val_loss: 0.2026\n",
            "Loss: 0.20722432434558868\n",
            "Validation Loss: 0.20260970294475555\n",
            "\n",
            "Epoch 306/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2067 - val_loss: 0.1977\n",
            "Loss: 0.2067388892173767\n",
            "Validation Loss: 0.19766969978809357\n",
            "\n",
            "Epoch 307/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2073 - val_loss: 0.2031\n",
            "Loss: 0.20725563168525696\n",
            "Validation Loss: 0.20312951505184174\n",
            "\n",
            "Epoch 308/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2068 - val_loss: 0.2021\n",
            "Loss: 0.20676781237125397\n",
            "Validation Loss: 0.2021208256483078\n",
            "\n",
            "Epoch 309/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2065 - val_loss: 0.1997\n",
            "Loss: 0.20653419196605682\n",
            "Validation Loss: 0.1996614784002304\n",
            "\n",
            "Epoch 310/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2078 - val_loss: 0.2036\n",
            "Loss: 0.20784041285514832\n",
            "Validation Loss: 0.20356492698192596\n",
            "\n",
            "Epoch 311/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2068 - val_loss: 0.2009\n",
            "Loss: 0.20683732628822327\n",
            "Validation Loss: 0.20092664659023285\n",
            "\n",
            "Epoch 312/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2055 - val_loss: 0.1968\n",
            "Loss: 0.20554080605506897\n",
            "Validation Loss: 0.19675175845623016\n",
            "\n",
            "Epoch 313/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2068 - val_loss: 0.1981\n",
            "Loss: 0.20682261884212494\n",
            "Validation Loss: 0.1980869323015213\n",
            "\n",
            "Epoch 314/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2079 - val_loss: 0.1992\n",
            "Loss: 0.20789892971515656\n",
            "Validation Loss: 0.1992020159959793\n",
            "\n",
            "Epoch 315/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2054 - val_loss: 0.2025\n",
            "Loss: 0.20542655885219574\n",
            "Validation Loss: 0.20254655182361603\n",
            "\n",
            "Epoch 316/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2069 - val_loss: 0.1996\n",
            "Loss: 0.20690852403640747\n",
            "Validation Loss: 0.19955717027187347\n",
            "\n",
            "Epoch 317/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2059 - val_loss: 0.2003\n",
            "Loss: 0.20588377118110657\n",
            "Validation Loss: 0.20029765367507935\n",
            "\n",
            "Epoch 318/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2051 - val_loss: 0.1998\n",
            "Loss: 0.20510388910770416\n",
            "Validation Loss: 0.19981899857521057\n",
            "\n",
            "Epoch 319/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2064 - val_loss: 0.1978\n",
            "Loss: 0.20638301968574524\n",
            "Validation Loss: 0.19781965017318726\n",
            "\n",
            "Epoch 320/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2063 - val_loss: 0.2025\n",
            "Loss: 0.20625784993171692\n",
            "Validation Loss: 0.20245960354804993\n",
            "\n",
            "Epoch 321/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2045 - val_loss: 0.2019\n",
            "Loss: 0.20449574291706085\n",
            "Validation Loss: 0.20194333791732788\n",
            "\n",
            "Epoch 322/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2050 - val_loss: 0.1990\n",
            "Loss: 0.2050008475780487\n",
            "Validation Loss: 0.19903652369976044\n",
            "\n",
            "Epoch 323/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2052 - val_loss: 0.1980\n",
            "Loss: 0.20521661639213562\n",
            "Validation Loss: 0.19798006117343903\n",
            "\n",
            "Epoch 324/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2058 - val_loss: 0.1992\n",
            "Loss: 0.2057759314775467\n",
            "Validation Loss: 0.19919949769973755\n",
            "\n",
            "Epoch 325/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2047 - val_loss: 0.1994\n",
            "Loss: 0.2047446072101593\n",
            "Validation Loss: 0.19937138259410858\n",
            "\n",
            "Epoch 326/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2056 - val_loss: 0.1966\n",
            "Loss: 0.20556417107582092\n",
            "Validation Loss: 0.19658702611923218\n",
            "\n",
            "Epoch 327/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2045 - val_loss: 0.1983\n",
            "Loss: 0.2044796496629715\n",
            "Validation Loss: 0.1983117312192917\n",
            "\n",
            "Epoch 328/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2044 - val_loss: 0.1969\n",
            "Loss: 0.20442697405815125\n",
            "Validation Loss: 0.19685916602611542\n",
            "\n",
            "Epoch 329/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2048 - val_loss: 0.1985\n",
            "Loss: 0.20483075082302094\n",
            "Validation Loss: 0.1985449194908142\n",
            "\n",
            "Epoch 330/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2060 - val_loss: 0.1956\n",
            "Loss: 0.20596632361412048\n",
            "Validation Loss: 0.19563688337802887\n",
            "\n",
            "Epoch 331/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2045 - val_loss: 0.1979\n",
            "Loss: 0.20448772609233856\n",
            "Validation Loss: 0.19787046313285828\n",
            "\n",
            "Epoch 332/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2055 - val_loss: 0.1987\n",
            "Loss: 0.20551088452339172\n",
            "Validation Loss: 0.19871675968170166\n",
            "\n",
            "Epoch 333/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2052 - val_loss: 0.1969\n",
            "Loss: 0.20517568290233612\n",
            "Validation Loss: 0.19690868258476257\n",
            "\n",
            "Epoch 334/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2043 - val_loss: 0.1998\n",
            "Loss: 0.20434480905532837\n",
            "Validation Loss: 0.19977067410945892\n",
            "\n",
            "Epoch 335/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2050 - val_loss: 0.1982\n",
            "Loss: 0.2049970179796219\n",
            "Validation Loss: 0.19823168218135834\n",
            "\n",
            "Epoch 336/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2044 - val_loss: 0.2013\n",
            "Loss: 0.204438716173172\n",
            "Validation Loss: 0.20128905773162842\n",
            "\n",
            "Epoch 337/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2043 - val_loss: 0.1961\n",
            "Loss: 0.204258993268013\n",
            "Validation Loss: 0.19610314071178436\n",
            "\n",
            "Epoch 338/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2034 - val_loss: 0.1986\n",
            "Loss: 0.20344598591327667\n",
            "Validation Loss: 0.19864186644554138\n",
            "\n",
            "Epoch 339/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2033 - val_loss: 0.1979\n",
            "Loss: 0.20334653556346893\n",
            "Validation Loss: 0.197923481464386\n",
            "\n",
            "Epoch 340/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2046 - val_loss: 0.1955\n",
            "Loss: 0.20455531775951385\n",
            "Validation Loss: 0.19551637768745422\n",
            "\n",
            "Epoch 341/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2044 - val_loss: 0.1953\n",
            "Loss: 0.20437069237232208\n",
            "Validation Loss: 0.19527970254421234\n",
            "\n",
            "Epoch 342/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2046 - val_loss: 0.1943\n",
            "Loss: 0.20462176203727722\n",
            "Validation Loss: 0.19434648752212524\n",
            "\n",
            "Epoch 343/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2033 - val_loss: 0.1990\n",
            "Loss: 0.20332325994968414\n",
            "Validation Loss: 0.19895893335342407\n",
            "\n",
            "Epoch 344/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2035 - val_loss: 0.2010\n",
            "Loss: 0.20347343385219574\n",
            "Validation Loss: 0.2009662240743637\n",
            "\n",
            "Epoch 345/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2040 - val_loss: 0.1967\n",
            "Loss: 0.20396968722343445\n",
            "Validation Loss: 0.19668620824813843\n",
            "\n",
            "Epoch 346/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2044 - val_loss: 0.1976\n",
            "Loss: 0.20444700121879578\n",
            "Validation Loss: 0.19757021963596344\n",
            "\n",
            "Epoch 347/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2048 - val_loss: 0.1989\n",
            "Loss: 0.20480462908744812\n",
            "Validation Loss: 0.19889692962169647\n",
            "\n",
            "Epoch 348/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2028 - val_loss: 0.1952\n",
            "Loss: 0.2028426229953766\n",
            "Validation Loss: 0.1951921284198761\n",
            "\n",
            "Epoch 349/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2044 - val_loss: 0.2003\n",
            "Loss: 0.20442470908164978\n",
            "Validation Loss: 0.20031864941120148\n",
            "\n",
            "Epoch 350/500\n",
            "21/21 [==============================] - 3s 161ms/step - loss: 0.2030 - val_loss: 0.1972\n",
            "Loss: 0.20298132300376892\n",
            "Validation Loss: 0.1971648782491684\n",
            "\n",
            "Epoch 351/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2031 - val_loss: 0.1946\n",
            "Loss: 0.20313449203968048\n",
            "Validation Loss: 0.194611594080925\n",
            "\n",
            "Epoch 352/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2036 - val_loss: 0.2012\n",
            "Loss: 0.2036186307668686\n",
            "Validation Loss: 0.2012278139591217\n",
            "\n",
            "Epoch 353/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2030 - val_loss: 0.1958\n",
            "Loss: 0.2029816210269928\n",
            "Validation Loss: 0.1957988440990448\n",
            "\n",
            "Epoch 354/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2032 - val_loss: 0.2015\n",
            "Loss: 0.20317842066287994\n",
            "Validation Loss: 0.20149420201778412\n",
            "\n",
            "Epoch 355/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2036 - val_loss: 0.1952\n",
            "Loss: 0.20361976325511932\n",
            "Validation Loss: 0.19522824883460999\n",
            "\n",
            "Epoch 356/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2034 - val_loss: 0.1976\n",
            "Loss: 0.20338810980319977\n",
            "Validation Loss: 0.19757036864757538\n",
            "\n",
            "Epoch 357/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2041 - val_loss: 0.1971\n",
            "Loss: 0.20406770706176758\n",
            "Validation Loss: 0.19712331891059875\n",
            "\n",
            "Epoch 358/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2031 - val_loss: 0.1951\n",
            "Loss: 0.20305028557777405\n",
            "Validation Loss: 0.19505755603313446\n",
            "\n",
            "Epoch 359/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.2022 - val_loss: 0.1974\n",
            "Loss: 0.20215986669063568\n",
            "Validation Loss: 0.19735510647296906\n",
            "\n",
            "Epoch 360/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2023 - val_loss: 0.1962\n",
            "Loss: 0.20226015150547028\n",
            "Validation Loss: 0.19621959328651428\n",
            "\n",
            "Epoch 361/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2023 - val_loss: 0.1950\n",
            "Loss: 0.20227159559726715\n",
            "Validation Loss: 0.19501136243343353\n",
            "\n",
            "Epoch 362/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2013 - val_loss: 0.1977\n",
            "Loss: 0.2012895792722702\n",
            "Validation Loss: 0.1976747363805771\n",
            "\n",
            "Epoch 363/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2024 - val_loss: 0.1950\n",
            "Loss: 0.20243827998638153\n",
            "Validation Loss: 0.19498160481452942\n",
            "\n",
            "Epoch 364/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2027 - val_loss: 0.1969\n",
            "Loss: 0.20271286368370056\n",
            "Validation Loss: 0.19689971208572388\n",
            "\n",
            "Epoch 365/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2031 - val_loss: 0.1965\n",
            "Loss: 0.2030547559261322\n",
            "Validation Loss: 0.19645589590072632\n",
            "\n",
            "Epoch 366/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2028 - val_loss: 0.1986\n",
            "Loss: 0.20278389751911163\n",
            "Validation Loss: 0.19858714938163757\n",
            "\n",
            "Epoch 367/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2030 - val_loss: 0.1944\n",
            "Loss: 0.20295043289661407\n",
            "Validation Loss: 0.19435498118400574\n",
            "\n",
            "Epoch 368/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2022 - val_loss: 0.1983\n",
            "Loss: 0.20216399431228638\n",
            "Validation Loss: 0.1982761174440384\n",
            "\n",
            "Epoch 369/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2015 - val_loss: 0.1972\n",
            "Loss: 0.201458141207695\n",
            "Validation Loss: 0.19716905057430267\n",
            "\n",
            "Epoch 370/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2014 - val_loss: 0.1953\n",
            "Loss: 0.20137625932693481\n",
            "Validation Loss: 0.19534817337989807\n",
            "\n",
            "Epoch 371/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2021 - val_loss: 0.1989\n",
            "Loss: 0.2020966112613678\n",
            "Validation Loss: 0.19885271787643433\n",
            "\n",
            "Epoch 372/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2026 - val_loss: 0.1962\n",
            "Loss: 0.20258592069149017\n",
            "Validation Loss: 0.19619469344615936\n",
            "\n",
            "Epoch 373/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2017 - val_loss: 0.1939\n",
            "Loss: 0.2017129361629486\n",
            "Validation Loss: 0.1938500702381134\n",
            "\n",
            "Epoch 374/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2015 - val_loss: 0.1946\n",
            "Loss: 0.20152854919433594\n",
            "Validation Loss: 0.19462409615516663\n",
            "\n",
            "Epoch 375/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2010 - val_loss: 0.1977\n",
            "Loss: 0.20099548995494843\n",
            "Validation Loss: 0.1976659893989563\n",
            "\n",
            "Epoch 376/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2021 - val_loss: 0.1963\n",
            "Loss: 0.20207515358924866\n",
            "Validation Loss: 0.19625619053840637\n",
            "\n",
            "Epoch 377/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2002 - val_loss: 0.1983\n",
            "Loss: 0.2001500278711319\n",
            "Validation Loss: 0.19828133285045624\n",
            "\n",
            "Epoch 378/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2021 - val_loss: 0.1940\n",
            "Loss: 0.20210544764995575\n",
            "Validation Loss: 0.1940135508775711\n",
            "\n",
            "Epoch 379/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2029 - val_loss: 0.1995\n",
            "Loss: 0.2029411941766739\n",
            "Validation Loss: 0.19949156045913696\n",
            "\n",
            "Epoch 380/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2028 - val_loss: 0.1964\n",
            "Loss: 0.20281356573104858\n",
            "Validation Loss: 0.19637000560760498\n",
            "\n",
            "Epoch 381/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2026 - val_loss: 0.1976\n",
            "Loss: 0.2025904804468155\n",
            "Validation Loss: 0.1975780874490738\n",
            "\n",
            "Epoch 382/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2019 - val_loss: 0.1957\n",
            "Loss: 0.20189569890499115\n",
            "Validation Loss: 0.1957128494977951\n",
            "\n",
            "Epoch 383/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2012 - val_loss: 0.1982\n",
            "Loss: 0.20121175050735474\n",
            "Validation Loss: 0.19816169142723083\n",
            "\n",
            "Epoch 384/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2023 - val_loss: 0.1963\n",
            "Loss: 0.2022661566734314\n",
            "Validation Loss: 0.1963052600622177\n",
            "\n",
            "Epoch 385/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2021 - val_loss: 0.1967\n",
            "Loss: 0.20214182138442993\n",
            "Validation Loss: 0.19674396514892578\n",
            "\n",
            "Epoch 386/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2006 - val_loss: 0.1971\n",
            "Loss: 0.20059749484062195\n",
            "Validation Loss: 0.19712623953819275\n",
            "\n",
            "Epoch 387/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2005 - val_loss: 0.1974\n",
            "Loss: 0.20052187144756317\n",
            "Validation Loss: 0.19736351072788239\n",
            "\n",
            "Epoch 388/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2015 - val_loss: 0.1958\n",
            "Loss: 0.20153076946735382\n",
            "Validation Loss: 0.19575192034244537\n",
            "\n",
            "Epoch 389/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2013 - val_loss: 0.1924\n",
            "Loss: 0.20130504667758942\n",
            "Validation Loss: 0.19244375824928284\n",
            "\n",
            "Epoch 390/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2012 - val_loss: 0.1966\n",
            "Loss: 0.2012091726064682\n",
            "Validation Loss: 0.19662770628929138\n",
            "\n",
            "Epoch 391/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2020 - val_loss: 0.1944\n",
            "Loss: 0.2020057737827301\n",
            "Validation Loss: 0.19441232085227966\n",
            "\n",
            "Epoch 392/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2020 - val_loss: 0.1944\n",
            "Loss: 0.20199039578437805\n",
            "Validation Loss: 0.1944408416748047\n",
            "\n",
            "Epoch 393/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2000 - val_loss: 0.1966\n",
            "Loss: 0.19997616112232208\n",
            "Validation Loss: 0.19663231074810028\n",
            "\n",
            "Epoch 394/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2003 - val_loss: 0.1954\n",
            "Loss: 0.20034536719322205\n",
            "Validation Loss: 0.19536985456943512\n",
            "\n",
            "Epoch 395/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2007 - val_loss: 0.1951\n",
            "Loss: 0.20073473453521729\n",
            "Validation Loss: 0.19511736929416656\n",
            "\n",
            "Epoch 396/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2006 - val_loss: 0.1967\n",
            "Loss: 0.20064038038253784\n",
            "Validation Loss: 0.19671155512332916\n",
            "\n",
            "Epoch 397/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2002 - val_loss: 0.1973\n",
            "Loss: 0.20019888877868652\n",
            "Validation Loss: 0.197323739528656\n",
            "\n",
            "Epoch 398/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2003 - val_loss: 0.1949\n",
            "Loss: 0.2003328800201416\n",
            "Validation Loss: 0.1948649287223816\n",
            "\n",
            "Epoch 399/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2014 - val_loss: 0.1990\n",
            "Loss: 0.20141352713108063\n",
            "Validation Loss: 0.1989557147026062\n",
            "\n",
            "Epoch 400/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2006 - val_loss: 0.1961\n",
            "Loss: 0.2006322741508484\n",
            "Validation Loss: 0.19606061279773712\n",
            "\n",
            "Epoch 401/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2007 - val_loss: 0.1944\n",
            "Loss: 0.20069673657417297\n",
            "Validation Loss: 0.19436953961849213\n",
            "\n",
            "Epoch 402/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2000 - val_loss: 0.1978\n",
            "Loss: 0.1999993920326233\n",
            "Validation Loss: 0.1977732926607132\n",
            "\n",
            "Epoch 403/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2008 - val_loss: 0.1947\n",
            "Loss: 0.20075660943984985\n",
            "Validation Loss: 0.1946846842765808\n",
            "\n",
            "Epoch 404/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2011 - val_loss: 0.1952\n",
            "Loss: 0.20111997425556183\n",
            "Validation Loss: 0.19520939886569977\n",
            "\n",
            "Epoch 405/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2002 - val_loss: 0.1967\n",
            "Loss: 0.20021188259124756\n",
            "Validation Loss: 0.19667620956897736\n",
            "\n",
            "Epoch 406/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2010 - val_loss: 0.1933\n",
            "Loss: 0.2010221779346466\n",
            "Validation Loss: 0.19331799447536469\n",
            "\n",
            "Epoch 407/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2008 - val_loss: 0.1949\n",
            "Loss: 0.20082807540893555\n",
            "Validation Loss: 0.19489040970802307\n",
            "\n",
            "Epoch 408/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2004 - val_loss: 0.1929\n",
            "Loss: 0.20038823783397675\n",
            "Validation Loss: 0.19290409982204437\n",
            "\n",
            "Epoch 409/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2013 - val_loss: 0.1938\n",
            "Loss: 0.2012593001127243\n",
            "Validation Loss: 0.19375760853290558\n",
            "\n",
            "Epoch 410/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1993 - val_loss: 0.1974\n",
            "Loss: 0.1992991417646408\n",
            "Validation Loss: 0.19740910828113556\n",
            "\n",
            "Epoch 411/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2003 - val_loss: 0.1917\n",
            "Loss: 0.20025859773159027\n",
            "Validation Loss: 0.19174708425998688\n",
            "\n",
            "Epoch 412/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1997 - val_loss: 0.1945\n",
            "Loss: 0.1997489035129547\n",
            "Validation Loss: 0.19451572000980377\n",
            "\n",
            "Epoch 413/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1992 - val_loss: 0.1940\n",
            "Loss: 0.19920100271701813\n",
            "Validation Loss: 0.1939673274755478\n",
            "\n",
            "Epoch 414/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1995 - val_loss: 0.1947\n",
            "Loss: 0.1995474100112915\n",
            "Validation Loss: 0.194692462682724\n",
            "\n",
            "Epoch 415/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1996 - val_loss: 0.1930\n",
            "Loss: 0.19964227080345154\n",
            "Validation Loss: 0.1930142194032669\n",
            "\n",
            "Epoch 416/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1988 - val_loss: 0.1945\n",
            "Loss: 0.19882647693157196\n",
            "Validation Loss: 0.19454307854175568\n",
            "\n",
            "Epoch 417/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1999 - val_loss: 0.1929\n",
            "Loss: 0.1998504251241684\n",
            "Validation Loss: 0.19286303222179413\n",
            "\n",
            "Epoch 418/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1997 - val_loss: 0.1969\n",
            "Loss: 0.19969308376312256\n",
            "Validation Loss: 0.1968584805727005\n",
            "\n",
            "Epoch 419/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1989 - val_loss: 0.1930\n",
            "Loss: 0.19893847405910492\n",
            "Validation Loss: 0.1929917335510254\n",
            "\n",
            "Epoch 420/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1998 - val_loss: 0.1942\n",
            "Loss: 0.19982637465000153\n",
            "Validation Loss: 0.19421057403087616\n",
            "\n",
            "Epoch 421/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1986 - val_loss: 0.1950\n",
            "Loss: 0.19860167801380157\n",
            "Validation Loss: 0.19500015676021576\n",
            "\n",
            "Epoch 422/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1996 - val_loss: 0.1935\n",
            "Loss: 0.19961398839950562\n",
            "Validation Loss: 0.19354404509067535\n",
            "\n",
            "Epoch 423/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1993 - val_loss: 0.1930\n",
            "Loss: 0.19929228723049164\n",
            "Validation Loss: 0.19297905266284943\n",
            "\n",
            "Epoch 424/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2009 - val_loss: 0.1950\n",
            "Loss: 0.20087306201457977\n",
            "Validation Loss: 0.19498415291309357\n",
            "\n",
            "Epoch 425/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1998 - val_loss: 0.1910\n",
            "Loss: 0.19975052773952484\n",
            "Validation Loss: 0.1909884810447693\n",
            "\n",
            "Epoch 426/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1990 - val_loss: 0.1933\n",
            "Loss: 0.19896405935287476\n",
            "Validation Loss: 0.19332671165466309\n",
            "\n",
            "Epoch 427/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1988 - val_loss: 0.1909\n",
            "Loss: 0.19877426326274872\n",
            "Validation Loss: 0.1909198760986328\n",
            "\n",
            "Epoch 428/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1984 - val_loss: 0.1956\n",
            "Loss: 0.19841857254505157\n",
            "Validation Loss: 0.19557759165763855\n",
            "\n",
            "Epoch 429/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1994 - val_loss: 0.1921\n",
            "Loss: 0.19938166439533234\n",
            "Validation Loss: 0.192122220993042\n",
            "\n",
            "Epoch 430/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1982 - val_loss: 0.1928\n",
            "Loss: 0.19820155203342438\n",
            "Validation Loss: 0.19281582534313202\n",
            "\n",
            "Epoch 431/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1989 - val_loss: 0.1937\n",
            "Loss: 0.19893839955329895\n",
            "Validation Loss: 0.1937173306941986\n",
            "\n",
            "Epoch 432/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1996 - val_loss: 0.1929\n",
            "Loss: 0.1996244490146637\n",
            "Validation Loss: 0.192904531955719\n",
            "\n",
            "Epoch 433/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1983 - val_loss: 0.1971\n",
            "Loss: 0.1982778161764145\n",
            "Validation Loss: 0.19711118936538696\n",
            "\n",
            "Epoch 434/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1993 - val_loss: 0.1914\n",
            "Loss: 0.1993343085050583\n",
            "Validation Loss: 0.19135788083076477\n",
            "\n",
            "Epoch 435/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1986 - val_loss: 0.1925\n",
            "Loss: 0.19855885207653046\n",
            "Validation Loss: 0.19251388311386108\n",
            "\n",
            "Epoch 436/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1989 - val_loss: 0.1949\n",
            "Loss: 0.19887198507785797\n",
            "Validation Loss: 0.19489730894565582\n",
            "\n",
            "Epoch 437/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1994 - val_loss: 0.1947\n",
            "Loss: 0.19943039119243622\n",
            "Validation Loss: 0.19467103481292725\n",
            "\n",
            "Epoch 438/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1984 - val_loss: 0.1951\n",
            "Loss: 0.1984023004770279\n",
            "Validation Loss: 0.1950862854719162\n",
            "\n",
            "Epoch 439/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1984 - val_loss: 0.1947\n",
            "Loss: 0.198358416557312\n",
            "Validation Loss: 0.1947200745344162\n",
            "\n",
            "Epoch 440/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1979 - val_loss: 0.1932\n",
            "Loss: 0.19786928594112396\n",
            "Validation Loss: 0.1931980848312378\n",
            "\n",
            "Epoch 441/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1989 - val_loss: 0.1906\n",
            "Loss: 0.198935404419899\n",
            "Validation Loss: 0.19063681364059448\n",
            "\n",
            "Epoch 442/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1986 - val_loss: 0.1926\n",
            "Loss: 0.1986062377691269\n",
            "Validation Loss: 0.19258014857769012\n",
            "\n",
            "Epoch 443/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1988 - val_loss: 0.1946\n",
            "Loss: 0.19880707561969757\n",
            "Validation Loss: 0.19457876682281494\n",
            "\n",
            "Epoch 444/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1975 - val_loss: 0.1936\n",
            "Loss: 0.19751891493797302\n",
            "Validation Loss: 0.1935543566942215\n",
            "\n",
            "Epoch 445/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1980 - val_loss: 0.1957\n",
            "Loss: 0.19802796840667725\n",
            "Validation Loss: 0.19567294418811798\n",
            "\n",
            "Epoch 446/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1974 - val_loss: 0.1965\n",
            "Loss: 0.1974049061536789\n",
            "Validation Loss: 0.19651848077774048\n",
            "\n",
            "Epoch 447/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1983 - val_loss: 0.1963\n",
            "Loss: 0.19828049838542938\n",
            "Validation Loss: 0.1963057965040207\n",
            "\n",
            "Epoch 448/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1982 - val_loss: 0.1923\n",
            "Loss: 0.19816970825195312\n",
            "Validation Loss: 0.19230955839157104\n",
            "\n",
            "Epoch 449/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1991 - val_loss: 0.1950\n",
            "Loss: 0.19907936453819275\n",
            "Validation Loss: 0.19501926004886627\n",
            "\n",
            "Epoch 450/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1977 - val_loss: 0.1958\n",
            "Loss: 0.19773399829864502\n",
            "Validation Loss: 0.19578367471694946\n",
            "\n",
            "Epoch 451/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1981 - val_loss: 0.1941\n",
            "Loss: 0.19805951416492462\n",
            "Validation Loss: 0.19411848485469818\n",
            "\n",
            "Epoch 452/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1977 - val_loss: 0.1934\n",
            "Loss: 0.19772043824195862\n",
            "Validation Loss: 0.19344332814216614\n",
            "\n",
            "Epoch 453/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1976 - val_loss: 0.1951\n",
            "Loss: 0.19760511815547943\n",
            "Validation Loss: 0.19508551061153412\n",
            "\n",
            "Epoch 454/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1975 - val_loss: 0.1915\n",
            "Loss: 0.19752709567546844\n",
            "Validation Loss: 0.1915462464094162\n",
            "\n",
            "Epoch 455/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1987 - val_loss: 0.1922\n",
            "Loss: 0.1987047642469406\n",
            "Validation Loss: 0.19217242300510406\n",
            "\n",
            "Epoch 456/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1978 - val_loss: 0.1930\n",
            "Loss: 0.19778843224048615\n",
            "Validation Loss: 0.19300101697444916\n",
            "\n",
            "Epoch 457/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1973 - val_loss: 0.1915\n",
            "Loss: 0.1973114162683487\n",
            "Validation Loss: 0.19148437678813934\n",
            "\n",
            "Epoch 458/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1966 - val_loss: 0.1931\n",
            "Loss: 0.1965738981962204\n",
            "Validation Loss: 0.19309942424297333\n",
            "\n",
            "Epoch 459/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1973 - val_loss: 0.1920\n",
            "Loss: 0.19730383157730103\n",
            "Validation Loss: 0.19201907515525818\n",
            "\n",
            "Epoch 460/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1979 - val_loss: 0.1929\n",
            "Loss: 0.19793517887592316\n",
            "Validation Loss: 0.19286669790744781\n",
            "\n",
            "Epoch 461/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1984 - val_loss: 0.1913\n",
            "Loss: 0.19837085902690887\n",
            "Validation Loss: 0.19130322337150574\n",
            "\n",
            "Epoch 462/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1973 - val_loss: 0.1914\n",
            "Loss: 0.19733113050460815\n",
            "Validation Loss: 0.19137534499168396\n",
            "\n",
            "Epoch 463/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1971 - val_loss: 0.1911\n",
            "Loss: 0.1970914751291275\n",
            "Validation Loss: 0.19113291800022125\n",
            "\n",
            "Epoch 464/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1968 - val_loss: 0.1921\n",
            "Loss: 0.19684597849845886\n",
            "Validation Loss: 0.19209948182106018\n",
            "\n",
            "Epoch 465/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1965 - val_loss: 0.1933\n",
            "Loss: 0.19649738073349\n",
            "Validation Loss: 0.19330982863903046\n",
            "\n",
            "Epoch 466/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1976 - val_loss: 0.1954\n",
            "Loss: 0.19756963849067688\n",
            "Validation Loss: 0.19537003338336945\n",
            "\n",
            "Epoch 467/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1967 - val_loss: 0.1915\n",
            "Loss: 0.19670450687408447\n",
            "Validation Loss: 0.19152715802192688\n",
            "\n",
            "Epoch 468/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1971 - val_loss: 0.1938\n",
            "Loss: 0.19707301259040833\n",
            "Validation Loss: 0.19384030997753143\n",
            "\n",
            "Epoch 469/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1957 - val_loss: 0.1953\n",
            "Loss: 0.19571366906166077\n",
            "Validation Loss: 0.19528965651988983\n",
            "\n",
            "Epoch 470/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1981 - val_loss: 0.1916\n",
            "Loss: 0.19811572134494781\n",
            "Validation Loss: 0.19163060188293457\n",
            "\n",
            "Epoch 471/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1976 - val_loss: 0.1945\n",
            "Loss: 0.19755534827709198\n",
            "Validation Loss: 0.19446159899234772\n",
            "\n",
            "Epoch 472/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1959 - val_loss: 0.1950\n",
            "Loss: 0.1958840936422348\n",
            "Validation Loss: 0.1950109601020813\n",
            "\n",
            "Epoch 473/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1974 - val_loss: 0.1921\n",
            "Loss: 0.1973741054534912\n",
            "Validation Loss: 0.19208690524101257\n",
            "\n",
            "Epoch 474/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1962 - val_loss: 0.1932\n",
            "Loss: 0.1961587816476822\n",
            "Validation Loss: 0.19322720170021057\n",
            "\n",
            "Epoch 475/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1973 - val_loss: 0.1921\n",
            "Loss: 0.1972513645887375\n",
            "Validation Loss: 0.19208860397338867\n",
            "\n",
            "Epoch 476/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1975 - val_loss: 0.1935\n",
            "Loss: 0.1975189447402954\n",
            "Validation Loss: 0.19345295429229736\n",
            "\n",
            "Epoch 477/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1962 - val_loss: 0.1925\n",
            "Loss: 0.196193665266037\n",
            "Validation Loss: 0.19253025949001312\n",
            "\n",
            "Epoch 478/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1965 - val_loss: 0.1921\n",
            "Loss: 0.1964893490076065\n",
            "Validation Loss: 0.19212689995765686\n",
            "\n",
            "Epoch 479/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1962 - val_loss: 0.1913\n",
            "Loss: 0.19616904854774475\n",
            "Validation Loss: 0.1913105845451355\n",
            "\n",
            "Epoch 480/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1973 - val_loss: 0.1909\n",
            "Loss: 0.1973104327917099\n",
            "Validation Loss: 0.19094383716583252\n",
            "\n",
            "Epoch 481/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1973 - val_loss: 0.1927\n",
            "Loss: 0.19725508987903595\n",
            "Validation Loss: 0.19269885122776031\n",
            "\n",
            "Epoch 482/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1969 - val_loss: 0.1918\n",
            "Loss: 0.19689686596393585\n",
            "Validation Loss: 0.19182419776916504\n",
            "\n",
            "Epoch 483/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1974 - val_loss: 0.1917\n",
            "Loss: 0.1974053829908371\n",
            "Validation Loss: 0.19174104928970337\n",
            "\n",
            "Epoch 484/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1976 - val_loss: 0.1914\n",
            "Loss: 0.19763804972171783\n",
            "Validation Loss: 0.19142058491706848\n",
            "\n",
            "Epoch 485/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1966 - val_loss: 0.1912\n",
            "Loss: 0.19663485884666443\n",
            "Validation Loss: 0.1911506950855255\n",
            "\n",
            "Epoch 486/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1960 - val_loss: 0.1925\n",
            "Loss: 0.19600504636764526\n",
            "Validation Loss: 0.1924595683813095\n",
            "\n",
            "Epoch 487/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1961 - val_loss: 0.1893\n",
            "Loss: 0.1961127668619156\n",
            "Validation Loss: 0.1892901510000229\n",
            "\n",
            "Epoch 488/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1964 - val_loss: 0.1923\n",
            "Loss: 0.1964467465877533\n",
            "Validation Loss: 0.19227902591228485\n",
            "\n",
            "Epoch 489/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1957 - val_loss: 0.1894\n",
            "Loss: 0.19574497640132904\n",
            "Validation Loss: 0.1893659383058548\n",
            "\n",
            "Epoch 490/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1970 - val_loss: 0.1928\n",
            "Loss: 0.19697017967700958\n",
            "Validation Loss: 0.1928027868270874\n",
            "\n",
            "Epoch 491/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1948 - val_loss: 0.1943\n",
            "Loss: 0.19481010735034943\n",
            "Validation Loss: 0.19428856670856476\n",
            "\n",
            "Epoch 492/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1964 - val_loss: 0.1905\n",
            "Loss: 0.19641335308551788\n",
            "Validation Loss: 0.19054345786571503\n",
            "\n",
            "Epoch 493/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1981 - val_loss: 0.1915\n",
            "Loss: 0.19813650846481323\n",
            "Validation Loss: 0.1914815753698349\n",
            "\n",
            "Epoch 494/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1955 - val_loss: 0.1899\n",
            "Loss: 0.19554629921913147\n",
            "Validation Loss: 0.18985171616077423\n",
            "\n",
            "Epoch 495/500\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.1967 - val_loss: 0.1906\n",
            "Loss: 0.19674189388751984\n",
            "Validation Loss: 0.19057197868824005\n",
            "\n",
            "Epoch 496/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1964 - val_loss: 0.1916\n",
            "Loss: 0.19640909135341644\n",
            "Validation Loss: 0.19162091612815857\n",
            "\n",
            "Epoch 497/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1962 - val_loss: 0.1929\n",
            "Loss: 0.19618618488311768\n",
            "Validation Loss: 0.19286227226257324\n",
            "\n",
            "Epoch 498/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1959 - val_loss: 0.1919\n",
            "Loss: 0.195855513215065\n",
            "Validation Loss: 0.19188319146633148\n",
            "\n",
            "Epoch 499/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1965 - val_loss: 0.1906\n",
            "Loss: 0.19653485715389252\n",
            "Validation Loss: 0.1905565708875656\n",
            "\n",
            "Epoch 500/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1964 - val_loss: 0.1914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.19639070332050323\n",
            "Validation Loss: 0.19138720631599426\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  (None, 5, 128)       73216       ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer_5 (AttentionLa  (None, 128)         128         ['lstm_5[0][0]',                 \n",
            " yer)                                                             'lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 128)       0           ['attention_layer_5[0][0]']      \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, 1, 1)        129         ['reshape_2[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.3420 - val_loss: 0.1876\n",
            "Loss: 0.3419925272464752\n",
            "Validation Loss: 0.18755972385406494\n",
            "\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2112 - val_loss: 0.1338\n",
            "Loss: 0.21118055284023285\n",
            "Validation Loss: 0.13382361829280853\n",
            "\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1967 - val_loss: 0.1288\n",
            "Loss: 0.19667434692382812\n",
            "Validation Loss: 0.12882652878761292\n",
            "\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1885 - val_loss: 0.1262\n",
            "Loss: 0.18850204348564148\n",
            "Validation Loss: 0.12623488903045654\n",
            "\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1873 - val_loss: 0.1222\n",
            "Loss: 0.18733768165111542\n",
            "Validation Loss: 0.12219534814357758\n",
            "\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1843 - val_loss: 0.1203\n",
            "Loss: 0.18429572880268097\n",
            "Validation Loss: 0.12025187909603119\n",
            "\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1820 - val_loss: 0.1194\n",
            "Loss: 0.1819627434015274\n",
            "Validation Loss: 0.11935710906982422\n",
            "\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1738 - val_loss: 0.1184\n",
            "Loss: 0.17378458380699158\n",
            "Validation Loss: 0.11841842532157898\n",
            "\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1727 - val_loss: 0.1170\n",
            "Loss: 0.17266935110092163\n",
            "Validation Loss: 0.11701173335313797\n",
            "\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1704 - val_loss: 0.1161\n",
            "Loss: 0.17039574682712555\n",
            "Validation Loss: 0.11610141396522522\n",
            "\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1681 - val_loss: 0.1168\n",
            "Loss: 0.16806547343730927\n",
            "Validation Loss: 0.11676270514726639\n",
            "\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1645 - val_loss: 0.1145\n",
            "Loss: 0.16452927887439728\n",
            "Validation Loss: 0.11448299139738083\n",
            "\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1600 - val_loss: 0.1164\n",
            "Loss: 0.15998034179210663\n",
            "Validation Loss: 0.11637286096811295\n",
            "\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1585 - val_loss: 0.1134\n",
            "Loss: 0.15848472714424133\n",
            "Validation Loss: 0.11344591528177261\n",
            "\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1574 - val_loss: 0.1151\n",
            "Loss: 0.15740296244621277\n",
            "Validation Loss: 0.11507754772901535\n",
            "\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1549 - val_loss: 0.1114\n",
            "Loss: 0.15492717921733856\n",
            "Validation Loss: 0.11143514513969421\n",
            "\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1527 - val_loss: 0.1122\n",
            "Loss: 0.15274129807949066\n",
            "Validation Loss: 0.11216413229703903\n",
            "\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1536 - val_loss: 0.1117\n",
            "Loss: 0.15358756482601166\n",
            "Validation Loss: 0.11170122772455215\n",
            "\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1521 - val_loss: 0.1117\n",
            "Loss: 0.15213456749916077\n",
            "Validation Loss: 0.11172331869602203\n",
            "\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1501 - val_loss: 0.1095\n",
            "Loss: 0.15014927089214325\n",
            "Validation Loss: 0.10954681038856506\n",
            "\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1509 - val_loss: 0.1097\n",
            "Loss: 0.1509370505809784\n",
            "Validation Loss: 0.10966049134731293\n",
            "\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1505 - val_loss: 0.1096\n",
            "Loss: 0.15051712095737457\n",
            "Validation Loss: 0.10958942025899887\n",
            "\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1484 - val_loss: 0.1093\n",
            "Loss: 0.1483624279499054\n",
            "Validation Loss: 0.10925126820802689\n",
            "\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1494 - val_loss: 0.1102\n",
            "Loss: 0.14939497411251068\n",
            "Validation Loss: 0.11020097881555557\n",
            "\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1481 - val_loss: 0.1089\n",
            "Loss: 0.14811678230762482\n",
            "Validation Loss: 0.10887125134468079\n",
            "\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1473 - val_loss: 0.1089\n",
            "Loss: 0.14728371798992157\n",
            "Validation Loss: 0.10889042168855667\n",
            "\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1462 - val_loss: 0.1090\n",
            "Loss: 0.14622169733047485\n",
            "Validation Loss: 0.10897126793861389\n",
            "\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1462 - val_loss: 0.1086\n",
            "Loss: 0.14616073668003082\n",
            "Validation Loss: 0.10857832431793213\n",
            "\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1441 - val_loss: 0.1085\n",
            "Loss: 0.1440969854593277\n",
            "Validation Loss: 0.10854215174913406\n",
            "\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1451 - val_loss: 0.1072\n",
            "Loss: 0.14511747658252716\n",
            "Validation Loss: 0.10724545270204544\n",
            "\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1452 - val_loss: 0.1091\n",
            "Loss: 0.14519362151622772\n",
            "Validation Loss: 0.10906899720430374\n",
            "\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1453 - val_loss: 0.1102\n",
            "Loss: 0.14526227116584778\n",
            "Validation Loss: 0.11024677008390427\n",
            "\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1452 - val_loss: 0.1085\n",
            "Loss: 0.14519783854484558\n",
            "Validation Loss: 0.10851408541202545\n",
            "\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1420 - val_loss: 0.1085\n",
            "Loss: 0.14201754331588745\n",
            "Validation Loss: 0.1085142269730568\n",
            "\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1425 - val_loss: 0.1081\n",
            "Loss: 0.14252685010433197\n",
            "Validation Loss: 0.10810552537441254\n",
            "\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1430 - val_loss: 0.1079\n",
            "Loss: 0.14302697777748108\n",
            "Validation Loss: 0.10789323598146439\n",
            "\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1421 - val_loss: 0.1073\n",
            "Loss: 0.14208826422691345\n",
            "Validation Loss: 0.10729371011257172\n",
            "\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1413 - val_loss: 0.1083\n",
            "Loss: 0.14134806394577026\n",
            "Validation Loss: 0.1083032563328743\n",
            "\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1399 - val_loss: 0.1060\n",
            "Loss: 0.13990288972854614\n",
            "Validation Loss: 0.10601513087749481\n",
            "\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1400 - val_loss: 0.1056\n",
            "Loss: 0.13996614515781403\n",
            "Validation Loss: 0.10557210445404053\n",
            "\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1391 - val_loss: 0.1060\n",
            "Loss: 0.13914474844932556\n",
            "Validation Loss: 0.10595445334911346\n",
            "\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1389 - val_loss: 0.1069\n",
            "Loss: 0.13887247443199158\n",
            "Validation Loss: 0.10692872107028961\n",
            "\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1389 - val_loss: 0.1069\n",
            "Loss: 0.13885128498077393\n",
            "Validation Loss: 0.10688833892345428\n",
            "\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1382 - val_loss: 0.1051\n",
            "Loss: 0.13823318481445312\n",
            "Validation Loss: 0.1050773561000824\n",
            "\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1391 - val_loss: 0.1061\n",
            "Loss: 0.1391257792711258\n",
            "Validation Loss: 0.1060960441827774\n",
            "\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1370 - val_loss: 0.1058\n",
            "Loss: 0.13697440922260284\n",
            "Validation Loss: 0.10583574324846268\n",
            "\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1374 - val_loss: 0.1041\n",
            "Loss: 0.13742923736572266\n",
            "Validation Loss: 0.10406617820262909\n",
            "\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1359 - val_loss: 0.1046\n",
            "Loss: 0.13586075603961945\n",
            "Validation Loss: 0.10462382435798645\n",
            "\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1368 - val_loss: 0.1053\n",
            "Loss: 0.13683351874351501\n",
            "Validation Loss: 0.10532324761152267\n",
            "\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1359 - val_loss: 0.1041\n",
            "Loss: 0.1359165757894516\n",
            "Validation Loss: 0.1040586605668068\n",
            "\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1363 - val_loss: 0.1057\n",
            "Loss: 0.13633477687835693\n",
            "Validation Loss: 0.1056826263666153\n",
            "\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1354 - val_loss: 0.1051\n",
            "Loss: 0.13543647527694702\n",
            "Validation Loss: 0.10514439642429352\n",
            "\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1354 - val_loss: 0.1042\n",
            "Loss: 0.13539181649684906\n",
            "Validation Loss: 0.10419798642396927\n",
            "\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1355 - val_loss: 0.1037\n",
            "Loss: 0.13545764982700348\n",
            "Validation Loss: 0.10365813970565796\n",
            "\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1343 - val_loss: 0.1027\n",
            "Loss: 0.13432933390140533\n",
            "Validation Loss: 0.10269390046596527\n",
            "\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1342 - val_loss: 0.1042\n",
            "Loss: 0.13424266874790192\n",
            "Validation Loss: 0.10420705378055573\n",
            "\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1345 - val_loss: 0.1023\n",
            "Loss: 0.13445694744586945\n",
            "Validation Loss: 0.10226459056138992\n",
            "\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1325 - val_loss: 0.1047\n",
            "Loss: 0.13246682286262512\n",
            "Validation Loss: 0.10466936975717545\n",
            "\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1327 - val_loss: 0.1029\n",
            "Loss: 0.13268737494945526\n",
            "Validation Loss: 0.10294169187545776\n",
            "\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1328 - val_loss: 0.1026\n",
            "Loss: 0.13282738626003265\n",
            "Validation Loss: 0.10264536738395691\n",
            "\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1340 - val_loss: 0.1025\n",
            "Loss: 0.13395844399929047\n",
            "Validation Loss: 0.10252068936824799\n",
            "\n",
            "Epoch 62/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1316 - val_loss: 0.1020\n",
            "Loss: 0.1316150724887848\n",
            "Validation Loss: 0.1020452231168747\n",
            "\n",
            "Epoch 63/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1322 - val_loss: 0.1026\n",
            "Loss: 0.13220196962356567\n",
            "Validation Loss: 0.10257265716791153\n",
            "\n",
            "Epoch 64/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1315 - val_loss: 0.1024\n",
            "Loss: 0.13147494196891785\n",
            "Validation Loss: 0.10240846127271652\n",
            "\n",
            "Epoch 65/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1302 - val_loss: 0.1006\n",
            "Loss: 0.13024182617664337\n",
            "Validation Loss: 0.10056710243225098\n",
            "\n",
            "Epoch 66/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1300 - val_loss: 0.1005\n",
            "Loss: 0.12997949123382568\n",
            "Validation Loss: 0.10045813024044037\n",
            "\n",
            "Epoch 67/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1305 - val_loss: 0.1015\n",
            "Loss: 0.1305403709411621\n",
            "Validation Loss: 0.10145611315965652\n",
            "\n",
            "Epoch 68/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1313 - val_loss: 0.1006\n",
            "Loss: 0.13127665221691132\n",
            "Validation Loss: 0.10058505833148956\n",
            "\n",
            "Epoch 69/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1295 - val_loss: 0.1014\n",
            "Loss: 0.1294698268175125\n",
            "Validation Loss: 0.10136967897415161\n",
            "\n",
            "Epoch 70/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1294 - val_loss: 0.0991\n",
            "Loss: 0.12937882542610168\n",
            "Validation Loss: 0.09913941472768784\n",
            "\n",
            "Epoch 71/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1277 - val_loss: 0.1002\n",
            "Loss: 0.12766163051128387\n",
            "Validation Loss: 0.10021121799945831\n",
            "\n",
            "Epoch 72/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1279 - val_loss: 0.1021\n",
            "Loss: 0.12790459394454956\n",
            "Validation Loss: 0.10211780667304993\n",
            "\n",
            "Epoch 73/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1295 - val_loss: 0.1009\n",
            "Loss: 0.12951450049877167\n",
            "Validation Loss: 0.10094888508319855\n",
            "\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1279 - val_loss: 0.1010\n",
            "Loss: 0.1279323548078537\n",
            "Validation Loss: 0.10098331421613693\n",
            "\n",
            "Epoch 75/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1279 - val_loss: 0.1014\n",
            "Loss: 0.12786325812339783\n",
            "Validation Loss: 0.10138072818517685\n",
            "\n",
            "Epoch 76/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1276 - val_loss: 0.1008\n",
            "Loss: 0.12756922841072083\n",
            "Validation Loss: 0.1008177250623703\n",
            "\n",
            "Epoch 77/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1269 - val_loss: 0.0993\n",
            "Loss: 0.12693817913532257\n",
            "Validation Loss: 0.0993393063545227\n",
            "\n",
            "Epoch 78/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1269 - val_loss: 0.0997\n",
            "Loss: 0.12692861258983612\n",
            "Validation Loss: 0.09973728656768799\n",
            "\n",
            "Epoch 79/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1266 - val_loss: 0.0990\n",
            "Loss: 0.12663622200489044\n",
            "Validation Loss: 0.09904515743255615\n",
            "\n",
            "Epoch 80/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1267 - val_loss: 0.1000\n",
            "Loss: 0.1266891211271286\n",
            "Validation Loss: 0.10001518577337265\n",
            "\n",
            "Epoch 81/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1267 - val_loss: 0.0984\n",
            "Loss: 0.12670409679412842\n",
            "Validation Loss: 0.09839224815368652\n",
            "\n",
            "Epoch 82/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1270 - val_loss: 0.0997\n",
            "Loss: 0.1270393282175064\n",
            "Validation Loss: 0.09966025501489639\n",
            "\n",
            "Epoch 83/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1245 - val_loss: 0.0977\n",
            "Loss: 0.12451658397912979\n",
            "Validation Loss: 0.09774976223707199\n",
            "\n",
            "Epoch 84/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1262 - val_loss: 0.0986\n",
            "Loss: 0.12621939182281494\n",
            "Validation Loss: 0.09862277656793594\n",
            "\n",
            "Epoch 85/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1251 - val_loss: 0.0993\n",
            "Loss: 0.1250646859407425\n",
            "Validation Loss: 0.0993134155869484\n",
            "\n",
            "Epoch 86/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1254 - val_loss: 0.0985\n",
            "Loss: 0.12543568015098572\n",
            "Validation Loss: 0.09850180149078369\n",
            "\n",
            "Epoch 87/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1237 - val_loss: 0.0970\n",
            "Loss: 0.12369150668382645\n",
            "Validation Loss: 0.0970444604754448\n",
            "\n",
            "Epoch 88/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1253 - val_loss: 0.0970\n",
            "Loss: 0.12529709935188293\n",
            "Validation Loss: 0.09695936739444733\n",
            "\n",
            "Epoch 89/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1248 - val_loss: 0.0987\n",
            "Loss: 0.12478229403495789\n",
            "Validation Loss: 0.09866273403167725\n",
            "\n",
            "Epoch 90/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1245 - val_loss: 0.0982\n",
            "Loss: 0.1244954839348793\n",
            "Validation Loss: 0.09822984784841537\n",
            "\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1232 - val_loss: 0.1001\n",
            "Loss: 0.1231679692864418\n",
            "Validation Loss: 0.10014425963163376\n",
            "\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1232 - val_loss: 0.0977\n",
            "Loss: 0.12319429963827133\n",
            "Validation Loss: 0.09770949184894562\n",
            "\n",
            "Epoch 93/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1228 - val_loss: 0.0997\n",
            "Loss: 0.1227690652012825\n",
            "Validation Loss: 0.09972896426916122\n",
            "\n",
            "Epoch 94/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1215 - val_loss: 0.0967\n",
            "Loss: 0.12150505185127258\n",
            "Validation Loss: 0.09669094532728195\n",
            "\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1222 - val_loss: 0.1000\n",
            "Loss: 0.12218249589204788\n",
            "Validation Loss: 0.09995583444833755\n",
            "\n",
            "Epoch 96/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1216 - val_loss: 0.0953\n",
            "Loss: 0.12159166485071182\n",
            "Validation Loss: 0.09528875350952148\n",
            "\n",
            "Epoch 97/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1216 - val_loss: 0.0989\n",
            "Loss: 0.12155810743570328\n",
            "Validation Loss: 0.09887750446796417\n",
            "\n",
            "Epoch 98/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1211 - val_loss: 0.0973\n",
            "Loss: 0.12112917006015778\n",
            "Validation Loss: 0.09731435775756836\n",
            "\n",
            "Epoch 99/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1215 - val_loss: 0.0970\n",
            "Loss: 0.12150224298238754\n",
            "Validation Loss: 0.09697869420051575\n",
            "\n",
            "Epoch 100/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1215 - val_loss: 0.0988\n",
            "Loss: 0.12149075418710709\n",
            "Validation Loss: 0.09877309203147888\n",
            "\n",
            "Epoch 101/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1228 - val_loss: 0.0984\n",
            "Loss: 0.12276219576597214\n",
            "Validation Loss: 0.09837973862886429\n",
            "\n",
            "Epoch 102/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1212 - val_loss: 0.0989\n",
            "Loss: 0.1211761012673378\n",
            "Validation Loss: 0.09888584911823273\n",
            "\n",
            "Epoch 103/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1203 - val_loss: 0.0960\n",
            "Loss: 0.12033839523792267\n",
            "Validation Loss: 0.0959712341427803\n",
            "\n",
            "Epoch 104/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1205 - val_loss: 0.0946\n",
            "Loss: 0.12054644525051117\n",
            "Validation Loss: 0.09462913870811462\n",
            "\n",
            "Epoch 105/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1222 - val_loss: 0.0973\n",
            "Loss: 0.12217520922422409\n",
            "Validation Loss: 0.09732074290513992\n",
            "\n",
            "Epoch 106/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1197 - val_loss: 0.0963\n",
            "Loss: 0.11965437233448029\n",
            "Validation Loss: 0.09633831679821014\n",
            "\n",
            "Epoch 107/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1210 - val_loss: 0.0949\n",
            "Loss: 0.12103529274463654\n",
            "Validation Loss: 0.09485287219285965\n",
            "\n",
            "Epoch 108/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1202 - val_loss: 0.0968\n",
            "Loss: 0.1202249601483345\n",
            "Validation Loss: 0.09678180515766144\n",
            "\n",
            "Epoch 109/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1205 - val_loss: 0.0984\n",
            "Loss: 0.12045320868492126\n",
            "Validation Loss: 0.09839623421430588\n",
            "\n",
            "Epoch 110/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1192 - val_loss: 0.0959\n",
            "Loss: 0.11918459087610245\n",
            "Validation Loss: 0.0959492102265358\n",
            "\n",
            "Epoch 111/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1187 - val_loss: 0.0964\n",
            "Loss: 0.11867792904376984\n",
            "Validation Loss: 0.09641516953706741\n",
            "\n",
            "Epoch 112/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1198 - val_loss: 0.0937\n",
            "Loss: 0.11983521282672882\n",
            "Validation Loss: 0.09374543279409409\n",
            "\n",
            "Epoch 113/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1187 - val_loss: 0.0961\n",
            "Loss: 0.11870908737182617\n",
            "Validation Loss: 0.09609892219305038\n",
            "\n",
            "Epoch 114/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1186 - val_loss: 0.0957\n",
            "Loss: 0.11863003671169281\n",
            "Validation Loss: 0.09574680775403976\n",
            "\n",
            "Epoch 115/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1182 - val_loss: 0.0973\n",
            "Loss: 0.11817888170480728\n",
            "Validation Loss: 0.09733404964208603\n",
            "\n",
            "Epoch 116/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1181 - val_loss: 0.0946\n",
            "Loss: 0.1180858388543129\n",
            "Validation Loss: 0.09458277374505997\n",
            "\n",
            "Epoch 117/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1180 - val_loss: 0.0963\n",
            "Loss: 0.11801201850175858\n",
            "Validation Loss: 0.0963459387421608\n",
            "\n",
            "Epoch 118/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1182 - val_loss: 0.0958\n",
            "Loss: 0.11817239224910736\n",
            "Validation Loss: 0.09575033187866211\n",
            "\n",
            "Epoch 119/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1176 - val_loss: 0.0969\n",
            "Loss: 0.11759496480226517\n",
            "Validation Loss: 0.09688305109739304\n",
            "\n",
            "Epoch 120/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1184 - val_loss: 0.0931\n",
            "Loss: 0.11840831488370895\n",
            "Validation Loss: 0.09312618523836136\n",
            "\n",
            "Epoch 121/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1172 - val_loss: 0.0939\n",
            "Loss: 0.11715707927942276\n",
            "Validation Loss: 0.0939471498131752\n",
            "\n",
            "Epoch 122/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1183 - val_loss: 0.0965\n",
            "Loss: 0.11826302856206894\n",
            "Validation Loss: 0.09651774913072586\n",
            "\n",
            "Epoch 123/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1170 - val_loss: 0.0935\n",
            "Loss: 0.11700134724378586\n",
            "Validation Loss: 0.09354658424854279\n",
            "\n",
            "Epoch 124/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1174 - val_loss: 0.0935\n",
            "Loss: 0.11738169938325882\n",
            "Validation Loss: 0.09349939227104187\n",
            "\n",
            "Epoch 125/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1165 - val_loss: 0.0927\n",
            "Loss: 0.1165318712592125\n",
            "Validation Loss: 0.09273795038461685\n",
            "\n",
            "Epoch 126/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1170 - val_loss: 0.0946\n",
            "Loss: 0.11698336899280548\n",
            "Validation Loss: 0.09463171660900116\n",
            "\n",
            "Epoch 127/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1160 - val_loss: 0.0938\n",
            "Loss: 0.11598100513219833\n",
            "Validation Loss: 0.09380202740430832\n",
            "\n",
            "Epoch 128/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1146 - val_loss: 0.0946\n",
            "Loss: 0.11458277702331543\n",
            "Validation Loss: 0.09458800405263901\n",
            "\n",
            "Epoch 129/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1165 - val_loss: 0.0930\n",
            "Loss: 0.11649189889431\n",
            "Validation Loss: 0.0930347889661789\n",
            "\n",
            "Epoch 130/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1161 - val_loss: 0.0933\n",
            "Loss: 0.11614754796028137\n",
            "Validation Loss: 0.09326650202274323\n",
            "\n",
            "Epoch 131/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1156 - val_loss: 0.0936\n",
            "Loss: 0.11564289778470993\n",
            "Validation Loss: 0.09361274540424347\n",
            "\n",
            "Epoch 132/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1159 - val_loss: 0.0937\n",
            "Loss: 0.115929514169693\n",
            "Validation Loss: 0.0936875119805336\n",
            "\n",
            "Epoch 133/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1161 - val_loss: 0.0932\n",
            "Loss: 0.11605296283960342\n",
            "Validation Loss: 0.09319068491458893\n",
            "\n",
            "Epoch 134/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1157 - val_loss: 0.0943\n",
            "Loss: 0.11574938148260117\n",
            "Validation Loss: 0.09429175406694412\n",
            "\n",
            "Epoch 135/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1152 - val_loss: 0.0925\n",
            "Loss: 0.11521627008914948\n",
            "Validation Loss: 0.09246554970741272\n",
            "\n",
            "Epoch 136/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1155 - val_loss: 0.0948\n",
            "Loss: 0.1155078187584877\n",
            "Validation Loss: 0.0947999432682991\n",
            "\n",
            "Epoch 137/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1142 - val_loss: 0.0930\n",
            "Loss: 0.11422747373580933\n",
            "Validation Loss: 0.09295610338449478\n",
            "\n",
            "Epoch 138/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1154 - val_loss: 0.0925\n",
            "Loss: 0.11535143107175827\n",
            "Validation Loss: 0.09254413843154907\n",
            "\n",
            "Epoch 139/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1146 - val_loss: 0.0931\n",
            "Loss: 0.11464358121156693\n",
            "Validation Loss: 0.09305532276630402\n",
            "\n",
            "Epoch 140/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1161 - val_loss: 0.0927\n",
            "Loss: 0.11609430611133575\n",
            "Validation Loss: 0.09268582612276077\n",
            "\n",
            "Epoch 141/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1144 - val_loss: 0.0910\n",
            "Loss: 0.11435119807720184\n",
            "Validation Loss: 0.09100376069545746\n",
            "\n",
            "Epoch 142/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1142 - val_loss: 0.0913\n",
            "Loss: 0.11418795585632324\n",
            "Validation Loss: 0.09134707599878311\n",
            "\n",
            "Epoch 143/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1137 - val_loss: 0.0920\n",
            "Loss: 0.11373064666986465\n",
            "Validation Loss: 0.09200096875429153\n",
            "\n",
            "Epoch 144/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1144 - val_loss: 0.0934\n",
            "Loss: 0.11443960666656494\n",
            "Validation Loss: 0.09343962371349335\n",
            "\n",
            "Epoch 145/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1137 - val_loss: 0.0935\n",
            "Loss: 0.11369788646697998\n",
            "Validation Loss: 0.09354619681835175\n",
            "\n",
            "Epoch 146/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1146 - val_loss: 0.0934\n",
            "Loss: 0.11463730037212372\n",
            "Validation Loss: 0.09341878443956375\n",
            "\n",
            "Epoch 147/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1134 - val_loss: 0.0912\n",
            "Loss: 0.1133551299571991\n",
            "Validation Loss: 0.09123440086841583\n",
            "\n",
            "Epoch 148/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1135 - val_loss: 0.0941\n",
            "Loss: 0.11349169909954071\n",
            "Validation Loss: 0.09407170861959457\n",
            "\n",
            "Epoch 149/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1142 - val_loss: 0.0925\n",
            "Loss: 0.11422368884086609\n",
            "Validation Loss: 0.09250080585479736\n",
            "\n",
            "Epoch 150/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1157 - val_loss: 0.0925\n",
            "Loss: 0.11573489755392075\n",
            "Validation Loss: 0.0924912765622139\n",
            "\n",
            "Epoch 151/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1137 - val_loss: 0.0924\n",
            "Loss: 0.11367005854845047\n",
            "Validation Loss: 0.09237446635961533\n",
            "\n",
            "Epoch 152/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1137 - val_loss: 0.0918\n",
            "Loss: 0.11373671144247055\n",
            "Validation Loss: 0.09178254753351212\n",
            "\n",
            "Epoch 153/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1135 - val_loss: 0.0928\n",
            "Loss: 0.11350313574075699\n",
            "Validation Loss: 0.09281480312347412\n",
            "\n",
            "Epoch 154/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1141 - val_loss: 0.0922\n",
            "Loss: 0.11407604068517685\n",
            "Validation Loss: 0.09218676388263702\n",
            "\n",
            "Epoch 155/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1129 - val_loss: 0.0915\n",
            "Loss: 0.11285685747861862\n",
            "Validation Loss: 0.09154926985502243\n",
            "\n",
            "Epoch 156/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1123 - val_loss: 0.0911\n",
            "Loss: 0.11231466382741928\n",
            "Validation Loss: 0.09114652872085571\n",
            "\n",
            "Epoch 157/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1134 - val_loss: 0.0934\n",
            "Loss: 0.11337996274232864\n",
            "Validation Loss: 0.09337499737739563\n",
            "\n",
            "Epoch 158/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1127 - val_loss: 0.0916\n",
            "Loss: 0.1127261221408844\n",
            "Validation Loss: 0.0916171446442604\n",
            "\n",
            "Epoch 159/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1132 - val_loss: 0.0915\n",
            "Loss: 0.11322223395109177\n",
            "Validation Loss: 0.09151851385831833\n",
            "\n",
            "Epoch 160/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1130 - val_loss: 0.0913\n",
            "Loss: 0.11295780539512634\n",
            "Validation Loss: 0.09133385866880417\n",
            "\n",
            "Epoch 161/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1124 - val_loss: 0.0906\n",
            "Loss: 0.11238124966621399\n",
            "Validation Loss: 0.09062308073043823\n",
            "\n",
            "Epoch 162/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1132 - val_loss: 0.0901\n",
            "Loss: 0.11321759223937988\n",
            "Validation Loss: 0.09010407328605652\n",
            "\n",
            "Epoch 163/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1122 - val_loss: 0.0900\n",
            "Loss: 0.11223047226667404\n",
            "Validation Loss: 0.09000876545906067\n",
            "\n",
            "Epoch 164/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1123 - val_loss: 0.0904\n",
            "Loss: 0.11229757964611053\n",
            "Validation Loss: 0.09039764851331711\n",
            "\n",
            "Epoch 165/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1121 - val_loss: 0.0904\n",
            "Loss: 0.11211031675338745\n",
            "Validation Loss: 0.09039002656936646\n",
            "\n",
            "Epoch 166/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1116 - val_loss: 0.0926\n",
            "Loss: 0.11161697655916214\n",
            "Validation Loss: 0.09259949624538422\n",
            "\n",
            "Epoch 167/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1105 - val_loss: 0.0913\n",
            "Loss: 0.11051558703184128\n",
            "Validation Loss: 0.09131906926631927\n",
            "\n",
            "Epoch 168/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1117 - val_loss: 0.0908\n",
            "Loss: 0.11170665174722672\n",
            "Validation Loss: 0.09077420830726624\n",
            "\n",
            "Epoch 169/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1121 - val_loss: 0.0929\n",
            "Loss: 0.11205185949802399\n",
            "Validation Loss: 0.09292501956224442\n",
            "\n",
            "Epoch 170/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1108 - val_loss: 0.0889\n",
            "Loss: 0.110793337225914\n",
            "Validation Loss: 0.08889209479093552\n",
            "\n",
            "Epoch 171/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1112 - val_loss: 0.0923\n",
            "Loss: 0.11121849715709686\n",
            "Validation Loss: 0.09225885570049286\n",
            "\n",
            "Epoch 172/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1108 - val_loss: 0.0898\n",
            "Loss: 0.11075477302074432\n",
            "Validation Loss: 0.089838907122612\n",
            "\n",
            "Epoch 173/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1108 - val_loss: 0.0901\n",
            "Loss: 0.11076575517654419\n",
            "Validation Loss: 0.09008898586034775\n",
            "\n",
            "Epoch 174/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1110 - val_loss: 0.0915\n",
            "Loss: 0.11102926731109619\n",
            "Validation Loss: 0.09151095896959305\n",
            "\n",
            "Epoch 175/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1118 - val_loss: 0.0886\n",
            "Loss: 0.11175736039876938\n",
            "Validation Loss: 0.08864781260490417\n",
            "\n",
            "Epoch 176/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1114 - val_loss: 0.0926\n",
            "Loss: 0.11139526218175888\n",
            "Validation Loss: 0.09262622892856598\n",
            "\n",
            "Epoch 177/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1108 - val_loss: 0.0909\n",
            "Loss: 0.1108330562710762\n",
            "Validation Loss: 0.09089228510856628\n",
            "\n",
            "Epoch 178/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1102 - val_loss: 0.0905\n",
            "Loss: 0.11021726578474045\n",
            "Validation Loss: 0.0905396044254303\n",
            "\n",
            "Epoch 179/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1110 - val_loss: 0.0905\n",
            "Loss: 0.11102989315986633\n",
            "Validation Loss: 0.09053948521614075\n",
            "\n",
            "Epoch 180/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1103 - val_loss: 0.0905\n",
            "Loss: 0.11033083498477936\n",
            "Validation Loss: 0.09050345420837402\n",
            "\n",
            "Epoch 181/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1107 - val_loss: 0.0905\n",
            "Loss: 0.11073385179042816\n",
            "Validation Loss: 0.09045781940221786\n",
            "\n",
            "Epoch 182/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1107 - val_loss: 0.0886\n",
            "Loss: 0.11069978773593903\n",
            "Validation Loss: 0.088550865650177\n",
            "\n",
            "Epoch 183/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1108 - val_loss: 0.0914\n",
            "Loss: 0.11075261980295181\n",
            "Validation Loss: 0.09143169224262238\n",
            "\n",
            "Epoch 184/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1094 - val_loss: 0.0893\n",
            "Loss: 0.1094474345445633\n",
            "Validation Loss: 0.08926860988140106\n",
            "\n",
            "Epoch 185/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1117 - val_loss: 0.0897\n",
            "Loss: 0.11170325428247452\n",
            "Validation Loss: 0.08972594141960144\n",
            "\n",
            "Epoch 186/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1101 - val_loss: 0.0910\n",
            "Loss: 0.1100589781999588\n",
            "Validation Loss: 0.0909985601902008\n",
            "\n",
            "Epoch 187/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1098 - val_loss: 0.0907\n",
            "Loss: 0.10975556820631027\n",
            "Validation Loss: 0.09074622392654419\n",
            "\n",
            "Epoch 188/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1100 - val_loss: 0.0919\n",
            "Loss: 0.10995537042617798\n",
            "Validation Loss: 0.09189146012067795\n",
            "\n",
            "Epoch 189/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1107 - val_loss: 0.0906\n",
            "Loss: 0.11069509387016296\n",
            "Validation Loss: 0.09056498110294342\n",
            "\n",
            "Epoch 190/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1101 - val_loss: 0.0898\n",
            "Loss: 0.11005926132202148\n",
            "Validation Loss: 0.08975725620985031\n",
            "\n",
            "Epoch 191/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1088 - val_loss: 0.0901\n",
            "Loss: 0.1088433638215065\n",
            "Validation Loss: 0.09011626988649368\n",
            "\n",
            "Epoch 192/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1093 - val_loss: 0.0910\n",
            "Loss: 0.10926424711942673\n",
            "Validation Loss: 0.09103021025657654\n",
            "\n",
            "Epoch 193/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1099 - val_loss: 0.0895\n",
            "Loss: 0.10992826521396637\n",
            "Validation Loss: 0.08946026116609573\n",
            "\n",
            "Epoch 194/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1103 - val_loss: 0.0887\n",
            "Loss: 0.11029548943042755\n",
            "Validation Loss: 0.08873097598552704\n",
            "\n",
            "Epoch 195/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1100 - val_loss: 0.0882\n",
            "Loss: 0.11000847071409225\n",
            "Validation Loss: 0.08821788430213928\n",
            "\n",
            "Epoch 196/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1087 - val_loss: 0.0905\n",
            "Loss: 0.10869883745908737\n",
            "Validation Loss: 0.0904788002371788\n",
            "\n",
            "Epoch 197/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1093 - val_loss: 0.0911\n",
            "Loss: 0.1093287542462349\n",
            "Validation Loss: 0.09114325791597366\n",
            "\n",
            "Epoch 198/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1091 - val_loss: 0.0875\n",
            "Loss: 0.10911859571933746\n",
            "Validation Loss: 0.08748750388622284\n",
            "\n",
            "Epoch 199/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1083 - val_loss: 0.0916\n",
            "Loss: 0.10825320333242416\n",
            "Validation Loss: 0.09159347414970398\n",
            "\n",
            "Epoch 200/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1094 - val_loss: 0.0884\n",
            "Loss: 0.1093546524643898\n",
            "Validation Loss: 0.08836093544960022\n",
            "\n",
            "Epoch 201/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1086 - val_loss: 0.0897\n",
            "Loss: 0.10857334733009338\n",
            "Validation Loss: 0.08973179012537003\n",
            "\n",
            "Epoch 202/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1090 - val_loss: 0.0886\n",
            "Loss: 0.10900455713272095\n",
            "Validation Loss: 0.08859562128782272\n",
            "\n",
            "Epoch 203/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1091 - val_loss: 0.0877\n",
            "Loss: 0.10906572639942169\n",
            "Validation Loss: 0.08768852800130844\n",
            "\n",
            "Epoch 204/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1097 - val_loss: 0.0880\n",
            "Loss: 0.10969510674476624\n",
            "Validation Loss: 0.08803515136241913\n",
            "\n",
            "Epoch 205/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1086 - val_loss: 0.0903\n",
            "Loss: 0.10861439257860184\n",
            "Validation Loss: 0.09034326672554016\n",
            "\n",
            "Epoch 206/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1091 - val_loss: 0.0881\n",
            "Loss: 0.10910504311323166\n",
            "Validation Loss: 0.08812808990478516\n",
            "\n",
            "Epoch 207/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1096 - val_loss: 0.0889\n",
            "Loss: 0.1095505952835083\n",
            "Validation Loss: 0.08887580782175064\n",
            "\n",
            "Epoch 208/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1088 - val_loss: 0.0866\n",
            "Loss: 0.1088186502456665\n",
            "Validation Loss: 0.08656129986047745\n",
            "\n",
            "Epoch 209/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1077 - val_loss: 0.0898\n",
            "Loss: 0.10774430632591248\n",
            "Validation Loss: 0.0897681787610054\n",
            "\n",
            "Epoch 210/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1085 - val_loss: 0.0872\n",
            "Loss: 0.10845166444778442\n",
            "Validation Loss: 0.08716054260730743\n",
            "\n",
            "Epoch 211/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1080 - val_loss: 0.0859\n",
            "Loss: 0.10795210301876068\n",
            "Validation Loss: 0.08588907867670059\n",
            "\n",
            "Epoch 212/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1082 - val_loss: 0.0890\n",
            "Loss: 0.10824976861476898\n",
            "Validation Loss: 0.08903228491544724\n",
            "\n",
            "Epoch 213/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1077 - val_loss: 0.0890\n",
            "Loss: 0.10765532404184341\n",
            "Validation Loss: 0.08901853114366531\n",
            "\n",
            "Epoch 214/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1077 - val_loss: 0.0870\n",
            "Loss: 0.10767312347888947\n",
            "Validation Loss: 0.08697367459535599\n",
            "\n",
            "Epoch 215/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1073 - val_loss: 0.0884\n",
            "Loss: 0.10731220245361328\n",
            "Validation Loss: 0.08843901008367538\n",
            "\n",
            "Epoch 216/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1083 - val_loss: 0.0878\n",
            "Loss: 0.10829854756593704\n",
            "Validation Loss: 0.08780677616596222\n",
            "\n",
            "Epoch 217/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1080 - val_loss: 0.0873\n",
            "Loss: 0.10796074569225311\n",
            "Validation Loss: 0.08725668489933014\n",
            "\n",
            "Epoch 218/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1080 - val_loss: 0.0882\n",
            "Loss: 0.10798926651477814\n",
            "Validation Loss: 0.08823508024215698\n",
            "\n",
            "Epoch 219/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1080 - val_loss: 0.0890\n",
            "Loss: 0.10804213583469391\n",
            "Validation Loss: 0.0889953002333641\n",
            "\n",
            "Epoch 220/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1080 - val_loss: 0.0871\n",
            "Loss: 0.10802308470010757\n",
            "Validation Loss: 0.0870986133813858\n",
            "\n",
            "Epoch 221/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1077 - val_loss: 0.0901\n",
            "Loss: 0.10773885995149612\n",
            "Validation Loss: 0.09009438753128052\n",
            "\n",
            "Epoch 222/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1071 - val_loss: 0.0862\n",
            "Loss: 0.10711390525102615\n",
            "Validation Loss: 0.08616416901350021\n",
            "\n",
            "Epoch 223/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1076 - val_loss: 0.0891\n",
            "Loss: 0.1075943186879158\n",
            "Validation Loss: 0.08906944841146469\n",
            "\n",
            "Epoch 224/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1087 - val_loss: 0.0879\n",
            "Loss: 0.10872461646795273\n",
            "Validation Loss: 0.08792489022016525\n",
            "\n",
            "Epoch 225/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1072 - val_loss: 0.0875\n",
            "Loss: 0.10721579939126968\n",
            "Validation Loss: 0.08746524900197983\n",
            "\n",
            "Epoch 226/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1069 - val_loss: 0.0874\n",
            "Loss: 0.10689830780029297\n",
            "Validation Loss: 0.08739956468343735\n",
            "\n",
            "Epoch 227/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1071 - val_loss: 0.0884\n",
            "Loss: 0.10713300108909607\n",
            "Validation Loss: 0.08844666928052902\n",
            "\n",
            "Epoch 228/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1089 - val_loss: 0.0879\n",
            "Loss: 0.1089240238070488\n",
            "Validation Loss: 0.08793096244335175\n",
            "\n",
            "Epoch 229/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1072 - val_loss: 0.0893\n",
            "Loss: 0.10715041309595108\n",
            "Validation Loss: 0.08932369947433472\n",
            "\n",
            "Epoch 230/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1067 - val_loss: 0.0882\n",
            "Loss: 0.10670319199562073\n",
            "Validation Loss: 0.08823078125715256\n",
            "\n",
            "Epoch 231/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1061 - val_loss: 0.0881\n",
            "Loss: 0.106117844581604\n",
            "Validation Loss: 0.08805109560489655\n",
            "\n",
            "Epoch 232/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1064 - val_loss: 0.0881\n",
            "Loss: 0.10637910664081573\n",
            "Validation Loss: 0.08813222497701645\n",
            "\n",
            "Epoch 233/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1071 - val_loss: 0.0866\n",
            "Loss: 0.10714767128229141\n",
            "Validation Loss: 0.08660676330327988\n",
            "\n",
            "Epoch 234/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1069 - val_loss: 0.0888\n",
            "Loss: 0.10693059861660004\n",
            "Validation Loss: 0.088767409324646\n",
            "\n",
            "Epoch 235/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1059 - val_loss: 0.0854\n",
            "Loss: 0.10590630769729614\n",
            "Validation Loss: 0.08540131896734238\n",
            "\n",
            "Epoch 236/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1068 - val_loss: 0.0885\n",
            "Loss: 0.10684042423963547\n",
            "Validation Loss: 0.08845523744821548\n",
            "\n",
            "Epoch 237/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1067 - val_loss: 0.0857\n",
            "Loss: 0.10668201744556427\n",
            "Validation Loss: 0.08571425080299377\n",
            "\n",
            "Epoch 238/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1069 - val_loss: 0.0890\n",
            "Loss: 0.10686159133911133\n",
            "Validation Loss: 0.08897796273231506\n",
            "\n",
            "Epoch 239/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1062 - val_loss: 0.0863\n",
            "Loss: 0.10623694956302643\n",
            "Validation Loss: 0.08632947504520416\n",
            "\n",
            "Epoch 240/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1060 - val_loss: 0.0880\n",
            "Loss: 0.10597225278615952\n",
            "Validation Loss: 0.08796065300703049\n",
            "\n",
            "Epoch 241/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1071 - val_loss: 0.0863\n",
            "Loss: 0.10707781463861465\n",
            "Validation Loss: 0.08633754402399063\n",
            "\n",
            "Epoch 242/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1065 - val_loss: 0.0866\n",
            "Loss: 0.10652314126491547\n",
            "Validation Loss: 0.08664753288030624\n",
            "\n",
            "Epoch 243/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1064 - val_loss: 0.0865\n",
            "Loss: 0.10643313080072403\n",
            "Validation Loss: 0.0865338146686554\n",
            "\n",
            "Epoch 244/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1061 - val_loss: 0.0877\n",
            "Loss: 0.10612570494413376\n",
            "Validation Loss: 0.0877489522099495\n",
            "\n",
            "Epoch 245/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1058 - val_loss: 0.0866\n",
            "Loss: 0.10576135665178299\n",
            "Validation Loss: 0.08664435893297195\n",
            "\n",
            "Epoch 246/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1059 - val_loss: 0.0862\n",
            "Loss: 0.10594982653856277\n",
            "Validation Loss: 0.08616755157709122\n",
            "\n",
            "Epoch 247/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1056 - val_loss: 0.0869\n",
            "Loss: 0.105582095682621\n",
            "Validation Loss: 0.08686251938343048\n",
            "\n",
            "Epoch 248/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1059 - val_loss: 0.0874\n",
            "Loss: 0.10587968677282333\n",
            "Validation Loss: 0.08735774457454681\n",
            "\n",
            "Epoch 249/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1057 - val_loss: 0.0853\n",
            "Loss: 0.10565207898616791\n",
            "Validation Loss: 0.08532704412937164\n",
            "\n",
            "Epoch 250/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1061 - val_loss: 0.0868\n",
            "Loss: 0.10612329840660095\n",
            "Validation Loss: 0.08683192729949951\n",
            "\n",
            "Epoch 251/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1062 - val_loss: 0.0868\n",
            "Loss: 0.10621191561222076\n",
            "Validation Loss: 0.08675309270620346\n",
            "\n",
            "Epoch 252/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1059 - val_loss: 0.0860\n",
            "Loss: 0.10588118433952332\n",
            "Validation Loss: 0.08602558076381683\n",
            "\n",
            "Epoch 253/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1065 - val_loss: 0.0869\n",
            "Loss: 0.10646647959947586\n",
            "Validation Loss: 0.08693666011095047\n",
            "\n",
            "Epoch 254/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1049 - val_loss: 0.0872\n",
            "Loss: 0.10486624389886856\n",
            "Validation Loss: 0.08720995485782623\n",
            "\n",
            "Epoch 255/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1058 - val_loss: 0.0876\n",
            "Loss: 0.10576607286930084\n",
            "Validation Loss: 0.08755021542310715\n",
            "\n",
            "Epoch 256/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1054 - val_loss: 0.0853\n",
            "Loss: 0.10544534772634506\n",
            "Validation Loss: 0.08525075763463974\n",
            "\n",
            "Epoch 257/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1058 - val_loss: 0.0867\n",
            "Loss: 0.10577142983675003\n",
            "Validation Loss: 0.08668605983257294\n",
            "\n",
            "Epoch 258/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1057 - val_loss: 0.0854\n",
            "Loss: 0.10567403584718704\n",
            "Validation Loss: 0.08539798855781555\n",
            "\n",
            "Epoch 259/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1046 - val_loss: 0.0861\n",
            "Loss: 0.10458023846149445\n",
            "Validation Loss: 0.08612748235464096\n",
            "\n",
            "Epoch 260/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1060 - val_loss: 0.0861\n",
            "Loss: 0.10598434507846832\n",
            "Validation Loss: 0.08611427992582321\n",
            "\n",
            "Epoch 261/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1056 - val_loss: 0.0868\n",
            "Loss: 0.1056223064661026\n",
            "Validation Loss: 0.0868079736828804\n",
            "\n",
            "Epoch 262/500\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1060 - val_loss: 0.0862\n",
            "Loss: 0.10601779818534851\n",
            "Validation Loss: 0.08621512353420258\n",
            "\n",
            "Epoch 263/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1057 - val_loss: 0.0876\n",
            "Loss: 0.10567692667245865\n",
            "Validation Loss: 0.08760150521993637\n",
            "\n",
            "Epoch 264/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1053 - val_loss: 0.0856\n",
            "Loss: 0.1053081676363945\n",
            "Validation Loss: 0.0855623260140419\n",
            "\n",
            "Epoch 265/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1057 - val_loss: 0.0877\n",
            "Loss: 0.10573374480009079\n",
            "Validation Loss: 0.08772304654121399\n",
            "\n",
            "Epoch 266/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1042 - val_loss: 0.0853\n",
            "Loss: 0.1042117103934288\n",
            "Validation Loss: 0.08530725538730621\n",
            "\n",
            "Epoch 267/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1040 - val_loss: 0.0837\n",
            "Loss: 0.10396484285593033\n",
            "Validation Loss: 0.0837043970823288\n",
            "\n",
            "Epoch 268/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1052 - val_loss: 0.0876\n",
            "Loss: 0.10520686209201813\n",
            "Validation Loss: 0.08762951195240021\n",
            "\n",
            "Epoch 269/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1051 - val_loss: 0.0856\n",
            "Loss: 0.10510745644569397\n",
            "Validation Loss: 0.08563270419836044\n",
            "\n",
            "Epoch 270/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1041 - val_loss: 0.0876\n",
            "Loss: 0.10411136597394943\n",
            "Validation Loss: 0.08756203949451447\n",
            "\n",
            "Epoch 271/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1049 - val_loss: 0.0854\n",
            "Loss: 0.10494405031204224\n",
            "Validation Loss: 0.08542738109827042\n",
            "\n",
            "Epoch 272/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1052 - val_loss: 0.0854\n",
            "Loss: 0.10520745068788528\n",
            "Validation Loss: 0.08541246503591537\n",
            "\n",
            "Epoch 273/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1047 - val_loss: 0.0858\n",
            "Loss: 0.10465064644813538\n",
            "Validation Loss: 0.08584630489349365\n",
            "\n",
            "Epoch 274/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1047 - val_loss: 0.0851\n",
            "Loss: 0.10466431826353073\n",
            "Validation Loss: 0.0851050391793251\n",
            "\n",
            "Epoch 275/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1050 - val_loss: 0.0858\n",
            "Loss: 0.10504573583602905\n",
            "Validation Loss: 0.08582758158445358\n",
            "\n",
            "Epoch 276/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1040 - val_loss: 0.0862\n",
            "Loss: 0.10399884730577469\n",
            "Validation Loss: 0.08621573448181152\n",
            "\n",
            "Epoch 277/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1055 - val_loss: 0.0855\n",
            "Loss: 0.10548548400402069\n",
            "Validation Loss: 0.08548009395599365\n",
            "\n",
            "Epoch 278/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1041 - val_loss: 0.0869\n",
            "Loss: 0.10409185290336609\n",
            "Validation Loss: 0.0868510827422142\n",
            "\n",
            "Epoch 279/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1039 - val_loss: 0.0853\n",
            "Loss: 0.10394895076751709\n",
            "Validation Loss: 0.08533794432878494\n",
            "\n",
            "Epoch 280/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1052 - val_loss: 0.0863\n",
            "Loss: 0.1051836758852005\n",
            "Validation Loss: 0.0863264948129654\n",
            "\n",
            "Epoch 281/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1046 - val_loss: 0.0847\n",
            "Loss: 0.10458004474639893\n",
            "Validation Loss: 0.08471094071865082\n",
            "\n",
            "Epoch 282/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1045 - val_loss: 0.0865\n",
            "Loss: 0.10451101511716843\n",
            "Validation Loss: 0.0864814892411232\n",
            "\n",
            "Epoch 283/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1044 - val_loss: 0.0859\n",
            "Loss: 0.1044083759188652\n",
            "Validation Loss: 0.0859118402004242\n",
            "\n",
            "Epoch 284/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1043 - val_loss: 0.0859\n",
            "Loss: 0.10426586121320724\n",
            "Validation Loss: 0.08586565405130386\n",
            "\n",
            "Epoch 285/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1050 - val_loss: 0.0850\n",
            "Loss: 0.10496464371681213\n",
            "Validation Loss: 0.08504403382539749\n",
            "\n",
            "Epoch 286/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1043 - val_loss: 0.0851\n",
            "Loss: 0.1042885035276413\n",
            "Validation Loss: 0.08513309806585312\n",
            "\n",
            "Epoch 287/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1043 - val_loss: 0.0869\n",
            "Loss: 0.10428369790315628\n",
            "Validation Loss: 0.0868595540523529\n",
            "\n",
            "Epoch 288/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1038 - val_loss: 0.0861\n",
            "Loss: 0.10382635146379471\n",
            "Validation Loss: 0.08611815422773361\n",
            "\n",
            "Epoch 289/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1039 - val_loss: 0.0851\n",
            "Loss: 0.10385871678590775\n",
            "Validation Loss: 0.08513496071100235\n",
            "\n",
            "Epoch 290/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1040 - val_loss: 0.0864\n",
            "Loss: 0.10402992367744446\n",
            "Validation Loss: 0.08638487756252289\n",
            "\n",
            "Epoch 291/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1044 - val_loss: 0.0843\n",
            "Loss: 0.1043509915471077\n",
            "Validation Loss: 0.08433237671852112\n",
            "\n",
            "Epoch 292/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1039 - val_loss: 0.0865\n",
            "Loss: 0.10393588989973068\n",
            "Validation Loss: 0.08648552745580673\n",
            "\n",
            "Epoch 293/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1039 - val_loss: 0.0852\n",
            "Loss: 0.10386016964912415\n",
            "Validation Loss: 0.08515226095914841\n",
            "\n",
            "Epoch 294/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1028 - val_loss: 0.0842\n",
            "Loss: 0.10284598171710968\n",
            "Validation Loss: 0.08419737219810486\n",
            "\n",
            "Epoch 295/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1040 - val_loss: 0.0842\n",
            "Loss: 0.1039537787437439\n",
            "Validation Loss: 0.08415412902832031\n",
            "\n",
            "Epoch 296/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1039 - val_loss: 0.0863\n",
            "Loss: 0.10392136126756668\n",
            "Validation Loss: 0.0862555280327797\n",
            "\n",
            "Epoch 297/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1030 - val_loss: 0.0840\n",
            "Loss: 0.10298143327236176\n",
            "Validation Loss: 0.08402390778064728\n",
            "\n",
            "Epoch 298/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1039 - val_loss: 0.0849\n",
            "Loss: 0.10385873913764954\n",
            "Validation Loss: 0.08493085950613022\n",
            "\n",
            "Epoch 299/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1028 - val_loss: 0.0848\n",
            "Loss: 0.10276494920253754\n",
            "Validation Loss: 0.08475527912378311\n",
            "\n",
            "Epoch 300/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1034 - val_loss: 0.0875\n",
            "Loss: 0.10342676937580109\n",
            "Validation Loss: 0.08745457977056503\n",
            "\n",
            "Epoch 301/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1044 - val_loss: 0.0830\n",
            "Loss: 0.10435013473033905\n",
            "Validation Loss: 0.08295052498579025\n",
            "\n",
            "Epoch 302/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1039 - val_loss: 0.0849\n",
            "Loss: 0.10391809046268463\n",
            "Validation Loss: 0.08491417020559311\n",
            "\n",
            "Epoch 303/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1036 - val_loss: 0.0841\n",
            "Loss: 0.10364566743373871\n",
            "Validation Loss: 0.0840526595711708\n",
            "\n",
            "Epoch 304/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1031 - val_loss: 0.0857\n",
            "Loss: 0.10306988656520844\n",
            "Validation Loss: 0.08571275323629379\n",
            "\n",
            "Epoch 305/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1034 - val_loss: 0.0844\n",
            "Loss: 0.10340770334005356\n",
            "Validation Loss: 0.08444806188344955\n",
            "\n",
            "Epoch 306/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1027 - val_loss: 0.0848\n",
            "Loss: 0.10268043726682663\n",
            "Validation Loss: 0.08480038493871689\n",
            "\n",
            "Epoch 307/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1029 - val_loss: 0.0849\n",
            "Loss: 0.10294321179389954\n",
            "Validation Loss: 0.08487249910831451\n",
            "\n",
            "Epoch 308/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1028 - val_loss: 0.0847\n",
            "Loss: 0.10281834006309509\n",
            "Validation Loss: 0.08471641689538956\n",
            "\n",
            "Epoch 309/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1032 - val_loss: 0.0855\n",
            "Loss: 0.10324307531118393\n",
            "Validation Loss: 0.08551124483346939\n",
            "\n",
            "Epoch 310/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1031 - val_loss: 0.0840\n",
            "Loss: 0.10310280323028564\n",
            "Validation Loss: 0.08399149775505066\n",
            "\n",
            "Epoch 311/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1033 - val_loss: 0.0837\n",
            "Loss: 0.10326966643333435\n",
            "Validation Loss: 0.08371473103761673\n",
            "\n",
            "Epoch 312/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1023 - val_loss: 0.0851\n",
            "Loss: 0.10229874402284622\n",
            "Validation Loss: 0.0851375013589859\n",
            "\n",
            "Epoch 313/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1023 - val_loss: 0.0844\n",
            "Loss: 0.10230845212936401\n",
            "Validation Loss: 0.08435441553592682\n",
            "\n",
            "Epoch 314/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1027 - val_loss: 0.0834\n",
            "Loss: 0.10268786549568176\n",
            "Validation Loss: 0.08344138413667679\n",
            "\n",
            "Epoch 315/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1021 - val_loss: 0.0834\n",
            "Loss: 0.10205071419477463\n",
            "Validation Loss: 0.0833934098482132\n",
            "\n",
            "Epoch 316/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1026 - val_loss: 0.0844\n",
            "Loss: 0.10259190946817398\n",
            "Validation Loss: 0.08439672738313675\n",
            "\n",
            "Epoch 317/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1033 - val_loss: 0.0854\n",
            "Loss: 0.10332801938056946\n",
            "Validation Loss: 0.08543602377176285\n",
            "\n",
            "Epoch 318/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1022 - val_loss: 0.0842\n",
            "Loss: 0.10219747573137283\n",
            "Validation Loss: 0.08421614021062851\n",
            "\n",
            "Epoch 319/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1027 - val_loss: 0.0833\n",
            "Loss: 0.10265929251909256\n",
            "Validation Loss: 0.08325900882482529\n",
            "\n",
            "Epoch 320/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1033 - val_loss: 0.0838\n",
            "Loss: 0.10328347235918045\n",
            "Validation Loss: 0.08378229290246964\n",
            "\n",
            "Epoch 321/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1022 - val_loss: 0.0842\n",
            "Loss: 0.1021849662065506\n",
            "Validation Loss: 0.0841878354549408\n",
            "\n",
            "Epoch 322/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1024 - val_loss: 0.0849\n",
            "Loss: 0.10235385596752167\n",
            "Validation Loss: 0.0848669484257698\n",
            "\n",
            "Epoch 323/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1026 - val_loss: 0.0827\n",
            "Loss: 0.10264082998037338\n",
            "Validation Loss: 0.08266108483076096\n",
            "\n",
            "Epoch 324/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1033 - val_loss: 0.0854\n",
            "Loss: 0.10325995087623596\n",
            "Validation Loss: 0.08537942171096802\n",
            "\n",
            "Epoch 325/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1021 - val_loss: 0.0838\n",
            "Loss: 0.10209399461746216\n",
            "Validation Loss: 0.08382690697908401\n",
            "\n",
            "Epoch 326/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1032 - val_loss: 0.0831\n",
            "Loss: 0.10322868824005127\n",
            "Validation Loss: 0.08314493298530579\n",
            "\n",
            "Epoch 327/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1016 - val_loss: 0.0843\n",
            "Loss: 0.10159780830144882\n",
            "Validation Loss: 0.08425062149763107\n",
            "\n",
            "Epoch 328/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1022 - val_loss: 0.0831\n",
            "Loss: 0.10218308120965958\n",
            "Validation Loss: 0.08308900147676468\n",
            "\n",
            "Epoch 329/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1018 - val_loss: 0.0842\n",
            "Loss: 0.10182246565818787\n",
            "Validation Loss: 0.08424574136734009\n",
            "\n",
            "Epoch 330/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1018 - val_loss: 0.0843\n",
            "Loss: 0.10177554935216904\n",
            "Validation Loss: 0.08425070345401764\n",
            "\n",
            "Epoch 331/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1020 - val_loss: 0.0839\n",
            "Loss: 0.10195077955722809\n",
            "Validation Loss: 0.08387644588947296\n",
            "\n",
            "Epoch 332/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1019 - val_loss: 0.0813\n",
            "Loss: 0.10193266719579697\n",
            "Validation Loss: 0.08128182590007782\n",
            "\n",
            "Epoch 333/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1016 - val_loss: 0.0841\n",
            "Loss: 0.10159635543823242\n",
            "Validation Loss: 0.08405449241399765\n",
            "\n",
            "Epoch 334/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1019 - val_loss: 0.0843\n",
            "Loss: 0.10188379138708115\n",
            "Validation Loss: 0.08434061706066132\n",
            "\n",
            "Epoch 335/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1022 - val_loss: 0.0826\n",
            "Loss: 0.10215814411640167\n",
            "Validation Loss: 0.0825766921043396\n",
            "\n",
            "Epoch 336/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1026 - val_loss: 0.0843\n",
            "Loss: 0.10261469334363937\n",
            "Validation Loss: 0.08428845554590225\n",
            "\n",
            "Epoch 337/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1015 - val_loss: 0.0827\n",
            "Loss: 0.10154014080762863\n",
            "Validation Loss: 0.0827406719326973\n",
            "\n",
            "Epoch 338/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1019 - val_loss: 0.0839\n",
            "Loss: 0.10190792381763458\n",
            "Validation Loss: 0.08389271050691605\n",
            "\n",
            "Epoch 339/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1024 - val_loss: 0.0853\n",
            "Loss: 0.10237972438335419\n",
            "Validation Loss: 0.08533112704753876\n",
            "\n",
            "Epoch 340/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1023 - val_loss: 0.0827\n",
            "Loss: 0.10227327793836594\n",
            "Validation Loss: 0.08266662061214447\n",
            "\n",
            "Epoch 341/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1023 - val_loss: 0.0849\n",
            "Loss: 0.10227262228727341\n",
            "Validation Loss: 0.08491317182779312\n",
            "\n",
            "Epoch 342/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1024 - val_loss: 0.0839\n",
            "Loss: 0.1023954302072525\n",
            "Validation Loss: 0.08392134308815002\n",
            "\n",
            "Epoch 343/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1016 - val_loss: 0.0842\n",
            "Loss: 0.10163982212543488\n",
            "Validation Loss: 0.08417156338691711\n",
            "\n",
            "Epoch 344/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1022 - val_loss: 0.0824\n",
            "Loss: 0.10224664956331253\n",
            "Validation Loss: 0.08238590508699417\n",
            "\n",
            "Epoch 345/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1013 - val_loss: 0.0829\n",
            "Loss: 0.10127664357423782\n",
            "Validation Loss: 0.08290814608335495\n",
            "\n",
            "Epoch 346/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1017 - val_loss: 0.0838\n",
            "Loss: 0.10166776925325394\n",
            "Validation Loss: 0.0838213562965393\n",
            "\n",
            "Epoch 347/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1017 - val_loss: 0.0824\n",
            "Loss: 0.10174135118722916\n",
            "Validation Loss: 0.08242563158273697\n",
            "\n",
            "Epoch 348/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1018 - val_loss: 0.0835\n",
            "Loss: 0.10175487399101257\n",
            "Validation Loss: 0.083522267639637\n",
            "\n",
            "Epoch 349/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1023 - val_loss: 0.0823\n",
            "Loss: 0.10232407599687576\n",
            "Validation Loss: 0.08225327730178833\n",
            "\n",
            "Epoch 350/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1012 - val_loss: 0.0838\n",
            "Loss: 0.10118364542722702\n",
            "Validation Loss: 0.08383587747812271\n",
            "\n",
            "Epoch 351/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1024 - val_loss: 0.0819\n",
            "Loss: 0.10241126269102097\n",
            "Validation Loss: 0.08193518966436386\n",
            "\n",
            "Epoch 352/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1009 - val_loss: 0.0852\n",
            "Loss: 0.10094913095235825\n",
            "Validation Loss: 0.08524405211210251\n",
            "\n",
            "Epoch 353/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1014 - val_loss: 0.0826\n",
            "Loss: 0.10144327580928802\n",
            "Validation Loss: 0.08255503326654434\n",
            "\n",
            "Epoch 354/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1018 - val_loss: 0.0830\n",
            "Loss: 0.10181070864200592\n",
            "Validation Loss: 0.0829654410481453\n",
            "\n",
            "Epoch 355/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1006 - val_loss: 0.0822\n",
            "Loss: 0.10061968117952347\n",
            "Validation Loss: 0.0822080597281456\n",
            "\n",
            "Epoch 356/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1015 - val_loss: 0.0823\n",
            "Loss: 0.10152796655893326\n",
            "Validation Loss: 0.08228293806314468\n",
            "\n",
            "Epoch 357/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1015 - val_loss: 0.0841\n",
            "Loss: 0.10145383328199387\n",
            "Validation Loss: 0.08410417288541794\n",
            "\n",
            "Epoch 358/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1008 - val_loss: 0.0831\n",
            "Loss: 0.10077950358390808\n",
            "Validation Loss: 0.08310095220804214\n",
            "\n",
            "Epoch 359/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1004 - val_loss: 0.0832\n",
            "Loss: 0.10041532665491104\n",
            "Validation Loss: 0.08324896544218063\n",
            "\n",
            "Epoch 360/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1008 - val_loss: 0.0835\n",
            "Loss: 0.10077451914548874\n",
            "Validation Loss: 0.08354634791612625\n",
            "\n",
            "Epoch 361/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1016 - val_loss: 0.0821\n",
            "Loss: 0.10157835483551025\n",
            "Validation Loss: 0.08207482844591141\n",
            "\n",
            "Epoch 362/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1019 - val_loss: 0.0841\n",
            "Loss: 0.10188670456409454\n",
            "Validation Loss: 0.08408979326486588\n",
            "\n",
            "Epoch 363/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1012 - val_loss: 0.0816\n",
            "Loss: 0.10118900239467621\n",
            "Validation Loss: 0.08157961815595627\n",
            "\n",
            "Epoch 364/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1018 - val_loss: 0.0834\n",
            "Loss: 0.10178054124116898\n",
            "Validation Loss: 0.083415187895298\n",
            "\n",
            "Epoch 365/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1005 - val_loss: 0.0812\n",
            "Loss: 0.10045398771762848\n",
            "Validation Loss: 0.08115310966968536\n",
            "\n",
            "Epoch 366/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1006 - val_loss: 0.0819\n",
            "Loss: 0.10056892782449722\n",
            "Validation Loss: 0.08194231241941452\n",
            "\n",
            "Epoch 367/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1009 - val_loss: 0.0829\n",
            "Loss: 0.10086997598409653\n",
            "Validation Loss: 0.08290369808673859\n",
            "\n",
            "Epoch 368/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1010 - val_loss: 0.0820\n",
            "Loss: 0.10097307711839676\n",
            "Validation Loss: 0.08202902227640152\n",
            "\n",
            "Epoch 369/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1001 - val_loss: 0.0835\n",
            "Loss: 0.1000986322760582\n",
            "Validation Loss: 0.08347940444946289\n",
            "\n",
            "Epoch 370/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1000 - val_loss: 0.0822\n",
            "Loss: 0.10002189874649048\n",
            "Validation Loss: 0.08217604458332062\n",
            "\n",
            "Epoch 371/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1011 - val_loss: 0.0827\n",
            "Loss: 0.10108587145805359\n",
            "Validation Loss: 0.08268743753433228\n",
            "\n",
            "Epoch 372/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1018 - val_loss: 0.0840\n",
            "Loss: 0.1017654538154602\n",
            "Validation Loss: 0.08396577835083008\n",
            "\n",
            "Epoch 373/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1005 - val_loss: 0.0819\n",
            "Loss: 0.10052838921546936\n",
            "Validation Loss: 0.08192954957485199\n",
            "\n",
            "Epoch 374/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1014 - val_loss: 0.0827\n",
            "Loss: 0.10135211050510406\n",
            "Validation Loss: 0.08271470665931702\n",
            "\n",
            "Epoch 375/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1005 - val_loss: 0.0831\n",
            "Loss: 0.10054542869329453\n",
            "Validation Loss: 0.08309419453144073\n",
            "\n",
            "Epoch 376/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1008 - val_loss: 0.0817\n",
            "Loss: 0.10084535926580429\n",
            "Validation Loss: 0.08165938407182693\n",
            "\n",
            "Epoch 377/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1007 - val_loss: 0.0822\n",
            "Loss: 0.10065469890832901\n",
            "Validation Loss: 0.08219798654317856\n",
            "\n",
            "Epoch 378/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1004 - val_loss: 0.0814\n",
            "Loss: 0.10036491602659225\n",
            "Validation Loss: 0.08135990053415298\n",
            "\n",
            "Epoch 379/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1009 - val_loss: 0.0817\n",
            "Loss: 0.10089615732431412\n",
            "Validation Loss: 0.0816941186785698\n",
            "\n",
            "Epoch 380/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1015 - val_loss: 0.0826\n",
            "Loss: 0.10148600488901138\n",
            "Validation Loss: 0.08260329812765121\n",
            "\n",
            "Epoch 381/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1008 - val_loss: 0.0807\n",
            "Loss: 0.10082400590181351\n",
            "Validation Loss: 0.08074960112571716\n",
            "\n",
            "Epoch 382/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1003 - val_loss: 0.0816\n",
            "Loss: 0.10033880174160004\n",
            "Validation Loss: 0.08162886649370193\n",
            "\n",
            "Epoch 383/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1007 - val_loss: 0.0814\n",
            "Loss: 0.10072863847017288\n",
            "Validation Loss: 0.08142612129449844\n",
            "\n",
            "Epoch 384/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1008 - val_loss: 0.0822\n",
            "Loss: 0.10076221823692322\n",
            "Validation Loss: 0.08220397680997849\n",
            "\n",
            "Epoch 385/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1002 - val_loss: 0.0822\n",
            "Loss: 0.10018008202314377\n",
            "Validation Loss: 0.08222772926092148\n",
            "\n",
            "Epoch 386/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1003 - val_loss: 0.0825\n",
            "Loss: 0.10033901035785675\n",
            "Validation Loss: 0.08254267275333405\n",
            "\n",
            "Epoch 387/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1003 - val_loss: 0.0815\n",
            "Loss: 0.10031960159540176\n",
            "Validation Loss: 0.08151458203792572\n",
            "\n",
            "Epoch 388/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0997 - val_loss: 0.0833\n",
            "Loss: 0.09972071647644043\n",
            "Validation Loss: 0.08327528834342957\n",
            "\n",
            "Epoch 389/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1014 - val_loss: 0.0813\n",
            "Loss: 0.10141202062368393\n",
            "Validation Loss: 0.0813065841794014\n",
            "\n",
            "Epoch 390/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0994 - val_loss: 0.0825\n",
            "Loss: 0.09935534745454788\n",
            "Validation Loss: 0.08254729211330414\n",
            "\n",
            "Epoch 391/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1005 - val_loss: 0.0807\n",
            "Loss: 0.10054729878902435\n",
            "Validation Loss: 0.08069148659706116\n",
            "\n",
            "Epoch 392/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0997 - val_loss: 0.0815\n",
            "Loss: 0.09968629479408264\n",
            "Validation Loss: 0.08151833713054657\n",
            "\n",
            "Epoch 393/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1012 - val_loss: 0.0813\n",
            "Loss: 0.1011568084359169\n",
            "Validation Loss: 0.08127539604902267\n",
            "\n",
            "Epoch 394/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0995 - val_loss: 0.0818\n",
            "Loss: 0.09949803352355957\n",
            "Validation Loss: 0.081791952252388\n",
            "\n",
            "Epoch 395/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1004 - val_loss: 0.0815\n",
            "Loss: 0.10035905987024307\n",
            "Validation Loss: 0.08154569566249847\n",
            "\n",
            "Epoch 396/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1006 - val_loss: 0.0817\n",
            "Loss: 0.10063081979751587\n",
            "Validation Loss: 0.08170194178819656\n",
            "\n",
            "Epoch 397/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1001 - val_loss: 0.0814\n",
            "Loss: 0.10006416589021683\n",
            "Validation Loss: 0.0814499780535698\n",
            "\n",
            "Epoch 398/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1003 - val_loss: 0.0814\n",
            "Loss: 0.10031921416521072\n",
            "Validation Loss: 0.0813683271408081\n",
            "\n",
            "Epoch 399/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1002 - val_loss: 0.0821\n",
            "Loss: 0.1001734510064125\n",
            "Validation Loss: 0.0820993110537529\n",
            "\n",
            "Epoch 400/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1001 - val_loss: 0.0805\n",
            "Loss: 0.10014791041612625\n",
            "Validation Loss: 0.08051840215921402\n",
            "\n",
            "Epoch 401/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1001 - val_loss: 0.0823\n",
            "Loss: 0.10011706501245499\n",
            "Validation Loss: 0.08233106881380081\n",
            "\n",
            "Epoch 402/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1004 - val_loss: 0.0807\n",
            "Loss: 0.10038209706544876\n",
            "Validation Loss: 0.08071333914995193\n",
            "\n",
            "Epoch 403/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.0997 - val_loss: 0.0814\n",
            "Loss: 0.09969687461853027\n",
            "Validation Loss: 0.08144432306289673\n",
            "\n",
            "Epoch 404/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1013 - val_loss: 0.0811\n",
            "Loss: 0.10127485543489456\n",
            "Validation Loss: 0.08105441927909851\n",
            "\n",
            "Epoch 405/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0999 - val_loss: 0.0826\n",
            "Loss: 0.09993279725313187\n",
            "Validation Loss: 0.08257239311933517\n",
            "\n",
            "Epoch 406/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.0995 - val_loss: 0.0823\n",
            "Loss: 0.09953919798135757\n",
            "Validation Loss: 0.08234377950429916\n",
            "\n",
            "Epoch 407/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1001 - val_loss: 0.0814\n",
            "Loss: 0.10008548945188522\n",
            "Validation Loss: 0.08142299950122833\n",
            "\n",
            "Epoch 408/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0999 - val_loss: 0.0829\n",
            "Loss: 0.09986548870801926\n",
            "Validation Loss: 0.08290201425552368\n",
            "\n",
            "Epoch 409/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0998 - val_loss: 0.0820\n",
            "Loss: 0.09983498603105545\n",
            "Validation Loss: 0.08203905075788498\n",
            "\n",
            "Epoch 410/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0994 - val_loss: 0.0811\n",
            "Loss: 0.09939735382795334\n",
            "Validation Loss: 0.0811276063323021\n",
            "\n",
            "Epoch 411/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1003 - val_loss: 0.0817\n",
            "Loss: 0.10034773498773575\n",
            "Validation Loss: 0.08173035830259323\n",
            "\n",
            "Epoch 412/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0991 - val_loss: 0.0820\n",
            "Loss: 0.09910814464092255\n",
            "Validation Loss: 0.08196799457073212\n",
            "\n",
            "Epoch 413/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0990 - val_loss: 0.0818\n",
            "Loss: 0.09902242571115494\n",
            "Validation Loss: 0.08181632310152054\n",
            "\n",
            "Epoch 414/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0997 - val_loss: 0.0837\n",
            "Loss: 0.0996893048286438\n",
            "Validation Loss: 0.08369212597608566\n",
            "\n",
            "Epoch 415/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.0997 - val_loss: 0.0799\n",
            "Loss: 0.09970047324895859\n",
            "Validation Loss: 0.07993679493665695\n",
            "\n",
            "Epoch 416/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0988 - val_loss: 0.0813\n",
            "Loss: 0.09878352284431458\n",
            "Validation Loss: 0.0813160240650177\n",
            "\n",
            "Epoch 417/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0990 - val_loss: 0.0808\n",
            "Loss: 0.09898900985717773\n",
            "Validation Loss: 0.08078887313604355\n",
            "\n",
            "Epoch 418/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0995 - val_loss: 0.0818\n",
            "Loss: 0.09952586144208908\n",
            "Validation Loss: 0.08183281868696213\n",
            "\n",
            "Epoch 419/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1000 - val_loss: 0.0812\n",
            "Loss: 0.10002882778644562\n",
            "Validation Loss: 0.08115939050912857\n",
            "\n",
            "Epoch 420/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1001 - val_loss: 0.0807\n",
            "Loss: 0.10012039542198181\n",
            "Validation Loss: 0.0806661918759346\n",
            "\n",
            "Epoch 421/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0992 - val_loss: 0.0809\n",
            "Loss: 0.09919100999832153\n",
            "Validation Loss: 0.08094468712806702\n",
            "\n",
            "Epoch 422/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.0995 - val_loss: 0.0828\n",
            "Loss: 0.09946650266647339\n",
            "Validation Loss: 0.08281499892473221\n",
            "\n",
            "Epoch 423/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0993 - val_loss: 0.0806\n",
            "Loss: 0.09932450950145721\n",
            "Validation Loss: 0.08062274008989334\n",
            "\n",
            "Epoch 424/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0992 - val_loss: 0.0818\n",
            "Loss: 0.09923863410949707\n",
            "Validation Loss: 0.08182699978351593\n",
            "\n",
            "Epoch 425/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0991 - val_loss: 0.0810\n",
            "Loss: 0.09909956902265549\n",
            "Validation Loss: 0.08098211884498596\n",
            "\n",
            "Epoch 426/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0998 - val_loss: 0.0814\n",
            "Loss: 0.09984927624464035\n",
            "Validation Loss: 0.08139476925134659\n",
            "\n",
            "Epoch 427/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0998 - val_loss: 0.0796\n",
            "Loss: 0.09983740746974945\n",
            "Validation Loss: 0.07958267629146576\n",
            "\n",
            "Epoch 428/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0986 - val_loss: 0.0822\n",
            "Loss: 0.09861103445291519\n",
            "Validation Loss: 0.08215257525444031\n",
            "\n",
            "Epoch 429/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0991 - val_loss: 0.0808\n",
            "Loss: 0.0991021916270256\n",
            "Validation Loss: 0.08077742904424667\n",
            "\n",
            "Epoch 430/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0992 - val_loss: 0.0809\n",
            "Loss: 0.09920942038297653\n",
            "Validation Loss: 0.08089175820350647\n",
            "\n",
            "Epoch 431/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0989 - val_loss: 0.0814\n",
            "Loss: 0.09890694916248322\n",
            "Validation Loss: 0.08142544329166412\n",
            "\n",
            "Epoch 432/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0994 - val_loss: 0.0816\n",
            "Loss: 0.0994328111410141\n",
            "Validation Loss: 0.08160239458084106\n",
            "\n",
            "Epoch 433/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0985 - val_loss: 0.0818\n",
            "Loss: 0.09847473353147507\n",
            "Validation Loss: 0.08179685473442078\n",
            "\n",
            "Epoch 434/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0985 - val_loss: 0.0818\n",
            "Loss: 0.09853602200746536\n",
            "Validation Loss: 0.08182799071073532\n",
            "\n",
            "Epoch 435/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.0991 - val_loss: 0.0812\n",
            "Loss: 0.09912601113319397\n",
            "Validation Loss: 0.08123729377985\n",
            "\n",
            "Epoch 436/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0987 - val_loss: 0.0809\n",
            "Loss: 0.09874632954597473\n",
            "Validation Loss: 0.080915667116642\n",
            "\n",
            "Epoch 437/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0994 - val_loss: 0.0811\n",
            "Loss: 0.09938865154981613\n",
            "Validation Loss: 0.0811438336968422\n",
            "\n",
            "Epoch 438/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0996 - val_loss: 0.0818\n",
            "Loss: 0.09958846122026443\n",
            "Validation Loss: 0.08176863938570023\n",
            "\n",
            "Epoch 439/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0985 - val_loss: 0.0811\n",
            "Loss: 0.09850332885980606\n",
            "Validation Loss: 0.08109332621097565\n",
            "\n",
            "Epoch 440/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0997 - val_loss: 0.0805\n",
            "Loss: 0.09970659017562866\n",
            "Validation Loss: 0.08051951229572296\n",
            "\n",
            "Epoch 441/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0983 - val_loss: 0.0803\n",
            "Loss: 0.09829621762037277\n",
            "Validation Loss: 0.08028149604797363\n",
            "\n",
            "Epoch 442/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0989 - val_loss: 0.0813\n",
            "Loss: 0.09890557825565338\n",
            "Validation Loss: 0.08131419122219086\n",
            "\n",
            "Epoch 443/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0982 - val_loss: 0.0804\n",
            "Loss: 0.0982244610786438\n",
            "Validation Loss: 0.0803569108247757\n",
            "\n",
            "Epoch 444/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0991 - val_loss: 0.0803\n",
            "Loss: 0.09907771646976471\n",
            "Validation Loss: 0.08028575778007507\n",
            "\n",
            "Epoch 445/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0981 - val_loss: 0.0809\n",
            "Loss: 0.09813649952411652\n",
            "Validation Loss: 0.0808771401643753\n",
            "\n",
            "Epoch 446/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0987 - val_loss: 0.0804\n",
            "Loss: 0.09868466109037399\n",
            "Validation Loss: 0.0803958848118782\n",
            "\n",
            "Epoch 447/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.0999 - val_loss: 0.0815\n",
            "Loss: 0.09993509203195572\n",
            "Validation Loss: 0.08154702186584473\n",
            "\n",
            "Epoch 448/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0994 - val_loss: 0.0804\n",
            "Loss: 0.09938985854387283\n",
            "Validation Loss: 0.08039058744907379\n",
            "\n",
            "Epoch 449/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0988 - val_loss: 0.0809\n",
            "Loss: 0.09875662624835968\n",
            "Validation Loss: 0.08094412833452225\n",
            "\n",
            "Epoch 450/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0987 - val_loss: 0.0803\n",
            "Loss: 0.09865492582321167\n",
            "Validation Loss: 0.08031697571277618\n",
            "\n",
            "Epoch 451/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0986 - val_loss: 0.0814\n",
            "Loss: 0.09855987131595612\n",
            "Validation Loss: 0.08138047158718109\n",
            "\n",
            "Epoch 452/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0986 - val_loss: 0.0789\n",
            "Loss: 0.09858831763267517\n",
            "Validation Loss: 0.07887139171361923\n",
            "\n",
            "Epoch 453/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0992 - val_loss: 0.0819\n",
            "Loss: 0.09920860826969147\n",
            "Validation Loss: 0.08192454278469086\n",
            "\n",
            "Epoch 454/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0988 - val_loss: 0.0792\n",
            "Loss: 0.0988207757472992\n",
            "Validation Loss: 0.07918775826692581\n",
            "\n",
            "Epoch 455/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0994 - val_loss: 0.0814\n",
            "Loss: 0.09943594038486481\n",
            "Validation Loss: 0.0814456045627594\n",
            "\n",
            "Epoch 456/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0984 - val_loss: 0.0797\n",
            "Loss: 0.09838730096817017\n",
            "Validation Loss: 0.07971172034740448\n",
            "\n",
            "Epoch 457/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0992 - val_loss: 0.0793\n",
            "Loss: 0.09924747049808502\n",
            "Validation Loss: 0.07929279655218124\n",
            "\n",
            "Epoch 458/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0990 - val_loss: 0.0790\n",
            "Loss: 0.09904897958040237\n",
            "Validation Loss: 0.07900462299585342\n",
            "\n",
            "Epoch 459/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.0988 - val_loss: 0.0810\n",
            "Loss: 0.09884331375360489\n",
            "Validation Loss: 0.08101712167263031\n",
            "\n",
            "Epoch 460/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0984 - val_loss: 0.0803\n",
            "Loss: 0.09839638322591782\n",
            "Validation Loss: 0.08030880242586136\n",
            "\n",
            "Epoch 461/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0981 - val_loss: 0.0792\n",
            "Loss: 0.0980505645275116\n",
            "Validation Loss: 0.07924378663301468\n",
            "\n",
            "Epoch 462/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0989 - val_loss: 0.0808\n",
            "Loss: 0.09891922026872635\n",
            "Validation Loss: 0.08079929649829865\n",
            "\n",
            "Epoch 463/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0986 - val_loss: 0.0789\n",
            "Loss: 0.09862404316663742\n",
            "Validation Loss: 0.07887651026248932\n",
            "\n",
            "Epoch 464/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0987 - val_loss: 0.0808\n",
            "Loss: 0.09866543859243393\n",
            "Validation Loss: 0.08077198266983032\n",
            "\n",
            "Epoch 465/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0985 - val_loss: 0.0805\n",
            "Loss: 0.09849436581134796\n",
            "Validation Loss: 0.08048326522111893\n",
            "\n",
            "Epoch 466/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0980 - val_loss: 0.0802\n",
            "Loss: 0.09795787185430527\n",
            "Validation Loss: 0.08020102232694626\n",
            "\n",
            "Epoch 467/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0976 - val_loss: 0.0813\n",
            "Loss: 0.09762952476739883\n",
            "Validation Loss: 0.081257663667202\n",
            "\n",
            "Epoch 468/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0977 - val_loss: 0.0800\n",
            "Loss: 0.09774568676948547\n",
            "Validation Loss: 0.07996951043605804\n",
            "\n",
            "Epoch 469/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.0983 - val_loss: 0.0810\n",
            "Loss: 0.09830136597156525\n",
            "Validation Loss: 0.08098728954792023\n",
            "\n",
            "Epoch 470/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0985 - val_loss: 0.0811\n",
            "Loss: 0.09854073822498322\n",
            "Validation Loss: 0.08112214505672455\n",
            "\n",
            "Epoch 471/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0986 - val_loss: 0.0794\n",
            "Loss: 0.09858901053667068\n",
            "Validation Loss: 0.07940752059221268\n",
            "\n",
            "Epoch 472/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0991 - val_loss: 0.0802\n",
            "Loss: 0.0990535169839859\n",
            "Validation Loss: 0.08016867190599442\n",
            "\n",
            "Epoch 473/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0979 - val_loss: 0.0802\n",
            "Loss: 0.0979384109377861\n",
            "Validation Loss: 0.08021050691604614\n",
            "\n",
            "Epoch 474/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0983 - val_loss: 0.0801\n",
            "Loss: 0.09827973693609238\n",
            "Validation Loss: 0.0800703763961792\n",
            "\n",
            "Epoch 475/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0976 - val_loss: 0.0794\n",
            "Loss: 0.09756151586771011\n",
            "Validation Loss: 0.07942129671573639\n",
            "\n",
            "Epoch 476/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0985 - val_loss: 0.0801\n",
            "Loss: 0.09854795038700104\n",
            "Validation Loss: 0.0801166221499443\n",
            "\n",
            "Epoch 477/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0987 - val_loss: 0.0799\n",
            "Loss: 0.09873304516077042\n",
            "Validation Loss: 0.0798751562833786\n",
            "\n",
            "Epoch 478/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0984 - val_loss: 0.0797\n",
            "Loss: 0.09839097410440445\n",
            "Validation Loss: 0.07965202629566193\n",
            "\n",
            "Epoch 479/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0985 - val_loss: 0.0808\n",
            "Loss: 0.09846826642751694\n",
            "Validation Loss: 0.08077017217874527\n",
            "\n",
            "Epoch 480/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0982 - val_loss: 0.0786\n",
            "Loss: 0.09818176180124283\n",
            "Validation Loss: 0.07858777791261673\n",
            "\n",
            "Epoch 481/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0981 - val_loss: 0.0807\n",
            "Loss: 0.0980704128742218\n",
            "Validation Loss: 0.08074551820755005\n",
            "\n",
            "Epoch 482/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0978 - val_loss: 0.0807\n",
            "Loss: 0.09784301370382309\n",
            "Validation Loss: 0.0807061493396759\n",
            "\n",
            "Epoch 483/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0976 - val_loss: 0.0789\n",
            "Loss: 0.09762316197156906\n",
            "Validation Loss: 0.07893390953540802\n",
            "\n",
            "Epoch 484/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0982 - val_loss: 0.0798\n",
            "Loss: 0.09820285439491272\n",
            "Validation Loss: 0.0797729641199112\n",
            "\n",
            "Epoch 485/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0983 - val_loss: 0.0787\n",
            "Loss: 0.0983404666185379\n",
            "Validation Loss: 0.07873053103685379\n",
            "\n",
            "Epoch 486/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0973 - val_loss: 0.0798\n",
            "Loss: 0.09727256000041962\n",
            "Validation Loss: 0.07977072894573212\n",
            "\n",
            "Epoch 487/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0984 - val_loss: 0.0811\n",
            "Loss: 0.09838791936635971\n",
            "Validation Loss: 0.08113724738359451\n",
            "\n",
            "Epoch 488/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0982 - val_loss: 0.0799\n",
            "Loss: 0.09819967299699783\n",
            "Validation Loss: 0.07993224263191223\n",
            "\n",
            "Epoch 489/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0974 - val_loss: 0.0801\n",
            "Loss: 0.09738121181726456\n",
            "Validation Loss: 0.08005041629076004\n",
            "\n",
            "Epoch 490/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0978 - val_loss: 0.0806\n",
            "Loss: 0.09780983626842499\n",
            "Validation Loss: 0.08063393831253052\n",
            "\n",
            "Epoch 491/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0970 - val_loss: 0.0799\n",
            "Loss: 0.09703338146209717\n",
            "Validation Loss: 0.07991141080856323\n",
            "\n",
            "Epoch 492/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0985 - val_loss: 0.0810\n",
            "Loss: 0.09846395254135132\n",
            "Validation Loss: 0.08101057261228561\n",
            "\n",
            "Epoch 493/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0979 - val_loss: 0.0796\n",
            "Loss: 0.09794884920120239\n",
            "Validation Loss: 0.07961195707321167\n",
            "\n",
            "Epoch 494/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0982 - val_loss: 0.0807\n",
            "Loss: 0.09819581359624863\n",
            "Validation Loss: 0.08065775781869888\n",
            "\n",
            "Epoch 495/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0974 - val_loss: 0.0800\n",
            "Loss: 0.09739238023757935\n",
            "Validation Loss: 0.07999491691589355\n",
            "\n",
            "Epoch 496/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.0977 - val_loss: 0.0788\n",
            "Loss: 0.09765257686376572\n",
            "Validation Loss: 0.07875147461891174\n",
            "\n",
            "Epoch 497/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.0987 - val_loss: 0.0811\n",
            "Loss: 0.09874898195266724\n",
            "Validation Loss: 0.08106984198093414\n",
            "\n",
            "Epoch 498/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.0982 - val_loss: 0.0800\n",
            "Loss: 0.0981622114777565\n",
            "Validation Loss: 0.08004377037286758\n",
            "\n",
            "Epoch 499/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.0970 - val_loss: 0.0807\n",
            "Loss: 0.0970180481672287\n",
            "Validation Loss: 0.0806826651096344\n",
            "\n",
            "Epoch 500/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.0977 - val_loss: 0.0803\n",
            "Loss: 0.09773440659046173\n",
            "Validation Loss: 0.08025629818439484\n",
            "\n",
            "History for Model 1\n",
            "Loss: [0.1767531782388687]\n",
            "Validation Loss: [0.1874268651008606]\n",
            "\n",
            "History for Model 2\n",
            "Loss: [0.19639070332050323]\n",
            "Validation Loss: [0.19138720631599426]\n",
            "\n",
            "History for Model 3\n",
            "Loss: [0.09773440659046173]\n",
            "Validation Loss: [0.08025629818439484]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras.layers import TimeDistributed, Reshape\n",
        "\n",
        "def attention_layer(inputs):\n",
        "    hidden_states, context_vector = inputs\n",
        "    \n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    \n",
        "    # Reshape context vector to perform element-wise multiplication\n",
        "    context_vector = Dense(hidden_size)(context_vector)\n",
        "    context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[1], axis=1)\n",
        "    \n",
        "    # Attention mechanism\n",
        "    attention_weights = tf.keras.layers.Attention()([hidden_states, context_vector])\n",
        "    attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "    \n",
        "    # Weighted sum of hidden states\n",
        "    weighted_sum = tf.reduce_sum(attention_weights * hidden_states, axis=1)\n",
        "    \n",
        "    return weighted_sum\n",
        "\n",
        "\n",
        "def build_model(input_shape, hidden_units, output_dim, dropout_rate=0.15, recurrent_dropout_rate=0.15):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    lstm_output = LSTM(hidden_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)(inputs)\n",
        "    attention_output = AttentionLayer(hidden_units)([lstm_output, lstm_output])\n",
        "    \n",
        "    # Add a time step dimension\n",
        "    reshaped_output = Reshape((-1, hidden_units))(attention_output)\n",
        "    \n",
        "    time_distributed_output = TimeDistributed(Dense(output_dim))(reshaped_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=time_distributed_output)\n",
        "    return model\n",
        "\n",
        "def train_model(X_train, X_test, y_train, y_test, output_dim, n_epochs):\n",
        "    input_shape = X_train.shape[1:]\n",
        "    hidden_units = 128\n",
        "\n",
        "    model = build_model(input_shape, hidden_units, output_dim)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(n_epochs):\n",
        "        # Early stopping\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        history = model.fit(X_train, y_train, epochs=1, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
        "        print(\"Loss:\", history.history['loss'][0])\n",
        "        loss.append(history.history['loss'][0])\n",
        "        print(\"Validation Loss:\", history.history['val_loss'][0])\n",
        "        val_loss.append(history.history['val_loss'][0])\n",
        "        print()\n",
        "\n",
        "    return model, history, loss, val_loss\n",
        "\n",
        "# Create our cross-validation data structure\n",
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(processed_data['x'], processed_data['y'], train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "# Define the features to train for\n",
        "features = [2, 0, 1]  # Specify the indices of the features to train for\n",
        "\n",
        "# Train multiple models\n",
        "models = []\n",
        "histories = []\n",
        "losses = []\n",
        "val_losses = []\n",
        "n_epochs = 500\n",
        "\n",
        "for feature_idx in features:\n",
        "    y_train_feature = np.array([[[features[feature_idx]] for features in y] for y in y_train], dtype=np.float64)\n",
        "    y_valid_feature = np.array([[[features[feature_idx]] for features in y] for y in y_valid], dtype=np.float64)\n",
        "    \n",
        "    model, history, loss, val_loss = train_model(X_train, X_valid, y_train_feature, y_valid_feature, output_dim=1, n_epochs=n_epochs)\n",
        "    \n",
        "    models.append(model)\n",
        "    histories.append(history)\n",
        "    losses.append(loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "# Access the history of each model\n",
        "for i, history in enumerate(histories):\n",
        "    print(f\"History for Model {i+1}\")\n",
        "    print(\"Loss:\", history.history['loss'])\n",
        "    print(\"Validation Loss:\", history.history['val_loss'])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model \n",
        "wind_model = models[0]\n",
        "lat_model = models[1]\n",
        "long_model = models[2]\n",
        "\n",
        "wind_loss = np.array(losses[0])\n",
        "lat_loss = np.array(losses[1])\n",
        "long_loss = np.array(losses[2])\n",
        "\n",
        "wind_val_loss = np.array(val_losses[0])\n",
        "lat_val_loss = np.array(val_losses[1])\n",
        "long_val_loss = np.array(val_losses[2])\n",
        "\n",
        "folder_path_loss = '/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/losses'\n",
        "folder_path_val_loss = '/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/val_losses'\n",
        "\n",
        "np.save(f'{folder_path_loss}/wind_loss.npy', wind_loss)\n",
        "np.save(f'{folder_path_loss}/lat_loss.npy', lat_loss)\n",
        "np.save(f'{folder_path_loss}/long_loss.npy', long_loss)\n",
        "\n",
        "np.save(f'{folder_path_val_loss}/wind_loss.npy', wind_val_loss)\n",
        "np.save(f'{folder_path_val_loss}/lat_loss.npy', lat_val_loss)\n",
        "np.save(f'{folder_path_val_loss}/long_loss.npy', long_val_loss)\n",
        "\n",
        "wind_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/wind_model.h5')\n",
        "lat_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/lat_model.h5')\n",
        "long_model.save('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/long_model.h5')"
      ],
      "metadata": {
        "id": "9fYjKBxPXcGp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Predict values\n",
        "wind_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/wind_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "lat_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/lat_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "long_model = keras.models.load_model('/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/outputs/lstm_attention/trained_models/long_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "wind_predictions = models[0].predict(X_test)\n",
        "lat_predictions = models[1].predict(X_test)\n",
        "long_predictions = models[2].predict(X_test)"
      ],
      "metadata": {
        "id": "7Dl_hKCGKi9X",
        "outputId": "62ebb252-cdc4-4e2f-d8b8-26b8133b5443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2/42 [>.............................] - ETA: 2s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 2s 50ms/step\n",
            "42/42 [==============================] - 2s 49ms/step\n",
            "42/42 [==============================] - 2s 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wind_loss = np.load(f'{folder_path_loss}/wind_loss.npy')\n",
        "lat_loss = np.load(f'{folder_path_loss}/lat_loss.npy')\n",
        "long_loss = np.load(f'{folder_path_loss}/long_loss.npy')\n",
        "\n",
        "wind_val_loss = np.load(f'{folder_path_val_loss}/wind_loss.npy')\n",
        "lat_val_loss = np.load(f'{folder_path_val_loss}/lat_loss.npy')\n",
        "long_val_loss = np.load(f'{folder_path_val_loss}/long_loss.npy')"
      ],
      "metadata": {
        "id": "gQSnRwHTc5yE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses[0], label=\"Wind Model\")\n",
        "plt.plot(losses[1], label=\"Lat Model\")\n",
        "plt.plot(losses[2], label=\"Long Model\")\n",
        "plt.title(\"Loss Over Time\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation loss over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(val_losses[0], label=\"Wind Model\")\n",
        "plt.plot(val_losses[1], label=\"Lat Model\")\n",
        "plt.plot(val_losses[2], label=\"Long Model\")\n",
        "plt.title(\"Validation Loss Over Time\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FXrlj3V-MWhu",
        "outputId": "9b46dd32-e02d-46ed-c69c-b4bfee818877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}