{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYl6itUaG8M",
        "outputId": "c5d96d28-e3bf-4dff-af5d-e3ee9dd519a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZpPn-6aSjm",
        "outputId": "b8b2d86d-07a4-41b1-c312-08e8c1f04af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/atlantic-hurricane-trajectory-prediction/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wksjVxR-cZph",
        "outputId": "b8f199a5-c215-431b-f718-2bfe65ba9125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  errors\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wU6pXh5ycf8N",
        "outputId": "965ef845-fe75-4805-c291-387310c954dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(60000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autosaving every 60 seconds\n"
          ]
        }
      ],
      "source": [
        "%autosave 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "elmYIsXechGh"
      },
      "outputs": [],
      "source": [
        "# Import various libraries throughout the software\n",
        "from pprint import pprint\n",
        "from datetime import timedelta\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from geopy.distance import great_circle as vc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math as Math\n",
        "import datetime\n",
        "import dateutil\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IaLbuPxDdnVL"
      },
      "outputs": [],
      "source": [
        "# data cleaning/processing: (from hurricane-net, hammad)\n",
        "db = []\n",
        "with open('data/hurdat2-1851-2022-050423.txt') as raw: \n",
        "    for line in raw: \n",
        "        line = line.replace(' ', '').split(',')\n",
        "    \n",
        "        # Identify atlantic storm, first 2 letters should be AL\n",
        "        if (line[0][:2] == 'AL') :\n",
        "            storm_id = line[0]\n",
        "            storm_name = line[1]\n",
        "            storm_entries = line[2]\n",
        "\n",
        "            # Iterate and read through best track entries\n",
        "            for i in range(int(storm_entries)) :\n",
        "                entry = raw.readline().replace(' ', '').split(',')\n",
        "                # Filter -999 placeholder for missing central pressure\n",
        "                entry = [None if x == \"-999\" else x for x in entry]\n",
        "                # Construct date and time based on first two columns\n",
        "                timestamp = datetime.datetime(int(entry[0][:4]), int(entry[0][4:6]), int(entry[0][6:8]), int(entry[1][:2]), int(entry[1][3:]))\n",
        "                # Add entry into our current database\n",
        "                db.append([storm_id, storm_name, timestamp] + entry[2:-1])\n",
        "        else :\n",
        "            print(\"Error, unidentified storm \".join(str(line[0])))\n",
        "\n",
        "# Return DataFrame\n",
        "dataset = pd.DataFrame(db, columns = ['storm_id', 'storm_name', 'entry_time', 'entry_id', 'entry_status', 'lat', 'long','max_wind', 'min_pressure', '34kt_ne', '34kt_se', '34kt_sw', '34kt_nw', '50kt_ne', '50kt_se', '50kt_sw', '50kt_nw', '64kt_ne', '64kt_se', '64kt_sw', '64kt_nw'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YVqCzNzDmg0R"
      },
      "outputs": [],
      "source": [
        "models = dict()\n",
        "class model :\n",
        "  '''\n",
        "  PURPOSE: To create a class for each model included in the forecast error database\n",
        "  METHOD: Provide an API\n",
        "  OUTOUT: A class with a DataFrame and associated operations\n",
        "  '''\n",
        "  name = None\n",
        "  # Dictionary key: STMID\n",
        "  storm = dict()\n",
        "  def __init__(self, model_name) :\n",
        "    self.name = model_name\n",
        "    return\n",
        "\n",
        "with open('errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt') as raw :\n",
        "    lines = raw.readlines()\n",
        "    \n",
        "    # Get model names and declare model objects\n",
        "    line = lines[1].split()\n",
        "    model_names = line[2:]\n",
        "    for model_name in model_names :\n",
        "        models[model_name] = model(model_name)\n",
        "    \n",
        "    # Data starts at line 9 \n",
        "    for line in lines[9:] :\n",
        "        line = line.split()\n",
        "        # Identify atlantic storm date, storm id, associated sample sizes, latitude and longitude, and windspeed\n",
        "        timestamp = datetime.datetime.strptime(line[0], \"%d-%m-%Y/%H:%M:%S\")\n",
        "        storm_id = line[1]\n",
        "        sample_sizes = {\"F012\": float(line[2]), \"F024\": float(line[3]),\"F036\": float(line[4]), \"F048\": float(line[5]), \"F072\": float(line[6]), \"F096\": float(line[7]), \"F120\": float(line[8]), \"F144\": float(line[9]), \"F168\": float(line[10])} \n",
        "        latitude = float(line[11])\n",
        "        longitude = float(line[12])\n",
        "        wind_speed = float(line[13])\n",
        "    \n",
        "                \n",
        "        # Iterate through model forecast track and intensity errors \n",
        "        for i in range(len(model_names)) :\n",
        "            intensity_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[14 + (20 * i) : 24 + (20 * i)]])))\n",
        "            track_forecast = dict(list(zip([timestamp, timestamp + timedelta(hours = 12), timestamp + timedelta(hours = 24), timestamp + timedelta(hours = 36), timestamp + timedelta(hours = 48), timestamp + timedelta(hours = 72), timestamp + timedelta(hours = 96), timestamp + timedelta(hours = 120), timestamp + timedelta(hours = 144), timestamp + timedelta(hours = 168)], [None if x == \"-9999.0\" else float(x) for x in line[24 + (20 * i) : 34 + (20 * i)]])))\n",
        "        \n",
        "        # Add forecast to model and storm, initialize if storm id does not exist\n",
        "        if storm_id not in models[model_names[i]].storm.keys() :\n",
        "            models[model_names[i]].storm[storm_id] = dict()\n",
        "\n",
        "        models[model_names[i]].storm[storm_id].update({\n",
        "            timestamp : {\n",
        "            \"sample_sizes\" : sample_sizes,\n",
        "            \"lat\" : latitude,\n",
        "            \"long\" : longitude,\n",
        "            \"wind_speed\" : wind_speed,\n",
        "            \"intensity_forecast\" : intensity_forecast,\n",
        "            \"track_forecast\" : track_forecast,\n",
        "            }\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG4AXCzkl7Sw",
        "outputId": "a1250550-e90e-4196-9055-ca0191718e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 8, 30, 6, 0): 0.0,\n",
            "                                      datetime.datetime(2005, 8, 30, 18, 0): 20.9,\n",
            "                                      datetime.datetime(2005, 8, 31, 18, 0): 93.6,\n",
            "                                      datetime.datetime(2005, 9, 1, 18, 0): 170.2,\n",
            "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'lat': 0.0,\n",
            "        'long': 26.3,\n",
            "        'sample_sizes': {       'F012': 0.33,\n",
            "                                'F024': 0.33,\n",
            "                                'F036': 0.33,\n",
            "                                'F048': 0.0,\n",
            "                                'F072': 0.0,\n",
            "                                'F096': 0.0,\n",
            "                                'F120': 0.0,\n",
            "                                'F144': 0.0,\n",
            "                                'F168': 0.0},\n",
            "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 29, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 6, 0): None,\n",
            "                                  datetime.datetime(2005, 8, 30, 18, 0): 0.0,\n",
            "                                  datetime.datetime(2005, 8, 31, 18, 0): 28.0,\n",
            "                                  datetime.datetime(2005, 9, 1, 18, 0): 32.0,\n",
            "                                  datetime.datetime(2005, 9, 2, 18, 0): 17.0,\n",
            "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
            "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
            "        'wind_speed': 88.6}\n"
          ]
        }
      ],
      "source": [
        "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
        "pprint(models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "6jC4jkJSG7-C",
        "outputId": "40d5aa1d-1c9e-4c3e-8ded-8f475985798a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
              "44681  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
              "44682  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
              "44683  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
              "44684  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
              "44685  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
              "\n",
              "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
              "44681  75.1W       30         1008       0  ...       0       0       0   \n",
              "44682  75.7W       30         1007       0  ...       0       0       0   \n",
              "44683  76.2W       30         1007       0  ...       0       0       0   \n",
              "44684  76.5W       35         1006      60  ...       0       0       0   \n",
              "44685  76.9W       40         1003      60  ...       0       0       0   \n",
              "\n",
              "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
              "44681       0       0       0       0       0       0       0  \n",
              "44682       0       0       0       0       0       0       0  \n",
              "44683       0       0       0       0       0       0       0  \n",
              "44684       0       0       0       0       0       0       0  \n",
              "44685       0       0       0       0       0       0       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46c46e5e-8f30-47ce-a2f2-495b4f32419a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storm_id</th>\n",
              "      <th>storm_name</th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>34kt_ne</th>\n",
              "      <th>...</th>\n",
              "      <th>34kt_sw</th>\n",
              "      <th>34kt_nw</th>\n",
              "      <th>50kt_ne</th>\n",
              "      <th>50kt_se</th>\n",
              "      <th>50kt_sw</th>\n",
              "      <th>50kt_nw</th>\n",
              "      <th>64kt_ne</th>\n",
              "      <th>64kt_se</th>\n",
              "      <th>64kt_sw</th>\n",
              "      <th>64kt_nw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44681</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-23 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.1N</td>\n",
              "      <td>75.1W</td>\n",
              "      <td>30</td>\n",
              "      <td>1008</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44682</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.4N</td>\n",
              "      <td>75.7W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44683</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>23.8N</td>\n",
              "      <td>76.2W</td>\n",
              "      <td>30</td>\n",
              "      <td>1007</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44684</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>24.5N</td>\n",
              "      <td>76.5W</td>\n",
              "      <td>35</td>\n",
              "      <td>1006</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44685</th>\n",
              "      <td>AL122005</td>\n",
              "      <td>KATRINA</td>\n",
              "      <td>2005-08-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TS</td>\n",
              "      <td>25.4N</td>\n",
              "      <td>76.9W</td>\n",
              "      <td>40</td>\n",
              "      <td>1003</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46c46e5e-8f30-47ce-a2f2-495b4f32419a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46c46e5e-8f30-47ce-a2f2-495b4f32419a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46c46e5e-8f30-47ce-a2f2-495b4f32419a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
        "dataset.query('storm_id == \"AL122005\"').head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1USsREqJHDnG"
      },
      "source": [
        "# Transform Data\n",
        "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a storm_id dictionary to store storm names matched with ID's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Db-7PBHHBR",
        "outputId": "eddf4752-c372-4527-87b1-51da6a7d0d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming HURDAT2 into objects . . .\n",
            "Transforming 53976/53976 entries from HURDAT2\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Create hurricane class\n",
        "class hurricane(object) : \n",
        "    def __init__(self, name, id) :\n",
        "        # Set instance variables\n",
        "        self.name = name\n",
        "        self.id = id\n",
        "        self.entries = dict()\n",
        "        self.models = dict()\n",
        "        \n",
        "        return\n",
        "    # Add hurricane track entry based on standard HURDAT2 format\n",
        "    def add_entry(self, array) :\n",
        "        entry = {\n",
        "            array[0] : { # dateteime of entry\n",
        "                'entry_time' : array[0], \n",
        "                'entry_id' : array[1],\n",
        "                'entry_status' : array[2],\n",
        "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
        "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
        "                'max_wind' : float(array[5]),\n",
        "                'min_pressure' : 980 if array[6] is None else float(array[6]), # Early records are -999 or None\n",
        "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
        "                'distance': 0,\n",
        "                'direction': 0\n",
        "            }\n",
        "        }\n",
        "        self.entries.update(entry)\n",
        "        \n",
        "        return\n",
        "    # Add hurricane model errors\n",
        "    def add_model(self, name, model) :\n",
        "        self.models[name] = model\n",
        "        \n",
        "        return\n",
        "\n",
        "\n",
        "    def update_dist_direc(self):\n",
        "      t = pd.DataFrame(self.entries.values())\n",
        "      dst = 0\n",
        "      prev = (0,0)\n",
        "      \n",
        "      # For all latitude and longitude points of hurricane, calculate the angle of travel and distance\n",
        "      for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "          \n",
        "          if prev == (0,0):\n",
        "              prev = p\n",
        "              continue \n",
        "          # Stores the distance into the DataFrame\n",
        "          list(self.entries.values())[index]['distance'] = vc(prev,p).miles\n",
        "          \n",
        "          dLon = p[1] - prev[1];  \n",
        "          temp = float(p[0]) # p[0] is a str?\n",
        "          y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "          \n",
        "          x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "          brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "          if (brng < 0):\n",
        "              brng+= 360;\n",
        "          \n",
        "          # Stores the angle of travel into the DataFrame\n",
        "          list(self.entries.values())[index]['direction'] = brng\n",
        "          # if self.id == 'AL122005' and index==2:\n",
        "          if self.id == 'AL081994' and index==2:\n",
        "            print(f'p[1]:{p[1]}')\n",
        "            print(f'prev[1]:{prev[1]}')\n",
        "            print(f'dLon:{dLon}')\n",
        "            print(f'temp:{temp}')\n",
        "            print(f'y_x:{y_x}')\n",
        "            print(f'x_x:{x_x}')\n",
        "            print(f'brng:{brng}')\n",
        "          dst += vc(prev,p).miles\n",
        "          prev = p\n",
        "\n",
        "# Storm ID Key for matching between datasets\n",
        "storm_ids = dict()\n",
        "# Parse in hurricanes\n",
        "hurricanes = dict()\n",
        "\n",
        "print(\"Transforming HURDAT2 into objects . . .\")\n",
        "for index, entry in dataset.iterrows() :\n",
        "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset)), end = \"\\r\")\n",
        "    # New hurricane\n",
        "    if entry['storm_id'] not in hurricanes :\n",
        "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
        "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
        "    # Add entry to hurricane\n",
        "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxGx5Rg-uN_"
      },
      "source": [
        "# Load Data\n",
        "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPbnSHF8-s9O",
        "outputId": "0dcc3e82-ee16-4f5d-8fff-06e14a154116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n"
          ]
        }
      ],
      "source": [
        "# Get all available model errors\n",
        "# Load model errors into hurricanes\n",
        "for id in storm_ids :\n",
        "    for model in models :\n",
        "        # Skip if this hurricane does not have the model\n",
        "        if id not in models[model].storm :\n",
        "            continue\n",
        "        hurricanes[id].add_model(model, models[model].storm[id])\n",
        "    hurricanes[id].update_dist_direc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LZL5n_PJCTh1",
        "outputId": "e64717c0-f115-4f0b-bcec-c048b6dd8d48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction  \n",
              "0    0.000000  \n",
              "1  306.719439  \n",
              "2  259.483425  \n",
              "3  214.647871  \n",
              "4  205.375417  \n",
              "5  220.828574  \n",
              "6  226.705956  \n",
              "7  284.940686  \n",
              "8  332.536353  \n",
              "9  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1afd86e2-09fe-4061-ba6f-2900e9d57881\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1afd86e2-09fe-4061-ba6f-2900e9d57881')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1afd86e2-09fe-4061-ba6f-2900e9d57881 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1afd86e2-09fe-4061-ba6f-2900e9d57881');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#will test distance and direction of the bulk update vs individual update\n",
        "t=pd.DataFrame(hurricanes['AL081994'].entries.values())\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z3EhCEBPDa_j"
      },
      "outputs": [],
      "source": [
        "t['dist']=0\n",
        "t['direc']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPUaZqElDiHF",
        "outputId": "bccb20f9-3708-4756-a1fe-ffd48add02dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index:0,prev:(16.0, 84.5)\n",
            "1 306.71943856277255\n",
            "p[1]:85.9\n",
            "prev[1]:85.1\n",
            "dLon:0.8000000000000114\n",
            "temp:16.5\n",
            "y_x:-0.5038688074294795\n",
            "x_x:-0.09353734284162374\n",
            "brng:259.4834249123352\n",
            "2 259.4834249123352\n",
            "3 214.6478709156233\n",
            "4 205.37541693715318\n",
            "5 220.82857383503298\n",
            "6 226.7059563604921\n",
            "7 284.9406861076747\n",
            "8 332.53635339353264\n",
            "9 342.17177270335054\n"
          ]
        }
      ],
      "source": [
        "#testing for one hurricane\n",
        "prev=(0,0)\n",
        "for index,p in enumerate(zip(t['lat'], t['long'])):\n",
        "  if prev == (0,0):\n",
        "    prev = p\n",
        "    print(f'index:{index},prev:{prev}')\n",
        "    continue \n",
        "  # Stores the distance into the DataFrame\n",
        "  t.at[index,'dist'] = vc(prev,p).miles\n",
        "\n",
        "  dLon = p[1] - prev[1];  \n",
        "  temp = float(p[0]) # p[0] is a str?\n",
        "  y_x = Math.sin(dLon) * Math.cos(temp);\n",
        "\n",
        "  x_x = Math.cos(p[1]) * Math.sin(temp) - Math.sin(p[1]) * Math.cos(temp) * Math.cos(dLon);\n",
        "  brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
        "  if (brng < 0):\n",
        "    brng+= 360;\n",
        "  t.at[index,'direc'] = brng\n",
        "  if index==2:\n",
        "    print(f'p[1]:{p[1]}')\n",
        "    print(f'prev[1]:{prev[1]}')\n",
        "    print(f'dLon:{dLon}')\n",
        "    print(f'temp:{temp}')\n",
        "    print(f'y_x:{y_x}')\n",
        "    print(f'x_x:{x_x}')\n",
        "    print(f'brng:{brng}')\n",
        "  print(index,t.at[index,'direc'])\n",
        "  prev = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "A-6f67phDjvJ",
        "outputId": "99f6d1e5-ca79-4ed7-f4c6-2b04d2b6b16e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           entry_time entry_id entry_status   lat  long  max_wind  \\\n",
              "0 1994-09-24 12:00:00                    TD  16.0  84.5      25.0   \n",
              "1 1994-09-24 18:00:00                    TD  16.3  85.1      30.0   \n",
              "2 1994-09-25 00:00:00                    TD  16.5  85.9      30.0   \n",
              "3 1994-09-25 06:00:00                    TD  16.6  86.7      30.0   \n",
              "4 1994-09-25 12:00:00                    TD  16.7  87.6      30.0   \n",
              "5 1994-09-25 18:00:00        L           TD  16.6  88.4      30.0   \n",
              "6 1994-09-26 00:00:00                    TD  16.6  88.7      30.0   \n",
              "7 1994-09-26 06:00:00                    TD  16.6  88.9      25.0   \n",
              "8 1994-09-26 12:00:00                    TD  16.5  89.2      25.0   \n",
              "9 1994-09-26 18:00:00                    TD  16.5  89.5      25.0   \n",
              "\n",
              "   min_pressure                                         wind_radii   distance  \\\n",
              "0        1008.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...   0.000000   \n",
              "1        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  44.891903   \n",
              "2        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  54.796781   \n",
              "3        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.433344   \n",
              "4        1005.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  59.976134   \n",
              "5        1004.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  53.406014   \n",
              "6        1006.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.864134   \n",
              "7        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  13.242757   \n",
              "8        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  21.036343   \n",
              "9        1007.0  34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...  19.874439   \n",
              "\n",
              "    direction       dist       direc  \n",
              "0    0.000000   0.000000    0.000000  \n",
              "1  306.719439  44.891903  306.719439  \n",
              "2  259.483425  54.796781  259.483425  \n",
              "3  214.647871  53.433344  214.647871  \n",
              "4  205.375417  59.976134  205.375417  \n",
              "5  220.828574  53.406014  220.828574  \n",
              "6  226.705956  19.864134  226.705956  \n",
              "7  284.940686  13.242757  284.940686  \n",
              "8  332.536353  21.036343  332.536353  \n",
              "9  342.171773  19.874439  342.171773  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07e005e8-86b0-4e2c-9f5c-e85187227857\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_time</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>entry_status</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>max_wind</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>wind_radii</th>\n",
              "      <th>distance</th>\n",
              "      <th>direction</th>\n",
              "      <th>dist</th>\n",
              "      <th>direc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994-09-24 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.0</td>\n",
              "      <td>84.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994-09-24 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.3</td>\n",
              "      <td>85.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "      <td>44.891903</td>\n",
              "      <td>306.719439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994-09-25 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>85.9</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "      <td>54.796781</td>\n",
              "      <td>259.483425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994-09-25 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>86.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "      <td>53.433344</td>\n",
              "      <td>214.647871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994-09-25 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "      <td>59.976134</td>\n",
              "      <td>205.375417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1994-09-25 18:00:00</td>\n",
              "      <td>L</td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "      <td>53.406014</td>\n",
              "      <td>220.828574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1994-09-26 00:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "      <td>19.864134</td>\n",
              "      <td>226.705956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1994-09-26 06:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.6</td>\n",
              "      <td>88.9</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "      <td>13.242757</td>\n",
              "      <td>284.940686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1994-09-26 12:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "      <td>21.036343</td>\n",
              "      <td>332.536353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1994-09-26 18:00:00</td>\n",
              "      <td></td>\n",
              "      <td>TD</td>\n",
              "      <td>16.5</td>\n",
              "      <td>89.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>34kt_ne    None\n",
              "34kt_se    None\n",
              "34kt_sw    Non...</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "      <td>19.874439</td>\n",
              "      <td>342.171773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07e005e8-86b0-4e2c-9f5c-e85187227857')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07e005e8-86b0-4e2c-9f5c-e85187227857 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07e005e8-86b0-4e2c-9f5c-e85187227857');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t #to check that distance calculation and direction calculation from bulk vs individual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwdLRdvVDrxM",
        "outputId": "6e093c8e-d27a-48f5-c574-73bb06f92cca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['OFCL', 'BCD5'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "models.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt3z6MwrD23n"
      },
      "source": [
        "# Feature Engineering & Data Augmentation\n",
        "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
        "\n",
        "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
        "1. Date Information\n",
        "2. Zonal Speed Of The Storm (U) (kt)\n",
        "3. Meridional Speed Of The Storm (V) (kt)\n",
        "4. 12-h Change In Intensity (DVMX) (kt)\n",
        "\n",
        "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE9LxW_OD7q8",
        "outputId": "b24332a8-3305-459d-a194-25e4c8511c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineered 1944/1952 hurricanes for 5 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Scaling Data . . . (1 timestep for unqiue data)\n",
            "Feature engineered 1952/1952 hurricanes for 1 timestep(s)\n",
            "Done feature engineering hurricanes.\n",
            "Done scaling.\n"
          ]
        }
      ],
      "source": [
        "def feature_extraction(timestep, previous) :\n",
        "    '''\n",
        "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
        "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
        "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
        "            previous - previous timestep dictionary of features in the hurricane object format\n",
        "    OUTPUT: Dictionary of features\n",
        "    \n",
        "    timestep = {\n",
        "      'lat' : float,\n",
        "      'long' : float,\n",
        "      'max-wind' : float,\n",
        "      'entry-time' : datetime\n",
        "    }\n",
        "    '''\n",
        "    features = {\n",
        "        'lat' : timestep['lat'],\n",
        "        'long' : timestep['long'],\n",
        "        'max_wind' : timestep['max_wind'],\n",
        "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'min_pressure' : timestep['min_pressure'], \n",
        "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
        "        'year' : timestep['entry_time'].year,\n",
        "        'month' : timestep['entry_time'].month,\n",
        "        'day' : timestep['entry_time'].day,\n",
        "        'hour' : timestep['entry_time'].hour,\n",
        "        'delta_pressure': (timestep['min_pressure'] - previous['min_pressure']) /\n",
        "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
        "        'distance': timestep['distance'],\n",
        "        'direction': timestep['direction']\n",
        "    }\n",
        "    return features\n",
        "    \n",
        "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
        "    '''\n",
        "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
        "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
        "    INPUT:  storm - hurricane object\n",
        "            timesteps - (default = 1) number of timesteps to calculate\n",
        "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
        "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
        "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
        "    '''\n",
        "    x = []\n",
        "    # Create testing data structure with a dictionary\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    y = dict([(time,[]) for time in times])\n",
        "    \n",
        "    # Sort by entry time\n",
        "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
        "    \n",
        "    for index in range(len(entries)) :\n",
        "        if index < timesteps : # Flag for insufficient initial time steps\n",
        "            continue\n",
        "\n",
        "        # If we're not including None values, check to see if there will be any\n",
        "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
        "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
        "            \n",
        "        # Calculate time steps and their features for independent values\n",
        "        sample = []\n",
        "        for step in range(timesteps) :\n",
        "            # Training sample\n",
        "            timestep = entries[index - step]\n",
        "            previous = entries[index - step - 1]\n",
        "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
        "        x.append(sample) # Add our constructed sample\n",
        "        \n",
        "        # Calculate time steps and their features for dependent values\n",
        "        for future in times :\n",
        "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
        "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
        "            \n",
        "            if timestep and previous: \n",
        "                y[future].append(feature_extraction(timestep, previous))\n",
        "            else :\n",
        "                y[future].append(None)\n",
        "    \n",
        "    # Return output, if there is no output, return None.\n",
        "    if len(x) == 0 :\n",
        "        return None\n",
        "    else:\n",
        "        return {'x': x, 'y': y}\n",
        "def shape(hurricanes, timesteps, remove_missing = True) :\n",
        "    '''\n",
        "    PURPOSE: Shape our data for input into machine learning models\n",
        "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            timesteps - number of timesteps for the shape\n",
        "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
        "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
        "    '''\n",
        "    x = []\n",
        "    y = []\n",
        "    lag = 24 # lag time in hours\n",
        "    precision = np.float64 # defines the precision of our data type\n",
        "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
        "    count = 0\n",
        "    for hurricane in hurricanes.values() :\n",
        "        count += 1\n",
        "        result = storm_x_y(hurricane, timesteps, lag)\n",
        "        if result is None :\n",
        "            continue\n",
        "        # Extract only the values from the strom features using our specified precision\n",
        "        hurricane_x = np.array(\n",
        "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
        "            dtype = precision)\n",
        "        hurricane_y = np.array(\n",
        "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
        "            dtype = precision)\n",
        "        # Disregard if algorithm requires no missing values\n",
        "        if remove_missing :\n",
        "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
        "                continue\n",
        "        # Add to our results\n",
        "        x.extend(hurricane_x)\n",
        "        y.extend(hurricane_y)\n",
        "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
        "    print(\"\\nDone feature engineering hurricanes.\")\n",
        "    \n",
        "    return {'x': np.array(x), 'y': np.array(y)}\n",
        "def scaler(processed_data, hurricanes) :\n",
        "    '''\n",
        "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
        "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
        "    INPUT:  hurricanes - dictionary of hurricane objects\n",
        "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
        "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
        "            2) RobustScaler object fit with appropriate data\n",
        "    '''\n",
        "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
        "    # Create our scaler\n",
        "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
        "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
        "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
        "    scaler = RobustScaler()\n",
        "    scaler.fit(x)\n",
        "    \n",
        "    # Scale our data\n",
        "    for index in range(len(processed_data['x'])) :\n",
        "        # Scale our x\n",
        "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
        "        # Scale our y\n",
        "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
        "    print(\"Done scaling.\")\n",
        "    return processed_data, scaler\n",
        "# Finalize and scale procesed data into a dictionary\n",
        "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
        "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NapGhxs0vKF4"
      },
      "source": [
        "# Model Architecture\n",
        "Following feature engineering, we are now ready to input our data into a machine learning algorithm. The scope of this project will attempt a deep learning approach to forecasting Atlantic tropical cyclones. We will experiment with nunermous different architectures but we will focus around a Recurrent Neural Network utilizing LSTM cells.\n",
        "\n",
        "Notes:\n",
        "\n",
        "1.   We will use 500 epochs for wind intensity because the validation loss is not decreasing\n",
        "2.   We will use 1,000 epochs for latitute and longitude"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda, Attention, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.context_vector = self.add_weight(shape=(self.hidden_size,),\n",
        "                                              initializer='random_normal',\n",
        "                                              trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hidden_states, _ = inputs\n",
        "\n",
        "        context_vector = tf.expand_dims(self.context_vector, axis=0)\n",
        "        context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[0], axis=0)\n",
        "\n",
        "        attention_weights = tf.einsum('ijk,ik->ij', hidden_states, context_vector)\n",
        "        attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "\n",
        "        weighted_sum = tf.einsum('ij,ijk->ik', attention_weights, hidden_states)\n",
        "\n",
        "        return weighted_sum\n",
        "\n"
      ],
      "metadata": {
        "id": "1_LGW5zSQpeV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd7P0bXwvg97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48cc7a0d-c852-4a33-c77f-40fa261a72aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 5, 14)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 5, 128)       73216       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " attention_layer_3 (AttentionLa  (None, 128)         128         ['lstm_3[0][0]',                 \n",
            " yer)                                                             'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            129         ['attention_layer_3[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,473\n",
            "Trainable params: 73,473\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 3s 148ms/step - loss: 0.4406 - val_loss: 0.3021\n",
            "Loss: 0.4406072795391083\n",
            "Validation Loss: 0.30211302638053894\n",
            "\n",
            "Epoch 2/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.3386 - val_loss: 0.2912\n",
            "Loss: 0.33864688873291016\n",
            "Validation Loss: 0.2912389636039734\n",
            "\n",
            "Epoch 3/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.3204 - val_loss: 0.2828\n",
            "Loss: 0.32039204239845276\n",
            "Validation Loss: 0.28278863430023193\n",
            "\n",
            "Epoch 4/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.3186 - val_loss: 0.2785\n",
            "Loss: 0.31858423352241516\n",
            "Validation Loss: 0.27851995825767517\n",
            "\n",
            "Epoch 5/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.3107 - val_loss: 0.2767\n",
            "Loss: 0.3106915354728699\n",
            "Validation Loss: 0.2766648232936859\n",
            "\n",
            "Epoch 6/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.3086 - val_loss: 0.2729\n",
            "Loss: 0.3086230754852295\n",
            "Validation Loss: 0.27290889620780945\n",
            "\n",
            "Epoch 7/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.3044 - val_loss: 0.2696\n",
            "Loss: 0.3043878972530365\n",
            "Validation Loss: 0.2696196138858795\n",
            "\n",
            "Epoch 8/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.3027 - val_loss: 0.2681\n",
            "Loss: 0.3027248680591583\n",
            "Validation Loss: 0.2681434750556946\n",
            "\n",
            "Epoch 9/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2985 - val_loss: 0.2681\n",
            "Loss: 0.2984544634819031\n",
            "Validation Loss: 0.2680739164352417\n",
            "\n",
            "Epoch 10/500\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.2982 - val_loss: 0.2662\n",
            "Loss: 0.2981942594051361\n",
            "Validation Loss: 0.2662222385406494\n",
            "\n",
            "Epoch 11/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2958 - val_loss: 0.2626\n",
            "Loss: 0.2958498001098633\n",
            "Validation Loss: 0.2626429796218872\n",
            "\n",
            "Epoch 12/500\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 0.2964 - val_loss: 0.2624\n",
            "Loss: 0.2964308261871338\n",
            "Validation Loss: 0.26240724325180054\n",
            "\n",
            "Epoch 13/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2921 - val_loss: 0.2602\n",
            "Loss: 0.2921096682548523\n",
            "Validation Loss: 0.26024672389030457\n",
            "\n",
            "Epoch 14/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.2906 - val_loss: 0.2602\n",
            "Loss: 0.2906002998352051\n",
            "Validation Loss: 0.2601701319217682\n",
            "\n",
            "Epoch 15/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2914 - val_loss: 0.2603\n",
            "Loss: 0.2914120852947235\n",
            "Validation Loss: 0.26028111577033997\n",
            "\n",
            "Epoch 16/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2863 - val_loss: 0.2618\n",
            "Loss: 0.2863103449344635\n",
            "Validation Loss: 0.2617652714252472\n",
            "\n",
            "Epoch 17/500\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.2883 - val_loss: 0.2574\n",
            "Loss: 0.2883107662200928\n",
            "Validation Loss: 0.2574031949043274\n",
            "\n",
            "Epoch 18/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2845 - val_loss: 0.2553\n",
            "Loss: 0.28453582525253296\n",
            "Validation Loss: 0.25531134009361267\n",
            "\n",
            "Epoch 19/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2833 - val_loss: 0.2553\n",
            "Loss: 0.28331542015075684\n",
            "Validation Loss: 0.25529780983924866\n",
            "\n",
            "Epoch 20/500\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.2841 - val_loss: 0.2547\n",
            "Loss: 0.28406524658203125\n",
            "Validation Loss: 0.25468623638153076\n",
            "\n",
            "Epoch 21/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2825 - val_loss: 0.2591\n",
            "Loss: 0.28250613808631897\n",
            "Validation Loss: 0.25905078649520874\n",
            "\n",
            "Epoch 22/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2848 - val_loss: 0.2542\n",
            "Loss: 0.2847565710544586\n",
            "Validation Loss: 0.2541895806789398\n",
            "\n",
            "Epoch 23/500\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.2802 - val_loss: 0.2546\n",
            "Loss: 0.2802259922027588\n",
            "Validation Loss: 0.25463831424713135\n",
            "\n",
            "Epoch 24/500\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2773 - val_loss: 0.2515\n",
            "Loss: 0.2772867977619171\n",
            "Validation Loss: 0.2514825761318207\n",
            "\n",
            "Epoch 25/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2780 - val_loss: 0.2524\n",
            "Loss: 0.2780044376850128\n",
            "Validation Loss: 0.25241267681121826\n",
            "\n",
            "Epoch 26/500\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2774 - val_loss: 0.2501\n",
            "Loss: 0.2774082124233246\n",
            "Validation Loss: 0.2501029074192047\n",
            "\n",
            "Epoch 27/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2785 - val_loss: 0.2502\n",
            "Loss: 0.27853938937187195\n",
            "Validation Loss: 0.25016123056411743\n",
            "\n",
            "Epoch 28/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.2756 - val_loss: 0.2495\n",
            "Loss: 0.2756398022174835\n",
            "Validation Loss: 0.2494790107011795\n",
            "\n",
            "Epoch 29/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2747 - val_loss: 0.2514\n",
            "Loss: 0.27467086911201477\n",
            "Validation Loss: 0.2513919174671173\n",
            "\n",
            "Epoch 30/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2726 - val_loss: 0.2494\n",
            "Loss: 0.2726203203201294\n",
            "Validation Loss: 0.24935553967952728\n",
            "\n",
            "Epoch 31/500\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2729 - val_loss: 0.2463\n",
            "Loss: 0.2728559374809265\n",
            "Validation Loss: 0.24629342555999756\n",
            "\n",
            "Epoch 32/500\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.2713 - val_loss: 0.2475\n",
            "Loss: 0.27126437425613403\n",
            "Validation Loss: 0.2474895417690277\n",
            "\n",
            "Epoch 33/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2708 - val_loss: 0.2471\n",
            "Loss: 0.2708069384098053\n",
            "Validation Loss: 0.24705328047275543\n",
            "\n",
            "Epoch 34/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2705 - val_loss: 0.2474\n",
            "Loss: 0.2705073356628418\n",
            "Validation Loss: 0.24739347398281097\n",
            "\n",
            "Epoch 35/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2683 - val_loss: 0.2446\n",
            "Loss: 0.26834380626678467\n",
            "Validation Loss: 0.24460749328136444\n",
            "\n",
            "Epoch 36/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.2698 - val_loss: 0.2463\n",
            "Loss: 0.26975521445274353\n",
            "Validation Loss: 0.24634037911891937\n",
            "\n",
            "Epoch 37/500\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 0.2674 - val_loss: 0.2429\n",
            "Loss: 0.2673698961734772\n",
            "Validation Loss: 0.2429260015487671\n",
            "\n",
            "Epoch 38/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2671 - val_loss: 0.2455\n",
            "Loss: 0.26710566878318787\n",
            "Validation Loss: 0.24548958241939545\n",
            "\n",
            "Epoch 39/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2675 - val_loss: 0.2431\n",
            "Loss: 0.26751798391342163\n",
            "Validation Loss: 0.24312199652194977\n",
            "\n",
            "Epoch 40/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2661 - val_loss: 0.2444\n",
            "Loss: 0.2660733759403229\n",
            "Validation Loss: 0.24438855051994324\n",
            "\n",
            "Epoch 41/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2653 - val_loss: 0.2441\n",
            "Loss: 0.265322208404541\n",
            "Validation Loss: 0.24414975941181183\n",
            "\n",
            "Epoch 42/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2637 - val_loss: 0.2393\n",
            "Loss: 0.26366013288497925\n",
            "Validation Loss: 0.2392788976430893\n",
            "\n",
            "Epoch 43/500\n",
            "21/21 [==============================] - 4s 185ms/step - loss: 0.2646 - val_loss: 0.2410\n",
            "Loss: 0.26462826132774353\n",
            "Validation Loss: 0.24103917181491852\n",
            "\n",
            "Epoch 44/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2632 - val_loss: 0.2398\n",
            "Loss: 0.26321807503700256\n",
            "Validation Loss: 0.2398291826248169\n",
            "\n",
            "Epoch 45/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2622 - val_loss: 0.2391\n",
            "Loss: 0.2621922194957733\n",
            "Validation Loss: 0.2390758991241455\n",
            "\n",
            "Epoch 46/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2620 - val_loss: 0.2397\n",
            "Loss: 0.26196131110191345\n",
            "Validation Loss: 0.23967348039150238\n",
            "\n",
            "Epoch 47/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2624 - val_loss: 0.2380\n",
            "Loss: 0.26244157552719116\n",
            "Validation Loss: 0.23804624378681183\n",
            "\n",
            "Epoch 48/500\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.2602 - val_loss: 0.2364\n",
            "Loss: 0.2601875364780426\n",
            "Validation Loss: 0.23637133836746216\n",
            "\n",
            "Epoch 49/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2595 - val_loss: 0.2377\n",
            "Loss: 0.259511262178421\n",
            "Validation Loss: 0.23773124814033508\n",
            "\n",
            "Epoch 50/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2601 - val_loss: 0.2346\n",
            "Loss: 0.2601236402988434\n",
            "Validation Loss: 0.2345617413520813\n",
            "\n",
            "Epoch 51/500\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2598 - val_loss: 0.2378\n",
            "Loss: 0.25983619689941406\n",
            "Validation Loss: 0.2377895563840866\n",
            "\n",
            "Epoch 52/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2577 - val_loss: 0.2365\n",
            "Loss: 0.25765886902809143\n",
            "Validation Loss: 0.2365330308675766\n",
            "\n",
            "Epoch 53/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2574 - val_loss: 0.2348\n",
            "Loss: 0.2573903501033783\n",
            "Validation Loss: 0.23484161496162415\n",
            "\n",
            "Epoch 54/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2567 - val_loss: 0.2333\n",
            "Loss: 0.2566610872745514\n",
            "Validation Loss: 0.23331338167190552\n",
            "\n",
            "Epoch 55/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2548 - val_loss: 0.2336\n",
            "Loss: 0.254838228225708\n",
            "Validation Loss: 0.23361316323280334\n",
            "\n",
            "Epoch 56/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2552 - val_loss: 0.2337\n",
            "Loss: 0.2551875114440918\n",
            "Validation Loss: 0.23374436795711517\n",
            "\n",
            "Epoch 57/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2535 - val_loss: 0.2326\n",
            "Loss: 0.2534511387348175\n",
            "Validation Loss: 0.23256151378154755\n",
            "\n",
            "Epoch 58/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2533 - val_loss: 0.2315\n",
            "Loss: 0.253284752368927\n",
            "Validation Loss: 0.2315194457769394\n",
            "\n",
            "Epoch 59/500\n",
            "21/21 [==============================] - 2s 115ms/step - loss: 0.2556 - val_loss: 0.2370\n",
            "Loss: 0.25564295053482056\n",
            "Validation Loss: 0.23699520528316498\n",
            "\n",
            "Epoch 60/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2518 - val_loss: 0.2312\n",
            "Loss: 0.25183263421058655\n",
            "Validation Loss: 0.23120170831680298\n",
            "\n",
            "Epoch 61/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2521 - val_loss: 0.2337\n",
            "Loss: 0.2520589530467987\n",
            "Validation Loss: 0.23368406295776367\n",
            "\n",
            "Epoch 62/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2534 - val_loss: 0.2288\n",
            "Loss: 0.2533552944660187\n",
            "Validation Loss: 0.2288249433040619\n",
            "\n",
            "Epoch 63/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2525 - val_loss: 0.2313\n",
            "Loss: 0.252466082572937\n",
            "Validation Loss: 0.23127232491970062\n",
            "\n",
            "Epoch 64/500\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 0.2528 - val_loss: 0.2312\n",
            "Loss: 0.25275951623916626\n",
            "Validation Loss: 0.23122377693653107\n",
            "\n",
            "Epoch 65/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2483 - val_loss: 0.2308\n",
            "Loss: 0.24825388193130493\n",
            "Validation Loss: 0.23078987002372742\n",
            "\n",
            "Epoch 66/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2507 - val_loss: 0.2303\n",
            "Loss: 0.25072890520095825\n",
            "Validation Loss: 0.2302604466676712\n",
            "\n",
            "Epoch 67/500\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2479 - val_loss: 0.2313\n",
            "Loss: 0.24789181351661682\n",
            "Validation Loss: 0.23126238584518433\n",
            "\n",
            "Epoch 68/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2465 - val_loss: 0.2270\n",
            "Loss: 0.246512770652771\n",
            "Validation Loss: 0.22699306905269623\n",
            "\n",
            "Epoch 69/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2468 - val_loss: 0.2269\n",
            "Loss: 0.24677182734012604\n",
            "Validation Loss: 0.22689607739448547\n",
            "\n",
            "Epoch 70/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2468 - val_loss: 0.2258\n",
            "Loss: 0.24676863849163055\n",
            "Validation Loss: 0.22580449283123016\n",
            "\n",
            "Epoch 71/500\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2441 - val_loss: 0.2243\n",
            "Loss: 0.24407021701335907\n",
            "Validation Loss: 0.22428269684314728\n",
            "\n",
            "Epoch 72/500\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2447 - val_loss: 0.2252\n",
            "Loss: 0.2446746975183487\n",
            "Validation Loss: 0.22515283524990082\n",
            "\n",
            "Epoch 73/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2456 - val_loss: 0.2289\n",
            "Loss: 0.24562649428844452\n",
            "Validation Loss: 0.22894315421581268\n",
            "\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2456 - val_loss: 0.2243\n",
            "Loss: 0.24564281105995178\n",
            "Validation Loss: 0.22431541979312897\n",
            "\n",
            "Epoch 75/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2425 - val_loss: 0.2228\n",
            "Loss: 0.24245895445346832\n",
            "Validation Loss: 0.22278256714344025\n",
            "\n",
            "Epoch 76/500\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.2428 - val_loss: 0.2236\n",
            "Loss: 0.24284200370311737\n",
            "Validation Loss: 0.2235729694366455\n",
            "\n",
            "Epoch 77/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2441 - val_loss: 0.2223\n",
            "Loss: 0.244113951921463\n",
            "Validation Loss: 0.2223450392484665\n",
            "\n",
            "Epoch 78/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2422 - val_loss: 0.2225\n",
            "Loss: 0.2421678900718689\n",
            "Validation Loss: 0.2224760204553604\n",
            "\n",
            "Epoch 79/500\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.2399 - val_loss: 0.2206\n",
            "Loss: 0.23993703722953796\n",
            "Validation Loss: 0.22060950100421906\n",
            "\n",
            "Epoch 80/500\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2411 - val_loss: 0.2209\n",
            "Loss: 0.24105364084243774\n",
            "Validation Loss: 0.2209385484457016\n",
            "\n",
            "Epoch 81/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2406 - val_loss: 0.2220\n",
            "Loss: 0.24061958491802216\n",
            "Validation Loss: 0.22195985913276672\n",
            "\n",
            "Epoch 82/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2377 - val_loss: 0.2178\n",
            "Loss: 0.23774760961532593\n",
            "Validation Loss: 0.21778270602226257\n",
            "\n",
            "Epoch 83/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2397 - val_loss: 0.2191\n",
            "Loss: 0.23967687785625458\n",
            "Validation Loss: 0.21909479796886444\n",
            "\n",
            "Epoch 84/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2402 - val_loss: 0.2167\n",
            "Loss: 0.24021519720554352\n",
            "Validation Loss: 0.21669001877307892\n",
            "\n",
            "Epoch 85/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2377 - val_loss: 0.2185\n",
            "Loss: 0.23770762979984283\n",
            "Validation Loss: 0.21846699714660645\n",
            "\n",
            "Epoch 86/500\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2361 - val_loss: 0.2179\n",
            "Loss: 0.236109659075737\n",
            "Validation Loss: 0.21792860329151154\n",
            "\n",
            "Epoch 87/500\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2382 - val_loss: 0.2182\n",
            "Loss: 0.23821796476840973\n",
            "Validation Loss: 0.21815365552902222\n",
            "\n",
            "Epoch 88/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2371 - val_loss: 0.2175\n",
            "Loss: 0.23706580698490143\n",
            "Validation Loss: 0.21752537786960602\n",
            "\n",
            "Epoch 89/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2359 - val_loss: 0.2177\n",
            "Loss: 0.23587335646152496\n",
            "Validation Loss: 0.2176530659198761\n",
            "\n",
            "Epoch 90/500\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 0.2365 - val_loss: 0.2173\n",
            "Loss: 0.2365403026342392\n",
            "Validation Loss: 0.21733054518699646\n",
            "\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - 3s 161ms/step - loss: 0.2332 - val_loss: 0.2173\n",
            "Loss: 0.2331927865743637\n",
            "Validation Loss: 0.21726082265377045\n",
            "\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2347 - val_loss: 0.2158\n",
            "Loss: 0.2346571683883667\n",
            "Validation Loss: 0.21582964062690735\n",
            "\n",
            "Epoch 93/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2348 - val_loss: 0.2149\n",
            "Loss: 0.234815314412117\n",
            "Validation Loss: 0.21488003432750702\n",
            "\n",
            "Epoch 94/500\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.2329 - val_loss: 0.2175\n",
            "Loss: 0.23290890455245972\n",
            "Validation Loss: 0.21752457320690155\n",
            "\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2319 - val_loss: 0.2153\n",
            "Loss: 0.23185062408447266\n",
            "Validation Loss: 0.21533355116844177\n",
            "\n",
            "Epoch 96/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2336 - val_loss: 0.2165\n",
            "Loss: 0.23355194926261902\n",
            "Validation Loss: 0.21649958193302155\n",
            "\n",
            "Epoch 97/500\n",
            "21/21 [==============================] - 3s 151ms/step - loss: 0.2333 - val_loss: 0.2147\n",
            "Loss: 0.23333510756492615\n",
            "Validation Loss: 0.21469298005104065\n",
            "\n",
            "Epoch 98/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2316 - val_loss: 0.2159\n",
            "Loss: 0.2316204011440277\n",
            "Validation Loss: 0.21594007313251495\n",
            "\n",
            "Epoch 99/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2313 - val_loss: 0.2140\n",
            "Loss: 0.2313118726015091\n",
            "Validation Loss: 0.21402941644191742\n",
            "\n",
            "Epoch 100/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2332 - val_loss: 0.2119\n",
            "Loss: 0.23319672048091888\n",
            "Validation Loss: 0.2118760496377945\n",
            "\n",
            "Epoch 101/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2306 - val_loss: 0.2122\n",
            "Loss: 0.23056751489639282\n",
            "Validation Loss: 0.21217745542526245\n",
            "\n",
            "Epoch 102/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2302 - val_loss: 0.2113\n",
            "Loss: 0.23023788630962372\n",
            "Validation Loss: 0.2112768292427063\n",
            "\n",
            "Epoch 103/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2304 - val_loss: 0.2130\n",
            "Loss: 0.23038233816623688\n",
            "Validation Loss: 0.2130187302827835\n",
            "\n",
            "Epoch 104/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.2300 - val_loss: 0.2116\n",
            "Loss: 0.23000837862491608\n",
            "Validation Loss: 0.21157844364643097\n",
            "\n",
            "Epoch 105/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2284 - val_loss: 0.2131\n",
            "Loss: 0.2284448891878128\n",
            "Validation Loss: 0.2131441980600357\n",
            "\n",
            "Epoch 106/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2305 - val_loss: 0.2112\n",
            "Loss: 0.23046734929084778\n",
            "Validation Loss: 0.21117886900901794\n",
            "\n",
            "Epoch 107/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2291 - val_loss: 0.2119\n",
            "Loss: 0.22910962998867035\n",
            "Validation Loss: 0.2118586301803589\n",
            "\n",
            "Epoch 108/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.2287 - val_loss: 0.2094\n",
            "Loss: 0.2287413477897644\n",
            "Validation Loss: 0.20939460396766663\n",
            "\n",
            "Epoch 109/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2258 - val_loss: 0.2087\n",
            "Loss: 0.22584286332130432\n",
            "Validation Loss: 0.2086811512708664\n",
            "\n",
            "Epoch 110/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2282 - val_loss: 0.2088\n",
            "Loss: 0.228206604719162\n",
            "Validation Loss: 0.20880825817584991\n",
            "\n",
            "Epoch 111/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.2254 - val_loss: 0.2090\n",
            "Loss: 0.2253674417734146\n",
            "Validation Loss: 0.20903052389621735\n",
            "\n",
            "Epoch 112/500\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.2263 - val_loss: 0.2081\n",
            "Loss: 0.2262687385082245\n",
            "Validation Loss: 0.20807702839374542\n",
            "\n",
            "Epoch 113/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2234 - val_loss: 0.2096\n",
            "Loss: 0.2234213948249817\n",
            "Validation Loss: 0.2096414715051651\n",
            "\n",
            "Epoch 114/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2246 - val_loss: 0.2083\n",
            "Loss: 0.22464445233345032\n",
            "Validation Loss: 0.20833565294742584\n",
            "\n",
            "Epoch 115/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2246 - val_loss: 0.2072\n",
            "Loss: 0.22455419600009918\n",
            "Validation Loss: 0.20722267031669617\n",
            "\n",
            "Epoch 116/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2245 - val_loss: 0.2068\n",
            "Loss: 0.22447632253170013\n",
            "Validation Loss: 0.206808403134346\n",
            "\n",
            "Epoch 117/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2253 - val_loss: 0.2068\n",
            "Loss: 0.22525843977928162\n",
            "Validation Loss: 0.20683717727661133\n",
            "\n",
            "Epoch 118/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2253 - val_loss: 0.2076\n",
            "Loss: 0.2253478318452835\n",
            "Validation Loss: 0.2075854241847992\n",
            "\n",
            "Epoch 119/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2225 - val_loss: 0.2074\n",
            "Loss: 0.2225124090909958\n",
            "Validation Loss: 0.2073533833026886\n",
            "\n",
            "Epoch 120/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2227 - val_loss: 0.2046\n",
            "Loss: 0.22267796099185944\n",
            "Validation Loss: 0.2045583575963974\n",
            "\n",
            "Epoch 121/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2221 - val_loss: 0.2065\n",
            "Loss: 0.2221408486366272\n",
            "Validation Loss: 0.20650899410247803\n",
            "\n",
            "Epoch 122/500\n",
            "21/21 [==============================] - 3s 139ms/step - loss: 0.2232 - val_loss: 0.2098\n",
            "Loss: 0.2231823354959488\n",
            "Validation Loss: 0.20983359217643738\n",
            "\n",
            "Epoch 123/500\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.2225 - val_loss: 0.2062\n",
            "Loss: 0.22254453599452972\n",
            "Validation Loss: 0.20616967976093292\n",
            "\n",
            "Epoch 124/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2206 - val_loss: 0.2034\n",
            "Loss: 0.22055749595165253\n",
            "Validation Loss: 0.203408345580101\n",
            "\n",
            "Epoch 125/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2206 - val_loss: 0.2055\n",
            "Loss: 0.22064191102981567\n",
            "Validation Loss: 0.20552219450473785\n",
            "\n",
            "Epoch 126/500\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.2209 - val_loss: 0.2037\n",
            "Loss: 0.22094805538654327\n",
            "Validation Loss: 0.203709676861763\n",
            "\n",
            "Epoch 127/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2205 - val_loss: 0.2049\n",
            "Loss: 0.2204532027244568\n",
            "Validation Loss: 0.2049303948879242\n",
            "\n",
            "Epoch 128/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2194 - val_loss: 0.2039\n",
            "Loss: 0.21940767765045166\n",
            "Validation Loss: 0.20387795567512512\n",
            "\n",
            "Epoch 129/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2184 - val_loss: 0.2048\n",
            "Loss: 0.21835720539093018\n",
            "Validation Loss: 0.20480923354625702\n",
            "\n",
            "Epoch 130/500\n",
            "21/21 [==============================] - 3s 151ms/step - loss: 0.2209 - val_loss: 0.2059\n",
            "Loss: 0.22087162733078003\n",
            "Validation Loss: 0.20592394471168518\n",
            "\n",
            "Epoch 131/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2192 - val_loss: 0.2028\n",
            "Loss: 0.21917681396007538\n",
            "Validation Loss: 0.20281226933002472\n",
            "\n",
            "Epoch 132/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2202 - val_loss: 0.2036\n",
            "Loss: 0.2202427089214325\n",
            "Validation Loss: 0.20357023179531097\n",
            "\n",
            "Epoch 133/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.2190 - val_loss: 0.2057\n",
            "Loss: 0.21900515258312225\n",
            "Validation Loss: 0.2057008147239685\n",
            "\n",
            "Epoch 134/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2208 - val_loss: 0.2017\n",
            "Loss: 0.22081616520881653\n",
            "Validation Loss: 0.20171861350536346\n",
            "\n",
            "Epoch 135/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2200 - val_loss: 0.1999\n",
            "Loss: 0.2200327068567276\n",
            "Validation Loss: 0.1999068260192871\n",
            "\n",
            "Epoch 136/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2201 - val_loss: 0.2027\n",
            "Loss: 0.22006464004516602\n",
            "Validation Loss: 0.20265942811965942\n",
            "\n",
            "Epoch 137/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2164 - val_loss: 0.2019\n",
            "Loss: 0.2163601666688919\n",
            "Validation Loss: 0.20194800198078156\n",
            "\n",
            "Epoch 138/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2182 - val_loss: 0.2002\n",
            "Loss: 0.2182237207889557\n",
            "Validation Loss: 0.20018206536769867\n",
            "\n",
            "Epoch 139/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2181 - val_loss: 0.1978\n",
            "Loss: 0.21808548271656036\n",
            "Validation Loss: 0.19781018793582916\n",
            "\n",
            "Epoch 140/500\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.2172 - val_loss: 0.1989\n",
            "Loss: 0.21721018850803375\n",
            "Validation Loss: 0.1988712102174759\n",
            "\n",
            "Epoch 141/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2174 - val_loss: 0.2024\n",
            "Loss: 0.21739313006401062\n",
            "Validation Loss: 0.2023685872554779\n",
            "\n",
            "Epoch 142/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.2171 - val_loss: 0.1987\n",
            "Loss: 0.21714164316654205\n",
            "Validation Loss: 0.19872765243053436\n",
            "\n",
            "Epoch 143/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2178 - val_loss: 0.1999\n",
            "Loss: 0.21775835752487183\n",
            "Validation Loss: 0.1998646855354309\n",
            "\n",
            "Epoch 144/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2161 - val_loss: 0.2013\n",
            "Loss: 0.21607078611850739\n",
            "Validation Loss: 0.20133115351200104\n",
            "\n",
            "Epoch 145/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2170 - val_loss: 0.1982\n",
            "Loss: 0.21700890362262726\n",
            "Validation Loss: 0.19816163182258606\n",
            "\n",
            "Epoch 146/500\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.2162 - val_loss: 0.1978\n",
            "Loss: 0.21615847945213318\n",
            "Validation Loss: 0.19780579209327698\n",
            "\n",
            "Epoch 147/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2157 - val_loss: 0.1976\n",
            "Loss: 0.21573106944561005\n",
            "Validation Loss: 0.19756191968917847\n",
            "\n",
            "Epoch 148/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2158 - val_loss: 0.1966\n",
            "Loss: 0.21578693389892578\n",
            "Validation Loss: 0.19658632576465607\n",
            "\n",
            "Epoch 149/500\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2142 - val_loss: 0.2002\n",
            "Loss: 0.2141881287097931\n",
            "Validation Loss: 0.2002055048942566\n",
            "\n",
            "Epoch 150/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2144 - val_loss: 0.1963\n",
            "Loss: 0.21443480253219604\n",
            "Validation Loss: 0.1963261067867279\n",
            "\n",
            "Epoch 151/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2142 - val_loss: 0.2005\n",
            "Loss: 0.2141958475112915\n",
            "Validation Loss: 0.20051012933254242\n",
            "\n",
            "Epoch 152/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.2139 - val_loss: 0.2007\n",
            "Loss: 0.21391268074512482\n",
            "Validation Loss: 0.2006782442331314\n",
            "\n",
            "Epoch 153/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2133 - val_loss: 0.1955\n",
            "Loss: 0.2133226990699768\n",
            "Validation Loss: 0.19550473988056183\n",
            "\n",
            "Epoch 154/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2127 - val_loss: 0.1992\n",
            "Loss: 0.21267616748809814\n",
            "Validation Loss: 0.19915151596069336\n",
            "\n",
            "Epoch 155/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.2112 - val_loss: 0.1972\n",
            "Loss: 0.21116124093532562\n",
            "Validation Loss: 0.19723151624202728\n",
            "\n",
            "Epoch 156/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2128 - val_loss: 0.1952\n",
            "Loss: 0.21278905868530273\n",
            "Validation Loss: 0.19516517221927643\n",
            "\n",
            "Epoch 157/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2121 - val_loss: 0.1938\n",
            "Loss: 0.21210646629333496\n",
            "Validation Loss: 0.19381225109100342\n",
            "\n",
            "Epoch 158/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2121 - val_loss: 0.1933\n",
            "Loss: 0.21212828159332275\n",
            "Validation Loss: 0.1932629495859146\n",
            "\n",
            "Epoch 159/500\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.2103 - val_loss: 0.1955\n",
            "Loss: 0.21027544140815735\n",
            "Validation Loss: 0.19552481174468994\n",
            "\n",
            "Epoch 160/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2113 - val_loss: 0.1931\n",
            "Loss: 0.21127764880657196\n",
            "Validation Loss: 0.19308219850063324\n",
            "\n",
            "Epoch 161/500\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 0.2110 - val_loss: 0.1955\n",
            "Loss: 0.21095570921897888\n",
            "Validation Loss: 0.19546112418174744\n",
            "\n",
            "Epoch 162/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2116 - val_loss: 0.1951\n",
            "Loss: 0.211600661277771\n",
            "Validation Loss: 0.19514963030815125\n",
            "\n",
            "Epoch 163/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.2106 - val_loss: 0.1934\n",
            "Loss: 0.21061240136623383\n",
            "Validation Loss: 0.1934308260679245\n",
            "\n",
            "Epoch 164/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2100 - val_loss: 0.1966\n",
            "Loss: 0.21004340052604675\n",
            "Validation Loss: 0.19661901891231537\n",
            "\n",
            "Epoch 165/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2118 - val_loss: 0.1983\n",
            "Loss: 0.2118360996246338\n",
            "Validation Loss: 0.1982777714729309\n",
            "\n",
            "Epoch 166/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2095 - val_loss: 0.1945\n",
            "Loss: 0.20946931838989258\n",
            "Validation Loss: 0.19453229010105133\n",
            "\n",
            "Epoch 167/500\n",
            "21/21 [==============================] - 3s 165ms/step - loss: 0.2110 - val_loss: 0.1953\n",
            "Loss: 0.21102261543273926\n",
            "Validation Loss: 0.19534769654273987\n",
            "\n",
            "Epoch 168/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.2097 - val_loss: 0.1944\n",
            "Loss: 0.20968031883239746\n",
            "Validation Loss: 0.19437673687934875\n",
            "\n",
            "Epoch 169/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2095 - val_loss: 0.1910\n",
            "Loss: 0.20950226485729218\n",
            "Validation Loss: 0.19104790687561035\n",
            "\n",
            "Epoch 170/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.2091 - val_loss: 0.1911\n",
            "Loss: 0.20907922089099884\n",
            "Validation Loss: 0.1910760998725891\n",
            "\n",
            "Epoch 171/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.2099 - val_loss: 0.1920\n",
            "Loss: 0.20993947982788086\n",
            "Validation Loss: 0.19198258221149445\n",
            "\n",
            "Epoch 172/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2097 - val_loss: 0.1930\n",
            "Loss: 0.20967690646648407\n",
            "Validation Loss: 0.19302484393119812\n",
            "\n",
            "Epoch 173/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2089 - val_loss: 0.1940\n",
            "Loss: 0.20894408226013184\n",
            "Validation Loss: 0.1939924955368042\n",
            "\n",
            "Epoch 174/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2099 - val_loss: 0.1925\n",
            "Loss: 0.2099299132823944\n",
            "Validation Loss: 0.1924843192100525\n",
            "\n",
            "Epoch 175/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2070 - val_loss: 0.1932\n",
            "Loss: 0.20695561170578003\n",
            "Validation Loss: 0.1932448446750641\n",
            "\n",
            "Epoch 176/500\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.2091 - val_loss: 0.1941\n",
            "Loss: 0.20910878479480743\n",
            "Validation Loss: 0.19412016868591309\n",
            "\n",
            "Epoch 177/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2089 - val_loss: 0.1941\n",
            "Loss: 0.20887084305286407\n",
            "Validation Loss: 0.19410452246665955\n",
            "\n",
            "Epoch 178/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2086 - val_loss: 0.1907\n",
            "Loss: 0.20856763422489166\n",
            "Validation Loss: 0.1906675100326538\n",
            "\n",
            "Epoch 179/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2061 - val_loss: 0.1915\n",
            "Loss: 0.2061222642660141\n",
            "Validation Loss: 0.19152575731277466\n",
            "\n",
            "Epoch 180/500\n",
            "21/21 [==============================] - 3s 159ms/step - loss: 0.2064 - val_loss: 0.1909\n",
            "Loss: 0.2064087837934494\n",
            "Validation Loss: 0.19085361063480377\n",
            "\n",
            "Epoch 181/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2067 - val_loss: 0.1876\n",
            "Loss: 0.2066594958305359\n",
            "Validation Loss: 0.18760333955287933\n",
            "\n",
            "Epoch 182/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.2066 - val_loss: 0.1872\n",
            "Loss: 0.20658376812934875\n",
            "Validation Loss: 0.187188059091568\n",
            "\n",
            "Epoch 183/500\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.2064 - val_loss: 0.1896\n",
            "Loss: 0.20640738308429718\n",
            "Validation Loss: 0.18962934613227844\n",
            "\n",
            "Epoch 184/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2068 - val_loss: 0.1894\n",
            "Loss: 0.20679044723510742\n",
            "Validation Loss: 0.18938234448432922\n",
            "\n",
            "Epoch 185/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2077 - val_loss: 0.1879\n",
            "Loss: 0.2077159881591797\n",
            "Validation Loss: 0.18786147236824036\n",
            "\n",
            "Epoch 186/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.2067 - val_loss: 0.1883\n",
            "Loss: 0.2067246288061142\n",
            "Validation Loss: 0.188344806432724\n",
            "\n",
            "Epoch 187/500\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.2055 - val_loss: 0.1897\n",
            "Loss: 0.20548880100250244\n",
            "Validation Loss: 0.18969528377056122\n",
            "\n",
            "Epoch 188/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2068 - val_loss: 0.1887\n",
            "Loss: 0.20676741003990173\n",
            "Validation Loss: 0.1886984258890152\n",
            "\n",
            "Epoch 189/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2052 - val_loss: 0.1858\n",
            "Loss: 0.20519188046455383\n",
            "Validation Loss: 0.18578439950942993\n",
            "\n",
            "Epoch 190/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2056 - val_loss: 0.1866\n",
            "Loss: 0.20555931329727173\n",
            "Validation Loss: 0.18664415180683136\n",
            "\n",
            "Epoch 191/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2060 - val_loss: 0.1895\n",
            "Loss: 0.20600228011608124\n",
            "Validation Loss: 0.1895207315683365\n",
            "\n",
            "Epoch 192/500\n",
            "21/21 [==============================] - 3s 168ms/step - loss: 0.2048 - val_loss: 0.1873\n",
            "Loss: 0.20479953289031982\n",
            "Validation Loss: 0.1872660517692566\n",
            "\n",
            "Epoch 193/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2048 - val_loss: 0.1859\n",
            "Loss: 0.2047576904296875\n",
            "Validation Loss: 0.1858931928873062\n",
            "\n",
            "Epoch 194/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2044 - val_loss: 0.1854\n",
            "Loss: 0.2043641209602356\n",
            "Validation Loss: 0.18537637591362\n",
            "\n",
            "Epoch 195/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.2054 - val_loss: 0.1856\n",
            "Loss: 0.20537826418876648\n",
            "Validation Loss: 0.18560507893562317\n",
            "\n",
            "Epoch 196/500\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2039 - val_loss: 0.1845\n",
            "Loss: 0.20387718081474304\n",
            "Validation Loss: 0.18451909720897675\n",
            "\n",
            "Epoch 197/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2042 - val_loss: 0.1866\n",
            "Loss: 0.2042061984539032\n",
            "Validation Loss: 0.18660330772399902\n",
            "\n",
            "Epoch 198/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2031 - val_loss: 0.1865\n",
            "Loss: 0.20311850309371948\n",
            "Validation Loss: 0.1865263134241104\n",
            "\n",
            "Epoch 199/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2050 - val_loss: 0.1882\n",
            "Loss: 0.2050161063671112\n",
            "Validation Loss: 0.18817192316055298\n",
            "\n",
            "Epoch 200/500\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.2046 - val_loss: 0.1888\n",
            "Loss: 0.20456074178218842\n",
            "Validation Loss: 0.1887558102607727\n",
            "\n",
            "Epoch 201/500\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.2033 - val_loss: 0.1843\n",
            "Loss: 0.20329549908638\n",
            "Validation Loss: 0.1843118518590927\n",
            "\n",
            "Epoch 202/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2033 - val_loss: 0.1866\n",
            "Loss: 0.20331968367099762\n",
            "Validation Loss: 0.18656891584396362\n",
            "\n",
            "Epoch 203/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.2039 - val_loss: 0.1874\n",
            "Loss: 0.2038833051919937\n",
            "Validation Loss: 0.18744295835494995\n",
            "\n",
            "Epoch 204/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2023 - val_loss: 0.1854\n",
            "Loss: 0.20227858424186707\n",
            "Validation Loss: 0.18544435501098633\n",
            "\n",
            "Epoch 205/500\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2023 - val_loss: 0.1852\n",
            "Loss: 0.2022906094789505\n",
            "Validation Loss: 0.18521670997142792\n",
            "\n",
            "Epoch 206/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.2033 - val_loss: 0.1854\n",
            "Loss: 0.20328888297080994\n",
            "Validation Loss: 0.1853714883327484\n",
            "\n",
            "Epoch 207/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.2029 - val_loss: 0.1845\n",
            "Loss: 0.20292074978351593\n",
            "Validation Loss: 0.18454104661941528\n",
            "\n",
            "Epoch 208/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2010 - val_loss: 0.1870\n",
            "Loss: 0.20104138553142548\n",
            "Validation Loss: 0.18699397146701813\n",
            "\n",
            "Epoch 209/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.2020 - val_loss: 0.1817\n",
            "Loss: 0.20204585790634155\n",
            "Validation Loss: 0.1817174255847931\n",
            "\n",
            "Epoch 210/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2037 - val_loss: 0.1841\n",
            "Loss: 0.2037004977464676\n",
            "Validation Loss: 0.18409450352191925\n",
            "\n",
            "Epoch 211/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.2004 - val_loss: 0.1864\n",
            "Loss: 0.20038776099681854\n",
            "Validation Loss: 0.18636761605739594\n",
            "\n",
            "Epoch 212/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.2006 - val_loss: 0.1832\n",
            "Loss: 0.20058518648147583\n",
            "Validation Loss: 0.1831628829240799\n",
            "\n",
            "Epoch 213/500\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2001 - val_loss: 0.1823\n",
            "Loss: 0.20005619525909424\n",
            "Validation Loss: 0.18227380514144897\n",
            "\n",
            "Epoch 214/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1995 - val_loss: 0.1838\n",
            "Loss: 0.1994996964931488\n",
            "Validation Loss: 0.18375292420387268\n",
            "\n",
            "Epoch 215/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.2000 - val_loss: 0.1835\n",
            "Loss: 0.19998835027217865\n",
            "Validation Loss: 0.18353527784347534\n",
            "\n",
            "Epoch 216/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.2004 - val_loss: 0.1837\n",
            "Loss: 0.20037251710891724\n",
            "Validation Loss: 0.18374334275722504\n",
            "\n",
            "Epoch 217/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.2002 - val_loss: 0.1816\n",
            "Loss: 0.20023299753665924\n",
            "Validation Loss: 0.18155132234096527\n",
            "\n",
            "Epoch 218/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1998 - val_loss: 0.1858\n",
            "Loss: 0.1998041272163391\n",
            "Validation Loss: 0.18579092621803284\n",
            "\n",
            "Epoch 219/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.2020 - val_loss: 0.1860\n",
            "Loss: 0.20198401808738708\n",
            "Validation Loss: 0.18595848977565765\n",
            "\n",
            "Epoch 220/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2009 - val_loss: 0.1834\n",
            "Loss: 0.20090501010417938\n",
            "Validation Loss: 0.1834363043308258\n",
            "\n",
            "Epoch 221/500\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.1994 - val_loss: 0.1865\n",
            "Loss: 0.19938354194164276\n",
            "Validation Loss: 0.18650385737419128\n",
            "\n",
            "Epoch 222/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1996 - val_loss: 0.1814\n",
            "Loss: 0.19961613416671753\n",
            "Validation Loss: 0.18137101829051971\n",
            "\n",
            "Epoch 223/500\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1998 - val_loss: 0.1831\n",
            "Loss: 0.19983075559139252\n",
            "Validation Loss: 0.18311220407485962\n",
            "\n",
            "Epoch 224/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.2016 - val_loss: 0.1812\n",
            "Loss: 0.20158712565898895\n",
            "Validation Loss: 0.18115903437137604\n",
            "\n",
            "Epoch 225/500\n",
            "21/21 [==============================] - 3s 167ms/step - loss: 0.2007 - val_loss: 0.1822\n",
            "Loss: 0.2006779909133911\n",
            "Validation Loss: 0.18219058215618134\n",
            "\n",
            "Epoch 226/500\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 0.2009 - val_loss: 0.1805\n",
            "Loss: 0.20091956853866577\n",
            "Validation Loss: 0.1804828941822052\n",
            "\n",
            "Epoch 227/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1998 - val_loss: 0.1822\n",
            "Loss: 0.19981005787849426\n",
            "Validation Loss: 0.18216921389102936\n",
            "\n",
            "Epoch 228/500\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.1991 - val_loss: 0.1820\n",
            "Loss: 0.19906318187713623\n",
            "Validation Loss: 0.18203599750995636\n",
            "\n",
            "Epoch 229/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1982 - val_loss: 0.1832\n",
            "Loss: 0.19820787012577057\n",
            "Validation Loss: 0.18319658935070038\n",
            "\n",
            "Epoch 230/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1984 - val_loss: 0.1785\n",
            "Loss: 0.19840861856937408\n",
            "Validation Loss: 0.17851030826568604\n",
            "\n",
            "Epoch 231/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1985 - val_loss: 0.1825\n",
            "Loss: 0.19846369326114655\n",
            "Validation Loss: 0.1825009286403656\n",
            "\n",
            "Epoch 232/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1993 - val_loss: 0.1801\n",
            "Loss: 0.1993468701839447\n",
            "Validation Loss: 0.1801140457391739\n",
            "\n",
            "Epoch 233/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1982 - val_loss: 0.1812\n",
            "Loss: 0.19821158051490784\n",
            "Validation Loss: 0.18116281926631927\n",
            "\n",
            "Epoch 234/500\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.2003 - val_loss: 0.1809\n",
            "Loss: 0.20032857358455658\n",
            "Validation Loss: 0.18087425827980042\n",
            "\n",
            "Epoch 235/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1962 - val_loss: 0.1824\n",
            "Loss: 0.19624635577201843\n",
            "Validation Loss: 0.18239016830921173\n",
            "\n",
            "Epoch 236/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1976 - val_loss: 0.1806\n",
            "Loss: 0.19755035638809204\n",
            "Validation Loss: 0.18060927093029022\n",
            "\n",
            "Epoch 237/500\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.1983 - val_loss: 0.1797\n",
            "Loss: 0.1983439177274704\n",
            "Validation Loss: 0.1796816736459732\n",
            "\n",
            "Epoch 238/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1986 - val_loss: 0.1807\n",
            "Loss: 0.19857166707515717\n",
            "Validation Loss: 0.18073852360248566\n",
            "\n",
            "Epoch 239/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1979 - val_loss: 0.1831\n",
            "Loss: 0.19793324172496796\n",
            "Validation Loss: 0.18307554721832275\n",
            "\n",
            "Epoch 240/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1983 - val_loss: 0.1803\n",
            "Loss: 0.19827714562416077\n",
            "Validation Loss: 0.18026070296764374\n",
            "\n",
            "Epoch 241/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1983 - val_loss: 0.1806\n",
            "Loss: 0.1982557326555252\n",
            "Validation Loss: 0.1806214451789856\n",
            "\n",
            "Epoch 242/500\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1973 - val_loss: 0.1807\n",
            "Loss: 0.19729909300804138\n",
            "Validation Loss: 0.18070285022258759\n",
            "\n",
            "Epoch 243/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1964 - val_loss: 0.1808\n",
            "Loss: 0.1963643878698349\n",
            "Validation Loss: 0.18075644969940186\n",
            "\n",
            "Epoch 244/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1962 - val_loss: 0.1781\n",
            "Loss: 0.19621272385120392\n",
            "Validation Loss: 0.1780889332294464\n",
            "\n",
            "Epoch 245/500\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.1976 - val_loss: 0.1793\n",
            "Loss: 0.19760246574878693\n",
            "Validation Loss: 0.17927676439285278\n",
            "\n",
            "Epoch 246/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.1950 - val_loss: 0.1791\n",
            "Loss: 0.19496802985668182\n",
            "Validation Loss: 0.1790521740913391\n",
            "\n",
            "Epoch 247/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1970 - val_loss: 0.1779\n",
            "Loss: 0.19702574610710144\n",
            "Validation Loss: 0.17794716358184814\n",
            "\n",
            "Epoch 248/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1961 - val_loss: 0.1824\n",
            "Loss: 0.19611532986164093\n",
            "Validation Loss: 0.1824108064174652\n",
            "\n",
            "Epoch 249/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1978 - val_loss: 0.1794\n",
            "Loss: 0.19775567948818207\n",
            "Validation Loss: 0.179365873336792\n",
            "\n",
            "Epoch 250/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1963 - val_loss: 0.1787\n",
            "Loss: 0.19632919132709503\n",
            "Validation Loss: 0.17866559326648712\n",
            "\n",
            "Epoch 251/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1946 - val_loss: 0.1766\n",
            "Loss: 0.1946110725402832\n",
            "Validation Loss: 0.17662225663661957\n",
            "\n",
            "Epoch 252/500\n",
            "21/21 [==============================] - 3s 134ms/step - loss: 0.1962 - val_loss: 0.1778\n",
            "Loss: 0.19623616337776184\n",
            "Validation Loss: 0.17784348130226135\n",
            "\n",
            "Epoch 253/500\n",
            "21/21 [==============================] - 3s 164ms/step - loss: 0.1965 - val_loss: 0.1799\n",
            "Loss: 0.19649441540241241\n",
            "Validation Loss: 0.17985624074935913\n",
            "\n",
            "Epoch 254/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.1946 - val_loss: 0.1816\n",
            "Loss: 0.19463728368282318\n",
            "Validation Loss: 0.18158148229122162\n",
            "\n",
            "Epoch 255/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1957 - val_loss: 0.1780\n",
            "Loss: 0.19572050869464874\n",
            "Validation Loss: 0.17803515493869781\n",
            "\n",
            "Epoch 256/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1950 - val_loss: 0.1778\n",
            "Loss: 0.19498543441295624\n",
            "Validation Loss: 0.1778269112110138\n",
            "\n",
            "Epoch 257/500\n",
            "21/21 [==============================] - 3s 166ms/step - loss: 0.1968 - val_loss: 0.1771\n",
            "Loss: 0.1967518925666809\n",
            "Validation Loss: 0.17707739770412445\n",
            "\n",
            "Epoch 258/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1961 - val_loss: 0.1756\n",
            "Loss: 0.19611620903015137\n",
            "Validation Loss: 0.17557936906814575\n",
            "\n",
            "Epoch 259/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1927 - val_loss: 0.1774\n",
            "Loss: 0.1926773339509964\n",
            "Validation Loss: 0.17740821838378906\n",
            "\n",
            "Epoch 260/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1957 - val_loss: 0.1786\n",
            "Loss: 0.19568879902362823\n",
            "Validation Loss: 0.1785716712474823\n",
            "\n",
            "Epoch 261/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1953 - val_loss: 0.1783\n",
            "Loss: 0.1952597051858902\n",
            "Validation Loss: 0.1782611906528473\n",
            "\n",
            "Epoch 262/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1952 - val_loss: 0.1796\n",
            "Loss: 0.19518037140369415\n",
            "Validation Loss: 0.17958828806877136\n",
            "\n",
            "Epoch 263/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1938 - val_loss: 0.1777\n",
            "Loss: 0.19377218186855316\n",
            "Validation Loss: 0.17771856486797333\n",
            "\n",
            "Epoch 264/500\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.1935 - val_loss: 0.1772\n",
            "Loss: 0.19348450005054474\n",
            "Validation Loss: 0.17722445726394653\n",
            "\n",
            "Epoch 265/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1948 - val_loss: 0.1757\n",
            "Loss: 0.19484280049800873\n",
            "Validation Loss: 0.17571118474006653\n",
            "\n",
            "Epoch 266/500\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1942 - val_loss: 0.1754\n",
            "Loss: 0.1941772848367691\n",
            "Validation Loss: 0.17538847029209137\n",
            "\n",
            "Epoch 267/500\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1953 - val_loss: 0.1752\n",
            "Loss: 0.19528871774673462\n",
            "Validation Loss: 0.17521952092647552\n",
            "\n",
            "Epoch 268/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.1938 - val_loss: 0.1766\n",
            "Loss: 0.1938486248254776\n",
            "Validation Loss: 0.17661665380001068\n",
            "\n",
            "Epoch 269/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1938 - val_loss: 0.1739\n",
            "Loss: 0.19382724165916443\n",
            "Validation Loss: 0.17390307784080505\n",
            "\n",
            "Epoch 270/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1950 - val_loss: 0.1780\n",
            "Loss: 0.1949988454580307\n",
            "Validation Loss: 0.1780470907688141\n",
            "\n",
            "Epoch 271/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.1939 - val_loss: 0.1752\n",
            "Loss: 0.19386811554431915\n",
            "Validation Loss: 0.1752145141363144\n",
            "\n",
            "Epoch 272/500\n",
            "21/21 [==============================] - 3s 122ms/step - loss: 0.1945 - val_loss: 0.1752\n",
            "Loss: 0.19446255266666412\n",
            "Validation Loss: 0.1751691997051239\n",
            "\n",
            "Epoch 273/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1929 - val_loss: 0.1738\n",
            "Loss: 0.19294831156730652\n",
            "Validation Loss: 0.17376741766929626\n",
            "\n",
            "Epoch 274/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.1924 - val_loss: 0.1749\n",
            "Loss: 0.19240063428878784\n",
            "Validation Loss: 0.1748926043510437\n",
            "\n",
            "Epoch 275/500\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1933 - val_loss: 0.1754\n",
            "Loss: 0.19332844018936157\n",
            "Validation Loss: 0.1753983050584793\n",
            "\n",
            "Epoch 276/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1941 - val_loss: 0.1740\n",
            "Loss: 0.1940828263759613\n",
            "Validation Loss: 0.1740374118089676\n",
            "\n",
            "Epoch 277/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1942 - val_loss: 0.1764\n",
            "Loss: 0.19418294727802277\n",
            "Validation Loss: 0.17637431621551514\n",
            "\n",
            "Epoch 278/500\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.1940 - val_loss: 0.1740\n",
            "Loss: 0.19397468864917755\n",
            "Validation Loss: 0.17397165298461914\n",
            "\n",
            "Epoch 279/500\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1940 - val_loss: 0.1745\n",
            "Loss: 0.1940380334854126\n",
            "Validation Loss: 0.17448122799396515\n",
            "\n",
            "Epoch 280/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.1920 - val_loss: 0.1755\n",
            "Loss: 0.19200511276721954\n",
            "Validation Loss: 0.1754530966281891\n",
            "\n",
            "Epoch 281/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1926 - val_loss: 0.1762\n",
            "Loss: 0.1926463097333908\n",
            "Validation Loss: 0.17618060111999512\n",
            "\n",
            "Epoch 282/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.1922 - val_loss: 0.1752\n",
            "Loss: 0.19222965836524963\n",
            "Validation Loss: 0.17520444095134735\n",
            "\n",
            "Epoch 283/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1914 - val_loss: 0.1737\n",
            "Loss: 0.1914401799440384\n",
            "Validation Loss: 0.17372265458106995\n",
            "\n",
            "Epoch 284/500\n",
            "21/21 [==============================] - 3s 131ms/step - loss: 0.1919 - val_loss: 0.1761\n",
            "Loss: 0.19185534119606018\n",
            "Validation Loss: 0.17610511183738708\n",
            "\n",
            "Epoch 285/500\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.1916 - val_loss: 0.1763\n",
            "Loss: 0.19159673154354095\n",
            "Validation Loss: 0.1762559860944748\n",
            "\n",
            "Epoch 286/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1929 - val_loss: 0.1743\n",
            "Loss: 0.192867249250412\n",
            "Validation Loss: 0.17431607842445374\n",
            "\n",
            "Epoch 287/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1925 - val_loss: 0.1745\n",
            "Loss: 0.19245639443397522\n",
            "Validation Loss: 0.174464151263237\n",
            "\n",
            "Epoch 288/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1921 - val_loss: 0.1749\n",
            "Loss: 0.19212546944618225\n",
            "Validation Loss: 0.17485441267490387\n",
            "\n",
            "Epoch 289/500\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.1925 - val_loss: 0.1782\n",
            "Loss: 0.19246868789196014\n",
            "Validation Loss: 0.1782083511352539\n",
            "\n",
            "Epoch 290/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1910 - val_loss: 0.1747\n",
            "Loss: 0.19103582203388214\n",
            "Validation Loss: 0.1746796816587448\n",
            "\n",
            "Epoch 291/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1915 - val_loss: 0.1737\n",
            "Loss: 0.191525399684906\n",
            "Validation Loss: 0.17370487749576569\n",
            "\n",
            "Epoch 292/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1914 - val_loss: 0.1746\n",
            "Loss: 0.19139739871025085\n",
            "Validation Loss: 0.17456816136837006\n",
            "\n",
            "Epoch 293/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.1921 - val_loss: 0.1736\n",
            "Loss: 0.1920536309480667\n",
            "Validation Loss: 0.17358767986297607\n",
            "\n",
            "Epoch 294/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1915 - val_loss: 0.1719\n",
            "Loss: 0.19152948260307312\n",
            "Validation Loss: 0.17187152802944183\n",
            "\n",
            "Epoch 295/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.1914 - val_loss: 0.1749\n",
            "Loss: 0.1914447844028473\n",
            "Validation Loss: 0.1749143749475479\n",
            "\n",
            "Epoch 296/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1938 - val_loss: 0.1733\n",
            "Loss: 0.19376207888126373\n",
            "Validation Loss: 0.17333249747753143\n",
            "\n",
            "Epoch 297/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1918 - val_loss: 0.1738\n",
            "Loss: 0.19180673360824585\n",
            "Validation Loss: 0.17380505800247192\n",
            "\n",
            "Epoch 298/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.1916 - val_loss: 0.1734\n",
            "Loss: 0.1915801763534546\n",
            "Validation Loss: 0.17339320480823517\n",
            "\n",
            "Epoch 299/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1904 - val_loss: 0.1741\n",
            "Loss: 0.19037188589572906\n",
            "Validation Loss: 0.17411066591739655\n",
            "\n",
            "Epoch 300/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1909 - val_loss: 0.1747\n",
            "Loss: 0.19088271260261536\n",
            "Validation Loss: 0.1747075915336609\n",
            "\n",
            "Epoch 301/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1939 - val_loss: 0.1733\n",
            "Loss: 0.19392502307891846\n",
            "Validation Loss: 0.17334088683128357\n",
            "\n",
            "Epoch 302/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1900 - val_loss: 0.1753\n",
            "Loss: 0.190002903342247\n",
            "Validation Loss: 0.1753171980381012\n",
            "\n",
            "Epoch 303/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1918 - val_loss: 0.1739\n",
            "Loss: 0.19183731079101562\n",
            "Validation Loss: 0.17390675842761993\n",
            "\n",
            "Epoch 304/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1905 - val_loss: 0.1752\n",
            "Loss: 0.19052089750766754\n",
            "Validation Loss: 0.1752469688653946\n",
            "\n",
            "Epoch 305/500\n",
            "21/21 [==============================] - 3s 135ms/step - loss: 0.1909 - val_loss: 0.1725\n",
            "Loss: 0.19092053174972534\n",
            "Validation Loss: 0.17251579463481903\n",
            "\n",
            "Epoch 306/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1903 - val_loss: 0.1711\n",
            "Loss: 0.19028812646865845\n",
            "Validation Loss: 0.17110157012939453\n",
            "\n",
            "Epoch 307/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1908 - val_loss: 0.1730\n",
            "Loss: 0.1908472776412964\n",
            "Validation Loss: 0.17295809090137482\n",
            "\n",
            "Epoch 308/500\n",
            "21/21 [==============================] - 3s 136ms/step - loss: 0.1902 - val_loss: 0.1717\n",
            "Loss: 0.19015547633171082\n",
            "Validation Loss: 0.17174386978149414\n",
            "\n",
            "Epoch 309/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1924 - val_loss: 0.1714\n",
            "Loss: 0.19239386916160583\n",
            "Validation Loss: 0.17144805192947388\n",
            "\n",
            "Epoch 310/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1886 - val_loss: 0.1736\n",
            "Loss: 0.1885724812746048\n",
            "Validation Loss: 0.17357684671878815\n",
            "\n",
            "Epoch 311/500\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1893 - val_loss: 0.1719\n",
            "Loss: 0.18934164941310883\n",
            "Validation Loss: 0.1719408929347992\n",
            "\n",
            "Epoch 312/500\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.1885 - val_loss: 0.1739\n",
            "Loss: 0.18852952122688293\n",
            "Validation Loss: 0.17390531301498413\n",
            "\n",
            "Epoch 313/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1901 - val_loss: 0.1744\n",
            "Loss: 0.19008851051330566\n",
            "Validation Loss: 0.1744334101676941\n",
            "\n",
            "Epoch 314/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1898 - val_loss: 0.1721\n",
            "Loss: 0.18979257345199585\n",
            "Validation Loss: 0.1721118986606598\n",
            "\n",
            "Epoch 315/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.1902 - val_loss: 0.1722\n",
            "Loss: 0.19024093449115753\n",
            "Validation Loss: 0.17217344045639038\n",
            "\n",
            "Epoch 316/500\n",
            "21/21 [==============================] - 3s 161ms/step - loss: 0.1907 - val_loss: 0.1723\n",
            "Loss: 0.1906949132680893\n",
            "Validation Loss: 0.1723126471042633\n",
            "\n",
            "Epoch 317/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1900 - val_loss: 0.1732\n",
            "Loss: 0.19004356861114502\n",
            "Validation Loss: 0.17317615449428558\n",
            "\n",
            "Epoch 318/500\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 0.1899 - val_loss: 0.1709\n",
            "Loss: 0.18992164731025696\n",
            "Validation Loss: 0.17085421085357666\n",
            "\n",
            "Epoch 319/500\n",
            "21/21 [==============================] - 2s 119ms/step - loss: 0.1888 - val_loss: 0.1718\n",
            "Loss: 0.18881681561470032\n",
            "Validation Loss: 0.17181096971035004\n",
            "\n",
            "Epoch 320/500\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1893 - val_loss: 0.1709\n",
            "Loss: 0.18925932049751282\n",
            "Validation Loss: 0.1708822101354599\n",
            "\n",
            "Epoch 321/500\n",
            "21/21 [==============================] - 3s 133ms/step - loss: 0.1895 - val_loss: 0.1707\n",
            "Loss: 0.18948805332183838\n",
            "Validation Loss: 0.1706833690404892\n",
            "\n",
            "Epoch 322/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1887 - val_loss: 0.1726\n",
            "Loss: 0.18873967230319977\n",
            "Validation Loss: 0.17259258031845093\n",
            "\n",
            "Epoch 323/500\n",
            "21/21 [==============================] - 3s 120ms/step - loss: 0.1900 - val_loss: 0.1714\n",
            "Loss: 0.19000867009162903\n",
            "Validation Loss: 0.17144951224327087\n",
            "\n",
            "Epoch 324/500\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.1886 - val_loss: 0.1715\n",
            "Loss: 0.18856211006641388\n",
            "Validation Loss: 0.17149490118026733\n",
            "\n",
            "Epoch 325/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1906 - val_loss: 0.1716\n",
            "Loss: 0.19064120948314667\n",
            "Validation Loss: 0.17157061398029327\n",
            "\n",
            "Epoch 326/500\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1879 - val_loss: 0.1717\n",
            "Loss: 0.1879412680864334\n",
            "Validation Loss: 0.17169645428657532\n",
            "\n",
            "Epoch 327/500\n",
            "21/21 [==============================] - 2s 120ms/step - loss: 0.1890 - val_loss: 0.1726\n",
            "Loss: 0.18901614844799042\n",
            "Validation Loss: 0.1726190149784088\n",
            "\n",
            "Epoch 328/500\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1887 - val_loss: 0.1707\n",
            "Loss: 0.18870463967323303\n",
            "Validation Loss: 0.17070110142230988\n",
            "\n",
            "Epoch 329/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1878 - val_loss: 0.1714\n",
            "Loss: 0.1878024786710739\n",
            "Validation Loss: 0.17139582335948944\n",
            "\n",
            "Epoch 330/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1895 - val_loss: 0.1726\n",
            "Loss: 0.18945516645908356\n",
            "Validation Loss: 0.17257319390773773\n",
            "\n",
            "Epoch 331/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1873 - val_loss: 0.1697\n",
            "Loss: 0.1872515082359314\n",
            "Validation Loss: 0.16972704231739044\n",
            "\n",
            "Epoch 332/500\n",
            "21/21 [==============================] - 3s 128ms/step - loss: 0.1867 - val_loss: 0.1705\n",
            "Loss: 0.18665289878845215\n",
            "Validation Loss: 0.17049314081668854\n",
            "\n",
            "Epoch 333/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1882 - val_loss: 0.1719\n",
            "Loss: 0.18815359473228455\n",
            "Validation Loss: 0.17188723385334015\n",
            "\n",
            "Epoch 334/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1893 - val_loss: 0.1699\n",
            "Loss: 0.18927530944347382\n",
            "Validation Loss: 0.16990719735622406\n",
            "\n",
            "Epoch 335/500\n",
            "21/21 [==============================] - 3s 137ms/step - loss: 0.1879 - val_loss: 0.1713\n",
            "Loss: 0.18792709708213806\n",
            "Validation Loss: 0.1712859869003296\n",
            "\n",
            "Epoch 336/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1861 - val_loss: 0.1728\n",
            "Loss: 0.18610602617263794\n",
            "Validation Loss: 0.17280738055706024\n",
            "\n",
            "Epoch 337/500\n",
            "21/21 [==============================] - 3s 130ms/step - loss: 0.1864 - val_loss: 0.1694\n",
            "Loss: 0.18636223673820496\n",
            "Validation Loss: 0.16941067576408386\n",
            "\n",
            "Epoch 338/500\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.1884 - val_loss: 0.1698\n",
            "Loss: 0.18835021555423737\n",
            "Validation Loss: 0.16978929936885834\n",
            "\n",
            "Epoch 339/500\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.1873 - val_loss: 0.1688\n",
            "Loss: 0.18734683096408844\n",
            "Validation Loss: 0.16884008049964905\n",
            "\n",
            "Epoch 340/500\n",
            "21/21 [==============================] - 3s 132ms/step - loss: 0.1869 - val_loss: 0.1693\n",
            "Loss: 0.1868947297334671\n",
            "Validation Loss: 0.1692802906036377\n",
            "\n",
            "Epoch 341/500\n",
            "21/21 [==============================] - 3s 127ms/step - loss: 0.1876 - val_loss: 0.1690\n",
            "Loss: 0.18757781386375427\n",
            "Validation Loss: 0.1690051108598709\n",
            "\n",
            "Epoch 342/500\n",
            "21/21 [==============================] - 3s 126ms/step - loss: 0.1869 - val_loss: 0.1687\n",
            "Loss: 0.1869196593761444\n",
            "Validation Loss: 0.16872204840183258\n",
            "\n",
            "Epoch 343/500\n",
            "21/21 [==============================] - 3s 162ms/step - loss: 0.1871 - val_loss: 0.1690\n",
            "Loss: 0.1871466040611267\n",
            "Validation Loss: 0.168985515832901\n",
            "\n",
            "Epoch 344/500\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1877 - val_loss: 0.1689\n",
            "Loss: 0.18774116039276123\n",
            "Validation Loss: 0.16885343194007874\n",
            "\n",
            "Epoch 345/500\n",
            "21/21 [==============================] - 3s 125ms/step - loss: 0.1879 - val_loss: 0.1695\n",
            "Loss: 0.18785443902015686\n",
            "Validation Loss: 0.16954559087753296\n",
            "\n",
            "Epoch 346/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1871 - val_loss: 0.1700\n",
            "Loss: 0.18713334202766418\n",
            "Validation Loss: 0.17004181444644928\n",
            "\n",
            "Epoch 347/500\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.1881 - val_loss: 0.1691\n",
            "Loss: 0.18805131316184998\n",
            "Validation Loss: 0.16912326216697693\n",
            "\n",
            "Epoch 348/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1872 - val_loss: 0.1689\n",
            "Loss: 0.1871960461139679\n",
            "Validation Loss: 0.16893522441387177\n",
            "\n",
            "Epoch 349/500\n",
            "21/21 [==============================] - 3s 121ms/step - loss: 0.1867 - val_loss: 0.1692\n",
            "Loss: 0.18674726784229279\n",
            "Validation Loss: 0.16915133595466614\n",
            "\n",
            "Epoch 350/500\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1861 - val_loss: 0.1689\n",
            "Loss: 0.18614906072616577\n",
            "Validation Loss: 0.16888250410556793\n",
            "\n",
            "Epoch 351/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1860 - val_loss: 0.1690\n",
            "Loss: 0.18598952889442444\n",
            "Validation Loss: 0.16897128522396088\n",
            "\n",
            "Epoch 352/500\n",
            "21/21 [==============================] - 3s 123ms/step - loss: 0.1874 - val_loss: 0.1696\n",
            "Loss: 0.1873694658279419\n",
            "Validation Loss: 0.1695840209722519\n",
            "\n",
            "Epoch 353/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1876 - val_loss: 0.1699\n",
            "Loss: 0.18761803209781647\n",
            "Validation Loss: 0.16994281113147736\n",
            "\n",
            "Epoch 354/500\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.1876 - val_loss: 0.1707\n",
            "Loss: 0.1876237392425537\n",
            "Validation Loss: 0.1706741601228714\n",
            "\n",
            "Epoch 355/500\n",
            "21/21 [==============================] - 3s 124ms/step - loss: 0.1877 - val_loss: 0.1713\n",
            "Loss: 0.18772241473197937\n",
            "Validation Loss: 0.17129205167293549\n",
            "\n",
            "Epoch 356/500\n",
            "21/21 [==============================] - 3s 129ms/step - loss: 0.1863 - val_loss: 0.1695\n",
            "Loss: 0.18628603219985962\n",
            "Validation Loss: 0.16947725415229797\n",
            "\n",
            "Epoch 357/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1861"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def attention_layer(inputs):\n",
        "    hidden_states, context_vector = inputs\n",
        "    \n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    \n",
        "    # Reshape context vector to perform element-wise multiplication\n",
        "    context_vector = Dense(hidden_size)(context_vector)\n",
        "    context_vector = tf.repeat(context_vector, tf.shape(hidden_states)[1], axis=1)\n",
        "    \n",
        "    # Attention mechanism\n",
        "    attention_weights = tf.keras.layers.Attention()([hidden_states, context_vector])\n",
        "    attention_weights = tf.keras.layers.Activation('softmax')(attention_weights)\n",
        "    \n",
        "    # Weighted sum of hidden states\n",
        "    weighted_sum = tf.reduce_sum(attention_weights * hidden_states, axis=1)\n",
        "    \n",
        "    return weighted_sum\n",
        "\n",
        "def build_model(input_shape, hidden_units, output_dim, dropout_rate=0.15, recurrent_dropout_rate=0.15):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    lstm_output = LSTM(hidden_units, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)(inputs)\n",
        "    attention_output = AttentionLayer(hidden_units)([lstm_output, lstm_output])\n",
        "    output = Dense(output_dim)(attention_output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "def train_model(X_train, X_test, y_train, y_test, output_dim, n_epochs):\n",
        "    input_shape = X_train.shape[1:]\n",
        "    hidden_units = 128\n",
        "\n",
        "    model = build_model(input_shape, hidden_units, output_dim)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Early stopping\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        history = model.fit(X_train, y_train, epochs=1, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
        "        print(\"Loss:\", history.history['loss'][0])\n",
        "        print(\"Validation Loss:\", history.history['val_loss'][0])\n",
        "        print()\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Create our cross-validation data structure\n",
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(processed_data['x'], processed_data['y'], train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "# Define the features to train for\n",
        "features = [2, 0, 1, 12, 13]  # Specify the indices of the features to train for\n",
        "\n",
        "# Train multiple models\n",
        "models = []\n",
        "histories = []\n",
        "n_epochs = 500\n",
        "\n",
        "for feature_idx in features:\n",
        "    y_train_feature = np.array([[[features[feature_idx]] for features in y] for y in y_train], dtype=np.float64)\n",
        "    y_valid_feature = np.array([[[features[feature_idx]] for features in y] for y in y_valid], dtype=np.float64)\n",
        "    \n",
        "    model, history = train_model(X_train, X_valid, y_train_feature, y_valid_feature, output_dim=1, n_epochs=n_epochs)\n",
        "    \n",
        "    models.append(model)\n",
        "    histories.append(history)\n",
        "\n",
        "# Access the history of each model\n",
        "for i, history in enumerate(histories):\n",
        "    print(f\"History for Model {i+1}\")\n",
        "    print(\"Loss:\", history.history['loss'])\n",
        "    print(\"Validation Loss:\", history.history['val_loss'])\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}